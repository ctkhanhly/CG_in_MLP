Model name                            : MLP_Large
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : NonlinearCG
Learning rate                         : 0.1
Beta type                             :FR_PR
Total number of function evaluations  : 3047
Total number of iterations            : 1807
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 45.81580591201782
Total number of parameters            : 402001
Percentage of parameters < 1e-9       : 49.94937823537752%
Percentage of parameters < 1e-7       : 49.949626990977634%
Percentage of parameters < 1e-6       : 49.95062201337808%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.0026139572256673876
Loss at iteration [2]: 0.00260781550359877
Loss at iteration [3]: 0.0026061718006908843
Loss at iteration [4]: 0.0025747071149102574
Loss at iteration [5]: 0.0025735080820135955
Loss at iteration [6]: 0.0025671519673123215
Loss at iteration [7]: 0.0025661798212381413
Loss at iteration [8]: 0.0025652480062444234
Loss at iteration [9]: 0.002562770103427628
Loss at iteration [10]: 0.0025542421775189453
Loss at iteration [11]: 0.0025439166253053455
Loss at iteration [12]: 0.0025394795924326397
Loss at iteration [13]: 0.0025376147645419602
Loss at iteration [14]: 0.002536252812908969
Loss at iteration [15]: 0.0025349931770067813
Loss at iteration [16]: 0.0025275582975961912
Loss at iteration [17]: 0.0025275582975961912
Loss at iteration [18]: 0.00252576031457271
Loss at iteration [19]: 0.002525459870588664
Loss at iteration [20]: 0.002523261796273138
Loss at iteration [21]: 0.0025215320767467833
Loss at iteration [22]: 0.0025210926626337117
Loss at iteration [23]: 0.002519063222282204
Loss at iteration [24]: 0.002517196766287595
Loss at iteration [25]: 0.0025165326576047768
Loss at iteration [26]: 0.0025133314593137127
Loss at iteration [27]: 0.0025115187054247654
Loss at iteration [28]: 0.002503982793581256
Loss at iteration [29]: 0.0024994753708703302
Loss at iteration [30]: 0.002498785629852051
Loss at iteration [31]: 0.0024982619865764727
Loss at iteration [32]: 0.0024965313597468623
Loss at iteration [33]: 0.0024965313597468623
Loss at iteration [34]: 0.0024949793244295943
Loss at iteration [35]: 0.002494703827684991
Loss at iteration [36]: 0.0024928673080301792
Loss at iteration [37]: 0.0024918140594182786
Loss at iteration [38]: 0.002488053282838078
Loss at iteration [39]: 0.002487805519216954
Loss at iteration [40]: 0.0024876589449626054
Loss at iteration [41]: 0.0024872212872354546
Loss at iteration [42]: 0.002486843568404606
Loss at iteration [43]: 0.0024866837491206123
Loss at iteration [44]: 0.0024861353467897375
Loss at iteration [45]: 0.002484255241746924
Loss at iteration [46]: 0.002484255241746924
Loss at iteration [47]: 0.0024841000050609885
Loss at iteration [48]: 0.0024833295057588114
Loss at iteration [49]: 0.002482849920327906
Loss at iteration [50]: 0.0024826058868258234
Loss at iteration [51]: 0.002482055060145681
Loss at iteration [52]: 0.0024818662309317127
Loss at iteration [53]: 0.002481746966599183
Loss at iteration [54]: 0.0024814324543990197
Loss at iteration [55]: 0.0024812529809140472
Loss at iteration [56]: 0.002480820210122806
Loss at iteration [57]: 0.002478371682343275
Loss at iteration [58]: 0.0024774645183273576
Loss at iteration [59]: 0.002477130834698208
Loss at iteration [60]: 0.0024747818871687587
Loss at iteration [61]: 0.0024738177932040937
Loss at iteration [62]: 0.0024731926192637713
Loss at iteration [63]: 0.0024703727440405013
Loss at iteration [64]: 0.0024703727440405013
Loss at iteration [65]: 0.002468896710685568
Loss at iteration [66]: 0.0024687025939220397
Loss at iteration [67]: 0.0024677967824052165
Loss at iteration [68]: 0.002467702709957939
Loss at iteration [69]: 0.002467112180332732
Loss at iteration [70]: 0.002466532793897588
Loss at iteration [71]: 0.002466298359142407
Loss at iteration [72]: 0.0024661386721188945
Loss at iteration [73]: 0.0024653918827013664
Loss at iteration [74]: 0.0024653650872223406
Loss at iteration [75]: 0.0024651403753316974
Loss at iteration [76]: 0.0024649072947324877
Loss at iteration [77]: 0.00246393829365701
Loss at iteration [78]: 0.00246393829365701
Loss at iteration [79]: 0.0024637611134491226
Loss at iteration [80]: 0.002463594443387285
Loss at iteration [81]: 0.002463333696470851
Loss at iteration [82]: 0.0024632148550180863
Loss at iteration [83]: 0.0024630963393332986
Loss at iteration [84]: 0.0024628644163560537
Loss at iteration [85]: 0.0024627672807115866
Loss at iteration [86]: 0.00246246037330185
Loss at iteration [87]: 0.0024617721154446466
Loss at iteration [88]: 0.0024611851370678977
Loss at iteration [89]: 0.002458111957519322
Loss at iteration [90]: 0.0024532050431215454
Loss at iteration [91]: 0.0024524975666696124
Loss at iteration [92]: 0.002448756002454446
Loss at iteration [93]: 0.0024458609888756127
Loss at iteration [94]: 0.0024458609888756127
Loss at iteration [95]: 0.002445314452739823
Loss at iteration [96]: 0.0024444388774405423
Loss at iteration [97]: 0.002443723324349088
Loss at iteration [98]: 0.002443591784911277
Loss at iteration [99]: 0.0024432678181038753
Loss at iteration [100]: 0.0024421046302244265
Loss at iteration [101]: 0.0024414767744893114
Loss at iteration [102]: 0.002440990249756456
Loss at iteration [103]: 0.0024402320569499366
Loss at iteration [104]: 0.0024400155704274165
Loss at iteration [105]: 0.0024397396210934837
Loss at iteration [106]: 0.0024373346555339194
Loss at iteration [107]: 0.0024362358872841825
Loss at iteration [108]: 0.0024357323850238343
Loss at iteration [109]: 0.002434514349995133
Loss at iteration [110]: 0.002434514349995133
Loss at iteration [111]: 0.002434068532293049
Loss at iteration [112]: 0.002433951074464799
Loss at iteration [113]: 0.002432693601527538
Loss at iteration [114]: 0.0024325866350266463
Loss at iteration [115]: 0.0024320718866242073
Loss at iteration [116]: 0.002431908438343315
Loss at iteration [117]: 0.0024316421765559083
Loss at iteration [118]: 0.002430034298465537
Loss at iteration [119]: 0.0024298144934414073
Loss at iteration [120]: 0.002429727225824508
Loss at iteration [121]: 0.00242912027257092
Loss at iteration [122]: 0.00242912027257092
Loss at iteration [123]: 0.002428937948478956
Loss at iteration [124]: 0.0024288936305966275
Loss at iteration [125]: 0.002428371251081351
Loss at iteration [126]: 0.0024282896094768793
Loss at iteration [127]: 0.002427906360369718
Loss at iteration [128]: 0.002427619048471109
Loss at iteration [129]: 0.002427466229562751
Loss at iteration [130]: 0.0024271252331909514
Loss at iteration [131]: 0.0024266013040743608
Loss at iteration [132]: 0.0024264508359919377
Loss at iteration [133]: 0.002426168921289003
Loss at iteration [134]: 0.0024258926748304014
Loss at iteration [135]: 0.0024252528983180854
Loss at iteration [136]: 0.0024252528983180854
Loss at iteration [137]: 0.0024248597086015972
Loss at iteration [138]: 0.002424787340196037
Loss at iteration [139]: 0.002424501335547295
Loss at iteration [140]: 0.0024243529269053037
Loss at iteration [141]: 0.0024242584694466086
Loss at iteration [142]: 0.002424054410810503
Loss at iteration [143]: 0.002423896245678458
Loss at iteration [144]: 0.002423824945547528
Loss at iteration [145]: 0.0024235567582655414
Loss at iteration [146]: 0.002423086744107806
Loss at iteration [147]: 0.0024228952707521585
Loss at iteration [148]: 0.002421755354044277
Loss at iteration [149]: 0.002421255412708261
Loss at iteration [150]: 0.002421255412708261
Loss at iteration [151]: 0.0024212047633741353
Loss at iteration [152]: 0.0024209673435314143
Loss at iteration [153]: 0.0024207759952807727
Loss at iteration [154]: 0.0024207028479963453
Loss at iteration [155]: 0.0024200267233352537
Loss at iteration [156]: 0.002419939973395612
Loss at iteration [157]: 0.0024197048551193347
Loss at iteration [158]: 0.0024190815701290425
Loss at iteration [159]: 0.0024190543301567265
Loss at iteration [160]: 0.002418622253266097
Loss at iteration [161]: 0.0024184672659479356
Loss at iteration [162]: 0.0024179512745020194
Loss at iteration [163]: 0.0024179512745020194
Loss at iteration [164]: 0.002417726446664336
Loss at iteration [165]: 0.0024176859968079167
Loss at iteration [166]: 0.0024173249629338475
Loss at iteration [167]: 0.002417203017330431
Loss at iteration [168]: 0.0024165570102948146
Loss at iteration [169]: 0.002416344578692106
Loss at iteration [170]: 0.002416240133396809
Loss at iteration [171]: 0.002415946589835868
Loss at iteration [172]: 0.0024156721195132355
Loss at iteration [173]: 0.002415294882896721
Loss at iteration [174]: 0.00241490478283216
Loss at iteration [175]: 0.0024146136685978593
Loss at iteration [176]: 0.002412457725450367
Loss at iteration [177]: 0.002412457725450367
Loss at iteration [178]: 0.002412328800839194
Loss at iteration [179]: 0.0024117611714163036
Loss at iteration [180]: 0.002411518718548339
Loss at iteration [181]: 0.0024114520159297143
Loss at iteration [182]: 0.0024112486390577116
Loss at iteration [183]: 0.002410928163173714
Loss at iteration [184]: 0.0024108929021878925
Loss at iteration [185]: 0.0024107439616478793
Loss at iteration [186]: 0.002409998052564452
Loss at iteration [187]: 0.0024099219704162727
Loss at iteration [188]: 0.0024096617620316964
Loss at iteration [189]: 0.0024092371121037124
Loss at iteration [190]: 0.0024091720985046604
Loss at iteration [191]: 0.0024091720985046604
Loss at iteration [192]: 0.0024091302365936347
Loss at iteration [193]: 0.00240901366997315
Loss at iteration [194]: 0.0024088901653339777
Loss at iteration [195]: 0.0024087993032837047
Loss at iteration [196]: 0.0024086583958547224
Loss at iteration [197]: 0.0024085792482971616
Loss at iteration [198]: 0.0024084096144984875
Loss at iteration [199]: 0.002408356988931784
Loss at iteration [200]: 0.0024080700063756613
Loss at iteration [201]: 0.002407371639846278
Loss at iteration [202]: 0.002407027443546699
Loss at iteration [203]: 0.002406457461985604
Loss at iteration [204]: 0.002406271482472497
Loss at iteration [205]: 0.002406049804778299
Loss at iteration [206]: 0.0024060171481173984
Loss at iteration [207]: 0.0024059807508790038
Loss at iteration [208]: 0.0024059374105542632
Loss at iteration [209]: 0.0024059374105542632
Loss at iteration [210]: 0.0024059179286338526
Loss at iteration [211]: 0.002405861806518214
Loss at iteration [212]: 0.0024057259703081065
Loss at iteration [213]: 0.002405557203113016
Loss at iteration [214]: 0.0024053710552107113
Loss at iteration [215]: 0.002405189195007581
Loss at iteration [216]: 0.0024049727813027265
Loss at iteration [217]: 0.0024044237581072564
Loss at iteration [218]: 0.002403980289485375
Loss at iteration [219]: 0.002403835843755789
Loss at iteration [220]: 0.002403400835723559
Loss at iteration [221]: 0.0024023973473349626
Loss at iteration [222]: 0.0024019723115895155
Loss at iteration [223]: 0.002401672545429628
Loss at iteration [224]: 0.002401371729500711
Loss at iteration [225]: 0.002401371729500711
Loss at iteration [226]: 0.0024011585292240275
Loss at iteration [227]: 0.0024010969137286007
Loss at iteration [228]: 0.002400982664760074
Loss at iteration [229]: 0.0024008752176356888
Loss at iteration [230]: 0.002400656820065679
Loss at iteration [231]: 0.002400562256808972
Loss at iteration [232]: 0.002400377046091639
Loss at iteration [233]: 0.002400191374123684
Loss at iteration [234]: 0.0024001172906022543
Loss at iteration [235]: 0.002399734780894229
Loss at iteration [236]: 0.0023989417513530175
Loss at iteration [237]: 0.002398739090724484
Loss at iteration [238]: 0.0023985046164353035
Loss at iteration [239]: 0.0023985046164353035
Loss at iteration [240]: 0.0023983343159156988
Loss at iteration [241]: 0.0023981933254130948
Loss at iteration [242]: 0.0023981086714501935
Loss at iteration [243]: 0.002397414777263796
Loss at iteration [244]: 0.002397310045811052
Loss at iteration [245]: 0.0023972581546270436
Loss at iteration [246]: 0.002396973426092434
Loss at iteration [247]: 0.0023968560409003284
Loss at iteration [248]: 0.002396574538201818
Loss at iteration [249]: 0.0023963725849461296
Loss at iteration [250]: 0.0023962080069329476
Loss at iteration [251]: 0.002396002721878081
Loss at iteration [252]: 0.002395911417128481
Loss at iteration [253]: 0.002395911417128481
Loss at iteration [254]: 0.0023958551821870386
Loss at iteration [255]: 0.0023957787257629357
Loss at iteration [256]: 0.0023956733367411125
Loss at iteration [257]: 0.0023956058009455927
Loss at iteration [258]: 0.0023955462000262253
Loss at iteration [259]: 0.002395299926643456
Loss at iteration [260]: 0.0023949763693490557
Loss at iteration [261]: 0.0023949287221736626
Loss at iteration [262]: 0.0023946140093174927
Loss at iteration [263]: 0.002394484011212912
Loss at iteration [264]: 0.002394034777856228
Loss at iteration [265]: 0.002393865169918648
Loss at iteration [266]: 0.0023931613583151813
Loss at iteration [267]: 0.002392923701971828
Loss at iteration [268]: 0.002392631951786674
Loss at iteration [269]: 0.00239230405607361
Loss at iteration [270]: 0.0023922183062423746
Loss at iteration [271]: 0.0023922183062423746
Loss at iteration [272]: 0.0023921822995732742
Loss at iteration [273]: 0.002391977443440551
Loss at iteration [274]: 0.002391947014660678
Loss at iteration [275]: 0.002391841877726333
Loss at iteration [276]: 0.0023912153337731445
Loss at iteration [277]: 0.002391116443474451
Loss at iteration [278]: 0.0023904072010629746
Loss at iteration [279]: 0.002390192996771409
Loss at iteration [280]: 0.0023900819140645715
Loss at iteration [281]: 0.0023898115215945166
Loss at iteration [282]: 0.0023894817178275007
Loss at iteration [283]: 0.0023893403945340758
Loss at iteration [284]: 0.0023892092592521707
Loss at iteration [285]: 0.00238903502667635
Loss at iteration [286]: 0.002388826556734982
Loss at iteration [287]: 0.0023885544700814735
Loss at iteration [288]: 0.0023885544700814735
Loss at iteration [289]: 0.0023884320404317415
Loss at iteration [290]: 0.0023882735876327643
Loss at iteration [291]: 0.002388173762906648
Loss at iteration [292]: 0.0023881452310031866
Loss at iteration [293]: 0.002387833807529512
Loss at iteration [294]: 0.002387746556609279
Loss at iteration [295]: 0.002387672461772753
Loss at iteration [296]: 0.00238747128828512
Loss at iteration [297]: 0.0023873167496246245
Loss at iteration [298]: 0.002387249737505856
Loss at iteration [299]: 0.0023868933779097354
Loss at iteration [300]: 0.002386071003306864
Loss at iteration [301]: 0.002385866784882008
Loss at iteration [302]: 0.002385142970921938
Loss at iteration [303]: 0.0023848881103488376
Loss at iteration [304]: 0.002384661144802485
Loss at iteration [305]: 0.002384661144802485
Loss at iteration [306]: 0.00238452727635794
Loss at iteration [307]: 0.0023843597385793604
Loss at iteration [308]: 0.002383955854622412
Loss at iteration [309]: 0.0023838717389645927
Loss at iteration [310]: 0.0023837851963736043
Loss at iteration [311]: 0.0023835915832533623
Loss at iteration [312]: 0.0023835600189966756
Loss at iteration [313]: 0.0023834696424795414
Loss at iteration [314]: 0.0023833903035042955
Loss at iteration [315]: 0.002383315783674018
Loss at iteration [316]: 0.0023830974437554745
Loss at iteration [317]: 0.0023830531418767287
Loss at iteration [318]: 0.002382975271119958
Loss at iteration [319]: 0.002382927347858496
Loss at iteration [320]: 0.002382713946438462
Loss at iteration [321]: 0.002382713946438462
Loss at iteration [322]: 0.0023826073998092063
Loss at iteration [323]: 0.002382553529575507
Loss at iteration [324]: 0.0023823929602280057
Loss at iteration [325]: 0.002382369152206201
Loss at iteration [326]: 0.0023822783240850793
Loss at iteration [327]: 0.0023822215476571582
Loss at iteration [328]: 0.0023821335193761686
Loss at iteration [329]: 0.0023818889326135072
Loss at iteration [330]: 0.002381804220367294
Loss at iteration [331]: 0.00238163438023258
Loss at iteration [332]: 0.0023815243657249515
Loss at iteration [333]: 0.0023814324028464864
Loss at iteration [334]: 0.0023810114822612792
Loss at iteration [335]: 0.0023806562016445458
Loss at iteration [336]: 0.0023802831805805977
Loss at iteration [337]: 0.002379946010077051
Loss at iteration [338]: 0.002379946010077051
Loss at iteration [339]: 0.0023798367881525447
Loss at iteration [340]: 0.0023798049462434236
Loss at iteration [341]: 0.002379739848251246
Loss at iteration [342]: 0.0023796825640739583
Loss at iteration [343]: 0.0023796319445180524
Loss at iteration [344]: 0.002379362023934885
Loss at iteration [345]: 0.0023792215063393797
Loss at iteration [346]: 0.0023787695542882383
Loss at iteration [347]: 0.002378608911526017
Loss at iteration [348]: 0.002378337162542615
Loss at iteration [349]: 0.0023781313959934662
Loss at iteration [350]: 0.0023779289465315776
Loss at iteration [351]: 0.002377411480855647
Loss at iteration [352]: 0.0023769995334678934
Loss at iteration [353]: 0.0023766034051809753
Loss at iteration [354]: 0.0023766034051809753
Loss at iteration [355]: 0.002376385402333317
Loss at iteration [356]: 0.002376170226196609
Loss at iteration [357]: 0.002376041182483754
Loss at iteration [358]: 0.002376012006197882
Loss at iteration [359]: 0.002375988044496655
Loss at iteration [360]: 0.0023759620379512135
Loss at iteration [361]: 0.002375807646824607
Loss at iteration [362]: 0.0023756730471720315
Loss at iteration [363]: 0.0023756275071305554
Loss at iteration [364]: 0.0023755198878930082
Loss at iteration [365]: 0.0023752642083545916
Loss at iteration [366]: 0.0023751361755629027
Loss at iteration [367]: 0.002374867627253584
Loss at iteration [368]: 0.0023745889816427254
Loss at iteration [369]: 0.0023743044995752837
Loss at iteration [370]: 0.0023741512797465555
Loss at iteration [371]: 0.0023734302168785994
Loss at iteration [372]: 0.0023734302168785994
Loss at iteration [373]: 0.002373266667201578
Loss at iteration [374]: 0.0023731826023823057
Loss at iteration [375]: 0.002372900973847149
Loss at iteration [376]: 0.0023728457192101434
Loss at iteration [377]: 0.0023728134304484188
Loss at iteration [378]: 0.0023727229100283563
Loss at iteration [379]: 0.002372637766727251
Loss at iteration [380]: 0.0023725580938819637
Loss at iteration [381]: 0.00237245739063839
Loss at iteration [382]: 0.002372002171676897
Loss at iteration [383]: 0.0023718048399208073
Loss at iteration [384]: 0.002371746655676323
Loss at iteration [385]: 0.002371596247644484
Loss at iteration [386]: 0.0023715590811836736
Loss at iteration [387]: 0.002371502970626117
Loss at iteration [388]: 0.002371502970626117
Loss at iteration [389]: 0.002371462954480444
Loss at iteration [390]: 0.0023714145938626657
Loss at iteration [391]: 0.0023712871358012224
Loss at iteration [392]: 0.0023712289752421214
Loss at iteration [393]: 0.0023710287209389477
Loss at iteration [394]: 0.0023708294388667113
Loss at iteration [395]: 0.0023706432101147537
Loss at iteration [396]: 0.00237038877914661
Loss at iteration [397]: 0.0023701382188676895
Loss at iteration [398]: 0.002369456077820219
Loss at iteration [399]: 0.002369225279260876
Loss at iteration [400]: 0.0023669072577380593
Loss at iteration [401]: 0.0023655301150471973
Loss at iteration [402]: 0.0023655301150471973
Loss at iteration [403]: 0.002365230860198566
Loss at iteration [404]: 0.002364774449343549
Loss at iteration [405]: 0.00236468022558061
Loss at iteration [406]: 0.0023644049974367366
Loss at iteration [407]: 0.002364200313942392
Loss at iteration [408]: 0.0023640711828888665
Loss at iteration [409]: 0.0023638575661898108
Loss at iteration [410]: 0.002363818898202511
Loss at iteration [411]: 0.002363755277062458
Loss at iteration [412]: 0.0023635951025083443
Loss at iteration [413]: 0.0023632163521712314
Loss at iteration [414]: 0.002362995237098039
Loss at iteration [415]: 0.002362995237098039
Loss at iteration [416]: 0.002362844862812199
Loss at iteration [417]: 0.0023626952348939057
Loss at iteration [418]: 0.002362521511365693
Loss at iteration [419]: 0.002362437717090372
Loss at iteration [420]: 0.0023623754860374697
Loss at iteration [421]: 0.0023621085096586208
Loss at iteration [422]: 0.002362044530337662
Loss at iteration [423]: 0.0023619841845501067
Loss at iteration [424]: 0.0023618046868093268
Loss at iteration [425]: 0.00236172821893597
Loss at iteration [426]: 0.0023616397349900797
Loss at iteration [427]: 0.002361275698218606
Loss at iteration [428]: 0.002361201335623995
Loss at iteration [429]: 0.0023610713677842143
Loss at iteration [430]: 0.002360891110582071
Loss at iteration [431]: 0.002360808552870548
Loss at iteration [432]: 0.002360808552870548
Loss at iteration [433]: 0.002360718887634188
Loss at iteration [434]: 0.002360633426184716
Loss at iteration [435]: 0.0023605316947598602
Loss at iteration [436]: 0.0023605096733644846
Loss at iteration [437]: 0.002360457187874815
Loss at iteration [438]: 0.002360348354962802
Loss at iteration [439]: 0.0023602882709698606
Loss at iteration [440]: 0.0023601951677685467
Loss at iteration [441]: 0.0023601108625036335
Loss at iteration [442]: 0.002359998857633103
Loss at iteration [443]: 0.0023596190582536895
Loss at iteration [444]: 0.002358386365643194
Loss at iteration [445]: 0.002358016428689523
Loss at iteration [446]: 0.0023575594421797325
Loss at iteration [447]: 0.002357121709465714
Loss at iteration [448]: 0.002357121709465714
Loss at iteration [449]: 0.0023569185153712808
Loss at iteration [450]: 0.002356297223717031
Loss at iteration [451]: 0.002356199879976662
Loss at iteration [452]: 0.002355795544377193
Loss at iteration [453]: 0.00235572924489633
Loss at iteration [454]: 0.002355658431060245
Loss at iteration [455]: 0.0023554420629344954
Loss at iteration [456]: 0.0023553612652393013
Loss at iteration [457]: 0.002355086872184529
Loss at iteration [458]: 0.0023549644574366096
Loss at iteration [459]: 0.0023548960401240542
Loss at iteration [460]: 0.0023545955619943388
Loss at iteration [461]: 0.002354245704566893
Loss at iteration [462]: 0.0023541498559147694
Loss at iteration [463]: 0.0023541498559147694
Loss at iteration [464]: 0.0023541236668073637
Loss at iteration [465]: 0.0023540218425519015
Loss at iteration [466]: 0.002353752348185969
Loss at iteration [467]: 0.0023537225569948295
Loss at iteration [468]: 0.0023535908627604347
Loss at iteration [469]: 0.0023535169331621486
Loss at iteration [470]: 0.002353429540838219
Loss at iteration [471]: 0.0023533787249364804
Loss at iteration [472]: 0.0023531105834802618
Loss at iteration [473]: 0.0023530615754180383
Loss at iteration [474]: 0.0023529895425392746
Loss at iteration [475]: 0.002352863812737582
Loss at iteration [476]: 0.002352863812737582
Loss at iteration [477]: 0.0023527588328116403
Loss at iteration [478]: 0.002352725292772388
Loss at iteration [479]: 0.002352640620985182
Loss at iteration [480]: 0.0023525036249625554
Loss at iteration [481]: 0.0023523841910736087
Loss at iteration [482]: 0.0023522591399625058
Loss at iteration [483]: 0.0023522266737816535
Loss at iteration [484]: 0.002352072071111586
Loss at iteration [485]: 0.002351948995282111
Loss at iteration [486]: 0.002351775557394894
Loss at iteration [487]: 0.0023512495592216054
Loss at iteration [488]: 0.0023507579376746096
Loss at iteration [489]: 0.002350495304350715
Loss at iteration [490]: 0.0023496855444740286
Loss at iteration [491]: 0.0023490684286005007
Loss at iteration [492]: 0.0023483103201371734
Loss at iteration [493]: 0.0023483103201371734
Loss at iteration [494]: 0.0023478352617528103
Loss at iteration [495]: 0.002347055159482368
Loss at iteration [496]: 0.002346593875667711
Loss at iteration [497]: 0.0023463342073378607
Loss at iteration [498]: 0.0023460532193133486
Loss at iteration [499]: 0.002345922463752259
Loss at iteration [500]: 0.0023458650976453995
Loss at iteration [501]: 0.002345772483723943
Loss at iteration [502]: 0.002345710586483065
Loss at iteration [503]: 0.002345671631760794
Loss at iteration [504]: 0.0023455208299297133
Loss at iteration [505]: 0.002345483134898926
Loss at iteration [506]: 0.002345380638533267
Loss at iteration [507]: 0.002345296219589782
Loss at iteration [508]: 0.002345242791767854
Loss at iteration [509]: 0.002345242791767854
Loss at iteration [510]: 0.002345153970161063
Loss at iteration [511]: 0.0023451249293653634
Loss at iteration [512]: 0.00234506880778656
Loss at iteration [513]: 0.0023450061932939995
Loss at iteration [514]: 0.00234448454391321
Loss at iteration [515]: 0.0023442836318721366
Loss at iteration [516]: 0.0023442051642502933
Loss at iteration [517]: 0.0023436976827603526
Loss at iteration [518]: 0.0023434117460603815
Loss at iteration [519]: 0.002343087950318893
Loss at iteration [520]: 0.002342849606450744
Loss at iteration [521]: 0.0023424254299205063
Loss at iteration [522]: 0.0023422862226935197
Loss at iteration [523]: 0.0023420894412807336
Loss at iteration [524]: 0.0023420894412807336
Loss at iteration [525]: 0.0023420226537997114
Loss at iteration [526]: 0.0023419761181614246
Loss at iteration [527]: 0.0023417105269295715
Loss at iteration [528]: 0.0023416069743467023
Loss at iteration [529]: 0.0023414221453470496
Loss at iteration [530]: 0.002341219242002317
Loss at iteration [531]: 0.0023410901976596327
Loss at iteration [532]: 0.002340900382276901
Loss at iteration [533]: 0.002340773599237234
Loss at iteration [534]: 0.00234044478321421
Loss at iteration [535]: 0.002340228647006791
Loss at iteration [536]: 0.002340034975501301
Loss at iteration [537]: 0.0023398914470045165
Loss at iteration [538]: 0.002339709513210229
Loss at iteration [539]: 0.002339709513210229
Loss at iteration [540]: 0.0023396461337674935
Loss at iteration [541]: 0.002339532239402133
Loss at iteration [542]: 0.002339431989175349
Loss at iteration [543]: 0.0023393571668866315
Loss at iteration [544]: 0.002339085273548507
Loss at iteration [545]: 0.0023390543429298626
Loss at iteration [546]: 0.002339027270830934
Loss at iteration [547]: 0.002338919438280097
Loss at iteration [548]: 0.002338830022573773
Loss at iteration [549]: 0.0023387771754584223
Loss at iteration [550]: 0.0023385456626112047
Loss at iteration [551]: 0.002338455142250233
Loss at iteration [552]: 0.002338296464578075
Loss at iteration [553]: 0.0023380835405903094
Loss at iteration [554]: 0.0023379498805781045
Loss at iteration [555]: 0.0023379498805781045
Loss at iteration [556]: 0.0023378839424176784
Loss at iteration [557]: 0.002337796665299226
Loss at iteration [558]: 0.0023376954049786707
Loss at iteration [559]: 0.002337653832898567
Loss at iteration [560]: 0.0023375987222377065
Loss at iteration [561]: 0.0023375625294482305
Loss at iteration [562]: 0.0023374932557725663
Loss at iteration [563]: 0.0023373737139142734
Loss at iteration [564]: 0.002337218922891164
Loss at iteration [565]: 0.0023371343608452394
Loss at iteration [566]: 0.0023369062646865463
Loss at iteration [567]: 0.002336810072129614
Loss at iteration [568]: 0.0023360592931433244
Loss at iteration [569]: 0.002335588186167795
Loss at iteration [570]: 0.0023352648870899914
Loss at iteration [571]: 0.0023352648870899914
Loss at iteration [572]: 0.002335107690605479
Loss at iteration [573]: 0.00233491240063163
Loss at iteration [574]: 0.00233428542058575
Loss at iteration [575]: 0.002334215989830333
Loss at iteration [576]: 0.002334088433955585
Loss at iteration [577]: 0.0023340475176246425
Loss at iteration [578]: 0.002333885933653411
Loss at iteration [579]: 0.0023337638150087215
Loss at iteration [580]: 0.0023336714292072763
Loss at iteration [581]: 0.0023336363418017913
Loss at iteration [582]: 0.002333403933639905
Loss at iteration [583]: 0.0023332403145865667
Loss at iteration [584]: 0.0023331075563731026
Loss at iteration [585]: 0.0023330553512801292
Loss at iteration [586]: 0.0023330553512801292
Loss at iteration [587]: 0.002332962100948209
Loss at iteration [588]: 0.002332846758743635
Loss at iteration [589]: 0.0023327039799554603
Loss at iteration [590]: 0.002332652261802099
Loss at iteration [591]: 0.0023325638416174447
Loss at iteration [592]: 0.0023324721759722116
Loss at iteration [593]: 0.0023322890460008546
Loss at iteration [594]: 0.0023322367569879993
Loss at iteration [595]: 0.002332036662725252
Loss at iteration [596]: 0.0023319379951428553
Loss at iteration [597]: 0.0023318874016010705
Loss at iteration [598]: 0.0023316404014256204
Loss at iteration [599]: 0.002331430553912127
Loss at iteration [600]: 0.002330956186575948
Loss at iteration [601]: 0.0023306609110553323
Loss at iteration [602]: 0.0023306609110553323
Loss at iteration [603]: 0.0023305382233044913
Loss at iteration [604]: 0.0023304260777328206
Loss at iteration [605]: 0.0023303312138537712
Loss at iteration [606]: 0.002330228528787228
Loss at iteration [607]: 0.002330054669857568
Loss at iteration [608]: 0.002329979516756399
Loss at iteration [609]: 0.0023299267256109927
Loss at iteration [610]: 0.0023298747238044365
Loss at iteration [611]: 0.002329671014754706
Loss at iteration [612]: 0.002329463896751145
Loss at iteration [613]: 0.0023293295826710796
Loss at iteration [614]: 0.002329036099326747
Loss at iteration [615]: 0.0023288813203557724
Loss at iteration [616]: 0.002327881482005981
Loss at iteration [617]: 0.0023274623584371955
Loss at iteration [618]: 0.0023271507079754426
Loss at iteration [619]: 0.0023259512105861992
Loss at iteration [620]: 0.0023259512105861992
Loss at iteration [621]: 0.0023256032937005993
Loss at iteration [622]: 0.002325336173037711
Loss at iteration [623]: 0.0023247775724692357
Loss at iteration [624]: 0.002324702976129441
Loss at iteration [625]: 0.002324649612316969
Loss at iteration [626]: 0.0023243611889547074
Loss at iteration [627]: 0.0023242791979918263
Loss at iteration [628]: 0.002324206141809963
Loss at iteration [629]: 0.002324016336139828
Loss at iteration [630]: 0.0023239208341605676
Loss at iteration [631]: 0.0023236458065119705
Loss at iteration [632]: 0.002323566929562888
Loss at iteration [633]: 0.0023234927546402634
Loss at iteration [634]: 0.0023228458603682914
Loss at iteration [635]: 0.0023228458603682914
Loss at iteration [636]: 0.002322775754334767
Loss at iteration [637]: 0.0023226145513601084
Loss at iteration [638]: 0.002322488051781332
Loss at iteration [639]: 0.002322412167416092
Loss at iteration [640]: 0.0023223148764423026
Loss at iteration [641]: 0.0023222245068553363
Loss at iteration [642]: 0.002322179703812053
Loss at iteration [643]: 0.0023219708727695854
Loss at iteration [644]: 0.002321890163713126
Loss at iteration [645]: 0.0023217702573142497
Loss at iteration [646]: 0.002321510602853932
Loss at iteration [647]: 0.002321416369823872
Loss at iteration [648]: 0.002321416369823872
Loss at iteration [649]: 0.0023213567606513454
Loss at iteration [650]: 0.002321164114350912
Loss at iteration [651]: 0.002321089211998238
Loss at iteration [652]: 0.0023210604987862773
Loss at iteration [653]: 0.0023209808298217645
Loss at iteration [654]: 0.002320912368500612
Loss at iteration [655]: 0.0023208642548728712
Loss at iteration [656]: 0.0023207026021246683
Loss at iteration [657]: 0.002320660691405557
Loss at iteration [658]: 0.0023204582192977775
Loss at iteration [659]: 0.0023203158874016477
Loss at iteration [660]: 0.0023202040674115743
Loss at iteration [661]: 0.0023202040674115743
Loss at iteration [662]: 0.0023201321865883883
Loss at iteration [663]: 0.002320050717533214
Loss at iteration [664]: 0.002320024962518895
Loss at iteration [665]: 0.0023199599948812285
Loss at iteration [666]: 0.0023199042031215172
Loss at iteration [667]: 0.0023198569210694285
Loss at iteration [668]: 0.002319778764532082
Loss at iteration [669]: 0.002319544373681684
Loss at iteration [670]: 0.002319385837187081
Loss at iteration [671]: 0.002319119772558712
Loss at iteration [672]: 0.002318936774951588
Loss at iteration [673]: 0.0023186121311009724
Loss at iteration [674]: 0.0023171953883506366
Loss at iteration [675]: 0.0023168112466561974
Loss at iteration [676]: 0.0023168112466561974
Loss at iteration [677]: 0.002316618432911445
Loss at iteration [678]: 0.0023163540100873464
Loss at iteration [679]: 0.0023153099377447163
Loss at iteration [680]: 0.00231517077346774
Loss at iteration [681]: 0.002315032661059569
Loss at iteration [682]: 0.0023149866468292267
Loss at iteration [683]: 0.002314928651503759
Loss at iteration [684]: 0.00231484952788431
Loss at iteration [685]: 0.002314808319662268
Loss at iteration [686]: 0.002314745943760692
Loss at iteration [687]: 0.0023146687394204157
Loss at iteration [688]: 0.0023144906019151616
Loss at iteration [689]: 0.0023143722753847925
Loss at iteration [690]: 0.002314279750847715
Loss at iteration [691]: 0.0023140307433379796
Loss at iteration [692]: 0.0023140307433379796
Loss at iteration [693]: 0.0023139472984712124
Loss at iteration [694]: 0.002313813364790026
Loss at iteration [695]: 0.0023137716355846674
Loss at iteration [696]: 0.002313747774417559
Loss at iteration [697]: 0.0023136243011270003
Loss at iteration [698]: 0.002313580169331711
Loss at iteration [699]: 0.002313486435826696
Loss at iteration [700]: 0.002313421958326132
Loss at iteration [701]: 0.0023133639448109002
Loss at iteration [702]: 0.0023131900843162017
Loss at iteration [703]: 0.0023131534859564817
Loss at iteration [704]: 0.0023128683101518227
Loss at iteration [705]: 0.0023127514836152833
Loss at iteration [706]: 0.0023126700719954714
Loss at iteration [707]: 0.0023126700719954714
Loss at iteration [708]: 0.0023125919628433395
Loss at iteration [709]: 0.0023124947474382684
Loss at iteration [710]: 0.0023123605128946055
Loss at iteration [711]: 0.0023123133938095165
Loss at iteration [712]: 0.0023121783360929124
Loss at iteration [713]: 0.0023121041731438254
Loss at iteration [714]: 0.0023119947918111825
Loss at iteration [715]: 0.0023119151849045378
Loss at iteration [716]: 0.002311808554884791
Loss at iteration [717]: 0.002311716364943789
Loss at iteration [718]: 0.0023115730515495857
Loss at iteration [719]: 0.002311364195079324
Loss at iteration [720]: 0.0023111157963793634
Loss at iteration [721]: 0.0023110079983069617
Loss at iteration [722]: 0.0023107692690076675
Loss at iteration [723]: 0.002310583094620989
Loss at iteration [724]: 0.002310502517297173
Loss at iteration [725]: 0.0023102809207207887
Loss at iteration [726]: 0.0023102809207207887
Loss at iteration [727]: 0.002310239946876165
Loss at iteration [728]: 0.0023101913423268527
Loss at iteration [729]: 0.0023101001531232223
Loss at iteration [730]: 0.0023100413944200622
Loss at iteration [731]: 0.002309965915171977
Loss at iteration [732]: 0.0023099203136169645
Loss at iteration [733]: 0.002309807510953946
Loss at iteration [734]: 0.0023097125725504764
Loss at iteration [735]: 0.0023096666877290015
Loss at iteration [736]: 0.0023095949451029715
Loss at iteration [737]: 0.002309387370463703
Loss at iteration [738]: 0.002309340991381709
Loss at iteration [739]: 0.0023092785522576343
Loss at iteration [740]: 0.0023091993714178852
Loss at iteration [741]: 0.002309077434309351
Loss at iteration [742]: 0.0023089766589481026
Loss at iteration [743]: 0.0023089062080551837
Loss at iteration [744]: 0.002308776511335339
Loss at iteration [745]: 0.002308776511335339
Loss at iteration [746]: 0.0023087216073633815
Loss at iteration [747]: 0.0023086532468298312
Loss at iteration [748]: 0.002308619155054099
Loss at iteration [749]: 0.0023084862870860648
Loss at iteration [750]: 0.0023084575295328437
Loss at iteration [751]: 0.0023083857300591603
Loss at iteration [752]: 0.002308300595008101
Loss at iteration [753]: 0.0023082532324417023
Loss at iteration [754]: 0.00230793997801556
Loss at iteration [755]: 0.002307704664548114
Loss at iteration [756]: 0.0023075470401265397
Loss at iteration [757]: 0.0023072988677805637
Loss at iteration [758]: 0.0023070655259609736
Loss at iteration [759]: 0.0023065898284340587
Loss at iteration [760]: 0.00230325156891345
Loss at iteration [761]: 0.00230325156891345
Loss at iteration [762]: 0.0023019834561184924
Loss at iteration [763]: 0.0023016929793011546
Loss at iteration [764]: 0.002300419803932902
Loss at iteration [765]: 0.0022994765273177857
Loss at iteration [766]: 0.0022991272895309237
Loss at iteration [767]: 0.0022988885589667425
Loss at iteration [768]: 0.00229800513507233
Loss at iteration [769]: 0.0022978488903331777
Loss at iteration [770]: 0.0022977458701731617
Loss at iteration [771]: 0.0022974542702579514
Loss at iteration [772]: 0.0022974247122662926
Loss at iteration [773]: 0.002297336088029523
Loss at iteration [774]: 0.0022972130622311094
Loss at iteration [775]: 0.002297132104877705
Loss at iteration [776]: 0.0022966571285257358
Loss at iteration [777]: 0.0022966571285257358
Loss at iteration [778]: 0.0022965133513537595
Loss at iteration [779]: 0.0022964083010737313
Loss at iteration [780]: 0.0022962296869939777
Loss at iteration [781]: 0.00229612791829552
Loss at iteration [782]: 0.002296055403515326
Loss at iteration [783]: 0.0022959708945262916
Loss at iteration [784]: 0.002295817802567403
Loss at iteration [785]: 0.0022956589235586834
Loss at iteration [786]: 0.002295597522311488
Loss at iteration [787]: 0.0022955450771541173
Loss at iteration [788]: 0.002295372171417362
Loss at iteration [789]: 0.0022953209008949953
Loss at iteration [790]: 0.0022952192240789536
Loss at iteration [791]: 0.0022951674298958436
Loss at iteration [792]: 0.0022951674298958436
Loss at iteration [793]: 0.0022951431219793575
Loss at iteration [794]: 0.0022950527834881373
Loss at iteration [795]: 0.0022950379486583795
Loss at iteration [796]: 0.002295013245192341
Loss at iteration [797]: 0.002294950102137511
Loss at iteration [798]: 0.0022949115103082568
Loss at iteration [799]: 0.0022948297965220874
Loss at iteration [800]: 0.002294795169010506
Loss at iteration [801]: 0.002294613094057944
Loss at iteration [802]: 0.0022944448051441593
Loss at iteration [803]: 0.0022943278661103797
Loss at iteration [804]: 0.002293979702573302
Loss at iteration [805]: 0.002293979702573302
Loss at iteration [806]: 0.00229384388301573
Loss at iteration [807]: 0.002293791569542352
Loss at iteration [808]: 0.0022935493012103876
Loss at iteration [809]: 0.0022934437945334443
Loss at iteration [810]: 0.002293315641310352
Loss at iteration [811]: 0.0022932695925355915
Loss at iteration [812]: 0.0022932036308428603
Loss at iteration [813]: 0.002293179979660093
Loss at iteration [814]: 0.002293131029844686
Loss at iteration [815]: 0.002293086708299889
Loss at iteration [816]: 0.00229306297651094
Loss at iteration [817]: 0.002292918683866743
Loss at iteration [818]: 0.002292918683866743
Loss at iteration [819]: 0.0022928644802381395
Loss at iteration [820]: 0.002292846113766593
Loss at iteration [821]: 0.002292805946805984
Loss at iteration [822]: 0.0022927800702755054
Loss at iteration [823]: 0.002292698188959705
Loss at iteration [824]: 0.0022926275891197007
Loss at iteration [825]: 0.002292585927493037
Loss at iteration [826]: 0.002292402246030344
Loss at iteration [827]: 0.0022922985966278395
Loss at iteration [828]: 0.0022921922827534775
Loss at iteration [829]: 0.0022920468143094383
Loss at iteration [830]: 0.002291968537237513
Loss at iteration [831]: 0.002291775104102852
Loss at iteration [832]: 0.002291775104102852
Loss at iteration [833]: 0.0022916582953469446
Loss at iteration [834]: 0.002291576638288256
Loss at iteration [835]: 0.0022915026967373236
Loss at iteration [836]: 0.0022914500052728347
Loss at iteration [837]: 0.002291390295647164
Loss at iteration [838]: 0.0022913061039715743
Loss at iteration [839]: 0.0022912003651459974
Loss at iteration [840]: 0.002291135215400779
Loss at iteration [841]: 0.002291069281748303
Loss at iteration [842]: 0.0022909109525448444
Loss at iteration [843]: 0.0022906896638799986
Loss at iteration [844]: 0.0022903697372049247
Loss at iteration [845]: 0.00229021346298213
Loss at iteration [846]: 0.00229005079542459
Loss at iteration [847]: 0.0022893408754288045
Loss at iteration [848]: 0.0022884066988132913
Loss at iteration [849]: 0.0022880690590939058
Loss at iteration [850]: 0.0022880690590939058
Loss at iteration [851]: 0.0022879361975981487
Loss at iteration [852]: 0.0022869886111303865
Loss at iteration [853]: 0.002286864696889671
Loss at iteration [854]: 0.002286769514285934
Loss at iteration [855]: 0.002286589328978852
Loss at iteration [856]: 0.002286348700661537
Loss at iteration [857]: 0.0022861745835671852
Loss at iteration [858]: 0.0022861244099031974
Loss at iteration [859]: 0.002286036626983242
Loss at iteration [860]: 0.0022859102202838384
Loss at iteration [861]: 0.002285843697913939
Loss at iteration [862]: 0.0022857990043627743
Loss at iteration [863]: 0.002285698982928183
Loss at iteration [864]: 0.0022856126615009667
Loss at iteration [865]: 0.0022855214661567386
Loss at iteration [866]: 0.002285394630028503
Loss at iteration [867]: 0.002285394630028503
Loss at iteration [868]: 0.00228536500405261
Loss at iteration [869]: 0.002285264457949263
Loss at iteration [870]: 0.0022851701107816347
Loss at iteration [871]: 0.0022851382187757045
Loss at iteration [872]: 0.0022850711264363983
Loss at iteration [873]: 0.002284996528822602
Loss at iteration [874]: 0.002284929397351278
Loss at iteration [875]: 0.002284859748021228
Loss at iteration [876]: 0.0022846820944538307
Loss at iteration [877]: 0.00228444108316972
Loss at iteration [878]: 0.002284320416950486
Loss at iteration [879]: 0.0022840291952568466
Loss at iteration [880]: 0.002283821439201801
Loss at iteration [881]: 0.0022837150434993733
Loss at iteration [882]: 0.0022834110514151555
Loss at iteration [883]: 0.0022832101621987713
Loss at iteration [884]: 0.0022832101621987713
Loss at iteration [885]: 0.002283154936107575
Loss at iteration [886]: 0.00228308706196335
Loss at iteration [887]: 0.0022830059490222894
Loss at iteration [888]: 0.0022829738419529386
Loss at iteration [889]: 0.002282935238514678
Loss at iteration [890]: 0.0022829202715426225
Loss at iteration [891]: 0.0022828946500533403
Loss at iteration [892]: 0.002282864463130631
Loss at iteration [893]: 0.002282848090124663
Loss at iteration [894]: 0.002282670345474709
Loss at iteration [895]: 0.002282617994273893
Loss at iteration [896]: 0.0022824078572153596
Loss at iteration [897]: 0.0022823455881869977
Loss at iteration [898]: 0.002282285052631631
Loss at iteration [899]: 0.0022821354055271767
Loss at iteration [900]: 0.0022820982397870147
Loss at iteration [901]: 0.0022820982397870147
Loss at iteration [902]: 0.0022820740610175172
Loss at iteration [903]: 0.0022820077979445502
Loss at iteration [904]: 0.002281978554144818
Loss at iteration [905]: 0.0022819189154311783
Loss at iteration [906]: 0.0022818811829679745
Loss at iteration [907]: 0.0022818513158684834
Loss at iteration [908]: 0.002281781587504583
Loss at iteration [909]: 0.00228171931799612
Loss at iteration [910]: 0.0022816484939835215
Loss at iteration [911]: 0.002281523455253535
Loss at iteration [912]: 0.0022814116612979254
Loss at iteration [913]: 0.0022811504109846747
Loss at iteration [914]: 0.0022808017165054273
Loss at iteration [915]: 0.0022804335137285568
Loss at iteration [916]: 0.002278468022880034
Loss at iteration [917]: 0.0022770966124679823
Loss at iteration [918]: 0.0022770966124679823
Loss at iteration [919]: 0.0022769166274028275
Loss at iteration [920]: 0.0022765341375604914
Loss at iteration [921]: 0.002276115464512394
Loss at iteration [922]: 0.0022759607610835448
Loss at iteration [923]: 0.002275252169544395
Loss at iteration [924]: 0.0022747226275963315
Loss at iteration [925]: 0.0022746253770416507
Loss at iteration [926]: 0.0022745479835257895
Loss at iteration [927]: 0.0022744264025456678
Loss at iteration [928]: 0.00227421789779353
Loss at iteration [929]: 0.0022739892414318035
Loss at iteration [930]: 0.0022738313026784366
Loss at iteration [931]: 0.002273533831281063
Loss at iteration [932]: 0.0022734541298165905
Loss at iteration [933]: 0.0022734541298165905
Loss at iteration [934]: 0.002273401355743636
Loss at iteration [935]: 0.002273175543206719
Loss at iteration [936]: 0.0022731350396936146
Loss at iteration [937]: 0.002273092295930822
Loss at iteration [938]: 0.0022728531685498785
Loss at iteration [939]: 0.0022727701853587565
Loss at iteration [940]: 0.0022726407299492957
Loss at iteration [941]: 0.0022725986171344605
Loss at iteration [942]: 0.0022725533312794276
Loss at iteration [943]: 0.002272441336960023
Loss at iteration [944]: 0.0022723163615576657
Loss at iteration [945]: 0.0022722504577478895
Loss at iteration [946]: 0.002272145421906546
Loss at iteration [947]: 0.0022720707911876195
Loss at iteration [948]: 0.0022719908339025553
Loss at iteration [949]: 0.002271790425660198
Loss at iteration [950]: 0.002271790425660198
Loss at iteration [951]: 0.002271748053553469
Loss at iteration [952]: 0.002271684300842209
Loss at iteration [953]: 0.00227159848994713
Loss at iteration [954]: 0.002271525650699658
Loss at iteration [955]: 0.0022714357910036532
Loss at iteration [956]: 0.0022713365638064036
Loss at iteration [957]: 0.00227130165801604
Loss at iteration [958]: 0.0022712181414867197
Loss at iteration [959]: 0.002271140618449181
Loss at iteration [960]: 0.0022710931881112914
Loss at iteration [961]: 0.00227082573375528
Loss at iteration [962]: 0.0022707026662763617
Loss at iteration [963]: 0.0022705948245688216
Loss at iteration [964]: 0.0022704337080016405
Loss at iteration [965]: 0.002270100572337001
Loss at iteration [966]: 0.002270100572337001
Loss at iteration [967]: 0.002269938946693222
Loss at iteration [968]: 0.002269745664028344
Loss at iteration [969]: 0.0022697028037195715
Loss at iteration [970]: 0.0022696517258827616
Loss at iteration [971]: 0.002269517476305493
Loss at iteration [972]: 0.002269474798171263
Loss at iteration [973]: 0.0022693540024316125
Loss at iteration [974]: 0.0022692180771412026
Loss at iteration [975]: 0.0022690678936226048
Loss at iteration [976]: 0.002268875448932496
Loss at iteration [977]: 0.0022688435882594997
Loss at iteration [978]: 0.002268774260155312
Loss at iteration [979]: 0.0022686317827245363
Loss at iteration [980]: 0.002268583270108
Loss at iteration [981]: 0.002268583270108
Loss at iteration [982]: 0.002268558521310948
Loss at iteration [983]: 0.002268523820058894
Loss at iteration [984]: 0.0022684198244273326
Loss at iteration [985]: 0.0022684000101848194
Loss at iteration [986]: 0.0022683498903760977
Loss at iteration [987]: 0.002268288838631054
Loss at iteration [988]: 0.0022682262437260427
Loss at iteration [989]: 0.0022682024798036516
Loss at iteration [990]: 0.002268147525650787
Loss at iteration [991]: 0.0022681142159444406
Loss at iteration [992]: 0.002268075632680866
Loss at iteration [993]: 0.0022679649669883686
Loss at iteration [994]: 0.0022679082946751644
Loss at iteration [995]: 0.002267806437351402
Loss at iteration [996]: 0.0022676337302964256
Loss at iteration [997]: 0.0022675800107961478
Loss at iteration [998]: 0.0022672076668693985
Loss at iteration [999]: 0.002267053161872409
Loss at iteration [1000]: 0.002267053161872409
Loss at iteration [1001]: 0.0022669993034828612
Loss at iteration [1002]: 0.002266849266178691
Loss at iteration [1003]: 0.002266810665029333
Loss at iteration [1004]: 0.0022667390968634676
Loss at iteration [1005]: 0.0022666996819335978
Loss at iteration [1006]: 0.002266658501313285
Loss at iteration [1007]: 0.0022665881370364876
Loss at iteration [1008]: 0.0022664388959944396
Loss at iteration [1009]: 0.0022663122196637546
Loss at iteration [1010]: 0.0022662237230635213
Loss at iteration [1011]: 0.002266042537414036
Loss at iteration [1012]: 0.002265856588991454
Loss at iteration [1013]: 0.0022656657013405005
Loss at iteration [1014]: 0.002265346542419366
Loss at iteration [1015]: 0.002265059359915997
Loss at iteration [1016]: 0.0022646480586318617
Loss at iteration [1017]: 0.0022646480586318617
Loss at iteration [1018]: 0.002264486722081676
Loss at iteration [1019]: 0.0022644080131342444
Loss at iteration [1020]: 0.0022643141512119417
Loss at iteration [1021]: 0.002264279046670649
Loss at iteration [1022]: 0.002264212181049755
Loss at iteration [1023]: 0.0022641746086943244
Loss at iteration [1024]: 0.002264127394567044
Loss at iteration [1025]: 0.002264034789455872
Loss at iteration [1026]: 0.0022639936175640916
Loss at iteration [1027]: 0.002263938795794792
Loss at iteration [1028]: 0.002263852422401815
Loss at iteration [1029]: 0.002263742770285338
Loss at iteration [1030]: 0.002263684198436134
Loss at iteration [1031]: 0.0022636149773916526
Loss at iteration [1032]: 0.0022635527917860645
Loss at iteration [1033]: 0.002263445227660567
Loss at iteration [1034]: 0.002263375151395807
Loss at iteration [1035]: 0.0022632633102295575
Loss at iteration [1036]: 0.0022632633102295575
Loss at iteration [1037]: 0.002263244950788282
Loss at iteration [1038]: 0.002263217786469249
Loss at iteration [1039]: 0.002263200907617501
Loss at iteration [1040]: 0.002263159370435778
Loss at iteration [1041]: 0.002263140167061305
Loss at iteration [1042]: 0.0022631065032933367
Loss at iteration [1043]: 0.0022630495872785414
Loss at iteration [1044]: 0.0022630051954929207
Loss at iteration [1045]: 0.002262875780790555
Loss at iteration [1046]: 0.002262833727658243
Loss at iteration [1047]: 0.0022625301001498736
Loss at iteration [1048]: 0.002262348576558531
Loss at iteration [1049]: 0.0022621402639920627
Loss at iteration [1050]: 0.0022609831802622936
Loss at iteration [1051]: 0.0022609831802622936
Loss at iteration [1052]: 0.002260673653665579
Loss at iteration [1053]: 0.0022601560505307824
Loss at iteration [1054]: 0.0022600961396361512
Loss at iteration [1055]: 0.002259998480757899
Loss at iteration [1056]: 0.002259870882166165
Loss at iteration [1057]: 0.0022598343880156544
Loss at iteration [1058]: 0.002259727209169636
Loss at iteration [1059]: 0.002259701791628748
Loss at iteration [1060]: 0.0022596152273114843
Loss at iteration [1061]: 0.0022595172056662166
Loss at iteration [1062]: 0.0022593751336020653
Loss at iteration [1063]: 0.002259318570078052
Loss at iteration [1064]: 0.0022592150981134095
Loss at iteration [1065]: 0.002258923355338677
Loss at iteration [1066]: 0.002258923355338677
Loss at iteration [1067]: 0.0022588055587073066
Loss at iteration [1068]: 0.00225862813323354
Loss at iteration [1069]: 0.0022585746341730628
Loss at iteration [1070]: 0.0022584728105581723
Loss at iteration [1071]: 0.0022584330841902106
Loss at iteration [1072]: 0.00225839413407139
Loss at iteration [1073]: 0.0022583573902278647
Loss at iteration [1074]: 0.0022583364847154055
Loss at iteration [1075]: 0.0022582772578074685
Loss at iteration [1076]: 0.0022582175813197487
Loss at iteration [1077]: 0.002258156609248586
Loss at iteration [1078]: 0.002258114200793075
Loss at iteration [1079]: 0.0022580755395266734
Loss at iteration [1080]: 0.002258027554938563
Loss at iteration [1081]: 0.002257941415475375
Loss at iteration [1082]: 0.0022578724353038734
Loss at iteration [1083]: 0.0022577661438638505
Loss at iteration [1084]: 0.0022577661438638505
Loss at iteration [1085]: 0.002257693613850433
Loss at iteration [1086]: 0.002257647435879951
Loss at iteration [1087]: 0.002257586609581616
Loss at iteration [1088]: 0.0022575021066391326
Loss at iteration [1089]: 0.0022574546832269562
Loss at iteration [1090]: 0.0022573304709686054
Loss at iteration [1091]: 0.00225729929042966
Loss at iteration [1092]: 0.0022572584446306273
Loss at iteration [1093]: 0.002257201383601456
Loss at iteration [1094]: 0.0022571523076146804
Loss at iteration [1095]: 0.002257081686250883
Loss at iteration [1096]: 0.002257052384042775
Loss at iteration [1097]: 0.002256922395281328
Loss at iteration [1098]: 0.0022568784601556323
Loss at iteration [1099]: 0.002256848617708423
Loss at iteration [1100]: 0.002256827959602676
Loss at iteration [1101]: 0.0022568103198599815
Loss at iteration [1102]: 0.0022568103198599815
Loss at iteration [1103]: 0.0022567872549943543
Loss at iteration [1104]: 0.002256756315688688
Loss at iteration [1105]: 0.002256736813694826
Loss at iteration [1106]: 0.002256721062858437
Loss at iteration [1107]: 0.0022566864115206816
Loss at iteration [1108]: 0.0022566711060590986
Loss at iteration [1109]: 0.0022566544973378192
Loss at iteration [1110]: 0.002256611828294875
Loss at iteration [1111]: 0.0022565678248772435
Loss at iteration [1112]: 0.0022556615709063764
Loss at iteration [1113]: 0.002253828949538106
Loss at iteration [1114]: 0.002253381479412989
Loss at iteration [1115]: 0.002252539663077261
Loss at iteration [1116]: 0.002250084173718427
Loss at iteration [1117]: 0.002250084173718427
Loss at iteration [1118]: 0.0022498158588649163
Loss at iteration [1119]: 0.0022496120688312218
Loss at iteration [1120]: 0.0022489502795833218
Loss at iteration [1121]: 0.0022484877843819513
Loss at iteration [1122]: 0.0022483867964826426
Loss at iteration [1123]: 0.0022476831334946466
Loss at iteration [1124]: 0.0022474743848769226
Loss at iteration [1125]: 0.002247192363282257
Loss at iteration [1126]: 0.0022464851600855957
Loss at iteration [1127]: 0.0022459969320584882
Loss at iteration [1128]: 0.0022456936613332425
Loss at iteration [1129]: 0.0022455111457057968
Loss at iteration [1130]: 0.0022453336514715993
Loss at iteration [1131]: 0.0022449170055174566
Loss at iteration [1132]: 0.0022448392149091246
Loss at iteration [1133]: 0.0022447019017530403
Loss at iteration [1134]: 0.0022445307141986787
Loss at iteration [1135]: 0.0022445307141986787
Loss at iteration [1136]: 0.002244473082024475
Loss at iteration [1137]: 0.0022443693501031058
Loss at iteration [1138]: 0.0022441970592535377
Loss at iteration [1139]: 0.0022440906959903728
Loss at iteration [1140]: 0.0022440227167422493
Loss at iteration [1141]: 0.002243942820634659
Loss at iteration [1142]: 0.00224386184443246
Loss at iteration [1143]: 0.002243661823431202
Loss at iteration [1144]: 0.002243599221903618
Loss at iteration [1145]: 0.002243503159117818
Loss at iteration [1146]: 0.0022432741666504664
Loss at iteration [1147]: 0.0022431067327512858
Loss at iteration [1148]: 0.0022429724715722125
Loss at iteration [1149]: 0.002242757989691306
Loss at iteration [1150]: 0.0022426657563712014
Loss at iteration [1151]: 0.002242429763727536
Loss at iteration [1152]: 0.0022422456207141454
Loss at iteration [1153]: 0.0022421110693079853
Loss at iteration [1154]: 0.0022419311144551133
Loss at iteration [1155]: 0.0022418708092173424
Loss at iteration [1156]: 0.0022418708092173424
Loss at iteration [1157]: 0.002241810009847019
Loss at iteration [1158]: 0.0022415347291346523
Loss at iteration [1159]: 0.0022413792536506525
Loss at iteration [1160]: 0.002241297033307233
Loss at iteration [1161]: 0.0022412129734566515
Loss at iteration [1162]: 0.0022411878438900125
Loss at iteration [1163]: 0.0022411218893281792
Loss at iteration [1164]: 0.0022409706008243366
Loss at iteration [1165]: 0.002240946348507841
Loss at iteration [1166]: 0.002240916619031855
Loss at iteration [1167]: 0.0022408777494032444
Loss at iteration [1168]: 0.002240841166827211
Loss at iteration [1169]: 0.002240791156364263
Loss at iteration [1170]: 0.002240715973398014
Loss at iteration [1171]: 0.002240715973398014
Loss at iteration [1172]: 0.0022406910526292815
Loss at iteration [1173]: 0.0022406258456159913
Loss at iteration [1174]: 0.0022405813877435913
Loss at iteration [1175]: 0.0022405584292215417
Loss at iteration [1176]: 0.0022405033474082103
Loss at iteration [1177]: 0.002240458505475412
Loss at iteration [1178]: 0.002240440704893877
Loss at iteration [1179]: 0.0022404162665211865
Loss at iteration [1180]: 0.002240389200119817
Loss at iteration [1181]: 0.002240363754808332
Loss at iteration [1182]: 0.002240327736653793
Loss at iteration [1183]: 0.002240317337869576
Loss at iteration [1184]: 0.002240304979400477
Loss at iteration [1185]: 0.002240285202687594
Loss at iteration [1186]: 0.002240235946879715
Loss at iteration [1187]: 0.0022401387025772464
Loss at iteration [1188]: 0.002240080805221666
Loss at iteration [1189]: 0.002240080805221666
Loss at iteration [1190]: 0.002240041290057611
Loss at iteration [1191]: 0.0022400132411816752
Loss at iteration [1192]: 0.0022399981388456225
Loss at iteration [1193]: 0.0022399726034853075
Loss at iteration [1194]: 0.002239935628711257
Loss at iteration [1195]: 0.002239886742546183
Loss at iteration [1196]: 0.0022398038115645858
Loss at iteration [1197]: 0.0022397311282902894
Loss at iteration [1198]: 0.0022391286433593852
Loss at iteration [1199]: 0.002238975712066976
Loss at iteration [1200]: 0.002237480397289901
Loss at iteration [1201]: 0.0022359623990065914
Loss at iteration [1202]: 0.00223568402736235
Loss at iteration [1203]: 0.002234334897004272
Loss at iteration [1204]: 0.0022328243030246666
Loss at iteration [1205]: 0.0022321709496988316
Loss at iteration [1206]: 0.0022321709496988316
Loss at iteration [1207]: 0.0022311380324293744
Loss at iteration [1208]: 0.0022296824347141477
Loss at iteration [1209]: 0.002229522043239203
Loss at iteration [1210]: 0.002229368750171117
Loss at iteration [1211]: 0.0022284781155787804
Loss at iteration [1212]: 0.002227955314046487
Loss at iteration [1213]: 0.002227529858202254
Loss at iteration [1214]: 0.0022266328935163647
Loss at iteration [1215]: 0.0022263797844561664
Loss at iteration [1216]: 0.0022260537746383426
Loss at iteration [1217]: 0.0022256039702546896
Loss at iteration [1218]: 0.002225439575860145
Loss at iteration [1219]: 0.002224985306659085
Loss at iteration [1220]: 0.0022247947381864776
Loss at iteration [1221]: 0.002224580481580683
Loss at iteration [1222]: 0.002224580481580683
Loss at iteration [1223]: 0.002224468788835927
Loss at iteration [1224]: 0.002224182090338501
Loss at iteration [1225]: 0.0022238658016378783
Loss at iteration [1226]: 0.002223786994308636
Loss at iteration [1227]: 0.002223706677498179
Loss at iteration [1228]: 0.0022236518739621254
Loss at iteration [1229]: 0.002223533750498688
Loss at iteration [1230]: 0.002223473667681872
Loss at iteration [1231]: 0.0022233853505192985
Loss at iteration [1232]: 0.0022231263428945207
Loss at iteration [1233]: 0.002222902888562386
Loss at iteration [1234]: 0.0022226453729419587
Loss at iteration [1235]: 0.002222437869415347
Loss at iteration [1236]: 0.002222295112396667
Loss at iteration [1237]: 0.002222113676243247
Loss at iteration [1238]: 0.002222113676243247
Loss at iteration [1239]: 0.0022220764173081714
Loss at iteration [1240]: 0.002221984997608459
Loss at iteration [1241]: 0.002221852967724314
Loss at iteration [1242]: 0.002221757340137445
Loss at iteration [1243]: 0.002221653859133554
Loss at iteration [1244]: 0.002221490636323458
Loss at iteration [1245]: 0.0022213909245121094
Loss at iteration [1246]: 0.0022213078165568396
Loss at iteration [1247]: 0.002221256088863945
Loss at iteration [1248]: 0.0022210869191726366
Loss at iteration [1249]: 0.002221004387926784
Loss at iteration [1250]: 0.002220609261224901
Loss at iteration [1251]: 0.002220577687234092
Loss at iteration [1252]: 0.0022203150824077664
Loss at iteration [1253]: 0.0022203150824077664
Loss at iteration [1254]: 0.0022202947389188973
Loss at iteration [1255]: 0.002220097257278821
Loss at iteration [1256]: 0.0022200579061030204
Loss at iteration [1257]: 0.0022200015244540224
Loss at iteration [1258]: 0.002219929378656887
Loss at iteration [1259]: 0.0022197838660432388
Loss at iteration [1260]: 0.002219742119746481
Loss at iteration [1261]: 0.002219614376952108
Loss at iteration [1262]: 0.0022194731092263745
Loss at iteration [1263]: 0.00221941021205498
Loss at iteration [1264]: 0.0022192825670056347
Loss at iteration [1265]: 0.0022191058287274242
Loss at iteration [1266]: 0.0022190316768963517
Loss at iteration [1267]: 0.002218869328072674
Loss at iteration [1268]: 0.002218869328072674
Loss at iteration [1269]: 0.0022187911943073652
Loss at iteration [1270]: 0.002218724683087286
Loss at iteration [1271]: 0.0022186333387074885
Loss at iteration [1272]: 0.0022186100933108688
Loss at iteration [1273]: 0.002218579063613686
Loss at iteration [1274]: 0.0022185207998062974
Loss at iteration [1275]: 0.0022184382539353746
Loss at iteration [1276]: 0.0022184012413123287
Loss at iteration [1277]: 0.0022183610399380284
Loss at iteration [1278]: 0.0022182938200259244
Loss at iteration [1279]: 0.00221824570017509
Loss at iteration [1280]: 0.002218186421588616
Loss at iteration [1281]: 0.002218162980976049
Loss at iteration [1282]: 0.002218105474245963
Loss at iteration [1283]: 0.0022180666661153633
Loss at iteration [1284]: 0.002218027555282022
Loss at iteration [1285]: 0.002218027555282022
Loss at iteration [1286]: 0.00221799442342506
Loss at iteration [1287]: 0.0022179749971013704
Loss at iteration [1288]: 0.00221795765904153
Loss at iteration [1289]: 0.002217942093791962
Loss at iteration [1290]: 0.002217903764590917
Loss at iteration [1291]: 0.0022178608693903274
Loss at iteration [1292]: 0.0022178332921964517
Loss at iteration [1293]: 0.0022177682071080392
Loss at iteration [1294]: 0.0022177084860739034
Loss at iteration [1295]: 0.00221756937872812
Loss at iteration [1296]: 0.0022175213982090587
Loss at iteration [1297]: 0.002217436918753188
Loss at iteration [1298]: 0.002217392198618692
Loss at iteration [1299]: 0.0022173510923181212
Loss at iteration [1300]: 0.002217300688296579
Loss at iteration [1301]: 0.0022171425834750535
Loss at iteration [1302]: 0.0022171425834750535
Loss at iteration [1303]: 0.0022170345966128833
Loss at iteration [1304]: 0.0022169878518388986
Loss at iteration [1305]: 0.0022169245303900716
Loss at iteration [1306]: 0.0022168978086818314
Loss at iteration [1307]: 0.0022168426842781573
Loss at iteration [1308]: 0.0022167782312477002
Loss at iteration [1309]: 0.0022167615578728163
Loss at iteration [1310]: 0.002216699215471655
Loss at iteration [1311]: 0.0022166423011586505
Loss at iteration [1312]: 0.0022166128322682476
Loss at iteration [1313]: 0.0022165792800020235
Loss at iteration [1314]: 0.002216552805354767
Loss at iteration [1315]: 0.002216538800333531
Loss at iteration [1316]: 0.0022164997195436922
Loss at iteration [1317]: 0.0022164860471895836
Loss at iteration [1318]: 0.002216446430774763
Loss at iteration [1319]: 0.002216446430774763
Loss at iteration [1320]: 0.002216411080789146
Loss at iteration [1321]: 0.0022163667535879286
Loss at iteration [1322]: 0.002216315553311334
Loss at iteration [1323]: 0.0022162832147862104
Loss at iteration [1324]: 0.002216266185266774
Loss at iteration [1325]: 0.0022162497725840636
Loss at iteration [1326]: 0.002216237248723508
Loss at iteration [1327]: 0.0022162162150712464
Loss at iteration [1328]: 0.002216198801894306
Loss at iteration [1329]: 0.002216179218175054
Loss at iteration [1330]: 0.0022161419878114217
Loss at iteration [1331]: 0.0022160331046432303
Loss at iteration [1332]: 0.002215896162746858
Loss at iteration [1333]: 0.0022156580087769953
Loss at iteration [1334]: 0.0022153751879786755
Loss at iteration [1335]: 0.0022150806231036662
Loss at iteration [1336]: 0.0022150806231036662
Loss at iteration [1337]: 0.002214827985412287
Loss at iteration [1338]: 0.002214752174744148
Loss at iteration [1339]: 0.0022145908574228096
Loss at iteration [1340]: 0.002214543742006293
Loss at iteration [1341]: 0.002214508263378381
Loss at iteration [1342]: 0.0022144548827595237
Loss at iteration [1343]: 0.0022143990397513373
Loss at iteration [1344]: 0.00221434666768049
Loss at iteration [1345]: 0.0022143063679251032
Loss at iteration [1346]: 0.00221426631729663
Loss at iteration [1347]: 0.002214212692645379
Loss at iteration [1348]: 0.002214154235345001
Loss at iteration [1349]: 0.002214125464393867
Loss at iteration [1350]: 0.0022140719139341746
Loss at iteration [1351]: 0.002214041131169655
Loss at iteration [1352]: 0.002213979414081553
Loss at iteration [1353]: 0.002213979414081553
Loss at iteration [1354]: 0.0022139437719102557
Loss at iteration [1355]: 0.0022139214261874345
Loss at iteration [1356]: 0.0022138774755832073
Loss at iteration [1357]: 0.002213851485824546
Loss at iteration [1358]: 0.0022138166363638518
Loss at iteration [1359]: 0.002213808338452316
Loss at iteration [1360]: 0.0022137771292672754
Loss at iteration [1361]: 0.002213756688098474
Loss at iteration [1362]: 0.0022137358178790662
Loss at iteration [1363]: 0.002213722337875966
Loss at iteration [1364]: 0.0022136953597661608
Loss at iteration [1365]: 0.0022136603145883984
Loss at iteration [1366]: 0.002213622790706549
Loss at iteration [1367]: 0.0022135756362956244
Loss at iteration [1368]: 0.002213358678258891
Loss at iteration [1369]: 0.00221325736940083
Loss at iteration [1370]: 0.00221325736940083
Loss at iteration [1371]: 0.002213204839074837
Loss at iteration [1372]: 0.002213159915237
Loss at iteration [1373]: 0.00221311088310774
Loss at iteration [1374]: 0.002213057507938492
Loss at iteration [1375]: 0.002213006153705193
Loss at iteration [1376]: 0.002212978777787498
Loss at iteration [1377]: 0.002212955603533236
Loss at iteration [1378]: 0.0022129211286098524
Loss at iteration [1379]: 0.002212879002724226
Loss at iteration [1380]: 0.0022128602155483497
Loss at iteration [1381]: 0.0022128165170046776
Loss at iteration [1382]: 0.00221277214337113
Loss at iteration [1383]: 0.00221273485135384
Loss at iteration [1384]: 0.002212658252183007
Loss at iteration [1385]: 0.0022126333595143674
Loss at iteration [1386]: 0.002212554801896786
Loss at iteration [1387]: 0.0022125191428508397
Loss at iteration [1388]: 0.0022125191428508397
Loss at iteration [1389]: 0.00221250577795109
Loss at iteration [1390]: 0.002212496087248034
Loss at iteration [1391]: 0.0022124667303679776
Loss at iteration [1392]: 0.0022124565287262835
Loss at iteration [1393]: 0.002212454126758665
Loss at iteration [1394]: 0.002212427625645542
Loss at iteration [1395]: 0.0022124029154436003
Loss at iteration [1396]: 0.002212383199275046
Loss at iteration [1397]: 0.002212359347271989
Loss at iteration [1398]: 0.0022123339051993494
Loss at iteration [1399]: 0.0022123160984400697
Loss at iteration [1400]: 0.002212296113698164
Loss at iteration [1401]: 0.002212255453140898
Loss at iteration [1402]: 0.002212210046242049
Loss at iteration [1403]: 0.0022121779996796135
Loss at iteration [1404]: 0.002212106354875252
Loss at iteration [1405]: 0.002212106354875252
Loss at iteration [1406]: 0.002212089781822594
Loss at iteration [1407]: 0.0022120603008224564
Loss at iteration [1408]: 0.0022120356401973003
Loss at iteration [1409]: 0.002212020960565995
Loss at iteration [1410]: 0.002212005743003143
Loss at iteration [1411]: 0.002211992870298109
Loss at iteration [1412]: 0.0022119736443318347
Loss at iteration [1413]: 0.0022119550413494753
Loss at iteration [1414]: 0.002211894899690129
Loss at iteration [1415]: 0.002211833385061973
Loss at iteration [1416]: 0.0022117267245429432
Loss at iteration [1417]: 0.0022115210516010808
Loss at iteration [1418]: 0.0022112368350358288
Loss at iteration [1419]: 0.0022109844712904113
Loss at iteration [1420]: 0.0022106268536848696
Loss at iteration [1421]: 0.0022103094211358334
Loss at iteration [1422]: 0.0022080333012041283
Loss at iteration [1423]: 0.0022080333012041283
Loss at iteration [1424]: 0.0022066596145697104
Loss at iteration [1425]: 0.0022064271865008265
Loss at iteration [1426]: 0.002205754709884367
Loss at iteration [1427]: 0.0022053636791507297
Loss at iteration [1428]: 0.002204973322562404
Loss at iteration [1429]: 0.002204806054473813
Loss at iteration [1430]: 0.002204621589578594
Loss at iteration [1431]: 0.002204373574046603
Loss at iteration [1432]: 0.0022042700775710723
Loss at iteration [1433]: 0.002204211336344893
Loss at iteration [1434]: 0.0022041273839550155
Loss at iteration [1435]: 0.002203947759482204
Loss at iteration [1436]: 0.0022039075121021074
Loss at iteration [1437]: 0.0022039075121021074
Loss at iteration [1438]: 0.0022038731177591257
Loss at iteration [1439]: 0.002203748926137679
Loss at iteration [1440]: 0.002203698889994474
Loss at iteration [1441]: 0.0022035612103312144
Loss at iteration [1442]: 0.002203532277767761
Loss at iteration [1443]: 0.0022034649763113664
Loss at iteration [1444]: 0.0022033756117120166
Loss at iteration [1445]: 0.0022032747741634034
Loss at iteration [1446]: 0.0022031992015739926
Loss at iteration [1447]: 0.002203154638081325
Loss at iteration [1448]: 0.002203091592368719
Loss at iteration [1449]: 0.0022030237906631744
Loss at iteration [1450]: 0.002202980476188824
Loss at iteration [1451]: 0.0022028977560003544
Loss at iteration [1452]: 0.0022027865050056545
Loss at iteration [1453]: 0.0022026792170522563
Loss at iteration [1454]: 0.002202425004479833
Loss at iteration [1455]: 0.002202425004479833
Loss at iteration [1456]: 0.002202371586753612
Loss at iteration [1457]: 0.002202166444522105
Loss at iteration [1458]: 0.0022020943877458297
Loss at iteration [1459]: 0.0022020647061532957
Loss at iteration [1460]: 0.0022020247827349076
Loss at iteration [1461]: 0.0022019420694149687
Loss at iteration [1462]: 0.002201913667785159
Loss at iteration [1463]: 0.0022018743713652783
Loss at iteration [1464]: 0.002201845945702986
Loss at iteration [1465]: 0.002201826633194878
Loss at iteration [1466]: 0.002201797440988273
Loss at iteration [1467]: 0.0022017535661367138
Loss at iteration [1468]: 0.002201700616898902
Loss at iteration [1469]: 0.002201700616898902
Loss at iteration [1470]: 0.002201683402109123
Loss at iteration [1471]: 0.0022016631112909742
Loss at iteration [1472]: 0.0022016402436761855
Loss at iteration [1473]: 0.0022016237330068442
Loss at iteration [1474]: 0.002201595716523386
Loss at iteration [1475]: 0.0022015917233049118
Loss at iteration [1476]: 0.002201562987790016
Loss at iteration [1477]: 0.0022015286948630602
Loss at iteration [1478]: 0.002201436458746799
Loss at iteration [1479]: 0.0022013178048408233
Loss at iteration [1480]: 0.0022012349592208367
Loss at iteration [1481]: 0.0022011530396436473
Loss at iteration [1482]: 0.002200986864160855
Loss at iteration [1483]: 0.002200910779676474
Loss at iteration [1484]: 0.0022008564631674564
Loss at iteration [1485]: 0.0022005835908857374
Loss at iteration [1486]: 0.0022005835908857374
Loss at iteration [1487]: 0.002200546841325074
Loss at iteration [1488]: 0.0022004913012117593
Loss at iteration [1489]: 0.0022004697497819215
Loss at iteration [1490]: 0.002200437008958719
Loss at iteration [1491]: 0.002200409529074814
Loss at iteration [1492]: 0.002200385736960646
Loss at iteration [1493]: 0.002200351859664662
Loss at iteration [1494]: 0.002200323043224441
Loss at iteration [1495]: 0.002200287768394088
Loss at iteration [1496]: 0.002200252100964398
Loss at iteration [1497]: 0.0022001919455727262
Loss at iteration [1498]: 0.0022001315526447383
Loss at iteration [1499]: 0.002199965059039071
Loss at iteration [1500]: 0.002199852618907118
Loss at iteration [1501]: 0.002199604232677397
Loss at iteration [1502]: 0.002199479437992211
Loss at iteration [1503]: 0.002199479437992211
Loss at iteration [1504]: 0.0021994306387738065
Loss at iteration [1505]: 0.002199383023051483
Loss at iteration [1506]: 0.002199330720277695
Loss at iteration [1507]: 0.002199287714235944
Loss at iteration [1508]: 0.0021992432721823314
Loss at iteration [1509]: 0.002199208083099534
Loss at iteration [1510]: 0.002199167970700949
Loss at iteration [1511]: 0.002199130827916773
Loss at iteration [1512]: 0.0021990912377258015
Loss at iteration [1513]: 0.00219902843778622
Loss at iteration [1514]: 0.002198954205998858
Loss at iteration [1515]: 0.002198895578767515
Loss at iteration [1516]: 0.0021988120148405304
Loss at iteration [1517]: 0.0021987240556999707
Loss at iteration [1518]: 0.0021986640724808823
Loss at iteration [1519]: 0.002198534295903241
Loss at iteration [1520]: 0.0021983928221430207
Loss at iteration [1521]: 0.0021980304863565576
Loss at iteration [1522]: 0.0021980304863565576
Loss at iteration [1523]: 0.002197853252375442
Loss at iteration [1524]: 0.0021977977245224694
Loss at iteration [1525]: 0.002197578935923906
Loss at iteration [1526]: 0.002197477009525025
Loss at iteration [1527]: 0.0021973822491407257
Loss at iteration [1528]: 0.002197335157468322
Loss at iteration [1529]: 0.0021972795997108685
Loss at iteration [1530]: 0.0021972277014485745
Loss at iteration [1531]: 0.0021971901840748954
Loss at iteration [1532]: 0.0021971410211884066
Loss at iteration [1533]: 0.002197087811416957
Loss at iteration [1534]: 0.0021970362152778085
Loss at iteration [1535]: 0.002196966145399447
Loss at iteration [1536]: 0.00219692812334078
Loss at iteration [1537]: 0.0021968645966202044
Loss at iteration [1538]: 0.0021968645966202044
Loss at iteration [1539]: 0.0021968399090031487
Loss at iteration [1540]: 0.0021968075597582006
Loss at iteration [1541]: 0.0021967871610342814
Loss at iteration [1542]: 0.0021967714541112526
Loss at iteration [1543]: 0.002196750923832047
Loss at iteration [1544]: 0.002196733719036748
Loss at iteration [1545]: 0.002196695704017253
Loss at iteration [1546]: 0.002196668471362263
Loss at iteration [1547]: 0.002196561184119489
Loss at iteration [1548]: 0.002196449335799074
Loss at iteration [1549]: 0.002196348822961936
Loss at iteration [1550]: 0.0021962755101382057
Loss at iteration [1551]: 0.0021961557183561996
Loss at iteration [1552]: 0.0021960791309311935
Loss at iteration [1553]: 0.0021959670497246303
Loss at iteration [1554]: 0.0021958818563324657
Loss at iteration [1555]: 0.0021958818563324657
Loss at iteration [1556]: 0.0021958338202100105
Loss at iteration [1557]: 0.0021957470449155557
Loss at iteration [1558]: 0.002195680899082565
Loss at iteration [1559]: 0.0021956487213008196
Loss at iteration [1560]: 0.002195498861352402
Loss at iteration [1561]: 0.0021954778409018086
Loss at iteration [1562]: 0.0021954433161726697
Loss at iteration [1563]: 0.0021954119192378095
Loss at iteration [1564]: 0.002195372957866806
Loss at iteration [1565]: 0.002195344276629073
Loss at iteration [1566]: 0.0021953271998131135
Loss at iteration [1567]: 0.00219530675439059
Loss at iteration [1568]: 0.0021952822193602385
Loss at iteration [1569]: 0.002195269445990663
Loss at iteration [1570]: 0.002195269445990663
Loss at iteration [1571]: 0.002195257951534676
Loss at iteration [1572]: 0.0021952513410672587
Loss at iteration [1573]: 0.00219524027140816
Loss at iteration [1574]: 0.002195231409361008
Loss at iteration [1575]: 0.0021951957068127937
Loss at iteration [1576]: 0.002195154753482308
Loss at iteration [1577]: 0.0021950975054483035
Loss at iteration [1578]: 0.002195062330360174
Loss at iteration [1579]: 0.002194956574970425
Loss at iteration [1580]: 0.0021948448763022843
Loss at iteration [1581]: 0.0021947077706719626
Loss at iteration [1582]: 0.0021943149675797114
Loss at iteration [1583]: 0.0021941550312262973
Loss at iteration [1584]: 0.0021934745227732582
Loss at iteration [1585]: 0.0021916413554008813
Loss at iteration [1586]: 0.002190597868374433
Loss at iteration [1587]: 0.002190597868374433
Loss at iteration [1588]: 0.0021903311328297227
Loss at iteration [1589]: 0.002189800208221768
Loss at iteration [1590]: 0.002189493264347661
Loss at iteration [1591]: 0.0021890563196607813
Loss at iteration [1592]: 0.0021889280214554036
Loss at iteration [1593]: 0.002188843369131384
Loss at iteration [1594]: 0.002188391147953493
Loss at iteration [1595]: 0.0021883062381134557
Loss at iteration [1596]: 0.0021880510065411885
Loss at iteration [1597]: 0.0021878233272077416
Loss at iteration [1598]: 0.0021877497533542884
Loss at iteration [1599]: 0.0021875196137685574
Loss at iteration [1600]: 0.002187446522037536
Loss at iteration [1601]: 0.002187369144684429
Loss at iteration [1602]: 0.002187266946953062
Loss at iteration [1603]: 0.0021871649311763237
Loss at iteration [1604]: 0.0021871649311763237
Loss at iteration [1605]: 0.002187129645639281
Loss at iteration [1606]: 0.002187087431900531
Loss at iteration [1607]: 0.0021870185599978213
Loss at iteration [1608]: 0.0021869909215364858
Loss at iteration [1609]: 0.002186953986379577
Loss at iteration [1610]: 0.0021868505116839497
Loss at iteration [1611]: 0.0021867866956510567
Loss at iteration [1612]: 0.0021867569328179303
Loss at iteration [1613]: 0.0021866561534534474
Loss at iteration [1614]: 0.002186623925920883
Loss at iteration [1615]: 0.0021864959058937984
Loss at iteration [1616]: 0.0021864724887090425
Loss at iteration [1617]: 0.002186437530235336
Loss at iteration [1618]: 0.0021863908515114415
Loss at iteration [1619]: 0.0021863908515114415
Loss at iteration [1620]: 0.0021863704520843855
Loss at iteration [1621]: 0.0021863498370973313
Loss at iteration [1622]: 0.0021863332886873223
Loss at iteration [1623]: 0.0021863205892742868
Loss at iteration [1624]: 0.0021862897650475853
Loss at iteration [1625]: 0.0021862659771901866
Loss at iteration [1626]: 0.002186222212178611
Loss at iteration [1627]: 0.002186202674473104
Loss at iteration [1628]: 0.002186151643877076
Loss at iteration [1629]: 0.002186099857865543
Loss at iteration [1630]: 0.0021859700929977998
Loss at iteration [1631]: 0.0021858310949274184
Loss at iteration [1632]: 0.0021857633858602954
Loss at iteration [1633]: 0.0021855912791569703
Loss at iteration [1634]: 0.0021854782891502222
Loss at iteration [1635]: 0.0021854782891502222
Loss at iteration [1636]: 0.0021854457063249294
Loss at iteration [1637]: 0.002185388669877839
Loss at iteration [1638]: 0.0021853476985334496
Loss at iteration [1639]: 0.0021853171069343767
Loss at iteration [1640]: 0.0021852675254937916
Loss at iteration [1641]: 0.002185235315132402
Loss at iteration [1642]: 0.0021851927278283456
Loss at iteration [1643]: 0.0021851701202249135
Loss at iteration [1644]: 0.0021851294803935674
Loss at iteration [1645]: 0.0021851035662784836
Loss at iteration [1646]: 0.0021850625446064144
Loss at iteration [1647]: 0.002185021386531718
Loss at iteration [1648]: 0.002184981482522031
Loss at iteration [1649]: 0.0021848959438671494
Loss at iteration [1650]: 0.002184847099951505
Loss at iteration [1651]: 0.002184847099951505
Loss at iteration [1652]: 0.00218480397163727
Loss at iteration [1653]: 0.002184661177078504
Loss at iteration [1654]: 0.0021846224850198353
Loss at iteration [1655]: 0.002184605296749136
Loss at iteration [1656]: 0.0021845754188442954
Loss at iteration [1657]: 0.0021845397066402664
Loss at iteration [1658]: 0.0021845215248047904
Loss at iteration [1659]: 0.0021845103592844878
Loss at iteration [1660]: 0.002184462301526778
Loss at iteration [1661]: 0.002184443125278472
Loss at iteration [1662]: 0.002184429322463943
Loss at iteration [1663]: 0.0021843980977375725
Loss at iteration [1664]: 0.0021843803498437513
Loss at iteration [1665]: 0.002184366629629821
Loss at iteration [1666]: 0.0021843556346428446
Loss at iteration [1667]: 0.0021843556346428446
Loss at iteration [1668]: 0.002184328237943284
Loss at iteration [1669]: 0.002184311184429891
Loss at iteration [1670]: 0.0021842965325021284
Loss at iteration [1671]: 0.0021842853983901557
Loss at iteration [1672]: 0.0021842725987133256
Loss at iteration [1673]: 0.0021842633859679443
Loss at iteration [1674]: 0.002184240433481137
Loss at iteration [1675]: 0.0021842074134919274
Loss at iteration [1676]: 0.0021841210020710528
Loss at iteration [1677]: 0.0021840687432451043
Loss at iteration [1678]: 0.0021839981944519536
Loss at iteration [1679]: 0.002183795681584212
Loss at iteration [1680]: 0.0021837071338889832
Loss at iteration [1681]: 0.0021834834207162175
Loss at iteration [1682]: 0.002183141644650009
Loss at iteration [1683]: 0.002182934621794027
Loss at iteration [1684]: 0.002182934621794027
Loss at iteration [1685]: 0.002182838472255376
Loss at iteration [1686]: 0.002182785136054596
Loss at iteration [1687]: 0.0021826809683273864
Loss at iteration [1688]: 0.0021826505379178578
Loss at iteration [1689]: 0.00218256219811719
Loss at iteration [1690]: 0.002182513144221468
Loss at iteration [1691]: 0.0021824896076764557
Loss at iteration [1692]: 0.00218243783592172
Loss at iteration [1693]: 0.0021823948092095837
Loss at iteration [1694]: 0.002182353849533335
Loss at iteration [1695]: 0.0021823149559916945
Loss at iteration [1696]: 0.0021822675755158293
Loss at iteration [1697]: 0.0021822332381118727
Loss at iteration [1698]: 0.00218220616030674
Loss at iteration [1699]: 0.0021821566492778565
Loss at iteration [1700]: 0.0021820817950101755
Loss at iteration [1701]: 0.0021819904153494766
Loss at iteration [1702]: 0.0021819904153494766
Loss at iteration [1703]: 0.002181967191519456
Loss at iteration [1704]: 0.0021819256419165524
Loss at iteration [1705]: 0.002181893130576165
Loss at iteration [1706]: 0.0021818721463138786
Loss at iteration [1707]: 0.0021818465024684122
Loss at iteration [1708]: 0.0021818327732769788
Loss at iteration [1709]: 0.00218181473983564
Loss at iteration [1710]: 0.0021817948411257007
Loss at iteration [1711]: 0.0021817615530343288
Loss at iteration [1712]: 0.002181743594791214
Loss at iteration [1713]: 0.0021817309970225103
Loss at iteration [1714]: 0.0021816986580413663
Loss at iteration [1715]: 0.0021816387182169023
Loss at iteration [1716]: 0.0021815829933212196
Loss at iteration [1717]: 0.0021815235712073057
Loss at iteration [1718]: 0.0021815235712073057
Loss at iteration [1719]: 0.0021814973216949035
Loss at iteration [1720]: 0.0021814741031434357
Loss at iteration [1721]: 0.002181452025514683
Loss at iteration [1722]: 0.0021814338908732033
Loss at iteration [1723]: 0.0021814171923204245
Loss at iteration [1724]: 0.002181401553547047
Loss at iteration [1725]: 0.0021813752629668516
Loss at iteration [1726]: 0.0021813590933295393
Loss at iteration [1727]: 0.002181342158680271
Loss at iteration [1728]: 0.002181319708051794
Loss at iteration [1729]: 0.0021812322923827816
Loss at iteration [1730]: 0.002181196317078793
Loss at iteration [1731]: 0.002181196317078793
Loss at iteration [1732]: 0.002181179270513822
Loss at iteration [1733]: 0.002181147243976174
Loss at iteration [1734]: 0.0021811352741568095
Loss at iteration [1735]: 0.002181120812941304
Loss at iteration [1736]: 0.002181102677740181
Loss at iteration [1737]: 0.0021810920609242252
Loss at iteration [1738]: 0.002181057377625954
Loss at iteration [1739]: 0.002181019203697843
Loss at iteration [1740]: 0.0021809945686826595
Loss at iteration [1741]: 0.0021809603872715777
Loss at iteration [1742]: 0.0021808988601430893
Loss at iteration [1743]: 0.0021808607930176075
Loss at iteration [1744]: 0.00218081335208997
Loss at iteration [1745]: 0.0021807630094299725
Loss at iteration [1746]: 0.002180724774906941
Loss at iteration [1747]: 0.0021806399458501585
Loss at iteration [1748]: 0.0021806399458501585
Loss at iteration [1749]: 0.0021806176190127266
Loss at iteration [1750]: 0.002180603184023832
Loss at iteration [1751]: 0.0021805919057197153
Loss at iteration [1752]: 0.0021805775655567325
Loss at iteration [1753]: 0.0021805641081713884
Loss at iteration [1754]: 0.002180547662502734
Loss at iteration [1755]: 0.0021805081442221852
Loss at iteration [1756]: 0.00218048982454245
Loss at iteration [1757]: 0.002180457968357929
Loss at iteration [1758]: 0.002180419887169337
Loss at iteration [1759]: 0.0021803966361305543
Loss at iteration [1760]: 0.0021803535216538125
Loss at iteration [1761]: 0.0021803238022545884
Loss at iteration [1762]: 0.002180301164520081
Loss at iteration [1763]: 0.0021802626778978716
Loss at iteration [1764]: 0.0021802626778978716
Loss at iteration [1765]: 0.002180236676990128
Loss at iteration [1766]: 0.002180217032139016
Loss at iteration [1767]: 0.002180208013590054
Loss at iteration [1768]: 0.002180202349119221
Loss at iteration [1769]: 0.002180190345264729
Loss at iteration [1770]: 0.0021801612490839717
Loss at iteration [1771]: 0.0021801376343263262
Loss at iteration [1772]: 0.0021801162127188813
Loss at iteration [1773]: 0.002180088325069742
Loss at iteration [1774]: 0.0021800383388050704
Loss at iteration [1775]: 0.002179960971406063
Loss at iteration [1776]: 0.0021798802707657387
Loss at iteration [1777]: 0.0021798170245476457
Loss at iteration [1778]: 0.0021797339921038167
Loss at iteration [1779]: 0.002179498080486992
Loss at iteration [1780]: 0.002179498080486992
Loss at iteration [1781]: 0.002179394299963183
Loss at iteration [1782]: 0.002179327561083642
Loss at iteration [1783]: 0.0021792707080867143
Loss at iteration [1784]: 0.0021792361513760534
Loss at iteration [1785]: 0.00217922052143935
Loss at iteration [1786]: 0.0021792003075475205
Loss at iteration [1787]: 0.0021791690153890324
Loss at iteration [1788]: 0.0021791341285860057
Loss at iteration [1789]: 0.002179112353362923
Loss at iteration [1790]: 0.002179058821842274
Loss at iteration [1791]: 0.0021790150240453233
Loss at iteration [1792]: 0.0021789715902151645
Loss at iteration [1793]: 0.002178901173257029
Loss at iteration [1794]: 0.0021788587207011404
Loss at iteration [1795]: 0.0021787750698313213
Loss at iteration [1796]: 0.0021787750698313213
Loss at iteration [1797]: 0.0021787405523004165
Loss at iteration [1798]: 0.0021786903789226303
Loss at iteration [1799]: 0.0021786672831910037
Loss at iteration [1800]: 0.0021786384595114936
Loss at iteration [1801]: 0.00217861116025087
Loss at iteration [1802]: 0.0021785987987296084
Loss at iteration [1803]: 0.0021785565286796408
Loss at iteration [1804]: 0.002178523455510383
Loss at iteration [1805]: 0.002178497619456077
Loss at iteration [1806]: 0.0021784505626228226
Loss at iteration [1807]: 0.002178401378128404
Loss at iteration [1808]: 0.0021783448587267312
Loss at iteration [1809]: 0.0021782897891698518
Loss at iteration [1810]: 0.00217823340575936
Loss at iteration [1811]: 0.002178204838680403
Loss at iteration [1812]: 0.002178204838680403
Loss at iteration [1813]: 0.00217817584610865
Loss at iteration [1814]: 0.002178157294823144
Loss at iteration [1815]: 0.0021781479622857876
Loss at iteration [1816]: 0.002178137455438799
Loss at iteration [1817]: 0.002178128025407217
Loss at iteration [1818]: 0.0021781143235745557
Loss at iteration [1819]: 0.0021780651284565226
Loss at iteration [1820]: 0.002178036937959257
Loss at iteration [1821]: 0.0021779842656479316
Loss at iteration [1822]: 0.0021779526181695133
Loss at iteration [1823]: 0.002177926796230568
Loss at iteration [1824]: 0.0021779009114276148
Loss at iteration [1825]: 0.0021778828203135045
Loss at iteration [1826]: 0.00217785962079407
Loss at iteration [1827]: 0.002177842055230814
Loss at iteration [1828]: 0.002177842055230814
Loss at iteration [1829]: 0.002177829237834664
Loss at iteration [1830]: 0.002177821885250359
Loss at iteration [1831]: 0.0021778162947508743
Loss at iteration [1832]: 0.00217780590861477
Loss at iteration [1833]: 0.0021778038656381908
Loss at iteration [1834]: 0.002177787101965476
Loss at iteration [1835]: 0.002177761254712865
Loss at iteration [1836]: 0.002177700275292046
Loss at iteration [1837]: 0.0021776632131326632
Loss at iteration [1838]: 0.0021776316313262796
Loss at iteration [1839]: 0.0021775808766510423
Loss at iteration [1840]: 0.002177543205655913
Loss at iteration [1841]: 0.002177467723920479
Loss at iteration [1842]: 0.002177429873432002
Loss at iteration [1843]: 0.002177392416003482
Loss at iteration [1844]: 0.002177392416003482
Loss at iteration [1845]: 0.0021773631879262387
Loss at iteration [1846]: 0.002177341857382559
Loss at iteration [1847]: 0.002177327449362969
Loss at iteration [1848]: 0.0021773187564659347
Loss at iteration [1849]: 0.002177317485035891
Loss at iteration [1850]: 0.002177305932717966
Loss at iteration [1851]: 0.002177266079059216
Loss at iteration [1852]: 0.002177245268681268
Loss at iteration [1853]: 0.002177217235243955
Loss at iteration [1854]: 0.0021771888631110336
Loss at iteration [1855]: 0.0021771598396869156
Loss at iteration [1856]: 0.002177068644972052
Loss at iteration [1857]: 0.0021770004091263883
Loss at iteration [1858]: 0.0021768594729613447
Loss at iteration [1859]: 0.002176667051372225
Loss at iteration [1860]: 0.002176034466737715
Loss at iteration [1861]: 0.002176034466737715
Loss at iteration [1862]: 0.00217593136923913
Loss at iteration [1863]: 0.0021758610385375914
Loss at iteration [1864]: 0.0021757673779430413
Loss at iteration [1865]: 0.0021757007776556704
Loss at iteration [1866]: 0.00217561441199417
Loss at iteration [1867]: 0.0021755767339119696
Loss at iteration [1868]: 0.002175533732117871
Loss at iteration [1869]: 0.0021755015063776957
Loss at iteration [1870]: 0.002175465724389034
Loss at iteration [1871]: 0.0021754379039868863
Loss at iteration [1872]: 0.0021754037522349018
Loss at iteration [1873]: 0.0021753643900350424
Loss at iteration [1874]: 0.002175312363252343
Loss at iteration [1875]: 0.00217527266186738
Loss at iteration [1876]: 0.002175213074020946
Loss at iteration [1877]: 0.002175148326732433
Loss at iteration [1878]: 0.0021750321772187006
Loss at iteration [1879]: 0.0021750321772187006
Loss at iteration [1880]: 0.00217499414942117
Loss at iteration [1881]: 0.0021749588704790186
Loss at iteration [1882]: 0.0021749104170233477
Loss at iteration [1883]: 0.002174873257305353
Loss at iteration [1884]: 0.0021748350241488877
Loss at iteration [1885]: 0.0021748122787622966
Loss at iteration [1886]: 0.0021747813461260495
Loss at iteration [1887]: 0.0021747598787406593
Loss at iteration [1888]: 0.002174740270810423
Loss at iteration [1889]: 0.0021746822609903784
Loss at iteration [1890]: 0.002174633096475936
Loss at iteration [1891]: 0.0021745949308390458
Loss at iteration [1892]: 0.0021745603926353932
Loss at iteration [1893]: 0.002174541446303509
Loss at iteration [1894]: 0.002174516921313031
Loss at iteration [1895]: 0.002174516921313031
Loss at iteration [1896]: 0.0021744967395873156
Loss at iteration [1897]: 0.0021744870985732005
Loss at iteration [1898]: 0.002174476011174966
Loss at iteration [1899]: 0.0021744503394358007
Loss at iteration [1900]: 0.0021744403855579256
Loss at iteration [1901]: 0.0021744304015672653
Loss at iteration [1902]: 0.002174408786564351
Loss at iteration [1903]: 0.002174389090797134
Loss at iteration [1904]: 0.0021743472460721953
Loss at iteration [1905]: 0.0021743261670457877
Loss at iteration [1906]: 0.002174288429189013
Loss at iteration [1907]: 0.002174228259370374
Loss at iteration [1908]: 0.0021741572723300664
Loss at iteration [1909]: 0.002174097093134872
Loss at iteration [1910]: 0.002174060022237006
Loss at iteration [1911]: 0.002173908116642178
