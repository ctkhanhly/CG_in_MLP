Model name                            : MLP_Multistep
The number of input features          : 3
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.001
Beta type                             :HS
Total number of function evaluations  : 3052
Total number of iterations            : 1612
Max number of iterations              : 3000
Number of samples in training data    : 171
Number of samples in tests data       : 73
Total training time                   : 9.542371034622192
Total number of parameters            : 201902
Percentage of parameters < 1e-9       : 49.91332428603976%
Percentage of parameters < 1e-7       : 49.91332428603976%
Percentage of parameters < 1e-6       : 49.91381957583382%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.2589798982811262
Loss at iteration [2]: 1.256640638292389
Loss at iteration [3]: 1.2530032551324253
Loss at iteration [4]: 1.2484667284983775
Loss at iteration [5]: 1.2407053232708387
Loss at iteration [6]: 1.2280677178810084
Loss at iteration [7]: 1.2280677178810084
Loss at iteration [8]: 1.22213766990019
Loss at iteration [9]: 1.2141467746823664
Loss at iteration [10]: 1.2090362505817296
Loss at iteration [11]: 1.200060798298142
Loss at iteration [12]: 1.187905672723625
Loss at iteration [13]: 1.171715115726805
Loss at iteration [14]: 1.171715115726805
Loss at iteration [15]: 1.1635442132635307
Loss at iteration [16]: 1.1559154107513445
Loss at iteration [17]: 1.1536460196543759
Loss at iteration [18]: 1.1471294213523193
Loss at iteration [19]: 1.1396835035391963
Loss at iteration [20]: 1.1312759249783555
Loss at iteration [21]: 1.1182192379023386
Loss at iteration [22]: 1.1182192379023386
Loss at iteration [23]: 1.1126813309695127
Loss at iteration [24]: 1.1057685885459791
Loss at iteration [25]: 1.098056344124906
Loss at iteration [26]: 1.0936825783443014
Loss at iteration [27]: 1.0881313892806768
Loss at iteration [28]: 1.0785586260051745
Loss at iteration [29]: 1.074741960870346
Loss at iteration [30]: 1.074741960870346
Loss at iteration [31]: 1.0706162473796355
Loss at iteration [32]: 1.0641763237713355
Loss at iteration [33]: 1.0623948362718059
Loss at iteration [34]: 1.0564931127662731
Loss at iteration [35]: 1.0536433409306696
Loss at iteration [36]: 1.0478385954462692
Loss at iteration [37]: 1.0443849358737132
Loss at iteration [38]: 1.0443849358737132
Loss at iteration [39]: 1.043137581654248
Loss at iteration [40]: 1.0390237257024966
Loss at iteration [41]: 1.0370517250482305
Loss at iteration [42]: 1.0285798930099335
Loss at iteration [43]: 1.026474866561006
Loss at iteration [44]: 1.0118948314776641
Loss at iteration [45]: 1.0118948314776641
Loss at iteration [46]: 1.0095698832240323
Loss at iteration [47]: 1.0046332505318214
Loss at iteration [48]: 0.9984248718683655
Loss at iteration [49]: 0.9931878973117263
Loss at iteration [50]: 0.9901713945623578
Loss at iteration [51]: 0.9838378962724531
Loss at iteration [52]: 0.9825361970929216
Loss at iteration [53]: 0.9825361970929216
Loss at iteration [54]: 0.9816473682904955
Loss at iteration [55]: 0.9796483205336945
Loss at iteration [56]: 0.9768333879034726
Loss at iteration [57]: 0.9737642027232639
Loss at iteration [58]: 0.97189396228534
Loss at iteration [59]: 0.9698359392263132
Loss at iteration [60]: 0.9698359392263132
Loss at iteration [61]: 0.9687952844618257
Loss at iteration [62]: 0.9671548631192814
Loss at iteration [63]: 0.9659538371243449
Loss at iteration [64]: 0.9647367452919002
Loss at iteration [65]: 0.9635338358971733
Loss at iteration [66]: 0.9613409209356475
Loss at iteration [67]: 0.9480552451098219
Loss at iteration [68]: 0.9480552451098219
Loss at iteration [69]: 0.9438334849322653
Loss at iteration [70]: 0.9358986994118017
Loss at iteration [71]: 0.9312835379613291
Loss at iteration [72]: 0.9291122166461475
Loss at iteration [73]: 0.9283199101447377
Loss at iteration [74]: 0.926954996412312
Loss at iteration [75]: 0.9258872018342765
Loss at iteration [76]: 0.9258872018342765
Loss at iteration [77]: 0.9252001210802643
Loss at iteration [78]: 0.9235396652836785
Loss at iteration [79]: 0.9225413926899602
Loss at iteration [80]: 0.9206081494669653
Loss at iteration [81]: 0.9190976631708251
Loss at iteration [82]: 0.9165748257501253
Loss at iteration [83]: 0.9139463295983071
Loss at iteration [84]: 0.9043654930265852
Loss at iteration [85]: 0.9043654930265852
Loss at iteration [86]: 0.9027056217102339
Loss at iteration [87]: 0.8968328187581224
Loss at iteration [88]: 0.8925772608214536
Loss at iteration [89]: 0.8905648227490356
Loss at iteration [90]: 0.8872953388687361
Loss at iteration [91]: 0.8860750668223136
Loss at iteration [92]: 0.8819243266420568
Loss at iteration [93]: 0.8812021251697462
Loss at iteration [94]: 0.8771494947609907
Loss at iteration [95]: 0.8771494947609907
Loss at iteration [96]: 0.8761683590875092
Loss at iteration [97]: 0.8728929447558865
Loss at iteration [98]: 0.872160025310212
Loss at iteration [99]: 0.8689512365760823
Loss at iteration [100]: 0.8670977106804492
Loss at iteration [101]: 0.8655996890370969
Loss at iteration [102]: 0.8628167721829411
Loss at iteration [103]: 0.861764990429986
Loss at iteration [104]: 0.861764990429986
Loss at iteration [105]: 0.8593712152768432
Loss at iteration [106]: 0.8565406000547896
Loss at iteration [107]: 0.85506083157964
Loss at iteration [108]: 0.8530121515559084
Loss at iteration [109]: 0.8524056078329965
Loss at iteration [110]: 0.8512643363069141
Loss at iteration [111]: 0.8492966194420983
Loss at iteration [112]: 0.8484626583439229
Loss at iteration [113]: 0.8484626583439229
Loss at iteration [114]: 0.8477085317158981
Loss at iteration [115]: 0.8462906120515797
Loss at iteration [116]: 0.8458766140041896
Loss at iteration [117]: 0.8450498668553408
Loss at iteration [118]: 0.8447415696813911
Loss at iteration [119]: 0.8440055450746065
Loss at iteration [120]: 0.8434522619653864
Loss at iteration [121]: 0.842361228252339
Loss at iteration [122]: 0.842361228252339
Loss at iteration [123]: 0.8418134738993578
Loss at iteration [124]: 0.8406295144833199
Loss at iteration [125]: 0.8404016729882666
Loss at iteration [126]: 0.8399716792464902
Loss at iteration [127]: 0.8395080073748264
Loss at iteration [128]: 0.8390634326128256
Loss at iteration [129]: 0.8387701829687075
Loss at iteration [130]: 0.8383893343690992
Loss at iteration [131]: 0.83681623552432
Loss at iteration [132]: 0.83681623552432
Loss at iteration [133]: 0.8360998038120837
Loss at iteration [134]: 0.8352976152409105
Loss at iteration [135]: 0.8350286015460707
Loss at iteration [136]: 0.8344952377257246
Loss at iteration [137]: 0.8343111953024903
Loss at iteration [138]: 0.8338076739669859
Loss at iteration [139]: 0.833286059934249
Loss at iteration [140]: 0.8322382324536924
Loss at iteration [141]: 0.8306489028811097
Loss at iteration [142]: 0.8306489028811097
Loss at iteration [143]: 0.8302273121281367
Loss at iteration [144]: 0.829230948375752
Loss at iteration [145]: 0.8288420308058208
Loss at iteration [146]: 0.828407419303524
Loss at iteration [147]: 0.8278650384490855
Loss at iteration [148]: 0.8274686263755284
Loss at iteration [149]: 0.8269107143918257
Loss at iteration [150]: 0.8261454074656438
Loss at iteration [151]: 0.8261454074656438
Loss at iteration [152]: 0.8254573828596562
Loss at iteration [153]: 0.8251284576811954
Loss at iteration [154]: 0.8247056341767842
Loss at iteration [155]: 0.8244052570153896
Loss at iteration [156]: 0.8242518422702896
Loss at iteration [157]: 0.8239610991041767
Loss at iteration [158]: 0.823665430227319
Loss at iteration [159]: 0.8230179589439357
Loss at iteration [160]: 0.821734220305108
Loss at iteration [161]: 0.8191704967418099
Loss at iteration [162]: 0.8191704967418099
Loss at iteration [163]: 0.8180851725625343
Loss at iteration [164]: 0.8172777695325328
Loss at iteration [165]: 0.8167023358064327
Loss at iteration [166]: 0.8156450760629906
Loss at iteration [167]: 0.8152408197179111
Loss at iteration [168]: 0.8149685505614772
Loss at iteration [169]: 0.8142966042607153
Loss at iteration [170]: 0.8137968710957947
Loss at iteration [171]: 0.8134397744534079
Loss at iteration [172]: 0.812835522380594
Loss at iteration [173]: 0.812835522380594
Loss at iteration [174]: 0.8123942904041345
Loss at iteration [175]: 0.812205179725739
Loss at iteration [176]: 0.8118795452541081
Loss at iteration [177]: 0.8116316916091878
Loss at iteration [178]: 0.8113988622132734
Loss at iteration [179]: 0.8111455527127588
Loss at iteration [180]: 0.8107556425753201
Loss at iteration [181]: 0.8104974752825278
Loss at iteration [182]: 0.8102677908172439
Loss at iteration [183]: 0.8099288918105236
Loss at iteration [184]: 0.8099288918105236
Loss at iteration [185]: 0.8093369918473339
Loss at iteration [186]: 0.8089513103573357
Loss at iteration [187]: 0.8087042731520508
Loss at iteration [188]: 0.8085364115844216
Loss at iteration [189]: 0.8082643895835268
Loss at iteration [190]: 0.8079544913829402
Loss at iteration [191]: 0.80785944768722
Loss at iteration [192]: 0.8077428109351896
Loss at iteration [193]: 0.807674921194193
Loss at iteration [194]: 0.8075619221139354
Loss at iteration [195]: 0.8074467234572811
Loss at iteration [196]: 0.8074467234572811
Loss at iteration [197]: 0.8073208669519063
Loss at iteration [198]: 0.8072455875849425
Loss at iteration [199]: 0.8071741003858462
Loss at iteration [200]: 0.8071301406098723
Loss at iteration [201]: 0.8070669216564067
Loss at iteration [202]: 0.8070163379865609
Loss at iteration [203]: 0.8069704089566163
Loss at iteration [204]: 0.8069281896038527
Loss at iteration [205]: 0.8068749429232502
Loss at iteration [206]: 0.8068341570993486
Loss at iteration [207]: 0.806414463086382
Loss at iteration [208]: 0.805711773509993
Loss at iteration [209]: 0.7945092833784774
Loss at iteration [210]: 0.7945092833784774
Loss at iteration [211]: 0.7912267895913012
Loss at iteration [212]: 0.7889718665874391
Loss at iteration [213]: 0.7882440721781134
Loss at iteration [214]: 0.7872353041490034
Loss at iteration [215]: 0.7854579482097185
Loss at iteration [216]: 0.782952038431388
Loss at iteration [217]: 0.782220789096901
Loss at iteration [218]: 0.7809744851433353
Loss at iteration [219]: 0.7805952510978507
Loss at iteration [220]: 0.7805952510978507
Loss at iteration [221]: 0.7802735173522539
Loss at iteration [222]: 0.7797565784276411
Loss at iteration [223]: 0.7791219448208958
Loss at iteration [224]: 0.7785478521913072
Loss at iteration [225]: 0.7771770520700514
Loss at iteration [226]: 0.776512908509775
Loss at iteration [227]: 0.775505260830556
Loss at iteration [228]: 0.77456284004857
Loss at iteration [229]: 0.773772897089621
Loss at iteration [230]: 0.773772897089621
Loss at iteration [231]: 0.7732837527041662
Loss at iteration [232]: 0.7719501602362285
Loss at iteration [233]: 0.7716552684141054
Loss at iteration [234]: 0.7711568881244975
Loss at iteration [235]: 0.7707725608010573
Loss at iteration [236]: 0.770484717395467
Loss at iteration [237]: 0.7697845387746383
Loss at iteration [238]: 0.7693005772035035
Loss at iteration [239]: 0.768801951333148
Loss at iteration [240]: 0.768801951333148
Loss at iteration [241]: 0.7685923212664363
Loss at iteration [242]: 0.7683737846173836
Loss at iteration [243]: 0.7680484701118407
Loss at iteration [244]: 0.7679028263496963
Loss at iteration [245]: 0.7676317492833588
Loss at iteration [246]: 0.7670844450287531
Loss at iteration [247]: 0.7668680573549226
Loss at iteration [248]: 0.7667024411614825
Loss at iteration [249]: 0.7664880809970248
Loss at iteration [250]: 0.7664880809970248
Loss at iteration [251]: 0.7664002874074065
Loss at iteration [252]: 0.7663360767654824
Loss at iteration [253]: 0.7662906577930919
Loss at iteration [254]: 0.7662539775694069
Loss at iteration [255]: 0.766204399213784
Loss at iteration [256]: 0.7661625996822906
Loss at iteration [257]: 0.7660989766129933
Loss at iteration [258]: 0.7660437125475178
Loss at iteration [259]: 0.7659760797147727
Loss at iteration [260]: 0.765936612876111
Loss at iteration [261]: 0.7657834244511436
Loss at iteration [262]: 0.7655419495530906
Loss at iteration [263]: 0.7652590750978472
Loss at iteration [264]: 0.7651262590308661
Loss at iteration [265]: 0.764839760591984
Loss at iteration [266]: 0.764465646477289
Loss at iteration [267]: 0.764465646477289
Loss at iteration [268]: 0.7642848579726954
Loss at iteration [269]: 0.7641892020268428
Loss at iteration [270]: 0.764088982814593
Loss at iteration [271]: 0.7639816455782649
Loss at iteration [272]: 0.7638953388081308
Loss at iteration [273]: 0.7638286902450776
Loss at iteration [274]: 0.7637489798345214
Loss at iteration [275]: 0.763707262646249
Loss at iteration [276]: 0.7636436763848505
Loss at iteration [277]: 0.763594849339711
Loss at iteration [278]: 0.7635513649148701
Loss at iteration [279]: 0.7635165909167309
Loss at iteration [280]: 0.7634536351843015
Loss at iteration [281]: 0.763417216788521
Loss at iteration [282]: 0.763417216788521
Loss at iteration [283]: 0.763390583482695
Loss at iteration [284]: 0.763373392862835
Loss at iteration [285]: 0.7633661918829844
Loss at iteration [286]: 0.7633503576634326
Loss at iteration [287]: 0.7633124817742292
Loss at iteration [288]: 0.7632520693925138
Loss at iteration [289]: 0.7632083298631435
Loss at iteration [290]: 0.7631762122944552
Loss at iteration [291]: 0.7631341506946636
Loss at iteration [292]: 0.7630991149761829
Loss at iteration [293]: 0.7630229320831852
Loss at iteration [294]: 0.7629685886035514
Loss at iteration [295]: 0.7629268106042449
Loss at iteration [296]: 0.7628779766248084
Loss at iteration [297]: 0.7628318437791155
Loss at iteration [298]: 0.7627901617698786
Loss at iteration [299]: 0.7627408452833319
Loss at iteration [300]: 0.7626693301684832
Loss at iteration [301]: 0.7626184720167695
Loss at iteration [302]: 0.7625596168496898
Loss at iteration [303]: 0.7625596168496898
Loss at iteration [304]: 0.7625284427935913
Loss at iteration [305]: 0.7625122510178595
Loss at iteration [306]: 0.7624959729231825
Loss at iteration [307]: 0.7624871122239771
Loss at iteration [308]: 0.7624691567629484
Loss at iteration [309]: 0.7624638856135315
Loss at iteration [310]: 0.7624380893140389
Loss at iteration [311]: 0.7623878503462349
Loss at iteration [312]: 0.7623310129781149
Loss at iteration [313]: 0.7622863112648397
Loss at iteration [314]: 0.7622359984736921
Loss at iteration [315]: 0.7621538619354891
Loss at iteration [316]: 0.7620844453498521
Loss at iteration [317]: 0.7619969232889124
Loss at iteration [318]: 0.7619548894270612
Loss at iteration [319]: 0.7619040288621886
Loss at iteration [320]: 0.7618449885295273
Loss at iteration [321]: 0.761788599851469
Loss at iteration [322]: 0.7617320311115642
Loss at iteration [323]: 0.7616861152594331
Loss at iteration [324]: 0.7616861152594331
Loss at iteration [325]: 0.7616540910282845
Loss at iteration [326]: 0.7616442032156749
Loss at iteration [327]: 0.7616285741300008
Loss at iteration [328]: 0.7616149504930331
Loss at iteration [329]: 0.7616045525483206
Loss at iteration [330]: 0.7615839455393497
Loss at iteration [331]: 0.7615515856973603
Loss at iteration [332]: 0.7614958961169949
Loss at iteration [333]: 0.7614208057337627
Loss at iteration [334]: 0.7613763520903639
Loss at iteration [335]: 0.7613353733757914
Loss at iteration [336]: 0.7612716381709508
Loss at iteration [337]: 0.7612212106123596
Loss at iteration [338]: 0.7611658036813309
Loss at iteration [339]: 0.7611286954422898
Loss at iteration [340]: 0.7610723828972713
Loss at iteration [341]: 0.760998819532371
Loss at iteration [342]: 0.7609496147077146
Loss at iteration [343]: 0.7608976106910929
Loss at iteration [344]: 0.7608325554024213
Loss at iteration [345]: 0.7608325554024213
Loss at iteration [346]: 0.7607876022118546
Loss at iteration [347]: 0.7607698697284567
Loss at iteration [348]: 0.7607636057494721
Loss at iteration [349]: 0.7607506702121
Loss at iteration [350]: 0.7607329733306849
Loss at iteration [351]: 0.7607179299153032
Loss at iteration [352]: 0.7606900090838344
Loss at iteration [353]: 0.7606843994208385
Loss at iteration [354]: 0.7606364077416983
Loss at iteration [355]: 0.7605874218205124
Loss at iteration [356]: 0.7605347626209259
Loss at iteration [357]: 0.7605148239650841
Loss at iteration [358]: 0.7604674858753132
Loss at iteration [359]: 0.7604067157079774
Loss at iteration [360]: 0.7603436747558733
Loss at iteration [361]: 0.7602962618413264
Loss at iteration [362]: 0.7602416982224814
Loss at iteration [363]: 0.7602138571829217
Loss at iteration [364]: 0.7601544638741456
Loss at iteration [365]: 0.7600958696868204
Loss at iteration [366]: 0.7600958696868204
Loss at iteration [367]: 0.7600483973686708
Loss at iteration [368]: 0.7600367870364401
Loss at iteration [369]: 0.7600207563138697
Loss at iteration [370]: 0.7600154360883403
Loss at iteration [371]: 0.760002644410045
Loss at iteration [372]: 0.7599912538639346
Loss at iteration [373]: 0.7599908359395018
Loss at iteration [374]: 0.7599638990769514
Loss at iteration [375]: 0.7599012837433425
Loss at iteration [376]: 0.7598529849433219
Loss at iteration [377]: 0.7598054603972885
Loss at iteration [378]: 0.7597412959378192
Loss at iteration [379]: 0.7596816265417929
Loss at iteration [380]: 0.7596373720777118
Loss at iteration [381]: 0.7595848230620154
Loss at iteration [382]: 0.7595237841578574
Loss at iteration [383]: 0.7594622860357895
Loss at iteration [384]: 0.7593884094112708
Loss at iteration [385]: 0.7593417099984776
Loss at iteration [386]: 0.7593417099984776
Loss at iteration [387]: 0.7593083252776833
Loss at iteration [388]: 0.7592951652646912
Loss at iteration [389]: 0.7592827348983913
Loss at iteration [390]: 0.759273427746435
Loss at iteration [391]: 0.7592501184874844
Loss at iteration [392]: 0.7591906795612677
Loss at iteration [393]: 0.759153613861276
Loss at iteration [394]: 0.7591237649166254
Loss at iteration [395]: 0.7590693199989826
Loss at iteration [396]: 0.7589894218008911
Loss at iteration [397]: 0.7589503350745094
Loss at iteration [398]: 0.7589097328630097
Loss at iteration [399]: 0.7588718431441087
Loss at iteration [400]: 0.7588104008736626
Loss at iteration [401]: 0.7587608946096485
Loss at iteration [402]: 0.758701975150594
Loss at iteration [403]: 0.7586630597745158
Loss at iteration [404]: 0.7586242255311033
Loss at iteration [405]: 0.7585742456275818
Loss at iteration [406]: 0.7585366967303224
Loss at iteration [407]: 0.7585366967303224
Loss at iteration [408]: 0.7584947735654607
Loss at iteration [409]: 0.7584780585712154
Loss at iteration [410]: 0.7584688398554513
Loss at iteration [411]: 0.7584579079870936
Loss at iteration [412]: 0.7584369571570913
Loss at iteration [413]: 0.7584306028333003
Loss at iteration [414]: 0.7584119565279867
Loss at iteration [415]: 0.7583912685453287
Loss at iteration [416]: 0.7583727862239622
Loss at iteration [417]: 0.7583250025137107
Loss at iteration [418]: 0.7582530242026702
Loss at iteration [419]: 0.7582027318728004
Loss at iteration [420]: 0.7581539350817315
Loss at iteration [421]: 0.7581100838811234
Loss at iteration [422]: 0.7580527462947757
Loss at iteration [423]: 0.7579830560781067
Loss at iteration [424]: 0.7579358552342593
Loss at iteration [425]: 0.757901664148677
Loss at iteration [426]: 0.7578563225997864
Loss at iteration [427]: 0.7578563225997864
Loss at iteration [428]: 0.7578184387713132
Loss at iteration [429]: 0.757802222401049
Loss at iteration [430]: 0.7577973250005294
Loss at iteration [431]: 0.7577854135294929
Loss at iteration [432]: 0.7577660292482472
Loss at iteration [433]: 0.7577629151403559
Loss at iteration [434]: 0.7577467066790514
Loss at iteration [435]: 0.757714484396847
Loss at iteration [436]: 0.7576681395549191
Loss at iteration [437]: 0.7576017419147747
Loss at iteration [438]: 0.7575432282265865
Loss at iteration [439]: 0.7574988994644577
Loss at iteration [440]: 0.7574464693356113
Loss at iteration [441]: 0.7573992121766229
Loss at iteration [442]: 0.7573448540488347
Loss at iteration [443]: 0.7572691231859288
Loss at iteration [444]: 0.7572359097665843
Loss at iteration [445]: 0.7571821608889985
Loss at iteration [446]: 0.7571286304252226
Loss at iteration [447]: 0.7570493158292636
Loss at iteration [448]: 0.7570493158292636
Loss at iteration [449]: 0.757008743422747
Loss at iteration [450]: 0.7569914028503371
Loss at iteration [451]: 0.7569781643758516
Loss at iteration [452]: 0.7569670465272976
Loss at iteration [453]: 0.7569469049157436
Loss at iteration [454]: 0.7569277927629989
Loss at iteration [455]: 0.7569041664034201
Loss at iteration [456]: 0.7568683147229496
Loss at iteration [457]: 0.7568328721971341
Loss at iteration [458]: 0.7567999160401947
Loss at iteration [459]: 0.7567506079754152
Loss at iteration [460]: 0.756702176474262
Loss at iteration [461]: 0.7566746995257608
Loss at iteration [462]: 0.7566183462840312
Loss at iteration [463]: 0.7565684732324222
Loss at iteration [464]: 0.7565044153464846
Loss at iteration [465]: 0.7564649864768627
Loss at iteration [466]: 0.7564191008608997
Loss at iteration [467]: 0.756367202856305
Loss at iteration [468]: 0.7563218991155214
Loss at iteration [469]: 0.7563218991155214
Loss at iteration [470]: 0.7562911405391517
Loss at iteration [471]: 0.756281226899739
Loss at iteration [472]: 0.7562599178630702
Loss at iteration [473]: 0.7562441282444888
Loss at iteration [474]: 0.7562317591226376
Loss at iteration [475]: 0.7562157668641271
Loss at iteration [476]: 0.7562054639810235
Loss at iteration [477]: 0.7562049818386029
Loss at iteration [478]: 0.7561852330182134
Loss at iteration [479]: 0.7561353905153765
Loss at iteration [480]: 0.7560912929361976
Loss at iteration [481]: 0.7560254886785109
Loss at iteration [482]: 0.7559853549032094
Loss at iteration [483]: 0.7559324553665084
Loss at iteration [484]: 0.7558796804029962
Loss at iteration [485]: 0.7558454372268355
Loss at iteration [486]: 0.7557832322782788
Loss at iteration [487]: 0.7556786695019252
Loss at iteration [488]: 0.7556786695019252
Loss at iteration [489]: 0.7556369032576089
Loss at iteration [490]: 0.7556269622006793
Loss at iteration [491]: 0.7556106046117179
Loss at iteration [492]: 0.7555956617071461
Loss at iteration [493]: 0.7555794974898249
Loss at iteration [494]: 0.7555676457840119
Loss at iteration [495]: 0.7555583784387669
Loss at iteration [496]: 0.7555497375897717
Loss at iteration [497]: 0.7555284139159383
Loss at iteration [498]: 0.7554866786665926
Loss at iteration [499]: 0.7554015553373966
Loss at iteration [500]: 0.7553183159137044
Loss at iteration [501]: 0.7552321968446343
Loss at iteration [502]: 0.7551702814318593
Loss at iteration [503]: 0.7550207818150495
Loss at iteration [504]: 0.7549342968313675
Loss at iteration [505]: 0.7549173427422532
Loss at iteration [506]: 0.7549173427422532
Loss at iteration [507]: 0.7546132635417491
Loss at iteration [508]: 0.7545607271957536
Loss at iteration [509]: 0.75450480543994
Loss at iteration [510]: 0.7544558023307579
Loss at iteration [511]: 0.7544118441268275
Loss at iteration [512]: 0.7543882535654686
Loss at iteration [513]: 0.754371403708153
Loss at iteration [514]: 0.7543593527481026
Loss at iteration [515]: 0.754306226619397
Loss at iteration [516]: 0.7542570006075857
Loss at iteration [517]: 0.7542335124976871
Loss at iteration [518]: 0.7541977860298168
Loss at iteration [519]: 0.7541443563482921
Loss at iteration [520]: 0.7540649665177652
Loss at iteration [521]: 0.7540210447392176
Loss at iteration [522]: 0.7539847873195918
Loss at iteration [523]: 0.7539297791669088
Loss at iteration [524]: 0.7538636052780103
Loss at iteration [525]: 0.7538214721664441
Loss at iteration [526]: 0.7537742249721014
Loss at iteration [527]: 0.7537742249721014
Loss at iteration [528]: 0.7537196178327219
Loss at iteration [529]: 0.7537033428841694
Loss at iteration [530]: 0.7536768878800344
Loss at iteration [531]: 0.7536678654156035
Loss at iteration [532]: 0.7536508409921094
Loss at iteration [533]: 0.7536415910643283
Loss at iteration [534]: 0.7536280580168941
Loss at iteration [535]: 0.7536254750676669
Loss at iteration [536]: 0.7535990838847321
Loss at iteration [537]: 0.7535705559503174
Loss at iteration [538]: 0.7535122920476452
Loss at iteration [539]: 0.753427421736607
Loss at iteration [540]: 0.7533239162160409
Loss at iteration [541]: 0.7532593420329925
Loss at iteration [542]: 0.7532023842422064
Loss at iteration [543]: 0.7531160964383145
Loss at iteration [544]: 0.7530276249623479
Loss at iteration [545]: 0.752949993977049
Loss at iteration [546]: 0.752949993977049
Loss at iteration [547]: 0.7528962152062102
Loss at iteration [548]: 0.7528832569258463
Loss at iteration [549]: 0.7528742673306789
Loss at iteration [550]: 0.7528582915067484
Loss at iteration [551]: 0.7528531517198849
Loss at iteration [552]: 0.7528323842869764
Loss at iteration [553]: 0.75280201862771
Loss at iteration [554]: 0.7527563281157477
Loss at iteration [555]: 0.7527202286773181
Loss at iteration [556]: 0.7526592922081032
Loss at iteration [557]: 0.7525953591146683
Loss at iteration [558]: 0.7525131057867732
Loss at iteration [559]: 0.7524672436174252
Loss at iteration [560]: 0.7524019737977005
Loss at iteration [561]: 0.7523368796275827
Loss at iteration [562]: 0.7522929435217962
Loss at iteration [563]: 0.7522276823200537
Loss at iteration [564]: 0.7521572160111782
Loss at iteration [565]: 0.7521061802819753
Loss at iteration [566]: 0.7520275288648323
Loss at iteration [567]: 0.7520275288648323
Loss at iteration [568]: 0.7519759927074413
Loss at iteration [569]: 0.7519557789937112
Loss at iteration [570]: 0.7519362755673262
Loss at iteration [571]: 0.7519199072842793
Loss at iteration [572]: 0.7519099583166147
Loss at iteration [573]: 0.7518886454708361
Loss at iteration [574]: 0.7518708130036666
Loss at iteration [575]: 0.7518516078955516
Loss at iteration [576]: 0.7518420935644967
Loss at iteration [577]: 0.751830708030116
Loss at iteration [578]: 0.7518144772282486
Loss at iteration [579]: 0.7517948451044838
Loss at iteration [580]: 0.751775691087147
Loss at iteration [581]: 0.7517566576808563
Loss at iteration [582]: 0.7517566576808563
Loss at iteration [583]: 0.7517021827729623
Loss at iteration [584]: 0.7516929644171111
Loss at iteration [585]: 0.7516788086774203
Loss at iteration [586]: 0.7516679297957223
Loss at iteration [587]: 0.751660877216091
Loss at iteration [588]: 0.7516542874454364
Loss at iteration [589]: 0.7516440778319631
Loss at iteration [590]: 0.7516296869978082
Loss at iteration [591]: 0.751621983915689
Loss at iteration [592]: 0.7516109891479998
Loss at iteration [593]: 0.751598739487385
Loss at iteration [594]: 0.7515909421780829
Loss at iteration [595]: 0.7515521327706127
Loss at iteration [596]: 0.7515521327706127
Loss at iteration [597]: 0.7515242609238473
Loss at iteration [598]: 0.7515144583696513
Loss at iteration [599]: 0.7515033514802577
Loss at iteration [600]: 0.7514829728867101
Loss at iteration [601]: 0.7514711486708858
Loss at iteration [602]: 0.751460185727827
Loss at iteration [603]: 0.7514545503436308
Loss at iteration [604]: 0.7514424451509366
Loss at iteration [605]: 0.751393971746946
Loss at iteration [606]: 0.751379167558238
Loss at iteration [607]: 0.7513474028770788
Loss at iteration [608]: 0.7513312733713997
Loss at iteration [609]: 0.7513118100212008
Loss at iteration [610]: 0.751295346930599
Loss at iteration [611]: 0.7512950193758059
Loss at iteration [612]: 0.7512950193758059
Loss at iteration [613]: 0.7512475648846629
Loss at iteration [614]: 0.7512396571675993
Loss at iteration [615]: 0.751230218825352
Loss at iteration [616]: 0.7512233626336688
Loss at iteration [617]: 0.7512183229069006
Loss at iteration [618]: 0.7512128138101181
Loss at iteration [619]: 0.7512042172338307
Loss at iteration [620]: 0.751191955279389
Loss at iteration [621]: 0.7511862628282341
Loss at iteration [622]: 0.7511766768679274
Loss at iteration [623]: 0.7511609375925986
Loss at iteration [624]: 0.751148160888552
Loss at iteration [625]: 0.751148160888552
Loss at iteration [626]: 0.7511347035470304
Loss at iteration [627]: 0.7511296712996585
Loss at iteration [628]: 0.7511256347895786
Loss at iteration [629]: 0.7511235884028439
Loss at iteration [630]: 0.7511162550486493
Loss at iteration [631]: 0.7511075715732676
Loss at iteration [632]: 0.7510992997878556
Loss at iteration [633]: 0.7510898442792127
Loss at iteration [634]: 0.751058591873407
Loss at iteration [635]: 0.7509938519251692
Loss at iteration [636]: 0.750887223484581
Loss at iteration [637]: 0.7504462796501808
Loss at iteration [638]: 0.7495815144180479
Loss at iteration [639]: 0.7495815144180479
Loss at iteration [640]: 0.7491185541982146
Loss at iteration [641]: 0.7488102218824866
Loss at iteration [642]: 0.748711092426102
Loss at iteration [643]: 0.7485689870496559
Loss at iteration [644]: 0.748488683312587
Loss at iteration [645]: 0.7484192384618279
Loss at iteration [646]: 0.7483572871504838
Loss at iteration [647]: 0.7483202132155291
Loss at iteration [648]: 0.7482659946814938
Loss at iteration [649]: 0.7481844165334801
Loss at iteration [650]: 0.7481519114676677
Loss at iteration [651]: 0.7481211317900979
Loss at iteration [652]: 0.7480645312870335
Loss at iteration [653]: 0.7480027339050738
Loss at iteration [654]: 0.7479325105312233
Loss at iteration [655]: 0.7478753665116362
Loss at iteration [656]: 0.7478379385445315
Loss at iteration [657]: 0.7478037324111395
Loss at iteration [658]: 0.747759964039196
Loss at iteration [659]: 0.7476913331241409
Loss at iteration [660]: 0.7476913331241409
Loss at iteration [661]: 0.7476455694389111
Loss at iteration [662]: 0.7476338348480074
Loss at iteration [663]: 0.7476192100214832
Loss at iteration [664]: 0.7475998945816259
Loss at iteration [665]: 0.7475693755579156
Loss at iteration [666]: 0.7475614934927094
Loss at iteration [667]: 0.7475180088483626
Loss at iteration [668]: 0.7474533905077154
Loss at iteration [669]: 0.747417815818952
Loss at iteration [670]: 0.7473558019365021
Loss at iteration [671]: 0.7473335342210494
Loss at iteration [672]: 0.7473049351755201
Loss at iteration [673]: 0.7472562404212866
Loss at iteration [674]: 0.7472071875031739
Loss at iteration [675]: 0.7471492846396448
Loss at iteration [676]: 0.7471184352576065
Loss at iteration [677]: 0.7470491754792238
Loss at iteration [678]: 0.7469697217812328
Loss at iteration [679]: 0.7468680974546099
Loss at iteration [680]: 0.7468135398445287
Loss at iteration [681]: 0.7468135398445287
Loss at iteration [682]: 0.7467439890939678
Loss at iteration [683]: 0.7467290533559745
Loss at iteration [684]: 0.7467146774704475
Loss at iteration [685]: 0.7466887365129244
Loss at iteration [686]: 0.7466685036481183
Loss at iteration [687]: 0.7466175332327355
Loss at iteration [688]: 0.7465725850018713
Loss at iteration [689]: 0.7465260214002258
Loss at iteration [690]: 0.7464726077744067
Loss at iteration [691]: 0.7463980274489469
Loss at iteration [692]: 0.746361843004062
Loss at iteration [693]: 0.7462965009869242
Loss at iteration [694]: 0.7462521227292077
Loss at iteration [695]: 0.7462092927371042
Loss at iteration [696]: 0.7461497882410414
Loss at iteration [697]: 0.7461266358563102
Loss at iteration [698]: 0.7460838608846645
Loss at iteration [699]: 0.746027958534011
Loss at iteration [700]: 0.7459694246891135
Loss at iteration [701]: 0.7459344584027626
Loss at iteration [702]: 0.7459344584027626
Loss at iteration [703]: 0.745899477139539
Loss at iteration [704]: 0.7458814755193454
Loss at iteration [705]: 0.7458672192506834
Loss at iteration [706]: 0.7458561825364424
Loss at iteration [707]: 0.7458488887367536
Loss at iteration [708]: 0.7458362580585622
Loss at iteration [709]: 0.7458252493113726
Loss at iteration [710]: 0.7458157660794176
Loss at iteration [711]: 0.7458011498695392
Loss at iteration [712]: 0.7457522252364375
Loss at iteration [713]: 0.7456947901236515
Loss at iteration [714]: 0.7456299302557062
Loss at iteration [715]: 0.7455727607095575
Loss at iteration [716]: 0.7452616432180044
Loss at iteration [717]: 0.7440199694967911
Loss at iteration [718]: 0.7440199694967911
Loss at iteration [719]: 0.7432539751427873
Loss at iteration [720]: 0.7425387412475148
Loss at iteration [721]: 0.7422718306250987
Loss at iteration [722]: 0.7419799498152128
Loss at iteration [723]: 0.7417511356766169
Loss at iteration [724]: 0.7414952296600231
Loss at iteration [725]: 0.7412695265129328
Loss at iteration [726]: 0.7410667927193341
Loss at iteration [727]: 0.7410073759196896
Loss at iteration [728]: 0.7409349541936024
Loss at iteration [729]: 0.7408318153884343
Loss at iteration [730]: 0.7408318153884343
Loss at iteration [731]: 0.740786267610819
Loss at iteration [732]: 0.740758694267322
Loss at iteration [733]: 0.7407344081594435
Loss at iteration [734]: 0.7406854855572548
Loss at iteration [735]: 0.7405997149917802
Loss at iteration [736]: 0.7405497134395878
Loss at iteration [737]: 0.7404977839017759
Loss at iteration [738]: 0.7404391132886371
Loss at iteration [739]: 0.7403633789133524
Loss at iteration [740]: 0.7403504028687093
Loss at iteration [741]: 0.7403005431123738
Loss at iteration [742]: 0.7402331121005352
Loss at iteration [743]: 0.7401907360849765
Loss at iteration [744]: 0.7401421813701785
Loss at iteration [745]: 0.7400929893183616
Loss at iteration [746]: 0.740051782301121
Loss at iteration [747]: 0.7400138986825533
Loss at iteration [748]: 0.7399595539652658
Loss at iteration [749]: 0.7399331485825524
Loss at iteration [750]: 0.739888951062464
Loss at iteration [751]: 0.739888951062464
Loss at iteration [752]: 0.7398377922232515
Loss at iteration [753]: 0.739818339089554
Loss at iteration [754]: 0.739812126772595
Loss at iteration [755]: 0.7398063892926252
Loss at iteration [756]: 0.7398003666266926
Loss at iteration [757]: 0.7397841811248665
Loss at iteration [758]: 0.7397291421847839
Loss at iteration [759]: 0.7396598397189302
Loss at iteration [760]: 0.739640146973145
Loss at iteration [761]: 0.7395897514742433
Loss at iteration [762]: 0.7395633927934296
Loss at iteration [763]: 0.7394984503855614
Loss at iteration [764]: 0.7394363545248692
Loss at iteration [765]: 0.739383725820095
Loss at iteration [766]: 0.7393359081869008
Loss at iteration [767]: 0.7392838164481141
Loss at iteration [768]: 0.7392358166644277
Loss at iteration [769]: 0.7391857171982155
Loss at iteration [770]: 0.7391308090801527
Loss at iteration [771]: 0.739091440066457
Loss at iteration [772]: 0.739091440066457
Loss at iteration [773]: 0.7390412508683095
Loss at iteration [774]: 0.7390261972509206
Loss at iteration [775]: 0.7390076197047539
Loss at iteration [776]: 0.7389972085538901
Loss at iteration [777]: 0.7389797759742662
Loss at iteration [778]: 0.738972303237577
Loss at iteration [779]: 0.7389719401447568
Loss at iteration [780]: 0.7389595342463231
Loss at iteration [781]: 0.738917958043773
Loss at iteration [782]: 0.7388527413836067
Loss at iteration [783]: 0.7388157050493938
Loss at iteration [784]: 0.7387665527198675
Loss at iteration [785]: 0.7387206645353378
Loss at iteration [786]: 0.7386662524531982
Loss at iteration [787]: 0.7385603429453841
Loss at iteration [788]: 0.738461537365496
Loss at iteration [789]: 0.7383949602249801
Loss at iteration [790]: 0.7382868295353362
Loss at iteration [791]: 0.7381892516488965
Loss at iteration [792]: 0.7381892516488965
Loss at iteration [793]: 0.7381678648939582
Loss at iteration [794]: 0.7381500882156106
Loss at iteration [795]: 0.7381148519458299
Loss at iteration [796]: 0.7380917223826194
Loss at iteration [797]: 0.7380715041169918
Loss at iteration [798]: 0.738051237648365
Loss at iteration [799]: 0.7380223496025937
Loss at iteration [800]: 0.7379725798211779
Loss at iteration [801]: 0.7379083174059103
Loss at iteration [802]: 0.7378477380698568
Loss at iteration [803]: 0.7378025868038843
Loss at iteration [804]: 0.7377565634795794
Loss at iteration [805]: 0.7377023351869889
Loss at iteration [806]: 0.7376226938322792
Loss at iteration [807]: 0.7375652671037529
Loss at iteration [808]: 0.7375214592870971
Loss at iteration [809]: 0.7374742084195326
Loss at iteration [810]: 0.737416388799626
Loss at iteration [811]: 0.7373897668407268
Loss at iteration [812]: 0.7373474202356661
Loss at iteration [813]: 0.7373474202356661
Loss at iteration [814]: 0.7372869660771757
Loss at iteration [815]: 0.7372554540251651
Loss at iteration [816]: 0.7372451354656201
Loss at iteration [817]: 0.7372426463151275
Loss at iteration [818]: 0.7372206005384196
Loss at iteration [819]: 0.7372093892755667
Loss at iteration [820]: 0.7371679486206301
Loss at iteration [821]: 0.7371393121788535
Loss at iteration [822]: 0.7370767680025895
Loss at iteration [823]: 0.7370305114210868
Loss at iteration [824]: 0.73698458729332
Loss at iteration [825]: 0.736930261191337
Loss at iteration [826]: 0.7368646801355239
Loss at iteration [827]: 0.7368132619409895
Loss at iteration [828]: 0.736738933273847
Loss at iteration [829]: 0.7367037584618312
Loss at iteration [830]: 0.7366359270110077
Loss at iteration [831]: 0.7365597750106789
Loss at iteration [832]: 0.7365070965545971
Loss at iteration [833]: 0.7364483268000837
Loss at iteration [834]: 0.7364483268000837
Loss at iteration [835]: 0.736429897831581
Loss at iteration [836]: 0.7364140009407208
Loss at iteration [837]: 0.7363941570814181
Loss at iteration [838]: 0.7363758207901785
Loss at iteration [839]: 0.7363632941199554
Loss at iteration [840]: 0.7363371851847362
Loss at iteration [841]: 0.7363186678580984
Loss at iteration [842]: 0.7362688554345438
Loss at iteration [843]: 0.7362201776469433
Loss at iteration [844]: 0.7361446581986699
Loss at iteration [845]: 0.7360887541620152
Loss at iteration [846]: 0.7360218728184156
Loss at iteration [847]: 0.7359627113029912
Loss at iteration [848]: 0.7358809050667846
Loss at iteration [849]: 0.7358116970870984
Loss at iteration [850]: 0.7357563397709181
Loss at iteration [851]: 0.7356987116895901
Loss at iteration [852]: 0.735636845529711
Loss at iteration [853]: 0.7355693068495025
Loss at iteration [854]: 0.7355423114117993
Loss at iteration [855]: 0.7355423114117993
Loss at iteration [856]: 0.7355086955199555
Loss at iteration [857]: 0.7354981540498386
Loss at iteration [858]: 0.7354715289155245
Loss at iteration [859]: 0.7354662363313653
Loss at iteration [860]: 0.7354423103143816
Loss at iteration [861]: 0.7354266870808848
Loss at iteration [862]: 0.7354129993672256
Loss at iteration [863]: 0.7353957867347404
Loss at iteration [864]: 0.7353844385751813
Loss at iteration [865]: 0.7353668833693775
Loss at iteration [866]: 0.7353561288669398
Loss at iteration [867]: 0.7353421006319625
Loss at iteration [868]: 0.7353268199194223
Loss at iteration [869]: 0.7353268199194223
Loss at iteration [870]: 0.735315394356236
Loss at iteration [871]: 0.7353111459206532
Loss at iteration [872]: 0.735310093953908
Loss at iteration [873]: 0.735302364105213
Loss at iteration [874]: 0.7352924266928663
Loss at iteration [875]: 0.7352849762752611
Loss at iteration [876]: 0.7352784045841866
Loss at iteration [877]: 0.7352687525029291
Loss at iteration [878]: 0.7352650420194397
Loss at iteration [879]: 0.7352375442127598
Loss at iteration [880]: 0.7351919165954451
Loss at iteration [881]: 0.7351039745835722
Loss at iteration [882]: 0.7350452915931677
Loss at iteration [883]: 0.7349777178180464
Loss at iteration [884]: 0.734905358029181
Loss at iteration [885]: 0.7348286700540687
Loss at iteration [886]: 0.7348286700540687
Loss at iteration [887]: 0.7347719249623805
Loss at iteration [888]: 0.7347503796243661
Loss at iteration [889]: 0.7347458647463799
Loss at iteration [890]: 0.7347329914681948
Loss at iteration [891]: 0.7347181404623294
Loss at iteration [892]: 0.734694660190935
Loss at iteration [893]: 0.7346745170848062
Loss at iteration [894]: 0.7346560866727279
Loss at iteration [895]: 0.7346482180305552
Loss at iteration [896]: 0.7346336694127569
Loss at iteration [897]: 0.7346247627501358
Loss at iteration [898]: 0.7346091696969036
Loss at iteration [899]: 0.7345952335133701
Loss at iteration [900]: 0.7345952335133701
Loss at iteration [901]: 0.7345840521987561
Loss at iteration [902]: 0.7345797858089415
Loss at iteration [903]: 0.7345730109715449
Loss at iteration [904]: 0.7345718007992531
Loss at iteration [905]: 0.7345665790419125
Loss at iteration [906]: 0.7345608238988163
Loss at iteration [907]: 0.7345502250757251
Loss at iteration [908]: 0.7345359089566417
Loss at iteration [909]: 0.7345239010413155
Loss at iteration [910]: 0.7345095891851476
Loss at iteration [911]: 0.7344956681371879
Loss at iteration [912]: 0.7344917566834575
Loss at iteration [913]: 0.7344264351971672
Loss at iteration [914]: 0.7344264351971672
Loss at iteration [915]: 0.7343798134894449
Loss at iteration [916]: 0.734362450851724
Loss at iteration [917]: 0.7343469192532113
Loss at iteration [918]: 0.7343353181278673
Loss at iteration [919]: 0.7343202221694637
Loss at iteration [920]: 0.7343112164882116
Loss at iteration [921]: 0.734303255371102
Loss at iteration [922]: 0.7342938206278026
Loss at iteration [923]: 0.7342845636306825
Loss at iteration [924]: 0.7342769627348381
Loss at iteration [925]: 0.7342706600818054
Loss at iteration [926]: 0.7342585686613676
Loss at iteration [927]: 0.7342439537268608
Loss at iteration [928]: 0.7342439537268608
Loss at iteration [929]: 0.73423140838611
Loss at iteration [930]: 0.7342280550685332
Loss at iteration [931]: 0.7342256650099247
Loss at iteration [932]: 0.7342210631587072
Loss at iteration [933]: 0.7342118635544357
Loss at iteration [934]: 0.7342086566532471
Loss at iteration [935]: 0.7342018241235825
Loss at iteration [936]: 0.7341897285175
Loss at iteration [937]: 0.7341759386905622
Loss at iteration [938]: 0.7341740025342912
Loss at iteration [939]: 0.7341404471045105
Loss at iteration [940]: 0.7340576554562618
Loss at iteration [941]: 0.7336203221955716
Loss at iteration [942]: 0.7313459877149381
Loss at iteration [943]: 0.7313459877149381
Loss at iteration [944]: 0.730348740008811
Loss at iteration [945]: 0.7295446494003351
Loss at iteration [946]: 0.7291013310865149
Loss at iteration [947]: 0.7287980811918093
Loss at iteration [948]: 0.7286358164693639
Loss at iteration [949]: 0.7284623309031047
Loss at iteration [950]: 0.7282507315911019
Loss at iteration [951]: 0.7281208303900035
Loss at iteration [952]: 0.7280174999798036
Loss at iteration [953]: 0.7278883761417806
Loss at iteration [954]: 0.7278039677908921
Loss at iteration [955]: 0.7277373818274451
Loss at iteration [956]: 0.7276619649182356
Loss at iteration [957]: 0.7276217982601221
Loss at iteration [958]: 0.7276217982601221
Loss at iteration [959]: 0.7275665548559156
Loss at iteration [960]: 0.7275506595065875
Loss at iteration [961]: 0.7275220001804401
Loss at iteration [962]: 0.727479960433743
Loss at iteration [963]: 0.7274580719045419
Loss at iteration [964]: 0.7274075193464067
Loss at iteration [965]: 0.7273354011098693
Loss at iteration [966]: 0.7272995134332759
Loss at iteration [967]: 0.7272452437694799
Loss at iteration [968]: 0.7271762055520399
Loss at iteration [969]: 0.7271534770344923
Loss at iteration [970]: 0.7271084158722673
Loss at iteration [971]: 0.7270496728945287
Loss at iteration [972]: 0.7269807054771461
Loss at iteration [973]: 0.7269448552001686
Loss at iteration [974]: 0.7268937147641349
Loss at iteration [975]: 0.7268069418743848
Loss at iteration [976]: 0.726770561108506
Loss at iteration [977]: 0.7267105779361175
Loss at iteration [978]: 0.7266718875622012
Loss at iteration [979]: 0.7266718875622012
Loss at iteration [980]: 0.726625500912447
Loss at iteration [981]: 0.7266102568070861
Loss at iteration [982]: 0.7265927168735754
Loss at iteration [983]: 0.7265742448943242
Loss at iteration [984]: 0.7265626108702965
Loss at iteration [985]: 0.72654720513536
Loss at iteration [986]: 0.7265293574744042
Loss at iteration [987]: 0.7265293426564776
Loss at iteration [988]: 0.7264966575184612
Loss at iteration [989]: 0.7264294845573624
Loss at iteration [990]: 0.7263742599452448
Loss at iteration [991]: 0.7263133428931305
Loss at iteration [992]: 0.7262429903466858
Loss at iteration [993]: 0.7262241998720815
Loss at iteration [994]: 0.7261657295436378
Loss at iteration [995]: 0.7260904768001182
Loss at iteration [996]: 0.7260658073390669
Loss at iteration [997]: 0.7260319410874664
Loss at iteration [998]: 0.7260319410874664
Loss at iteration [999]: 0.7259850572887531
Loss at iteration [1000]: 0.7259540977565397
Loss at iteration [1001]: 0.7259486179718457
Loss at iteration [1002]: 0.7259274232735777
Loss at iteration [1003]: 0.7259079218241876
Loss at iteration [1004]: 0.7258922268505583
Loss at iteration [1005]: 0.7258717713089105
Loss at iteration [1006]: 0.7258606701286358
Loss at iteration [1007]: 0.7258527751993481
Loss at iteration [1008]: 0.7258415500967398
Loss at iteration [1009]: 0.7258294993647109
Loss at iteration [1010]: 0.7258171973139269
Loss at iteration [1011]: 0.7258137836956611
Loss at iteration [1012]: 0.7258137836956611
Loss at iteration [1013]: 0.7257696177501936
Loss at iteration [1014]: 0.7257628748773747
Loss at iteration [1015]: 0.7257569870313062
Loss at iteration [1016]: 0.7257464197699659
Loss at iteration [1017]: 0.7257373273920096
Loss at iteration [1018]: 0.7257357573785546
Loss at iteration [1019]: 0.7257206972908686
Loss at iteration [1020]: 0.7257135322296631
Loss at iteration [1021]: 0.725697775132954
Loss at iteration [1022]: 0.7256877956370942
Loss at iteration [1023]: 0.7256719990820308
Loss at iteration [1024]: 0.7256548419192962
Loss at iteration [1025]: 0.7256300305936028
Loss at iteration [1026]: 0.7256300305936028
Loss at iteration [1027]: 0.7255861090390672
Loss at iteration [1028]: 0.7255766315995165
Loss at iteration [1029]: 0.7255569928997828
Loss at iteration [1030]: 0.7255413894843407
Loss at iteration [1031]: 0.7255301392034884
Loss at iteration [1032]: 0.7255162992562932
Loss at iteration [1033]: 0.7255043198272232
Loss at iteration [1034]: 0.7254918481794793
Loss at iteration [1035]: 0.7254840243035642
Loss at iteration [1036]: 0.725473997678479
Loss at iteration [1037]: 0.7254653154323067
Loss at iteration [1038]: 0.7254526143812139
Loss at iteration [1039]: 0.7254410011895048
Loss at iteration [1040]: 0.7254410011895048
Loss at iteration [1041]: 0.7254245741588607
Loss at iteration [1042]: 0.7254197949905308
Loss at iteration [1043]: 0.7254168670860907
Loss at iteration [1044]: 0.7254112142254038
Loss at iteration [1045]: 0.725399523203573
Loss at iteration [1046]: 0.7253938657010652
Loss at iteration [1047]: 0.725383528197151
Loss at iteration [1048]: 0.7253808335510761
Loss at iteration [1049]: 0.7253558685560367
Loss at iteration [1050]: 0.7252791390643535
Loss at iteration [1051]: 0.7252243617449774
Loss at iteration [1052]: 0.7251458951806811
Loss at iteration [1053]: 0.7250436381962028
Loss at iteration [1054]: 0.7249668381822183
Loss at iteration [1055]: 0.7248788362018006
Loss at iteration [1056]: 0.724797132173856
Loss at iteration [1057]: 0.7246971344303074
Loss at iteration [1058]: 0.7246971344303074
Loss at iteration [1059]: 0.7246398027555311
Loss at iteration [1060]: 0.7246215999021678
Loss at iteration [1061]: 0.7246076338258253
Loss at iteration [1062]: 0.7245875873272114
Loss at iteration [1063]: 0.7245686019095522
Loss at iteration [1064]: 0.7245551489139955
Loss at iteration [1065]: 0.7245396465799893
Loss at iteration [1066]: 0.7245281146321029
Loss at iteration [1067]: 0.7245118356727123
Loss at iteration [1068]: 0.7244983103683195
Loss at iteration [1069]: 0.7244829617855781
Loss at iteration [1070]: 0.7244791322855353
Loss at iteration [1071]: 0.7244401048178993
Loss at iteration [1072]: 0.7243927271793155
Loss at iteration [1073]: 0.7243927271793155
Loss at iteration [1074]: 0.724341274895972
Loss at iteration [1075]: 0.7243253456361582
Loss at iteration [1076]: 0.7242986191627017
Loss at iteration [1077]: 0.7242803555009878
Loss at iteration [1078]: 0.724259149863723
Loss at iteration [1079]: 0.7242514089458597
Loss at iteration [1080]: 0.724247207927684
Loss at iteration [1081]: 0.7242374154089914
Loss at iteration [1082]: 0.7242308027046083
Loss at iteration [1083]: 0.7242163292232925
Loss at iteration [1084]: 0.724207426246035
Loss at iteration [1085]: 0.7241929755391874
Loss at iteration [1086]: 0.7241929755391874
Loss at iteration [1087]: 0.7241751066972835
Loss at iteration [1088]: 0.7241710428141241
Loss at iteration [1089]: 0.7241689773361547
Loss at iteration [1090]: 0.724167371874876
Loss at iteration [1091]: 0.7241645990201512
Loss at iteration [1092]: 0.7241589046162022
Loss at iteration [1093]: 0.7241480858843398
Loss at iteration [1094]: 0.7241369616859241
Loss at iteration [1095]: 0.7241242288080355
Loss at iteration [1096]: 0.7241135781335949
Loss at iteration [1097]: 0.7241050059734854
Loss at iteration [1098]: 0.7240367197142609
Loss at iteration [1099]: 0.723949345123932
Loss at iteration [1100]: 0.7238919598924642
Loss at iteration [1101]: 0.7238919598924642
Loss at iteration [1102]: 0.7238459177514452
Loss at iteration [1103]: 0.7238314541597457
Loss at iteration [1104]: 0.723802984615007
Loss at iteration [1105]: 0.7237702612722677
Loss at iteration [1106]: 0.7237515567502628
Loss at iteration [1107]: 0.7237204937410046
Loss at iteration [1108]: 0.7237041140833396
Loss at iteration [1109]: 0.723691732347223
Loss at iteration [1110]: 0.7236775792034587
Loss at iteration [1111]: 0.7236687823955773
Loss at iteration [1112]: 0.7236420759902753
Loss at iteration [1113]: 0.7235939873016124
Loss at iteration [1114]: 0.7235446661457444
Loss at iteration [1115]: 0.7235093732586507
Loss at iteration [1116]: 0.723479175523174
Loss at iteration [1117]: 0.7234356454031756
Loss at iteration [1118]: 0.7233884192881379
Loss at iteration [1119]: 0.7233263846619895
Loss at iteration [1120]: 0.7233263846619895
Loss at iteration [1121]: 0.7232939389626497
Loss at iteration [1122]: 0.7232794377248851
Loss at iteration [1123]: 0.7232595967263301
Loss at iteration [1124]: 0.7232479533561361
Loss at iteration [1125]: 0.723234579331042
Loss at iteration [1126]: 0.7232278832560933
Loss at iteration [1127]: 0.72321604930381
Loss at iteration [1128]: 0.7232052500624737
Loss at iteration [1129]: 0.7231969538691876
Loss at iteration [1130]: 0.7231803741479748
Loss at iteration [1131]: 0.72316331528015
Loss at iteration [1132]: 0.7231579766248151
Loss at iteration [1133]: 0.7231249729371321
Loss at iteration [1134]: 0.7230520753797726
Loss at iteration [1135]: 0.7230520753797726
Loss at iteration [1136]: 0.7229993445478499
Loss at iteration [1137]: 0.7229784096464463
Loss at iteration [1138]: 0.7229617081944473
Loss at iteration [1139]: 0.7229442219960652
Loss at iteration [1140]: 0.7229260118567822
Loss at iteration [1141]: 0.7229131114328095
Loss at iteration [1142]: 0.7228972413454896
Loss at iteration [1143]: 0.7228869392687228
Loss at iteration [1144]: 0.7228790662522808
Loss at iteration [1145]: 0.7228672730073266
Loss at iteration [1146]: 0.7228603547906707
Loss at iteration [1147]: 0.7228467737407264
Loss at iteration [1148]: 0.722834190664432
Loss at iteration [1149]: 0.722834190664432
Loss at iteration [1150]: 0.7228079315527557
Loss at iteration [1151]: 0.7228056564722682
Loss at iteration [1152]: 0.7227995731281334
Loss at iteration [1153]: 0.7227943082504178
Loss at iteration [1154]: 0.7227889843442293
Loss at iteration [1155]: 0.722786326969249
Loss at iteration [1156]: 0.7227753081318237
Loss at iteration [1157]: 0.7227600581762949
Loss at iteration [1158]: 0.7227488405257284
Loss at iteration [1159]: 0.722739878599502
Loss at iteration [1160]: 0.7226981653281834
Loss at iteration [1161]: 0.7225870018279268
Loss at iteration [1162]: 0.7225038194099612
Loss at iteration [1163]: 0.7224395869807289
Loss at iteration [1164]: 0.7223864584009392
Loss at iteration [1165]: 0.7223864584009392
Loss at iteration [1166]: 0.7223234639574997
Loss at iteration [1167]: 0.7223121306407803
Loss at iteration [1168]: 0.7222942697273009
Loss at iteration [1169]: 0.7222750063030796
Loss at iteration [1170]: 0.7222578226248378
Loss at iteration [1171]: 0.7222466634385295
Loss at iteration [1172]: 0.7222317146768235
Loss at iteration [1173]: 0.7222282104055988
Loss at iteration [1174]: 0.7222176530319441
Loss at iteration [1175]: 0.7222048428549769
Loss at iteration [1176]: 0.7221896005378367
Loss at iteration [1177]: 0.7221718046489356
Loss at iteration [1178]: 0.7221548451500623
Loss at iteration [1179]: 0.7221548451500623
Loss at iteration [1180]: 0.7221351684876604
Loss at iteration [1181]: 0.722131556259983
Loss at iteration [1182]: 0.722123054362194
Loss at iteration [1183]: 0.7221161861484705
Loss at iteration [1184]: 0.7221099413968795
Loss at iteration [1185]: 0.722106787895571
Loss at iteration [1186]: 0.7220962177827603
Loss at iteration [1187]: 0.7220861290891735
Loss at iteration [1188]: 0.7220774253025869
Loss at iteration [1189]: 0.7220696785364173
Loss at iteration [1190]: 0.7220609198681616
Loss at iteration [1191]: 0.7220487107910666
Loss at iteration [1192]: 0.7220487107910666
Loss at iteration [1193]: 0.72203343060382
Loss at iteration [1194]: 0.722027867984142
Loss at iteration [1195]: 0.7220221140687948
Loss at iteration [1196]: 0.7220174673621267
Loss at iteration [1197]: 0.722014012616402
Loss at iteration [1198]: 0.7220089981712333
Loss at iteration [1199]: 0.7220040662978104
Loss at iteration [1200]: 0.7219980197610333
Loss at iteration [1201]: 0.7219863039138732
Loss at iteration [1202]: 0.7219746592028893
Loss at iteration [1203]: 0.721962800851481
Loss at iteration [1204]: 0.7219513520403448
Loss at iteration [1205]: 0.7219513520403448
Loss at iteration [1206]: 0.7219472519606541
Loss at iteration [1207]: 0.7219343262735402
Loss at iteration [1208]: 0.721905276809902
Loss at iteration [1209]: 0.7218851265334322
Loss at iteration [1210]: 0.7218658729577103
Loss at iteration [1211]: 0.721858225937128
Loss at iteration [1212]: 0.7218509614971237
Loss at iteration [1213]: 0.7218369690352741
Loss at iteration [1214]: 0.7218297873465032
Loss at iteration [1215]: 0.7218246030640925
Loss at iteration [1216]: 0.721815932554819
Loss at iteration [1217]: 0.7218104984824891
Loss at iteration [1218]: 0.7218017468296101
Loss at iteration [1219]: 0.7218017468296101
Loss at iteration [1220]: 0.7217913484770708
Loss at iteration [1221]: 0.7217890141746838
Loss at iteration [1222]: 0.7217847957613496
Loss at iteration [1223]: 0.7217820508447244
Loss at iteration [1224]: 0.7217775056323169
Loss at iteration [1225]: 0.7217725091359868
Loss at iteration [1226]: 0.7217684525605252
Loss at iteration [1227]: 0.7217562261597902
Loss at iteration [1228]: 0.7217422087735765
Loss at iteration [1229]: 0.7217323583290085
Loss at iteration [1230]: 0.7217222683339115
Loss at iteration [1231]: 0.7216802019315403
Loss at iteration [1232]: 0.7216226223297317
Loss at iteration [1233]: 0.7216226223297317
Loss at iteration [1234]: 0.7215821192430633
Loss at iteration [1235]: 0.7215643084566417
Loss at iteration [1236]: 0.7215332143254445
Loss at iteration [1237]: 0.7215134512039223
Loss at iteration [1238]: 0.7214965999148768
Loss at iteration [1239]: 0.7214800143477464
Loss at iteration [1240]: 0.721466768201336
Loss at iteration [1241]: 0.7214515161632117
Loss at iteration [1242]: 0.7214395329320701
Loss at iteration [1243]: 0.7214311540429029
Loss at iteration [1244]: 0.7214151294903026
Loss at iteration [1245]: 0.7214073410019441
Loss at iteration [1246]: 0.7213935472542243
Loss at iteration [1247]: 0.7213935472542243
Loss at iteration [1248]: 0.7213774388413434
Loss at iteration [1249]: 0.7213680434799928
Loss at iteration [1250]: 0.7213658582687268
Loss at iteration [1251]: 0.7213646778449347
Loss at iteration [1252]: 0.7213568294662059
Loss at iteration [1253]: 0.7213488687886692
Loss at iteration [1254]: 0.7213438410120618
Loss at iteration [1255]: 0.7213382396558456
Loss at iteration [1256]: 0.7213258960112281
Loss at iteration [1257]: 0.7213151437382131
Loss at iteration [1258]: 0.7213028167374194
Loss at iteration [1259]: 0.7212876056497048
Loss at iteration [1260]: 0.7212876056497048
Loss at iteration [1261]: 0.7212715242240597
Loss at iteration [1262]: 0.7212672396803036
Loss at iteration [1263]: 0.7212632659006057
Loss at iteration [1264]: 0.7212606040986385
Loss at iteration [1265]: 0.7212582617105139
Loss at iteration [1266]: 0.7212486802138871
Loss at iteration [1267]: 0.7212428858960366
Loss at iteration [1268]: 0.721233792154771
Loss at iteration [1269]: 0.7212197670577586
Loss at iteration [1270]: 0.7212154604445483
Loss at iteration [1271]: 0.721161864670499
Loss at iteration [1272]: 0.7210842089278249
Loss at iteration [1273]: 0.7210200015023136
Loss at iteration [1274]: 0.7209476455844235
Loss at iteration [1275]: 0.7209184456890669
Loss at iteration [1276]: 0.7208592401504684
Loss at iteration [1277]: 0.7208592401504684
Loss at iteration [1278]: 0.7207800752708177
Loss at iteration [1279]: 0.7207540583101856
Loss at iteration [1280]: 0.7207380746495804
Loss at iteration [1281]: 0.7207232607888253
Loss at iteration [1282]: 0.7207057579868676
Loss at iteration [1283]: 0.7206964032792148
Loss at iteration [1284]: 0.7206881299279605
Loss at iteration [1285]: 0.7206795105649026
Loss at iteration [1286]: 0.7206675649779847
Loss at iteration [1287]: 0.7206581868394079
Loss at iteration [1288]: 0.7206470584192303
Loss at iteration [1289]: 0.72064074282787
Loss at iteration [1290]: 0.7206062816708111
Loss at iteration [1291]: 0.720567096663753
Loss at iteration [1292]: 0.720567096663753
Loss at iteration [1293]: 0.7205278116732461
Loss at iteration [1294]: 0.7205161810813088
Loss at iteration [1295]: 0.7204731163246653
Loss at iteration [1296]: 0.7204579135660565
Loss at iteration [1297]: 0.7204504141105331
Loss at iteration [1298]: 0.7204371679499532
Loss at iteration [1299]: 0.7204257704524917
Loss at iteration [1300]: 0.7204132987012981
Loss at iteration [1301]: 0.7204024310363683
Loss at iteration [1302]: 0.7203895611075826
Loss at iteration [1303]: 0.7203827834025311
Loss at iteration [1304]: 0.7203721301871343
Loss at iteration [1305]: 0.7203580593053361
Loss at iteration [1306]: 0.7203580593053361
Loss at iteration [1307]: 0.7203436457775871
Loss at iteration [1308]: 0.7203411603840517
Loss at iteration [1309]: 0.720338157737329
Loss at iteration [1310]: 0.7203306540664194
Loss at iteration [1311]: 0.7203267094191625
Loss at iteration [1312]: 0.7203256622632287
Loss at iteration [1313]: 0.720319744814872
Loss at iteration [1314]: 0.7203128466475156
Loss at iteration [1315]: 0.7202993165357525
Loss at iteration [1316]: 0.7202885899663377
Loss at iteration [1317]: 0.7202758630177829
Loss at iteration [1318]: 0.7202573102401599
Loss at iteration [1319]: 0.7202573102401599
Loss at iteration [1320]: 0.7202425790756605
Loss at iteration [1321]: 0.7202345351092572
Loss at iteration [1322]: 0.7202314649272863
Loss at iteration [1323]: 0.720230403452688
Loss at iteration [1324]: 0.7202271820599682
Loss at iteration [1325]: 0.720222122638631
Loss at iteration [1326]: 0.7202179937466958
Loss at iteration [1327]: 0.7202083245080286
Loss at iteration [1328]: 0.7201972922610091
Loss at iteration [1329]: 0.7201870510410775
Loss at iteration [1330]: 0.7201687848741568
Loss at iteration [1331]: 0.7201548193486722
Loss at iteration [1332]: 0.7201548193486722
Loss at iteration [1333]: 0.7200976652385147
Loss at iteration [1334]: 0.7200861468773699
Loss at iteration [1335]: 0.7200764136532143
Loss at iteration [1336]: 0.7200725863837031
Loss at iteration [1337]: 0.7200691350220456
Loss at iteration [1338]: 0.7200590020992622
Loss at iteration [1339]: 0.7200470013013864
Loss at iteration [1340]: 0.7200352746475689
Loss at iteration [1341]: 0.7200277382919751
Loss at iteration [1342]: 0.7200127806884702
Loss at iteration [1343]: 0.7200092417039882
Loss at iteration [1344]: 0.71997943115195
Loss at iteration [1345]: 0.7199376138875824
Loss at iteration [1346]: 0.719868959752323
Loss at iteration [1347]: 0.719868959752323
Loss at iteration [1348]: 0.7198086215623996
Loss at iteration [1349]: 0.7197953964375609
Loss at iteration [1350]: 0.7197593740744975
Loss at iteration [1351]: 0.7197478355424174
Loss at iteration [1352]: 0.7197373968356348
Loss at iteration [1353]: 0.7197227529178011
Loss at iteration [1354]: 0.7197142766605034
Loss at iteration [1355]: 0.7197086531661998
Loss at iteration [1356]: 0.7196952263006555
Loss at iteration [1357]: 0.719686015299381
Loss at iteration [1358]: 0.7196776549214512
Loss at iteration [1359]: 0.7196688614682277
Loss at iteration [1360]: 0.7196593895626957
Loss at iteration [1361]: 0.7196593895626957
Loss at iteration [1362]: 0.7196439829256713
Loss at iteration [1363]: 0.719639419512434
Loss at iteration [1364]: 0.7196368007820931
Loss at iteration [1365]: 0.719631606040488
Loss at iteration [1366]: 0.7196303191845818
Loss at iteration [1367]: 0.7196239009032979
Loss at iteration [1368]: 0.7196179904800118
Loss at iteration [1369]: 0.7196105660704943
Loss at iteration [1370]: 0.7195979196813055
Loss at iteration [1371]: 0.7195873224850037
Loss at iteration [1372]: 0.7195730662028864
Loss at iteration [1373]: 0.7195605552308393
Loss at iteration [1374]: 0.7195605552308393
Loss at iteration [1375]: 0.7195380420974936
Loss at iteration [1376]: 0.7195331603114873
Loss at iteration [1377]: 0.7195241829461108
Loss at iteration [1378]: 0.7195183038091232
Loss at iteration [1379]: 0.7195144587025578
Loss at iteration [1380]: 0.7195136025695106
Loss at iteration [1381]: 0.719512840126617
Loss at iteration [1382]: 0.7195047056044558
Loss at iteration [1383]: 0.7194962957718237
Loss at iteration [1384]: 0.7194839971824191
Loss at iteration [1385]: 0.7194700620779461
Loss at iteration [1386]: 0.7194700620779461
Loss at iteration [1387]: 0.7194536095121594
Loss at iteration [1388]: 0.7194482923010159
Loss at iteration [1389]: 0.7194428523404747
Loss at iteration [1390]: 0.7194399196117162
Loss at iteration [1391]: 0.7194328565652595
Loss at iteration [1392]: 0.7194299057831106
Loss at iteration [1393]: 0.719420964827353
Loss at iteration [1394]: 0.7194083302214578
Loss at iteration [1395]: 0.7193979118351431
Loss at iteration [1396]: 0.7193856096454923
Loss at iteration [1397]: 0.7193719536437679
Loss at iteration [1398]: 0.7193268229870967
Loss at iteration [1399]: 0.7192421084916591
Loss at iteration [1400]: 0.7192421084916591
Loss at iteration [1401]: 0.7191981807873123
Loss at iteration [1402]: 0.7191760130522602
Loss at iteration [1403]: 0.719158142235437
Loss at iteration [1404]: 0.7191357386475141
Loss at iteration [1405]: 0.7191126345951877
Loss at iteration [1406]: 0.7191013732604962
Loss at iteration [1407]: 0.7190863503089743
Loss at iteration [1408]: 0.7190771540043267
Loss at iteration [1409]: 0.719062977473687
Loss at iteration [1410]: 0.7190482149854794
Loss at iteration [1411]: 0.7190392823804644
Loss at iteration [1412]: 0.7190277090384761
Loss at iteration [1413]: 0.7190130796023027
Loss at iteration [1414]: 0.7190130796023027
Loss at iteration [1415]: 0.7189972037733668
Loss at iteration [1416]: 0.7189933959371534
Loss at iteration [1417]: 0.7189895196123208
Loss at iteration [1418]: 0.718985886216922
Loss at iteration [1419]: 0.7189798993942397
Loss at iteration [1420]: 0.7189770154721484
Loss at iteration [1421]: 0.7189729685827587
Loss at iteration [1422]: 0.7189711683646578
Loss at iteration [1423]: 0.718966002296497
Loss at iteration [1424]: 0.7189506471363375
Loss at iteration [1425]: 0.7189506471363375
Loss at iteration [1426]: 0.7189327987524632
Loss at iteration [1427]: 0.7189253186275663
Loss at iteration [1428]: 0.7189195835842117
Loss at iteration [1429]: 0.7189167624714071
Loss at iteration [1430]: 0.7189147013712138
Loss at iteration [1431]: 0.7189116504675687
Loss at iteration [1432]: 0.718910410437679
Loss at iteration [1433]: 0.7189044186636319
Loss at iteration [1434]: 0.7188979590625786
Loss at iteration [1435]: 0.7188902230739581
Loss at iteration [1436]: 0.7188779694300546
Loss at iteration [1437]: 0.7188779694300546
Loss at iteration [1438]: 0.7188659524266556
Loss at iteration [1439]: 0.7188595082953005
Loss at iteration [1440]: 0.7188558152085183
Loss at iteration [1441]: 0.718852410869093
Loss at iteration [1442]: 0.7188456278634783
Loss at iteration [1443]: 0.718843478193421
Loss at iteration [1444]: 0.7188392450711163
Loss at iteration [1445]: 0.7188317831162002
Loss at iteration [1446]: 0.7188177051858907
Loss at iteration [1447]: 0.7188130706734802
Loss at iteration [1448]: 0.7187448885316675
Loss at iteration [1449]: 0.7186736186726398
Loss at iteration [1450]: 0.7185652333735831
Loss at iteration [1451]: 0.7184798386826415
Loss at iteration [1452]: 0.7184798386826415
Loss at iteration [1453]: 0.7184426770281529
Loss at iteration [1454]: 0.7184187890348886
Loss at iteration [1455]: 0.7183974758844489
Loss at iteration [1456]: 0.7183843196830374
Loss at iteration [1457]: 0.7183683396505564
Loss at iteration [1458]: 0.7183542580446978
Loss at iteration [1459]: 0.7183471376116464
Loss at iteration [1460]: 0.7183339190301772
Loss at iteration [1461]: 0.7183215290429487
Loss at iteration [1462]: 0.7183105709178838
Loss at iteration [1463]: 0.7182984867401293
Loss at iteration [1464]: 0.7182865110612521
Loss at iteration [1465]: 0.7182796008804404
Loss at iteration [1466]: 0.7182796008804404
Loss at iteration [1467]: 0.7182676859139062
Loss at iteration [1468]: 0.7182628675746375
Loss at iteration [1469]: 0.7182598774847315
Loss at iteration [1470]: 0.7182546420433582
Loss at iteration [1471]: 0.7182535208782118
Loss at iteration [1472]: 0.7182497040302229
Loss at iteration [1473]: 0.7182451044924593
Loss at iteration [1474]: 0.7182381024645929
Loss at iteration [1475]: 0.7182337093257368
Loss at iteration [1476]: 0.7182259926543159
Loss at iteration [1477]: 0.7182102427938583
Loss at iteration [1478]: 0.7182102427938583
Loss at iteration [1479]: 0.7181947583005367
Loss at iteration [1480]: 0.7181878441341861
Loss at iteration [1481]: 0.7181844240198266
Loss at iteration [1482]: 0.7181816081922137
Loss at iteration [1483]: 0.7181798082801171
Loss at iteration [1484]: 0.7181754260262764
Loss at iteration [1485]: 0.718168432021858
Loss at iteration [1486]: 0.7181561985146221
Loss at iteration [1487]: 0.7181476823314075
Loss at iteration [1488]: 0.7181406523149423
Loss at iteration [1489]: 0.7181168525923186
Loss at iteration [1490]: 0.7180051439716759
Loss at iteration [1491]: 0.7178845295332219
Loss at iteration [1492]: 0.7178845295332219
Loss at iteration [1493]: 0.7178173439009504
Loss at iteration [1494]: 0.7177862736496302
Loss at iteration [1495]: 0.7177688579412738
Loss at iteration [1496]: 0.7177438418522003
Loss at iteration [1497]: 0.7177274029556633
Loss at iteration [1498]: 0.7177067725674109
Loss at iteration [1499]: 0.7176851621732894
Loss at iteration [1500]: 0.717667908539426
Loss at iteration [1501]: 0.7176522954182568
Loss at iteration [1502]: 0.7176392721583288
Loss at iteration [1503]: 0.7176261244485591
Loss at iteration [1504]: 0.7176145820937607
Loss at iteration [1505]: 0.7175944990256717
Loss at iteration [1506]: 0.7175944990256717
Loss at iteration [1507]: 0.7175658375547955
Loss at iteration [1508]: 0.7175559281493878
Loss at iteration [1509]: 0.7175488444888388
Loss at iteration [1510]: 0.7175429206908049
Loss at iteration [1511]: 0.7175329352889086
Loss at iteration [1512]: 0.7175238416278191
Loss at iteration [1513]: 0.7175195337246615
Loss at iteration [1514]: 0.7175105589086559
Loss at iteration [1515]: 0.7175002338622728
Loss at iteration [1516]: 0.7174832746369775
Loss at iteration [1517]: 0.7174809531095102
Loss at iteration [1518]: 0.7174638546946915
Loss at iteration [1519]: 0.7174107762729484
Loss at iteration [1520]: 0.7173284214154131
Loss at iteration [1521]: 0.7173284214154131
Loss at iteration [1522]: 0.717249700408157
Loss at iteration [1523]: 0.7172320945662293
Loss at iteration [1524]: 0.717206946098441
Loss at iteration [1525]: 0.7171827750498776
Loss at iteration [1526]: 0.7171678633620123
Loss at iteration [1527]: 0.7171538954748579
Loss at iteration [1528]: 0.7171414344191649
Loss at iteration [1529]: 0.7171334775461753
Loss at iteration [1530]: 0.717124840288943
Loss at iteration [1531]: 0.717118452573936
Loss at iteration [1532]: 0.717104346274042
Loss at iteration [1533]: 0.7170918337849368
Loss at iteration [1534]: 0.717081556609653
Loss at iteration [1535]: 0.717081556609653
Loss at iteration [1536]: 0.717064607250939
Loss at iteration [1537]: 0.7170605943887544
Loss at iteration [1538]: 0.7170565123019477
Loss at iteration [1539]: 0.7170528233571742
Loss at iteration [1540]: 0.7170476287342074
Loss at iteration [1541]: 0.7170422195376525
Loss at iteration [1542]: 0.717038240906012
Loss at iteration [1543]: 0.7170334105774997
Loss at iteration [1544]: 0.7170227363801852
Loss at iteration [1545]: 0.7170087087051926
Loss at iteration [1546]: 0.7169933969704191
Loss at iteration [1547]: 0.7169933969704191
Loss at iteration [1548]: 0.7169750376381616
Loss at iteration [1549]: 0.716966819350334
Loss at iteration [1550]: 0.716960308775772
Loss at iteration [1551]: 0.7169578866666667
Loss at iteration [1552]: 0.7169536691438796
Loss at iteration [1553]: 0.7169481598906032
Loss at iteration [1554]: 0.7169365509680251
Loss at iteration [1555]: 0.7169326301602169
Loss at iteration [1556]: 0.7169204747715057
Loss at iteration [1557]: 0.7169092585238062
Loss at iteration [1558]: 0.7168987274422034
Loss at iteration [1559]: 0.7168852840099662
Loss at iteration [1560]: 0.7168265621173474
Loss at iteration [1561]: 0.7168265621173474
Loss at iteration [1562]: 0.7167861408390844
Loss at iteration [1563]: 0.7167686264934978
Loss at iteration [1564]: 0.7167517571841652
Loss at iteration [1565]: 0.7167292254413624
Loss at iteration [1566]: 0.7167166757429837
Loss at iteration [1567]: 0.7167025254752122
Loss at iteration [1568]: 0.7166931819883988
Loss at iteration [1569]: 0.7166780243285199
Loss at iteration [1570]: 0.7166721382928664
Loss at iteration [1571]: 0.7166636312341005
Loss at iteration [1572]: 0.716659389470445
Loss at iteration [1573]: 0.7166501422281784
Loss at iteration [1574]: 0.716637391916053
Loss at iteration [1575]: 0.716637391916053
Loss at iteration [1576]: 0.7166206817802133
Loss at iteration [1577]: 0.7166162314442273
Loss at iteration [1578]: 0.7166137952142375
Loss at iteration [1579]: 0.7166099988729566
Loss at iteration [1580]: 0.7166055702380829
Loss at iteration [1581]: 0.716603615908168
Loss at iteration [1582]: 0.7166005538968112
Loss at iteration [1583]: 0.7165990690073822
Loss at iteration [1584]: 0.716597227180582
Loss at iteration [1585]: 0.716597227180582
Loss at iteration [1586]: 0.7165944410256695
Loss at iteration [1587]: 0.7165937939649732
Loss at iteration [1588]: 0.7165925114825967
Loss at iteration [1589]: 0.7165914920292453
Loss at iteration [1590]: 0.716590676751675
Loss at iteration [1591]: 0.7165880815798971
Loss at iteration [1592]: 0.7165880416945324
Loss at iteration [1593]: 0.7165833667020035
Loss at iteration [1594]: 0.7165311248787126
Loss at iteration [1595]: 0.7161802443004979
Loss at iteration [1596]: 0.7161802443004979
Loss at iteration [1597]: 0.7159631287227933
Loss at iteration [1598]: 0.7158689473400223
Loss at iteration [1599]: 0.7157896996157224
Loss at iteration [1600]: 0.7157542815437972
Loss at iteration [1601]: 0.7156919381522027
Loss at iteration [1602]: 0.7156351207844579
Loss at iteration [1603]: 0.715599854464019
Loss at iteration [1604]: 0.7155533735217289
Loss at iteration [1605]: 0.7155080095208036
Loss at iteration [1606]: 0.7154739053527716
Loss at iteration [1607]: 0.7154264310599774
Loss at iteration [1608]: 0.7153917650422126
Loss at iteration [1609]: 0.7153571752737053
Loss at iteration [1610]: 0.7153043459648667
Loss at iteration [1611]: 0.7152606379936001
Loss at iteration [1612]: 0.7152344391205468
Loss at iteration [1613]: 0.7152293451020602
Loss at iteration [1614]: 0.7151623708078099
Loss at iteration [1615]: 0.7151015137242829
Loss at iteration [1616]: 0.7150612875289174
Loss at iteration [1617]: 0.7150612875289174
Loss at iteration [1618]: 0.7150276699133221
Loss at iteration [1619]: 0.7150062271789007
Loss at iteration [1620]: 0.7149867222827313
Loss at iteration [1621]: 0.7149734054308139
Loss at iteration [1622]: 0.7149562846010571
Loss at iteration [1623]: 0.7149422643708898
Loss at iteration [1624]: 0.714931957689283
Loss at iteration [1625]: 0.7149216976907944
Loss at iteration [1626]: 0.7149126916636074
Loss at iteration [1627]: 0.7149017652204538
Loss at iteration [1628]: 0.7148934134184307
Loss at iteration [1629]: 0.7148897067250685
Loss at iteration [1630]: 0.7148684159665784
Loss at iteration [1631]: 0.7148684159665784
Loss at iteration [1632]: 0.7148398300898199
Loss at iteration [1633]: 0.7148288173325866
Loss at iteration [1634]: 0.7148206258510147
Loss at iteration [1635]: 0.7148102214371753
Loss at iteration [1636]: 0.7147963238840261
Loss at iteration [1637]: 0.7147810858963218
Loss at iteration [1638]: 0.7147725628576984
Loss at iteration [1639]: 0.7147645317593488
Loss at iteration [1640]: 0.7147566437942561
Loss at iteration [1641]: 0.7147407841049971
Loss at iteration [1642]: 0.7147337506821809
Loss at iteration [1643]: 0.7147108375742403
Loss at iteration [1644]: 0.7146620178736222
Loss at iteration [1645]: 0.7144314306890757
Loss at iteration [1646]: 0.7144314306890757
Loss at iteration [1647]: 0.7141964344387035
Loss at iteration [1648]: 0.7140943948580571
Loss at iteration [1649]: 0.7140388169349392
Loss at iteration [1650]: 0.7139693654430402
Loss at iteration [1651]: 0.7139310896777855
Loss at iteration [1652]: 0.7138768514700129
Loss at iteration [1653]: 0.7138260071644345
Loss at iteration [1654]: 0.713789184517885
Loss at iteration [1655]: 0.7137744921115338
Loss at iteration [1656]: 0.7137293368927541
Loss at iteration [1657]: 0.7137007976906498
Loss at iteration [1658]: 0.713684656464085
Loss at iteration [1659]: 0.7136410603772478
Loss at iteration [1660]: 0.7135842465327004
Loss at iteration [1661]: 0.7135452282253456
Loss at iteration [1662]: 0.7134634809322657
Loss at iteration [1663]: 0.7133850775410653
Loss at iteration [1664]: 0.7133132233157854
Loss at iteration [1665]: 0.7133132233157854
Loss at iteration [1666]: 0.7132534220772301
Loss at iteration [1667]: 0.7132318150236953
Loss at iteration [1668]: 0.7132092027278083
Loss at iteration [1669]: 0.7131937742938406
Loss at iteration [1670]: 0.7131807967943602
Loss at iteration [1671]: 0.7131648147862822
Loss at iteration [1672]: 0.7131493976491213
Loss at iteration [1673]: 0.7131366940257838
Loss at iteration [1674]: 0.7131217990916497
Loss at iteration [1675]: 0.7131048197151931
Loss at iteration [1676]: 0.713099702851886
Loss at iteration [1677]: 0.7130798108055676
Loss at iteration [1678]: 0.7130687701508042
Loss at iteration [1679]: 0.7130687701508042
Loss at iteration [1680]: 0.7130561950158435
Loss at iteration [1681]: 0.7130490905645157
Loss at iteration [1682]: 0.7130460259146472
Loss at iteration [1683]: 0.7130380269393332
Loss at iteration [1684]: 0.7130357712459946
Loss at iteration [1685]: 0.7130268787649774
Loss at iteration [1686]: 0.7130162328473734
Loss at iteration [1687]: 0.7130064109813723
Loss at iteration [1688]: 0.7129888388650771
Loss at iteration [1689]: 0.7129842599050558
Loss at iteration [1690]: 0.7129720975927568
Loss at iteration [1691]: 0.7129573677053185
Loss at iteration [1692]: 0.7129192233039121
Loss at iteration [1693]: 0.7129192233039121
Loss at iteration [1694]: 0.7128972363332159
Loss at iteration [1695]: 0.7128744214798581
Loss at iteration [1696]: 0.7128683299353996
Loss at iteration [1697]: 0.712849061673627
Loss at iteration [1698]: 0.7128285305151045
Loss at iteration [1699]: 0.7128223458945032
Loss at iteration [1700]: 0.71280987556787
Loss at iteration [1701]: 0.7128017486315695
Loss at iteration [1702]: 0.7127988721751473
Loss at iteration [1703]: 0.7127904433734809
Loss at iteration [1704]: 0.7127838332967122
Loss at iteration [1705]: 0.7127797344323701
Loss at iteration [1706]: 0.7127797344323701
Loss at iteration [1707]: 0.7127672418578935
Loss at iteration [1708]: 0.7127631916088991
Loss at iteration [1709]: 0.7127600409632528
Loss at iteration [1710]: 0.7127569963719265
Loss at iteration [1711]: 0.7127537493875062
Loss at iteration [1712]: 0.7127526904729785
Loss at iteration [1713]: 0.7127506288216303
Loss at iteration [1714]: 0.7127484013686293
Loss at iteration [1715]: 0.7127424586295007
Loss at iteration [1716]: 0.7127424586295007
Loss at iteration [1717]: 0.712736488395224
Loss at iteration [1718]: 0.7127341495914141
Loss at iteration [1719]: 0.7127309931032849
Loss at iteration [1720]: 0.7127263375213057
Loss at iteration [1721]: 0.7127221442594756
Loss at iteration [1722]: 0.7127195742597912
Loss at iteration [1723]: 0.7127163209320386
Loss at iteration [1724]: 0.7127127849547288
Loss at iteration [1725]: 0.7126974078226129
Loss at iteration [1726]: 0.7126901362576875
Loss at iteration [1727]: 0.712677083271632
