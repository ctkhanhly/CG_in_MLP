Model name                            : MLP_Multistep
The number of input features          : 3
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.0001
Beta type                             :FR_PR
Total number of function evaluations  : 3029
Total number of iterations            : 1214
Max number of iterations              : 3000
Number of samples in training data    : 171
Number of samples in tests data       : 73
Total training time                   : 8.872889995574951
Total number of parameters            : 201902
Percentage of parameters < 1e-9       : 49.93016413903775%
Percentage of parameters < 1e-7       : 49.93016413903775%
Percentage of parameters < 1e-6       : 49.93065942883181%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.2529105740316573
Loss at iteration [2]: 1.2485589978107694
Loss at iteration [3]: 1.2431646446270435
Loss at iteration [4]: 1.2361935695600699
Loss at iteration [5]: 1.2305190398819028
Loss at iteration [6]: 1.218888891680365
Loss at iteration [7]: 1.218888891680365
Loss at iteration [8]: 1.2127449975269928
Loss at iteration [9]: 1.2046699739933096
Loss at iteration [10]: 1.1909915491184262
Loss at iteration [11]: 1.1644239993369847
Loss at iteration [12]: 1.1644239993369847
Loss at iteration [13]: 1.1363159079328322
Loss at iteration [14]: 1.1250357070449586
Loss at iteration [15]: 1.1128294608777
Loss at iteration [16]: 1.1033691919007311
Loss at iteration [17]: 1.0910343940430687
Loss at iteration [18]: 1.0910343940430687
Loss at iteration [19]: 1.0870233394666484
Loss at iteration [20]: 1.0781849132692178
Loss at iteration [21]: 1.0690486169486013
Loss at iteration [22]: 1.0637735685581313
Loss at iteration [23]: 1.055852348552176
Loss at iteration [24]: 1.055852348552176
Loss at iteration [25]: 1.0506398311491327
Loss at iteration [26]: 1.048439934177087
Loss at iteration [27]: 1.0441507624268016
Loss at iteration [28]: 1.0393246380911991
Loss at iteration [29]: 1.033505677315528
Loss at iteration [30]: 1.033505677315528
Loss at iteration [31]: 1.0310055686904114
Loss at iteration [32]: 1.027723587913479
Loss at iteration [33]: 1.0263739683301858
Loss at iteration [34]: 1.022834313916017
Loss at iteration [35]: 1.0194830157678572
Loss at iteration [36]: 1.0137898586762364
Loss at iteration [37]: 1.0137898586762364
Loss at iteration [38]: 1.0123214055336904
Loss at iteration [39]: 1.010127821417133
Loss at iteration [40]: 1.0075121687272943
Loss at iteration [41]: 0.9992229621683952
Loss at iteration [42]: 0.9907434657324952
Loss at iteration [43]: 0.9907434657324952
Loss at iteration [44]: 0.9874551004137833
Loss at iteration [45]: 0.9832123472271137
Loss at iteration [46]: 0.9809373942943296
Loss at iteration [47]: 0.9769649026862844
Loss at iteration [48]: 0.9762192569712868
Loss at iteration [49]: 0.9729063739276305
Loss at iteration [50]: 0.9729063739276305
Loss at iteration [51]: 0.9712451288191066
Loss at iteration [52]: 0.9684214385602921
Loss at iteration [53]: 0.9672793876608475
Loss at iteration [54]: 0.9657981948439319
Loss at iteration [55]: 0.9618432931299841
Loss at iteration [56]: 0.9549752970869541
Loss at iteration [57]: 0.9549752970869541
Loss at iteration [58]: 0.9518883465235556
Loss at iteration [59]: 0.9484932255439688
Loss at iteration [60]: 0.9468920676039128
Loss at iteration [61]: 0.9445236690223704
Loss at iteration [62]: 0.9421602025750477
Loss at iteration [63]: 0.9421602025750477
Loss at iteration [64]: 0.9406562253119266
Loss at iteration [65]: 0.9392250244316466
Loss at iteration [66]: 0.9380284153342869
Loss at iteration [67]: 0.9370902524560322
Loss at iteration [68]: 0.93448833153151
Loss at iteration [69]: 0.9330838224643461
Loss at iteration [70]: 0.9330838224643461
Loss at iteration [71]: 0.9322623764019377
Loss at iteration [72]: 0.9313288664425221
Loss at iteration [73]: 0.9298085920954855
Loss at iteration [74]: 0.9274186454756861
Loss at iteration [75]: 0.9222803470542811
Loss at iteration [76]: 0.9171410023797898
Loss at iteration [77]: 0.9171410023797898
Loss at iteration [78]: 0.9162872633674218
Loss at iteration [79]: 0.9145394629088686
Loss at iteration [80]: 0.9133054640829538
Loss at iteration [81]: 0.9101790359113384
Loss at iteration [82]: 0.9083182135302743
Loss at iteration [83]: 0.9072083730621143
Loss at iteration [84]: 0.9072083730621143
Loss at iteration [85]: 0.906721256318612
Loss at iteration [86]: 0.9053325598223553
Loss at iteration [87]: 0.9044306965145014
Loss at iteration [88]: 0.9020882710970832
Loss at iteration [89]: 0.8989975828248274
Loss at iteration [90]: 0.8931584976588481
Loss at iteration [91]: 0.8931584976588481
Loss at iteration [92]: 0.8922838366421804
Loss at iteration [93]: 0.890201662712322
Loss at iteration [94]: 0.8892405431736593
Loss at iteration [95]: 0.886875076735447
Loss at iteration [96]: 0.8860317637025771
Loss at iteration [97]: 0.884114404941553
Loss at iteration [98]: 0.884114404941553
Loss at iteration [99]: 0.8835746415026059
Loss at iteration [100]: 0.8825856218684297
Loss at iteration [101]: 0.8816015570568279
Loss at iteration [102]: 0.8807149071381319
Loss at iteration [103]: 0.8784666267737999
Loss at iteration [104]: 0.8760407788279068
Loss at iteration [105]: 0.8760407788279068
Loss at iteration [106]: 0.8749261601542172
Loss at iteration [107]: 0.8712948693781871
Loss at iteration [108]: 0.8696696073268223
Loss at iteration [109]: 0.868500765352531
Loss at iteration [110]: 0.8671097327706923
Loss at iteration [111]: 0.8649821704365853
Loss at iteration [112]: 0.8649821704365853
Loss at iteration [113]: 0.8641502483634909
Loss at iteration [114]: 0.8635434756758404
Loss at iteration [115]: 0.8628201662704548
Loss at iteration [116]: 0.8612434363666944
Loss at iteration [117]: 0.8595563242271306
Loss at iteration [118]: 0.8595563242271306
Loss at iteration [119]: 0.8586446406883033
Loss at iteration [120]: 0.8571049899906451
Loss at iteration [121]: 0.8563656451559225
Loss at iteration [122]: 0.8556299123631682
Loss at iteration [123]: 0.8550290319215429
Loss at iteration [124]: 0.8545136283450224
Loss at iteration [125]: 0.8545136283450224
Loss at iteration [126]: 0.8541906498756876
Loss at iteration [127]: 0.8538416875314373
Loss at iteration [128]: 0.8531946382866326
Loss at iteration [129]: 0.8509063293800345
Loss at iteration [130]: 0.8487041716595196
Loss at iteration [131]: 0.8436547590210293
Loss at iteration [132]: 0.8436547590210293
Loss at iteration [133]: 0.8425238143591892
Loss at iteration [134]: 0.8401510967546524
Loss at iteration [135]: 0.8385015741996387
Loss at iteration [136]: 0.8378878957743178
Loss at iteration [137]: 0.836651916697673
Loss at iteration [138]: 0.8360722145286406
Loss at iteration [139]: 0.8360722145286406
Loss at iteration [140]: 0.8356023366561174
Loss at iteration [141]: 0.8348605741943416
Loss at iteration [142]: 0.8345225032485486
Loss at iteration [143]: 0.8341467794864187
Loss at iteration [144]: 0.83383426678265
Loss at iteration [145]: 0.8329457743878904
Loss at iteration [146]: 0.8329457743878904
Loss at iteration [147]: 0.8326296005762165
Loss at iteration [148]: 0.8322118807460899
Loss at iteration [149]: 0.8319527322184791
Loss at iteration [150]: 0.8313509948606539
Loss at iteration [151]: 0.8311291463350517
Loss at iteration [152]: 0.8307900260009393
Loss at iteration [153]: 0.830529776592695
Loss at iteration [154]: 0.830529776592695
Loss at iteration [155]: 0.8303203896866621
Loss at iteration [156]: 0.8300621681157103
Loss at iteration [157]: 0.8298886779847228
Loss at iteration [158]: 0.8296670559339723
Loss at iteration [159]: 0.8292426377834023
Loss at iteration [160]: 0.8277156939770237
Loss at iteration [161]: 0.8264895682625943
Loss at iteration [162]: 0.8264895682625943
Loss at iteration [163]: 0.8254829943835384
Loss at iteration [164]: 0.8245708162928522
Loss at iteration [165]: 0.8238374292701508
Loss at iteration [166]: 0.8231382221410679
Loss at iteration [167]: 0.82249816061452
Loss at iteration [168]: 0.8216086076590369
Loss at iteration [169]: 0.8216086076590369
Loss at iteration [170]: 0.8212788739337604
Loss at iteration [171]: 0.8204103094210478
Loss at iteration [172]: 0.8199085422205428
Loss at iteration [173]: 0.8195738378630032
Loss at iteration [174]: 0.8189632318334235
Loss at iteration [175]: 0.8184996664798645
Loss at iteration [176]: 0.8184996664798645
Loss at iteration [177]: 0.8182714878962796
Loss at iteration [178]: 0.8180696372723228
Loss at iteration [179]: 0.8177124523703185
Loss at iteration [180]: 0.816819897475815
Loss at iteration [181]: 0.815667379478435
Loss at iteration [182]: 0.8149788824970368
Loss at iteration [183]: 0.8149788824970368
Loss at iteration [184]: 0.8144001504554282
Loss at iteration [185]: 0.81392521333973
Loss at iteration [186]: 0.8136058501100516
Loss at iteration [187]: 0.8133607315683729
Loss at iteration [188]: 0.8130663010156975
Loss at iteration [189]: 0.8128063522512403
Loss at iteration [190]: 0.8123782535261961
Loss at iteration [191]: 0.8123782535261961
Loss at iteration [192]: 0.8121515227087457
Loss at iteration [193]: 0.8119690953357275
Loss at iteration [194]: 0.8118115928014916
Loss at iteration [195]: 0.8116911136381006
Loss at iteration [196]: 0.8114136997953524
Loss at iteration [197]: 0.8107884456467757
Loss at iteration [198]: 0.8095833582534147
Loss at iteration [199]: 0.8095833582534147
Loss at iteration [200]: 0.8091300616154876
Loss at iteration [201]: 0.8088404063451823
Loss at iteration [202]: 0.8085295725957532
Loss at iteration [203]: 0.8082773823737234
Loss at iteration [204]: 0.8081538025389781
Loss at iteration [205]: 0.8079067870382051
Loss at iteration [206]: 0.8079067870382051
Loss at iteration [207]: 0.8078080958798054
Loss at iteration [208]: 0.8077337039751261
Loss at iteration [209]: 0.8076564727749769
Loss at iteration [210]: 0.8074497687696344
Loss at iteration [211]: 0.8071306206436153
Loss at iteration [212]: 0.8067152453875107
Loss at iteration [213]: 0.8063304090939158
Loss at iteration [214]: 0.8063304090939158
Loss at iteration [215]: 0.8061292170974228
Loss at iteration [216]: 0.8059571087899534
Loss at iteration [217]: 0.8058400110437068
Loss at iteration [218]: 0.805638742464821
Loss at iteration [219]: 0.8054862947316154
Loss at iteration [220]: 0.8053338751830388
Loss at iteration [221]: 0.8050882027002451
Loss at iteration [222]: 0.8050882027002451
Loss at iteration [223]: 0.8048569729324911
Loss at iteration [224]: 0.8046791268493152
Loss at iteration [225]: 0.8045868818082187
Loss at iteration [226]: 0.8044944366235691
Loss at iteration [227]: 0.8044180026916083
Loss at iteration [228]: 0.804352163728556
Loss at iteration [229]: 0.8042338536433633
Loss at iteration [230]: 0.803744783610974
Loss at iteration [231]: 0.803744783610974
Loss at iteration [232]: 0.8035348952480638
Loss at iteration [233]: 0.8034201142956373
Loss at iteration [234]: 0.8033084519815853
Loss at iteration [235]: 0.8031943489391351
Loss at iteration [236]: 0.8030861683215286
Loss at iteration [237]: 0.8028579938258464
Loss at iteration [238]: 0.8028579938258464
Loss at iteration [239]: 0.8026523512864695
Loss at iteration [240]: 0.8025167815328135
Loss at iteration [241]: 0.8024597981003306
Loss at iteration [242]: 0.8023933291773067
Loss at iteration [243]: 0.8023358940984515
Loss at iteration [244]: 0.8022433710837963
Loss at iteration [245]: 0.802173248818157
Loss at iteration [246]: 0.802173248818157
Loss at iteration [247]: 0.802125670054637
Loss at iteration [248]: 0.8020861519758842
Loss at iteration [249]: 0.8020448307521792
Loss at iteration [250]: 0.8020011472579767
Loss at iteration [251]: 0.8019073888214245
Loss at iteration [252]: 0.8017991900127587
Loss at iteration [253]: 0.8015289840335373
Loss at iteration [254]: 0.8004545756257271
Loss at iteration [255]: 0.8004545756257271
Loss at iteration [256]: 0.7997011457855814
Loss at iteration [257]: 0.7992068344474457
Loss at iteration [258]: 0.7989110077125263
Loss at iteration [259]: 0.798580253494802
Loss at iteration [260]: 0.7983644186971263
Loss at iteration [261]: 0.7980717464423709
Loss at iteration [262]: 0.7977500165865133
Loss at iteration [263]: 0.7977500165865133
Loss at iteration [264]: 0.7975559288128512
Loss at iteration [265]: 0.7974671055121663
Loss at iteration [266]: 0.7973754298153161
Loss at iteration [267]: 0.7972071994031895
Loss at iteration [268]: 0.797103695924123
Loss at iteration [269]: 0.7970252430195528
Loss at iteration [270]: 0.7969292760987882
Loss at iteration [271]: 0.7969292760987882
Loss at iteration [272]: 0.7968706339435607
Loss at iteration [273]: 0.7968231004569852
Loss at iteration [274]: 0.7967899375011475
Loss at iteration [275]: 0.7967389366155774
Loss at iteration [276]: 0.7966973216371189
Loss at iteration [277]: 0.7966557154678158
Loss at iteration [278]: 0.7965822738417545
Loss at iteration [279]: 0.7964124006568836
Loss at iteration [280]: 0.7964124006568836
Loss at iteration [281]: 0.7962865515466393
Loss at iteration [282]: 0.7962244488445968
Loss at iteration [283]: 0.7961652871131893
Loss at iteration [284]: 0.79611909973588
Loss at iteration [285]: 0.7960163133249092
Loss at iteration [286]: 0.7959325805528779
Loss at iteration [287]: 0.795830003323151
Loss at iteration [288]: 0.7957665599083552
Loss at iteration [289]: 0.7957665599083552
Loss at iteration [290]: 0.7957095579916051
Loss at iteration [291]: 0.795677707450656
Loss at iteration [292]: 0.7956398420288234
Loss at iteration [293]: 0.7955940111146039
Loss at iteration [294]: 0.7951715666080942
Loss at iteration [295]: 0.7944286564567288
Loss at iteration [296]: 0.7922772066511203
Loss at iteration [297]: 0.7922772066511203
Loss at iteration [298]: 0.7907620485686606
Loss at iteration [299]: 0.7900796160965359
Loss at iteration [300]: 0.7894127966457385
Loss at iteration [301]: 0.7891875643637039
Loss at iteration [302]: 0.7888555518400223
Loss at iteration [303]: 0.7886277569947049
Loss at iteration [304]: 0.7885074869834608
Loss at iteration [305]: 0.7885074869834608
Loss at iteration [306]: 0.7883865359663776
Loss at iteration [307]: 0.7883154051762169
Loss at iteration [308]: 0.7882316991706625
Loss at iteration [309]: 0.7881860706997047
Loss at iteration [310]: 0.7880930520455809
Loss at iteration [311]: 0.7879331169306972
Loss at iteration [312]: 0.7878082687715103
Loss at iteration [313]: 0.787577606616146
Loss at iteration [314]: 0.787577606616146
Loss at iteration [315]: 0.7873223792778193
Loss at iteration [316]: 0.7871852565868471
Loss at iteration [317]: 0.7870621368094733
Loss at iteration [318]: 0.7869883963413731
Loss at iteration [319]: 0.7868919920921773
Loss at iteration [320]: 0.7868598202033494
Loss at iteration [321]: 0.7868002137598583
Loss at iteration [322]: 0.7867366565485167
Loss at iteration [323]: 0.7867366565485167
Loss at iteration [324]: 0.7866531082448198
Loss at iteration [325]: 0.7865818058832801
Loss at iteration [326]: 0.786500777319673
Loss at iteration [327]: 0.7864283468518175
Loss at iteration [328]: 0.786393131511205
Loss at iteration [329]: 0.7863635590696695
Loss at iteration [330]: 0.7863031856114252
Loss at iteration [331]: 0.7861969655517097
Loss at iteration [332]: 0.7861969655517097
Loss at iteration [333]: 0.7861257373716589
Loss at iteration [334]: 0.7860982353524156
Loss at iteration [335]: 0.7860646456431541
Loss at iteration [336]: 0.7860402992820066
Loss at iteration [337]: 0.7860084019911661
Loss at iteration [338]: 0.7859900555174526
Loss at iteration [339]: 0.7859625724049981
Loss at iteration [340]: 0.7859475409953237
Loss at iteration [341]: 0.7859089311805526
Loss at iteration [342]: 0.7859089311805526
Loss at iteration [343]: 0.7858926923225625
Loss at iteration [344]: 0.7858787858286846
Loss at iteration [345]: 0.7858716586948106
Loss at iteration [346]: 0.7858676590495409
Loss at iteration [347]: 0.785863611525734
Loss at iteration [348]: 0.7858534223538698
Loss at iteration [349]: 0.7858085718645488
Loss at iteration [350]: 0.7857392340556949
Loss at iteration [351]: 0.7855204574621476
Loss at iteration [352]: 0.784839800851984
Loss at iteration [353]: 0.784839800851984
Loss at iteration [354]: 0.7838722317403648
Loss at iteration [355]: 0.7834697106279654
Loss at iteration [356]: 0.783290820214222
Loss at iteration [357]: 0.7830511011031991
Loss at iteration [358]: 0.7828462458288478
Loss at iteration [359]: 0.7826221792849214
Loss at iteration [360]: 0.7824821167841789
Loss at iteration [361]: 0.7824821167841789
Loss at iteration [362]: 0.782385155635602
Loss at iteration [363]: 0.7822992872189879
Loss at iteration [364]: 0.7822449736308674
Loss at iteration [365]: 0.7822088671315767
Loss at iteration [366]: 0.7821724007451424
Loss at iteration [367]: 0.7821231969365707
Loss at iteration [368]: 0.7820963164233664
Loss at iteration [369]: 0.7820778304953223
Loss at iteration [370]: 0.7820778304953223
Loss at iteration [371]: 0.7820674508312028
Loss at iteration [372]: 0.7820548645488855
Loss at iteration [373]: 0.7820478349169635
Loss at iteration [374]: 0.7820378850131656
Loss at iteration [375]: 0.7820210094609527
Loss at iteration [376]: 0.7819810959766689
Loss at iteration [377]: 0.7819242226765789
Loss at iteration [378]: 0.7818638550052259
Loss at iteration [379]: 0.7818004574421477
Loss at iteration [380]: 0.7815283896380149
Loss at iteration [381]: 0.7815283896380149
Loss at iteration [382]: 0.7813426356288473
Loss at iteration [383]: 0.7812420340008591
Loss at iteration [384]: 0.7811222155052512
Loss at iteration [385]: 0.7810339439954876
Loss at iteration [386]: 0.7809238481024294
Loss at iteration [387]: 0.7808412026797918
Loss at iteration [388]: 0.7807794675621644
Loss at iteration [389]: 0.7807340331778702
Loss at iteration [390]: 0.7807340331778702
Loss at iteration [391]: 0.7806982456754458
Loss at iteration [392]: 0.7806841844314342
Loss at iteration [393]: 0.7806748388674266
Loss at iteration [394]: 0.7806507225855799
Loss at iteration [395]: 0.7805928820576391
Loss at iteration [396]: 0.7805254605935402
Loss at iteration [397]: 0.7804134745876046
Loss at iteration [398]: 0.7802599530003397
Loss at iteration [399]: 0.7801747193763571
Loss at iteration [400]: 0.7801747193763571
Loss at iteration [401]: 0.7800589317041025
Loss at iteration [402]: 0.780012741487536
Loss at iteration [403]: 0.779953157489951
Loss at iteration [404]: 0.7799257955864699
Loss at iteration [405]: 0.7798827106830161
Loss at iteration [406]: 0.7798376055990445
Loss at iteration [407]: 0.779801112113991
Loss at iteration [408]: 0.779801112113991
Loss at iteration [409]: 0.779784380781518
Loss at iteration [410]: 0.7797601905431126
Loss at iteration [411]: 0.7797478123235384
Loss at iteration [412]: 0.7797322277148676
Loss at iteration [413]: 0.7797252409132117
Loss at iteration [414]: 0.7797134386023418
Loss at iteration [415]: 0.7796991176668321
Loss at iteration [416]: 0.7796818446990504
Loss at iteration [417]: 0.7796596340655666
Loss at iteration [418]: 0.7796457871410121
Loss at iteration [419]: 0.7796326510244371
Loss at iteration [420]: 0.779611770568301
Loss at iteration [421]: 0.779611770568301
Loss at iteration [422]: 0.7795840324121698
Loss at iteration [423]: 0.7795633006103029
Loss at iteration [424]: 0.7795540727300223
Loss at iteration [425]: 0.7795514795658973
Loss at iteration [426]: 0.7795243567362704
Loss at iteration [427]: 0.7794911617847822
Loss at iteration [428]: 0.7793300628880238
Loss at iteration [429]: 0.7789041157523454
Loss at iteration [430]: 0.777748457995107
Loss at iteration [431]: 0.777748457995107
Loss at iteration [432]: 0.7772899558717838
Loss at iteration [433]: 0.77690570446462
Loss at iteration [434]: 0.7766550641885885
Loss at iteration [435]: 0.7765466174389419
Loss at iteration [436]: 0.7764343516458759
Loss at iteration [437]: 0.7763329958356323
Loss at iteration [438]: 0.7762454544480838
Loss at iteration [439]: 0.7761278167511085
Loss at iteration [440]: 0.7761278167511085
Loss at iteration [441]: 0.7760803183219082
Loss at iteration [442]: 0.7760267150502981
Loss at iteration [443]: 0.7759875101453361
Loss at iteration [444]: 0.7759447363837619
Loss at iteration [445]: 0.7758529194554254
Loss at iteration [446]: 0.7757621732619429
Loss at iteration [447]: 0.7756634408292381
Loss at iteration [448]: 0.775571555346234
Loss at iteration [449]: 0.775571555346234
Loss at iteration [450]: 0.7754758751365443
Loss at iteration [451]: 0.775439698887422
Loss at iteration [452]: 0.7754232536531922
Loss at iteration [453]: 0.7753690225042338
Loss at iteration [454]: 0.7753209356383504
Loss at iteration [455]: 0.7753073201114615
Loss at iteration [456]: 0.7752856344843977
Loss at iteration [457]: 0.7752655627049332
Loss at iteration [458]: 0.7752499352794345
Loss at iteration [459]: 0.7752499352794345
Loss at iteration [460]: 0.7752400171610543
Loss at iteration [461]: 0.7752298682178674
Loss at iteration [462]: 0.7752232383311146
Loss at iteration [463]: 0.7752121752505301
Loss at iteration [464]: 0.7752018905945479
Loss at iteration [465]: 0.7751854637629639
Loss at iteration [466]: 0.7751635422738268
Loss at iteration [467]: 0.7750393521858019
Loss at iteration [468]: 0.7747768692498936
Loss at iteration [469]: 0.774517234611331
Loss at iteration [470]: 0.774517234611331
Loss at iteration [471]: 0.7744136513448773
Loss at iteration [472]: 0.774373280238587
Loss at iteration [473]: 0.774351167230875
Loss at iteration [474]: 0.7742939578960427
Loss at iteration [475]: 0.7742535562888166
Loss at iteration [476]: 0.7742333955269148
Loss at iteration [477]: 0.7742148804968176
Loss at iteration [478]: 0.7741954925849804
Loss at iteration [479]: 0.774177691480947
Loss at iteration [480]: 0.7741525480885105
Loss at iteration [481]: 0.7741525480885105
Loss at iteration [482]: 0.7741370635493089
Loss at iteration [483]: 0.7741276180067959
Loss at iteration [484]: 0.7741195683023142
Loss at iteration [485]: 0.7741117701480049
Loss at iteration [486]: 0.7740921729554132
Loss at iteration [487]: 0.7740685764775405
Loss at iteration [488]: 0.7740492148360213
Loss at iteration [489]: 0.7740267736408643
Loss at iteration [490]: 0.7740036335417004
Loss at iteration [491]: 0.7739594679086504
Loss at iteration [492]: 0.7738453559038863
Loss at iteration [493]: 0.7738453559038863
Loss at iteration [494]: 0.7737653586702599
Loss at iteration [495]: 0.7737278614066996
Loss at iteration [496]: 0.7737015230323019
Loss at iteration [497]: 0.7736732964778837
Loss at iteration [498]: 0.7736477950318509
Loss at iteration [499]: 0.7736314976722894
Loss at iteration [500]: 0.7736149333329141
Loss at iteration [501]: 0.7736001197546439
Loss at iteration [502]: 0.7735722411981493
Loss at iteration [503]: 0.7735722411981493
Loss at iteration [504]: 0.7735432930165022
Loss at iteration [505]: 0.7735354156193099
Loss at iteration [506]: 0.7735285997929509
Loss at iteration [507]: 0.7735105188271552
Loss at iteration [508]: 0.7735044669703307
Loss at iteration [509]: 0.7734882116460691
Loss at iteration [510]: 0.7734632513205615
Loss at iteration [511]: 0.7734063402888323
Loss at iteration [512]: 0.7733352520478896
Loss at iteration [513]: 0.7731825308982515
Loss at iteration [514]: 0.7731825308982515
Loss at iteration [515]: 0.7730995739038348
Loss at iteration [516]: 0.7730654493396634
Loss at iteration [517]: 0.7730321491993052
Loss at iteration [518]: 0.7729886341263607
Loss at iteration [519]: 0.7729730108206706
Loss at iteration [520]: 0.7729272500950197
Loss at iteration [521]: 0.772906861628194
Loss at iteration [522]: 0.772906861628194
Loss at iteration [523]: 0.7728855118523503
Loss at iteration [524]: 0.7728714466946947
Loss at iteration [525]: 0.7728656232102877
Loss at iteration [526]: 0.7728572692113282
Loss at iteration [527]: 0.772836033263402
Loss at iteration [528]: 0.7728117753183804
Loss at iteration [529]: 0.772772710873498
Loss at iteration [530]: 0.7727153360845868
Loss at iteration [531]: 0.7726786513375757
Loss at iteration [532]: 0.7726786513375757
Loss at iteration [533]: 0.7726637815396101
Loss at iteration [534]: 0.7726496629900416
Loss at iteration [535]: 0.7726367119773282
Loss at iteration [536]: 0.7726231800332929
Loss at iteration [537]: 0.7726149994175215
Loss at iteration [538]: 0.7726045461135814
Loss at iteration [539]: 0.7725840565258937
Loss at iteration [540]: 0.772572539216881
Loss at iteration [541]: 0.7725544193913004
Loss at iteration [542]: 0.7725329246106555
Loss at iteration [543]: 0.7725329246106555
Loss at iteration [544]: 0.7725220938949563
Loss at iteration [545]: 0.7725142664310561
Loss at iteration [546]: 0.7725114973093485
Loss at iteration [547]: 0.772507555801065
Loss at iteration [548]: 0.7725035441065355
Loss at iteration [549]: 0.7725003747482778
Loss at iteration [550]: 0.7724979256373952
Loss at iteration [551]: 0.7724951449764547
Loss at iteration [552]: 0.7724910446848727
Loss at iteration [553]: 0.7724851752043929
Loss at iteration [554]: 0.7724515832882303
Loss at iteration [555]: 0.7722644979412655
Loss at iteration [556]: 0.7720234321955141
Loss at iteration [557]: 0.7720234321955141
Loss at iteration [558]: 0.7719328747456746
Loss at iteration [559]: 0.7718864890225507
Loss at iteration [560]: 0.7718601103213913
Loss at iteration [561]: 0.771806725320981
Loss at iteration [562]: 0.7717655357927465
Loss at iteration [563]: 0.7716578324686082
Loss at iteration [564]: 0.7715205685957086
Loss at iteration [565]: 0.7713890171208045
Loss at iteration [566]: 0.7713890171208045
Loss at iteration [567]: 0.7713179558008342
Loss at iteration [568]: 0.7712746167464997
Loss at iteration [569]: 0.771258366689478
Loss at iteration [570]: 0.771225885083994
Loss at iteration [571]: 0.7712074897296083
Loss at iteration [572]: 0.771184231490659
Loss at iteration [573]: 0.7711644651573044
Loss at iteration [574]: 0.7711435084887368
Loss at iteration [575]: 0.7711244858097105
Loss at iteration [576]: 0.7711244858097105
Loss at iteration [577]: 0.7711093925332692
Loss at iteration [578]: 0.7711012959532783
Loss at iteration [579]: 0.771097082196935
Loss at iteration [580]: 0.7710925220450818
Loss at iteration [581]: 0.771083684050817
Loss at iteration [582]: 0.7710140811355188
Loss at iteration [583]: 0.7709291224133608
Loss at iteration [584]: 0.7707148493285847
Loss at iteration [585]: 0.7705360932650059
Loss at iteration [586]: 0.7705360932650059
Loss at iteration [587]: 0.7704516064132014
Loss at iteration [588]: 0.7704055555202758
Loss at iteration [589]: 0.770382780875542
Loss at iteration [590]: 0.7703388049182776
Loss at iteration [591]: 0.7703154460472199
Loss at iteration [592]: 0.7702898889706292
Loss at iteration [593]: 0.7702739344556766
Loss at iteration [594]: 0.7702581989966596
Loss at iteration [595]: 0.7702458571265385
Loss at iteration [596]: 0.7702328309808935
Loss at iteration [597]: 0.7702328309808935
Loss at iteration [598]: 0.770182943876729
Loss at iteration [599]: 0.7701677188816917
Loss at iteration [600]: 0.7701587847461693
Loss at iteration [601]: 0.770150656642856
Loss at iteration [602]: 0.7701272518932207
Loss at iteration [603]: 0.7701049310544952
Loss at iteration [604]: 0.7700833207652411
Loss at iteration [605]: 0.7700459361025811
Loss at iteration [606]: 0.770007533383403
Loss at iteration [607]: 0.770007533383403
Loss at iteration [608]: 0.7699753816813433
Loss at iteration [609]: 0.7699650485696563
Loss at iteration [610]: 0.7699567311480899
Loss at iteration [611]: 0.7699400774729613
Loss at iteration [612]: 0.7699162738289144
Loss at iteration [613]: 0.7698848364310169
Loss at iteration [614]: 0.7698636589822854
Loss at iteration [615]: 0.7698459702532506
Loss at iteration [616]: 0.7698340024406334
Loss at iteration [617]: 0.7698179715411273
Loss at iteration [618]: 0.7698115887873725
Loss at iteration [619]: 0.7698115887873725
Loss at iteration [620]: 0.7697967840904915
Loss at iteration [621]: 0.769791183554203
Loss at iteration [622]: 0.7697868848804302
Loss at iteration [623]: 0.7697835220237478
Loss at iteration [624]: 0.769780797510562
Loss at iteration [625]: 0.769778459087582
Loss at iteration [626]: 0.7697744969189972
Loss at iteration [627]: 0.7697698929766756
Loss at iteration [628]: 0.7697658862833819
Loss at iteration [629]: 0.7697646083691864
Loss at iteration [630]: 0.7697611622319193
Loss at iteration [631]: 0.7697566129952252
Loss at iteration [632]: 0.7697515147081293
Loss at iteration [633]: 0.7697472465357534
Loss at iteration [634]: 0.7697436778475708
Loss at iteration [635]: 0.7697402675062409
Loss at iteration [636]: 0.7697356781046065
Loss at iteration [637]: 0.7697314482492295
Loss at iteration [638]: 0.7697283563070191
Loss at iteration [639]: 0.7697238403754575
Loss at iteration [640]: 0.7697238403754575
Loss at iteration [641]: 0.769721019525895
Loss at iteration [642]: 0.7697195711312174
Loss at iteration [643]: 0.7697180044166615
Loss at iteration [644]: 0.7697153052974146
Loss at iteration [645]: 0.7697115625709001
Loss at iteration [646]: 0.7697089410302217
Loss at iteration [647]: 0.7697060903659305
Loss at iteration [648]: 0.769701939075916
Loss at iteration [649]: 0.7696976117822483
Loss at iteration [650]: 0.7696932859088018
Loss at iteration [651]: 0.7696886082468318
Loss at iteration [652]: 0.7696829542351412
Loss at iteration [653]: 0.7696715528632554
Loss at iteration [654]: 0.7695491626260457
Loss at iteration [655]: 0.7684732287311822
Loss at iteration [656]: 0.7671081586941768
Loss at iteration [657]: 0.7671081586941768
Loss at iteration [658]: 0.7662028696582889
Loss at iteration [659]: 0.7659496095641065
Loss at iteration [660]: 0.7657692604057529
Loss at iteration [661]: 0.7657058590636262
Loss at iteration [662]: 0.7655787874600152
Loss at iteration [663]: 0.7653479300564159
Loss at iteration [664]: 0.7652296092374637
Loss at iteration [665]: 0.7652296092374637
Loss at iteration [666]: 0.765173177055295
Loss at iteration [667]: 0.7651168092602946
Loss at iteration [668]: 0.7650462472355838
Loss at iteration [669]: 0.7649724422479999
Loss at iteration [670]: 0.7648996856288188
Loss at iteration [671]: 0.7648605711937482
Loss at iteration [672]: 0.764841562987743
Loss at iteration [673]: 0.764786020463697
Loss at iteration [674]: 0.764786020463697
Loss at iteration [675]: 0.7647525749795437
Loss at iteration [676]: 0.7647364807085794
Loss at iteration [677]: 0.7646982379945726
Loss at iteration [678]: 0.764678345284933
Loss at iteration [679]: 0.76466407021576
Loss at iteration [680]: 0.764651826029049
Loss at iteration [681]: 0.7646344825615495
Loss at iteration [682]: 0.7646277517798636
Loss at iteration [683]: 0.7646202812417667
Loss at iteration [684]: 0.7646129636148062
Loss at iteration [685]: 0.7646087525582927
Loss at iteration [686]: 0.7646087525582927
Loss at iteration [687]: 0.7645958249663503
Loss at iteration [688]: 0.7645922556529055
Loss at iteration [689]: 0.7645876590856941
Loss at iteration [690]: 0.7645844142888318
Loss at iteration [691]: 0.7645821551677446
Loss at iteration [692]: 0.7645798606159757
Loss at iteration [693]: 0.7645763367041317
Loss at iteration [694]: 0.764572367930466
Loss at iteration [695]: 0.7645688160080426
Loss at iteration [696]: 0.7645657180532308
Loss at iteration [697]: 0.7645626929690535
Loss at iteration [698]: 0.7645588395798517
Loss at iteration [699]: 0.7645537837780421
Loss at iteration [700]: 0.7645491637499802
Loss at iteration [701]: 0.7645456198794404
Loss at iteration [702]: 0.7645419263389557
Loss at iteration [703]: 0.7645366289301715
Loss at iteration [704]: 0.7645323687081821
Loss at iteration [705]: 0.7645283232553546
Loss at iteration [706]: 0.7645220551118889
Loss at iteration [707]: 0.7645220551118889
Loss at iteration [708]: 0.7645101437057629
Loss at iteration [709]: 0.7645060676385781
Loss at iteration [710]: 0.7645018648055082
Loss at iteration [711]: 0.7644999420574329
Loss at iteration [712]: 0.764496588906898
Loss at iteration [713]: 0.7644924470891431
Loss at iteration [714]: 0.7644891448969043
Loss at iteration [715]: 0.7644865051034254
Loss at iteration [716]: 0.7644830652331277
Loss at iteration [717]: 0.7644784162601218
Loss at iteration [718]: 0.7644753045073557
Loss at iteration [719]: 0.76447154133928
Loss at iteration [720]: 0.7644679848317785
Loss at iteration [721]: 0.764464620324155
Loss at iteration [722]: 0.7644605526978737
Loss at iteration [723]: 0.7644563565378348
Loss at iteration [724]: 0.7644533890380124
Loss at iteration [725]: 0.7644495011449315
Loss at iteration [726]: 0.7644369178840501
Loss at iteration [727]: 0.764406609389669
Loss at iteration [728]: 0.764406609389669
Loss at iteration [729]: 0.764393133626585
Loss at iteration [730]: 0.7643881600570116
Loss at iteration [731]: 0.764381747356297
Loss at iteration [732]: 0.7643775804564581
Loss at iteration [733]: 0.7643722869550617
Loss at iteration [734]: 0.7643387542835954
Loss at iteration [735]: 0.7642915195916874
Loss at iteration [736]: 0.7642564712947915
Loss at iteration [737]: 0.764230665647706
Loss at iteration [738]: 0.764230665647706
Loss at iteration [739]: 0.7642225209679272
Loss at iteration [740]: 0.7642141350712975
Loss at iteration [741]: 0.7642106018856376
Loss at iteration [742]: 0.7642021421137104
Loss at iteration [743]: 0.764197807219774
Loss at iteration [744]: 0.7641918657398832
Loss at iteration [745]: 0.7641887890005645
Loss at iteration [746]: 0.7641729122118621
Loss at iteration [747]: 0.76415747358796
Loss at iteration [748]: 0.764135884430244
Loss at iteration [749]: 0.7641176249260218
Loss at iteration [750]: 0.7640954771112748
Loss at iteration [751]: 0.7640954771112748
Loss at iteration [752]: 0.7640794931509728
Loss at iteration [753]: 0.764076905952231
Loss at iteration [754]: 0.7640711642705406
Loss at iteration [755]: 0.7640652260994778
Loss at iteration [756]: 0.7640627516902064
Loss at iteration [757]: 0.7640586819019819
Loss at iteration [758]: 0.7640459065060119
Loss at iteration [759]: 0.7640291569061226
Loss at iteration [760]: 0.764011227089023
Loss at iteration [761]: 0.7639891709821426
Loss at iteration [762]: 0.7639574662817317
Loss at iteration [763]: 0.7639574662817317
Loss at iteration [764]: 0.7639329164453261
Loss at iteration [765]: 0.7639257378866466
Loss at iteration [766]: 0.763919396554779
Loss at iteration [767]: 0.7639015257258791
Loss at iteration [768]: 0.7638814862663861
Loss at iteration [769]: 0.7638663381722071
Loss at iteration [770]: 0.7638494414377084
Loss at iteration [771]: 0.7638357345760144
Loss at iteration [772]: 0.7638244590031431
Loss at iteration [773]: 0.7638095051594438
Loss at iteration [774]: 0.7638095051594438
Loss at iteration [775]: 0.763798642995421
Loss at iteration [776]: 0.7637924012192182
Loss at iteration [777]: 0.763788765387797
Loss at iteration [778]: 0.7637849203748337
Loss at iteration [779]: 0.7637828628185213
Loss at iteration [780]: 0.7637800371748437
Loss at iteration [781]: 0.7637762772708908
Loss at iteration [782]: 0.7637722473685732
Loss at iteration [783]: 0.7637686596151277
Loss at iteration [784]: 0.7637647920039218
Loss at iteration [785]: 0.7637610438891332
Loss at iteration [786]: 0.7637574412761443
Loss at iteration [787]: 0.7637544087143808
Loss at iteration [788]: 0.763750394883075
Loss at iteration [789]: 0.7637454718260395
Loss at iteration [790]: 0.7637423027801787
Loss at iteration [791]: 0.7637389732123331
Loss at iteration [792]: 0.7637355188121002
Loss at iteration [793]: 0.7637312280869327
Loss at iteration [794]: 0.7637237302166257
Loss at iteration [795]: 0.7637237302166257
Loss at iteration [796]: 0.7637130377872379
Loss at iteration [797]: 0.7637093749768776
Loss at iteration [798]: 0.7637059444118162
Loss at iteration [799]: 0.7637032704254358
Loss at iteration [800]: 0.7637004597804459
Loss at iteration [801]: 0.7636996469917308
Loss at iteration [802]: 0.7636964326651656
Loss at iteration [803]: 0.7636912132817072
Loss at iteration [804]: 0.7636870075514512
Loss at iteration [805]: 0.7636846774170827
Loss at iteration [806]: 0.7636826684407501
Loss at iteration [807]: 0.7636793337429109
Loss at iteration [808]: 0.7636744678062847
Loss at iteration [809]: 0.763671065842357
Loss at iteration [810]: 0.7636675399131274
Loss at iteration [811]: 0.7636631182983084
Loss at iteration [812]: 0.7636598858632025
Loss at iteration [813]: 0.76365543221538
Loss at iteration [814]: 0.7636511662749662
Loss at iteration [815]: 0.7636461721899764
Loss at iteration [816]: 0.7636461721899764
Loss at iteration [817]: 0.7636442992256256
Loss at iteration [818]: 0.76364389088379
Loss at iteration [819]: 0.7636422322541137
Loss at iteration [820]: 0.7636399741014155
Loss at iteration [821]: 0.7636365132458562
Loss at iteration [822]: 0.7636329996556964
Loss at iteration [823]: 0.7636301982614796
Loss at iteration [824]: 0.7636274151612861
Loss at iteration [825]: 0.7636230973290096
Loss at iteration [826]: 0.7636124940070739
Loss at iteration [827]: 0.7635284122865317
Loss at iteration [828]: 0.7632969867733297
Loss at iteration [829]: 0.7624400386681881
Loss at iteration [830]: 0.7616820251204519
Loss at iteration [831]: 0.7616820251204519
Loss at iteration [832]: 0.7607196626675233
Loss at iteration [833]: 0.7604987431504612
Loss at iteration [834]: 0.7604191428882767
Loss at iteration [835]: 0.7603223510895907
Loss at iteration [836]: 0.7602394290295484
Loss at iteration [837]: 0.7601495336450549
Loss at iteration [838]: 0.7600910966685998
Loss at iteration [839]: 0.7599865067509203
Loss at iteration [840]: 0.7599865067509203
Loss at iteration [841]: 0.7599334311194499
Loss at iteration [842]: 0.7598966299209017
Loss at iteration [843]: 0.7598657194419
Loss at iteration [844]: 0.7598455453305879
Loss at iteration [845]: 0.7598211998440381
Loss at iteration [846]: 0.7597994274631189
Loss at iteration [847]: 0.7597831168796177
Loss at iteration [848]: 0.7597658251550984
Loss at iteration [849]: 0.7597477991243804
Loss at iteration [850]: 0.7597477991243804
Loss at iteration [851]: 0.7597303358240541
Loss at iteration [852]: 0.7597232549322154
Loss at iteration [853]: 0.7597161314762707
Loss at iteration [854]: 0.7597051731212827
Loss at iteration [855]: 0.7596886620478258
Loss at iteration [856]: 0.759669792936033
Loss at iteration [857]: 0.7596415082602618
Loss at iteration [858]: 0.7596119931912958
Loss at iteration [859]: 0.7595817052049048
Loss at iteration [860]: 0.7595446646951172
Loss at iteration [861]: 0.7595446646951172
Loss at iteration [862]: 0.7595217504419914
Loss at iteration [863]: 0.7595069049172569
Loss at iteration [864]: 0.7594977638552994
Loss at iteration [865]: 0.7594800112418518
Loss at iteration [866]: 0.75946508983599
Loss at iteration [867]: 0.7594524933202301
Loss at iteration [868]: 0.7594341984050128
Loss at iteration [869]: 0.7594044768195475
Loss at iteration [870]: 0.7593876939930139
Loss at iteration [871]: 0.7593876939930139
Loss at iteration [872]: 0.7593805199924348
Loss at iteration [873]: 0.7593737931352487
Loss at iteration [874]: 0.7593703314205805
Loss at iteration [875]: 0.75936481187813
Loss at iteration [876]: 0.7593605040911655
Loss at iteration [877]: 0.7593572971728362
Loss at iteration [878]: 0.7593552049552033
Loss at iteration [879]: 0.7593516773254574
Loss at iteration [880]: 0.7593469716309521
Loss at iteration [881]: 0.7593445612323028
Loss at iteration [882]: 0.7593214046328405
Loss at iteration [883]: 0.7592798247758034
Loss at iteration [884]: 0.759005471654236
Loss at iteration [885]: 0.759005471654236
Loss at iteration [886]: 0.758695419355634
Loss at iteration [887]: 0.7586373949687955
Loss at iteration [888]: 0.7584189506482523
Loss at iteration [889]: 0.7583202127529475
Loss at iteration [890]: 0.7582463813112048
Loss at iteration [891]: 0.7581873621354426
Loss at iteration [892]: 0.7581438908601064
Loss at iteration [893]: 0.7580959519580109
Loss at iteration [894]: 0.7580959519580109
Loss at iteration [895]: 0.7580763614913123
Loss at iteration [896]: 0.7580639978464646
Loss at iteration [897]: 0.7580561542158528
Loss at iteration [898]: 0.7580413959532575
Loss at iteration [899]: 0.758031584359439
Loss at iteration [900]: 0.7580126032634269
Loss at iteration [901]: 0.7579962821690257
Loss at iteration [902]: 0.7579639033023692
Loss at iteration [903]: 0.7579444243558598
Loss at iteration [904]: 0.7579385695144527
Loss at iteration [905]: 0.7579385695144527
Loss at iteration [906]: 0.7579276665621542
Loss at iteration [907]: 0.7579214880992815
Loss at iteration [908]: 0.757914993470976
Loss at iteration [909]: 0.757901248268883
Loss at iteration [910]: 0.7578668997608888
Loss at iteration [911]: 0.7578028034558759
Loss at iteration [912]: 0.7577183271796705
Loss at iteration [913]: 0.7576474435608187
Loss at iteration [914]: 0.7575535462023544
Loss at iteration [915]: 0.7575535462023544
Loss at iteration [916]: 0.7574863207472564
Loss at iteration [917]: 0.7574675478280295
Loss at iteration [918]: 0.7574599467741685
Loss at iteration [919]: 0.7574129962621639
Loss at iteration [920]: 0.7573912489875194
Loss at iteration [921]: 0.7573702990881965
Loss at iteration [922]: 0.7573463883599955
Loss at iteration [923]: 0.7573325122406861
Loss at iteration [924]: 0.7573268760758818
Loss at iteration [925]: 0.7573268760758818
Loss at iteration [926]: 0.7573190965859269
Loss at iteration [927]: 0.7573147187389543
Loss at iteration [928]: 0.7573091683438252
Loss at iteration [929]: 0.7573015318770602
Loss at iteration [930]: 0.7572983724757688
Loss at iteration [931]: 0.7572949328453487
Loss at iteration [932]: 0.7572905732639048
Loss at iteration [933]: 0.7572878541457267
Loss at iteration [934]: 0.7572857203547606
Loss at iteration [935]: 0.7572826245460693
Loss at iteration [936]: 0.7572785230297205
Loss at iteration [937]: 0.7572744210577305
Loss at iteration [938]: 0.7572715810006518
Loss at iteration [939]: 0.7572685060857408
Loss at iteration [940]: 0.7572583053920616
Loss at iteration [941]: 0.7572385502914726
Loss at iteration [942]: 0.7572155017159964
Loss at iteration [943]: 0.7572155017159964
Loss at iteration [944]: 0.7571828272684578
Loss at iteration [945]: 0.7571736455114613
Loss at iteration [946]: 0.7571672247110576
Loss at iteration [947]: 0.7571562438297249
Loss at iteration [948]: 0.7571481414997099
Loss at iteration [949]: 0.7571330896719608
Loss at iteration [950]: 0.7571276517108027
Loss at iteration [951]: 0.7571228302215345
Loss at iteration [952]: 0.7571190324998488
Loss at iteration [953]: 0.75711660271658
Loss at iteration [954]: 0.7571153224930748
Loss at iteration [955]: 0.7571117475001489
Loss at iteration [956]: 0.757107071537132
Loss at iteration [957]: 0.7571041991284553
Loss at iteration [958]: 0.757102010758698
Loss at iteration [959]: 0.757102010758698
Loss at iteration [960]: 0.7570990170988857
Loss at iteration [961]: 0.7570980347253303
Loss at iteration [962]: 0.7570965595268905
Loss at iteration [963]: 0.7570955937617604
Loss at iteration [964]: 0.7570948721945182
Loss at iteration [965]: 0.7570925705453432
Loss at iteration [966]: 0.7570876575410972
Loss at iteration [967]: 0.7570836928393339
Loss at iteration [968]: 0.7570808245337546
Loss at iteration [969]: 0.757077994803686
Loss at iteration [970]: 0.7570733216814253
Loss at iteration [971]: 0.757069169645916
Loss at iteration [972]: 0.7570649925645264
Loss at iteration [973]: 0.7570617121730627
Loss at iteration [974]: 0.7570569464790253
Loss at iteration [975]: 0.7570523703553356
Loss at iteration [976]: 0.7570492285975814
Loss at iteration [977]: 0.7570449661761235
Loss at iteration [978]: 0.7570405649993307
Loss at iteration [979]: 0.7570359155364593
Loss at iteration [980]: 0.7570359155364593
Loss at iteration [981]: 0.757033451245936
Loss at iteration [982]: 0.7570324609468336
Loss at iteration [983]: 0.7570309631709432
Loss at iteration [984]: 0.7570303246797276
Loss at iteration [985]: 0.7570285434195866
Loss at iteration [986]: 0.75702649518065
Loss at iteration [987]: 0.7570232326314026
Loss at iteration [988]: 0.7570198596816233
Loss at iteration [989]: 0.7570160936087185
Loss at iteration [990]: 0.7570115295709586
Loss at iteration [991]: 0.7570074785040681
Loss at iteration [992]: 0.7570034561569704
Loss at iteration [993]: 0.7569999931646013
Loss at iteration [994]: 0.7569969364402102
Loss at iteration [995]: 0.7569927720829656
Loss at iteration [996]: 0.7569880077549626
Loss at iteration [997]: 0.756983831511777
Loss at iteration [998]: 0.756979151654914
Loss at iteration [999]: 0.7569753084542382
Loss at iteration [1000]: 0.7569708887766641
Loss at iteration [1001]: 0.7569708887766641
Loss at iteration [1002]: 0.756967352582844
Loss at iteration [1003]: 0.7569662189864952
Loss at iteration [1004]: 0.7569648645059959
Loss at iteration [1005]: 0.7569642067069946
Loss at iteration [1006]: 0.7569627546525888
Loss at iteration [1007]: 0.756959866370038
Loss at iteration [1008]: 0.756955454712071
Loss at iteration [1009]: 0.7569511060194114
Loss at iteration [1010]: 0.7569474204670017
Loss at iteration [1011]: 0.7569439919105382
Loss at iteration [1012]: 0.7569391294817485
Loss at iteration [1013]: 0.7569356759339813
Loss at iteration [1014]: 0.7569341162221647
Loss at iteration [1015]: 0.7569299275471735
Loss at iteration [1016]: 0.7569239283412704
Loss at iteration [1017]: 0.7569206052734244
Loss at iteration [1018]: 0.7569184718076789
Loss at iteration [1019]: 0.7569146162366484
Loss at iteration [1020]: 0.7569094486771872
Loss at iteration [1021]: 0.7569064810828229
Loss at iteration [1022]: 0.7569064810828229
Loss at iteration [1023]: 0.7569044333068011
Loss at iteration [1024]: 0.7569036078252299
Loss at iteration [1025]: 0.7569024759049469
Loss at iteration [1026]: 0.7569015869262312
Loss at iteration [1027]: 0.7568987411421209
Loss at iteration [1028]: 0.7568954449552583
Loss at iteration [1029]: 0.7568930521195778
Loss at iteration [1030]: 0.7568895502011027
Loss at iteration [1031]: 0.7568855152352907
Loss at iteration [1032]: 0.7568827514448911
Loss at iteration [1033]: 0.7568795398448549
Loss at iteration [1034]: 0.7568755054875198
Loss at iteration [1035]: 0.7568706905913192
Loss at iteration [1036]: 0.7568675500897966
Loss at iteration [1037]: 0.7568639352723403
Loss at iteration [1038]: 0.7568599510438413
Loss at iteration [1039]: 0.7568562658989247
Loss at iteration [1040]: 0.7568518063786965
Loss at iteration [1041]: 0.7568465317673689
Loss at iteration [1042]: 0.7568411699466135
Loss at iteration [1043]: 0.7568411699466135
Loss at iteration [1044]: 0.756838693336181
Loss at iteration [1045]: 0.7568384420409691
Loss at iteration [1046]: 0.7568378552308042
Loss at iteration [1047]: 0.7568345979030776
Loss at iteration [1048]: 0.7568316818439377
Loss at iteration [1049]: 0.7568299377690411
Loss at iteration [1050]: 0.7568270043041656
Loss at iteration [1051]: 0.756824540246697
Loss at iteration [1052]: 0.7568214372767607
Loss at iteration [1053]: 0.7568178983908058
Loss at iteration [1054]: 0.7568146402127659
Loss at iteration [1055]: 0.7568115932563306
Loss at iteration [1056]: 0.7568080078397136
Loss at iteration [1057]: 0.7568039364006137
Loss at iteration [1058]: 0.7567997356452016
Loss at iteration [1059]: 0.7567959752570382
Loss at iteration [1060]: 0.7567927169067379
Loss at iteration [1061]: 0.7567899536147108
Loss at iteration [1062]: 0.7567858593822302
Loss at iteration [1063]: 0.7567813492068396
Loss at iteration [1064]: 0.7567813492068396
Loss at iteration [1065]: 0.7567780584299058
Loss at iteration [1066]: 0.7567775040106395
Loss at iteration [1067]: 0.7567765280992813
Loss at iteration [1068]: 0.7567756155642115
Loss at iteration [1069]: 0.7567745705272572
Loss at iteration [1070]: 0.7567744394819312
Loss at iteration [1071]: 0.7567740055389904
Loss at iteration [1072]: 0.756769667761822
Loss at iteration [1073]: 0.7567648126486113
Loss at iteration [1074]: 0.7567612225350321
Loss at iteration [1075]: 0.7567586996409856
Loss at iteration [1076]: 0.7567557508383145
Loss at iteration [1077]: 0.7567519733279359
Loss at iteration [1078]: 0.7567480487994824
Loss at iteration [1079]: 0.7567444100778922
Loss at iteration [1080]: 0.7567404333128753
Loss at iteration [1081]: 0.7567379181901395
Loss at iteration [1082]: 0.7567334049682931
Loss at iteration [1083]: 0.7567289958035608
Loss at iteration [1084]: 0.7567256307817136
Loss at iteration [1085]: 0.7567256307817136
Loss at iteration [1086]: 0.7567224512986723
Loss at iteration [1087]: 0.7567214271719476
Loss at iteration [1088]: 0.7567203733196342
Loss at iteration [1089]: 0.7567201063346946
Loss at iteration [1090]: 0.7567193066350973
Loss at iteration [1091]: 0.756716012322232
Loss at iteration [1092]: 0.75671139360224
Loss at iteration [1093]: 0.7567070170859757
Loss at iteration [1094]: 0.7567039605990784
Loss at iteration [1095]: 0.7567013523543562
Loss at iteration [1096]: 0.7566971934105207
Loss at iteration [1097]: 0.7566916206389536
Loss at iteration [1098]: 0.7566869482730397
Loss at iteration [1099]: 0.756684823974827
Loss at iteration [1100]: 0.756681868371259
Loss at iteration [1101]: 0.7566767381443663
Loss at iteration [1102]: 0.7566725993127073
Loss at iteration [1103]: 0.7566690550689349
Loss at iteration [1104]: 0.7566675670605829
Loss at iteration [1105]: 0.756664210852665
Loss at iteration [1106]: 0.756664210852665
Loss at iteration [1107]: 0.7566593854055274
Loss at iteration [1108]: 0.7566582469280735
Loss at iteration [1109]: 0.7566575711850237
Loss at iteration [1110]: 0.756655298466614
Loss at iteration [1111]: 0.7566537955150536
Loss at iteration [1112]: 0.7566526566629669
Loss at iteration [1113]: 0.7566510237352337
Loss at iteration [1114]: 0.7566481185710446
Loss at iteration [1115]: 0.7566438113252819
Loss at iteration [1116]: 0.7566401139387327
Loss at iteration [1117]: 0.7566375265865596
Loss at iteration [1118]: 0.7566345857691738
Loss at iteration [1119]: 0.7566305459416743
Loss at iteration [1120]: 0.7566250904873497
Loss at iteration [1121]: 0.75662115152617
Loss at iteration [1122]: 0.7566175486046133
Loss at iteration [1123]: 0.7566131598471884
Loss at iteration [1124]: 0.7566089236567703
Loss at iteration [1125]: 0.7566046050673635
Loss at iteration [1126]: 0.7566001534993264
Loss at iteration [1127]: 0.7566001534993264
Loss at iteration [1128]: 0.7565974953708013
Loss at iteration [1129]: 0.7565969577624424
Loss at iteration [1130]: 0.7565960582157545
Loss at iteration [1131]: 0.7565934345228691
Loss at iteration [1132]: 0.7565918396456152
Loss at iteration [1133]: 0.7565902203276159
Loss at iteration [1134]: 0.7565861689884852
Loss at iteration [1135]: 0.7565820158171592
Loss at iteration [1136]: 0.7565788402698505
Loss at iteration [1137]: 0.7565758072279022
Loss at iteration [1138]: 0.7565724805870228
Loss at iteration [1139]: 0.7565683825003422
Loss at iteration [1140]: 0.7565646125344846
Loss at iteration [1141]: 0.7565611045948277
Loss at iteration [1142]: 0.7565554181295231
Loss at iteration [1143]: 0.7565341940387865
Loss at iteration [1144]: 0.7565086181008246
Loss at iteration [1145]: 0.7564588947973093
Loss at iteration [1146]: 0.7564588947973093
Loss at iteration [1147]: 0.7564152241931539
Loss at iteration [1148]: 0.7563917722615341
Loss at iteration [1149]: 0.7563765782894377
Loss at iteration [1150]: 0.7563653931833054
Loss at iteration [1151]: 0.7563546971581516
Loss at iteration [1152]: 0.7563503629675062
Loss at iteration [1153]: 0.7563419350424612
Loss at iteration [1154]: 0.7563367156535685
Loss at iteration [1155]: 0.7563330928055289
Loss at iteration [1156]: 0.7563299470876292
Loss at iteration [1157]: 0.7563264109446738
Loss at iteration [1158]: 0.756323286997396
Loss at iteration [1159]: 0.7563199929335314
Loss at iteration [1160]: 0.7563169519443412
Loss at iteration [1161]: 0.7563132779067088
Loss at iteration [1162]: 0.7563132779067088
Loss at iteration [1163]: 0.7563099808096434
Loss at iteration [1164]: 0.756309898980323
Loss at iteration [1165]: 0.7563088817874473
Loss at iteration [1166]: 0.7563065194291582
Loss at iteration [1167]: 0.7563044858071778
Loss at iteration [1168]: 0.7563015623593485
Loss at iteration [1169]: 0.7562988874130537
Loss at iteration [1170]: 0.7562956172760695
Loss at iteration [1171]: 0.7562918558465502
Loss at iteration [1172]: 0.7562893380707151
Loss at iteration [1173]: 0.7562868824510247
Loss at iteration [1174]: 0.7562820351172742
Loss at iteration [1175]: 0.756278264936504
Loss at iteration [1176]: 0.7562747150382385
Loss at iteration [1177]: 0.7562721019176714
Loss at iteration [1178]: 0.7562689729120025
Loss at iteration [1179]: 0.7562638381767265
Loss at iteration [1180]: 0.7562606964895785
Loss at iteration [1181]: 0.7562581096990962
Loss at iteration [1182]: 0.7562546567862519
Loss at iteration [1183]: 0.7562546567862519
Loss at iteration [1184]: 0.756242449655893
Loss at iteration [1185]: 0.7562372404327264
Loss at iteration [1186]: 0.7562326765008944
Loss at iteration [1187]: 0.7562297900745079
Loss at iteration [1188]: 0.7562283083807068
Loss at iteration [1189]: 0.756226406778528
Loss at iteration [1190]: 0.7562243464673135
Loss at iteration [1191]: 0.756221201732082
Loss at iteration [1192]: 0.756219522453793
Loss at iteration [1193]: 0.7562174884699254
Loss at iteration [1194]: 0.7562127601927808
Loss at iteration [1195]: 0.7562097844300919
Loss at iteration [1196]: 0.7562070835247141
Loss at iteration [1197]: 0.756203486935661
Loss at iteration [1198]: 0.756200419096178
Loss at iteration [1199]: 0.7561976898552456
Loss at iteration [1200]: 0.7561933921594195
Loss at iteration [1201]: 0.7561899718069288
Loss at iteration [1202]: 0.7561866015931751
Loss at iteration [1203]: 0.7561829731541125
Loss at iteration [1204]: 0.7561829731541125
Loss at iteration [1205]: 0.7561815668405171
Loss at iteration [1206]: 0.7561810236597306
Loss at iteration [1207]: 0.7561801420970437
Loss at iteration [1208]: 0.7561792869941873
Loss at iteration [1209]: 0.756176236028129
Loss at iteration [1210]: 0.7561736333129904
Loss at iteration [1211]: 0.756171585060109
Loss at iteration [1212]: 0.7561681704774109
Loss at iteration [1213]: 0.75616429053426
Loss at iteration [1214]: 0.7561612711891023
Loss at iteration [1215]: 0.7561581512700845
Loss at iteration [1216]: 0.7561546592398937
Loss at iteration [1217]: 0.7561506335301084
Loss at iteration [1218]: 0.7561455010699659
Loss at iteration [1219]: 0.7561425878123069
Loss at iteration [1220]: 0.7561406331827955
Loss at iteration [1221]: 0.7561363388709011
Loss at iteration [1222]: 0.7561334314622323
Loss at iteration [1223]: 0.7561309205954517
Loss at iteration [1224]: 0.7561268404515621
Loss at iteration [1225]: 0.7561268404515621
Loss at iteration [1226]: 0.7561234633248194
Loss at iteration [1227]: 0.7561219319974211
Loss at iteration [1228]: 0.756121101370932
Loss at iteration [1229]: 0.7561200563712445
Loss at iteration [1230]: 0.756119158392881
Loss at iteration [1231]: 0.7561184709015937
Loss at iteration [1232]: 0.756117335486812
Loss at iteration [1233]: 0.7561120853869177
Loss at iteration [1234]: 0.7561079723200077
Loss at iteration [1235]: 0.7561053002087155
Loss at iteration [1236]: 0.7561025734209055
Loss at iteration [1237]: 0.7560993068039826
Loss at iteration [1238]: 0.7560940998622594
Loss at iteration [1239]: 0.7560914555740362
Loss at iteration [1240]: 0.756089103566309
Loss at iteration [1241]: 0.7560846304340668
Loss at iteration [1242]: 0.756080779944705
Loss at iteration [1243]: 0.7560791858719748
Loss at iteration [1244]: 0.756074979071459
Loss at iteration [1245]: 0.7560701850106943
Loss at iteration [1246]: 0.7560701850106943
Loss at iteration [1247]: 0.7560680301404248
Loss at iteration [1248]: 0.7560668490870626
Loss at iteration [1249]: 0.7560645360446268
Loss at iteration [1250]: 0.7560636128128886
Loss at iteration [1251]: 0.756062994006674
Loss at iteration [1252]: 0.7560617216250515
Loss at iteration [1253]: 0.7560606961366783
Loss at iteration [1254]: 0.756060210867569
Loss at iteration [1255]: 0.7560583236307402
Loss at iteration [1256]: 0.7560532978094775
Loss at iteration [1257]: 0.7560493729791112
Loss at iteration [1258]: 0.7560465231658027
Loss at iteration [1259]: 0.7560435606906465
Loss at iteration [1260]: 0.7560386389006644
Loss at iteration [1261]: 0.7560332945584077
Loss at iteration [1262]: 0.7560299709863243
Loss at iteration [1263]: 0.7560258950132407
Loss at iteration [1264]: 0.756021046501159
Loss at iteration [1265]: 0.756021046501159
Loss at iteration [1266]: 0.7560193963877512
Loss at iteration [1267]: 0.7560184890536491
Loss at iteration [1268]: 0.7560175063202652
Loss at iteration [1269]: 0.7560165225843392
Loss at iteration [1270]: 0.756015715757688
Loss at iteration [1271]: 0.7560153829724192
Loss at iteration [1272]: 0.7560137768594563
Loss at iteration [1273]: 0.7560095158740345
Loss at iteration [1274]: 0.7560057796564585
Loss at iteration [1275]: 0.7560034127866991
Loss at iteration [1276]: 0.756000027493547
Loss at iteration [1277]: 0.7559952098082865
Loss at iteration [1278]: 0.7559904612905739
Loss at iteration [1279]: 0.75598724049726
Loss at iteration [1280]: 0.7559853536613124
Loss at iteration [1281]: 0.7559817314583139
Loss at iteration [1282]: 0.7559764490725035
Loss at iteration [1283]: 0.7559726946977168
Loss at iteration [1284]: 0.7559700451260027
Loss at iteration [1285]: 0.7559700451260027
Loss at iteration [1286]: 0.7559665915217753
Loss at iteration [1287]: 0.7559651953011693
Loss at iteration [1288]: 0.7559638470101518
Loss at iteration [1289]: 0.7559632646507993
Loss at iteration [1290]: 0.7559624186628854
Loss at iteration [1291]: 0.7559618242396983
Loss at iteration [1292]: 0.7559611887778023
Loss at iteration [1293]: 0.755956966342777
Loss at iteration [1294]: 0.7559518007289309
Loss at iteration [1295]: 0.7559495440009852
Loss at iteration [1296]: 0.755947600393962
Loss at iteration [1297]: 0.7559434858532383
Loss at iteration [1298]: 0.7559401254237611
Loss at iteration [1299]: 0.7559364493358643
Loss at iteration [1300]: 0.7559315380491066
Loss at iteration [1301]: 0.7559282945632847
Loss at iteration [1302]: 0.7559256710630927
Loss at iteration [1303]: 0.7559222097452096
Loss at iteration [1304]: 0.7559165107623415
Loss at iteration [1305]: 0.7559117808235886
Loss at iteration [1306]: 0.7559117808235886
Loss at iteration [1307]: 0.7559096471961377
Loss at iteration [1308]: 0.7559087434434508
Loss at iteration [1309]: 0.7559072719402231
Loss at iteration [1310]: 0.755906652773991
Loss at iteration [1311]: 0.755903870155198
Loss at iteration [1312]: 0.755900460417186
Loss at iteration [1313]: 0.7558976473039148
Loss at iteration [1314]: 0.7558949607902868
Loss at iteration [1315]: 0.7558915112472576
Loss at iteration [1316]: 0.7558877404590796
Loss at iteration [1317]: 0.7558848798005704
Loss at iteration [1318]: 0.755881137727217
Loss at iteration [1319]: 0.7558759977069108
Loss at iteration [1320]: 0.755870278058757
Loss at iteration [1321]: 0.7558674467392249
Loss at iteration [1322]: 0.7558655582827982
Loss at iteration [1323]: 0.7558619295281467
Loss at iteration [1324]: 0.7558603158634174
Loss at iteration [1325]: 0.7558422327011415
Loss at iteration [1326]: 0.7558157362117138
