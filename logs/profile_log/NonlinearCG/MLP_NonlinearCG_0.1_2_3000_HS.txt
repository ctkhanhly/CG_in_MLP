Model name                            : MLP
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : NonlinearCG
Learning rate                         : 0.1
Beta type                             :HS
Total number of function evaluations  : 3037
Total number of iterations            : 1698
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 15.01970386505127
Total number of parameters            : 101001
Percentage of parameters < 1e-9       : 50.145048068831%
Percentage of parameters < 1e-7       : 50.145048068831%
Percentage of parameters < 1e-6       : 50.14603815803804%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.0030099317717220677
Loss at iteration [2]: 0.002977541759551131
Loss at iteration [3]: 0.0028551535114631175
Loss at iteration [4]: 0.0027528116532916317
Loss at iteration [5]: 0.002719329397564421
Loss at iteration [6]: 0.0027074898466670876
Loss at iteration [7]: 0.0026738537214194454
Loss at iteration [8]: 0.0026644836969822124
Loss at iteration [9]: 0.0026399750648924097
Loss at iteration [10]: 0.0026160692500615907
Loss at iteration [11]: 0.002585798872206942
Loss at iteration [12]: 0.0025684976453171303
Loss at iteration [13]: 0.0025594350838436053
Loss at iteration [14]: 0.0025561373661167845
Loss at iteration [15]: 0.0025539662248454244
Loss at iteration [16]: 0.0025539662248454244
Loss at iteration [17]: 0.0025517415027563797
Loss at iteration [18]: 0.0025371658750220527
Loss at iteration [19]: 0.0025364807522082877
Loss at iteration [20]: 0.0025338815851865502
Loss at iteration [21]: 0.002527411961514369
Loss at iteration [22]: 0.0025268072521348306
Loss at iteration [23]: 0.002525024457555082
Loss at iteration [24]: 0.0025214563606071414
Loss at iteration [25]: 0.0025182267054088803
Loss at iteration [26]: 0.002515921552802545
Loss at iteration [27]: 0.002503532477630622
Loss at iteration [28]: 0.002502885893933569
Loss at iteration [29]: 0.002500811403205044
Loss at iteration [30]: 0.0025007485622363657
Loss at iteration [31]: 0.0025007485622363657
Loss at iteration [32]: 0.0025006335750666904
Loss at iteration [33]: 0.002498676554324974
Loss at iteration [34]: 0.0024977849314000507
Loss at iteration [35]: 0.0024964724287611173
Loss at iteration [36]: 0.002495274872881444
Loss at iteration [37]: 0.0024950002886652387
Loss at iteration [38]: 0.0024939257109320035
Loss at iteration [39]: 0.0024926310822181944
Loss at iteration [40]: 0.0024906244431810846
Loss at iteration [41]: 0.0024861590372404797
Loss at iteration [42]: 0.0024857968027119054
Loss at iteration [43]: 0.0024854921041378222
Loss at iteration [44]: 0.002484519600122607
Loss at iteration [45]: 0.002484519600122607
Loss at iteration [46]: 0.0024841102125861946
Loss at iteration [47]: 0.0024836969908841556
Loss at iteration [48]: 0.0024824966728295345
Loss at iteration [49]: 0.0024823480851209703
Loss at iteration [50]: 0.0024818263066094183
Loss at iteration [51]: 0.002480400730622349
Loss at iteration [52]: 0.0024800946094531906
Loss at iteration [53]: 0.002479307856184212
Loss at iteration [54]: 0.002479154313658684
Loss at iteration [55]: 0.0024788369853844996
Loss at iteration [56]: 0.002478280553763971
Loss at iteration [57]: 0.0024781508192427367
Loss at iteration [58]: 0.0024773802427343864
Loss at iteration [59]: 0.0024773802427343864
Loss at iteration [60]: 0.0024769051028680896
Loss at iteration [61]: 0.0024767222997668413
Loss at iteration [62]: 0.0024758497489181025
Loss at iteration [63]: 0.002475785084999765
Loss at iteration [64]: 0.0024756923635742005
Loss at iteration [65]: 0.0024750094661242397
Loss at iteration [66]: 0.0024749264659079543
Loss at iteration [67]: 0.0024746183027224405
Loss at iteration [68]: 0.0024743583746141156
Loss at iteration [69]: 0.0024742369173200718
Loss at iteration [70]: 0.0024731528006437004
Loss at iteration [71]: 0.002471865303388456
Loss at iteration [72]: 0.002471283001855867
Loss at iteration [73]: 0.002470738619411466
Loss at iteration [74]: 0.0024698306093790747
Loss at iteration [75]: 0.0024698306093790747
Loss at iteration [76]: 0.002469330630802361
Loss at iteration [77]: 0.002469031596841907
Loss at iteration [78]: 0.002468497003868622
Loss at iteration [79]: 0.0024683073124790846
Loss at iteration [80]: 0.002467904203511687
Loss at iteration [81]: 0.0024675981381003533
Loss at iteration [82]: 0.0024674097510687626
Loss at iteration [83]: 0.002466815255954675
Loss at iteration [84]: 0.0024666069500877
Loss at iteration [85]: 0.002466037180379026
Loss at iteration [86]: 0.002465544597309196
Loss at iteration [87]: 0.002463861213864084
Loss at iteration [88]: 0.002463861213864084
Loss at iteration [89]: 0.0024636689852195063
Loss at iteration [90]: 0.002462753455599617
Loss at iteration [91]: 0.002461958645761496
Loss at iteration [92]: 0.0024619366585460867
Loss at iteration [93]: 0.0024615761746780715
Loss at iteration [94]: 0.002461311130467109
Loss at iteration [95]: 0.0024612734321564317
Loss at iteration [96]: 0.002461202889326676
Loss at iteration [97]: 0.0024610450592906525
Loss at iteration [98]: 0.00246100672952606
Loss at iteration [99]: 0.002460651168077059
Loss at iteration [100]: 0.0024604358972178065
Loss at iteration [101]: 0.0024602578095610007
Loss at iteration [102]: 0.0024596182448364573
Loss at iteration [103]: 0.0024596182448364573
Loss at iteration [104]: 0.0024595133642799317
Loss at iteration [105]: 0.002459222298264386
Loss at iteration [106]: 0.0024583354276592677
Loss at iteration [107]: 0.0024582560970656192
Loss at iteration [108]: 0.002458222777160677
Loss at iteration [109]: 0.002458139821751545
Loss at iteration [110]: 0.002458068291483677
Loss at iteration [111]: 0.002458014648736991
Loss at iteration [112]: 0.0024577785670206642
Loss at iteration [113]: 0.0024573548590999176
Loss at iteration [114]: 0.0024572552619582253
Loss at iteration [115]: 0.002456499383400896
Loss at iteration [116]: 0.0024564108140661045
Loss at iteration [117]: 0.002456061883139943
Loss at iteration [118]: 0.002455920476582417
Loss at iteration [119]: 0.0024558324659360036
Loss at iteration [120]: 0.0024558324659360036
Loss at iteration [121]: 0.0024557074367704285
Loss at iteration [122]: 0.0024556063470163444
Loss at iteration [123]: 0.002455408544822457
Loss at iteration [124]: 0.0024549130428405124
Loss at iteration [125]: 0.0024547248528888105
Loss at iteration [126]: 0.0024546397980473723
Loss at iteration [127]: 0.0024535101106053763
Loss at iteration [128]: 0.002453217746393164
Loss at iteration [129]: 0.002453053353400157
Loss at iteration [130]: 0.0024526434413812206
Loss at iteration [131]: 0.0024522669530329328
Loss at iteration [132]: 0.0024515120312045484
Loss at iteration [133]: 0.0024511585174916877
Loss at iteration [134]: 0.0024511585174916877
Loss at iteration [135]: 0.0024508756704584712
Loss at iteration [136]: 0.002450801682530974
Loss at iteration [137]: 0.0024501031909149483
Loss at iteration [138]: 0.0024500234941020466
Loss at iteration [139]: 0.002449283363707112
Loss at iteration [140]: 0.0024489182425330197
Loss at iteration [141]: 0.0024488936362212104
Loss at iteration [142]: 0.0024487148012696048
Loss at iteration [143]: 0.0024484051722023707
Loss at iteration [144]: 0.0024483537054241465
Loss at iteration [145]: 0.002448197566343282
Loss at iteration [146]: 0.002448081142189664
Loss at iteration [147]: 0.002448081142189664
Loss at iteration [148]: 0.002448051178250137
Loss at iteration [149]: 0.002448010950618374
Loss at iteration [150]: 0.002447724286472526
Loss at iteration [151]: 0.002447706064489175
Loss at iteration [152]: 0.0024475694799481647
Loss at iteration [153]: 0.0024474496403834706
Loss at iteration [154]: 0.0024474274876136013
Loss at iteration [155]: 0.002447338123599713
Loss at iteration [156]: 0.00244713312283083
Loss at iteration [157]: 0.00244711792304932
Loss at iteration [158]: 0.0024470298005207394
Loss at iteration [159]: 0.002446777970577101
Loss at iteration [160]: 0.0024465548942233678
Loss at iteration [161]: 0.0024465548942233678
Loss at iteration [162]: 0.0024465053253863653
Loss at iteration [163]: 0.002446126709017433
Loss at iteration [164]: 0.0024460152847168666
Loss at iteration [165]: 0.00244582523295205
Loss at iteration [166]: 0.0024455587055589247
Loss at iteration [167]: 0.002445321100194804
Loss at iteration [168]: 0.00244518816316509
Loss at iteration [169]: 0.00244438687848004
Loss at iteration [170]: 0.002444191566766769
Loss at iteration [171]: 0.002443895186848211
Loss at iteration [172]: 0.002442797440253759
Loss at iteration [173]: 0.0024425773802715543
Loss at iteration [174]: 0.0024418940703190817
Loss at iteration [175]: 0.0024418940703190817
Loss at iteration [176]: 0.0024412697099711273
Loss at iteration [177]: 0.0024405997088015564
Loss at iteration [178]: 0.0024397189859982965
Loss at iteration [179]: 0.0024393601140198823
Loss at iteration [180]: 0.0024384571138044158
Loss at iteration [181]: 0.0024383377588436694
Loss at iteration [182]: 0.002437637699919557
Loss at iteration [183]: 0.00243749554545571
Loss at iteration [184]: 0.002436548225803287
Loss at iteration [185]: 0.0024361905936105166
Loss at iteration [186]: 0.002435805701532782
Loss at iteration [187]: 0.0024347565668540803
Loss at iteration [188]: 0.0024343173119118424
Loss at iteration [189]: 0.0024343173119118424
Loss at iteration [190]: 0.002434228886494279
Loss at iteration [191]: 0.0024341876206383944
Loss at iteration [192]: 0.002433850796196322
Loss at iteration [193]: 0.0024334993020624198
Loss at iteration [194]: 0.0024331749487043
Loss at iteration [195]: 0.0024329710008667415
Loss at iteration [196]: 0.002432890079593157
Loss at iteration [197]: 0.0024327682316440643
Loss at iteration [198]: 0.0024327120231815292
Loss at iteration [199]: 0.0024326149739347137
Loss at iteration [200]: 0.00243244373002469
Loss at iteration [201]: 0.002432321310821089
Loss at iteration [202]: 0.0024321357290030044
Loss at iteration [203]: 0.0024320192327654073
Loss at iteration [204]: 0.0024320192327654073
Loss at iteration [205]: 0.0024319443927784683
Loss at iteration [206]: 0.002431621455935711
Loss at iteration [207]: 0.0024313636535606468
Loss at iteration [208]: 0.0024312996752596412
Loss at iteration [209]: 0.002431191874434054
Loss at iteration [210]: 0.0024311151275710112
Loss at iteration [211]: 0.002431092100530337
Loss at iteration [212]: 0.0024309598724042147
Loss at iteration [213]: 0.0024308704203654433
Loss at iteration [214]: 0.0024307284835921885
Loss at iteration [215]: 0.002430587660148837
Loss at iteration [216]: 0.0024304361193341335
Loss at iteration [217]: 0.002430118958017272
Loss at iteration [218]: 0.002430117869889765
Loss at iteration [219]: 0.0024300394023077285
Loss at iteration [220]: 0.0024300394023077285
Loss at iteration [221]: 0.0024300036875937398
Loss at iteration [222]: 0.0024299509513274675
Loss at iteration [223]: 0.0024297677902355786
Loss at iteration [224]: 0.0024297304163073278
Loss at iteration [225]: 0.0024296107251477266
Loss at iteration [226]: 0.002429091414756386
Loss at iteration [227]: 0.002428737629192224
Loss at iteration [228]: 0.002428446837240935
Loss at iteration [229]: 0.00242836711280581
Loss at iteration [230]: 0.002428108948190749
Loss at iteration [231]: 0.002427670487695391
Loss at iteration [232]: 0.002427670487695391
Loss at iteration [233]: 0.0024276130725961326
Loss at iteration [234]: 0.0024271162445507356
Loss at iteration [235]: 0.0024268758661638475
Loss at iteration [236]: 0.002425697493247074
Loss at iteration [237]: 0.002425459529159202
Loss at iteration [238]: 0.002425117267826752
Loss at iteration [239]: 0.0024249724952244514
Loss at iteration [240]: 0.002424828132929949
Loss at iteration [241]: 0.0024247336457604482
Loss at iteration [242]: 0.0024246920737121184
Loss at iteration [243]: 0.0024245542918523337
Loss at iteration [244]: 0.0024241557005489464
Loss at iteration [245]: 0.002423908021492347
Loss at iteration [246]: 0.002423798812777488
Loss at iteration [247]: 0.002423798812777488
Loss at iteration [248]: 0.00242349330133921
Loss at iteration [249]: 0.0024231529861747903
Loss at iteration [250]: 0.002423035151453983
Loss at iteration [251]: 0.0024227916058094556
Loss at iteration [252]: 0.0024225783030276875
Loss at iteration [253]: 0.0024224686075368317
Loss at iteration [254]: 0.0024223661571927016
Loss at iteration [255]: 0.002422304521676083
Loss at iteration [256]: 0.0024218990169516575
Loss at iteration [257]: 0.0024217855424704623
Loss at iteration [258]: 0.002421652255706353
Loss at iteration [259]: 0.0024214623894582275
Loss at iteration [260]: 0.002421444627266931
Loss at iteration [261]: 0.0024213938087269686
Loss at iteration [262]: 0.0024211931344054996
Loss at iteration [263]: 0.0024211931344054996
Loss at iteration [264]: 0.00242107386045113
Loss at iteration [265]: 0.0024210310758397044
Loss at iteration [266]: 0.002420774952448175
Loss at iteration [267]: 0.00242072872525575
Loss at iteration [268]: 0.0024205474978744707
Loss at iteration [269]: 0.00242045566454569
Loss at iteration [270]: 0.002420432241037567
Loss at iteration [271]: 0.002420335603660221
Loss at iteration [272]: 0.0024202419775083348
Loss at iteration [273]: 0.002420214428249257
Loss at iteration [274]: 0.002420177411137859
Loss at iteration [275]: 0.0024201293468207948
Loss at iteration [276]: 0.002419877887712323
Loss at iteration [277]: 0.0024196610068696308
Loss at iteration [278]: 0.002419565643225803
Loss at iteration [279]: 0.002419565643225803
Loss at iteration [280]: 0.0024195353197862474
Loss at iteration [281]: 0.002419186555656213
Loss at iteration [282]: 0.0024190500342050605
Loss at iteration [283]: 0.0024190266643973244
Loss at iteration [284]: 0.0024189878382899674
Loss at iteration [285]: 0.002418940514771471
Loss at iteration [286]: 0.002418925527523633
Loss at iteration [287]: 0.002418856861447429
Loss at iteration [288]: 0.002418668120171927
Loss at iteration [289]: 0.002418500986436709
Loss at iteration [290]: 0.002418455881100913
Loss at iteration [291]: 0.0024183850406711235
Loss at iteration [292]: 0.002418004708383604
Loss at iteration [293]: 0.0024179770695546897
Loss at iteration [294]: 0.002417952611295483
Loss at iteration [295]: 0.0024179014686967646
Loss at iteration [296]: 0.0024179014686967646
Loss at iteration [297]: 0.0024178827910522906
Loss at iteration [298]: 0.0024178542364355756
Loss at iteration [299]: 0.0024176217669033325
Loss at iteration [300]: 0.0024175745993405507
Loss at iteration [301]: 0.0024174753544941546
Loss at iteration [302]: 0.0024174291102437443
Loss at iteration [303]: 0.0024173807511996496
Loss at iteration [304]: 0.0024172473219706606
Loss at iteration [305]: 0.0024171065372670685
Loss at iteration [306]: 0.0024169429233384227
Loss at iteration [307]: 0.002416919578979201
Loss at iteration [308]: 0.0024167067513193932
Loss at iteration [309]: 0.0024166885410511502
Loss at iteration [310]: 0.0024166622639471736
Loss at iteration [311]: 0.0024163794312595465
Loss at iteration [312]: 0.0024163794312595465
Loss at iteration [313]: 0.002416340922879863
Loss at iteration [314]: 0.0024161494859250847
Loss at iteration [315]: 0.0024160432172538005
Loss at iteration [316]: 0.0024160174260618316
Loss at iteration [317]: 0.0024159533739699524
Loss at iteration [318]: 0.0024158540581597867
Loss at iteration [319]: 0.0024158067581454227
Loss at iteration [320]: 0.0024154571269947873
Loss at iteration [321]: 0.002415425504865648
Loss at iteration [322]: 0.0024146115055703713
Loss at iteration [323]: 0.002414423751103933
Loss at iteration [324]: 0.0024138511231901237
Loss at iteration [325]: 0.0024138511231901237
Loss at iteration [326]: 0.002413366173969444
Loss at iteration [327]: 0.002413250680227617
Loss at iteration [328]: 0.002412788224857634
Loss at iteration [329]: 0.002412762226291237
Loss at iteration [330]: 0.0024126372115764656
Loss at iteration [331]: 0.0024123429062224214
Loss at iteration [332]: 0.002412292627199667
Loss at iteration [333]: 0.0024122188179962344
Loss at iteration [334]: 0.0024117562635443336
Loss at iteration [335]: 0.002411413780609508
Loss at iteration [336]: 0.002411222582213961
Loss at iteration [337]: 0.002410980462986842
Loss at iteration [338]: 0.0024100238498136342
Loss at iteration [339]: 0.0024100238498136342
Loss at iteration [340]: 0.0024099335369662457
Loss at iteration [341]: 0.002409296881233953
Loss at iteration [342]: 0.002409202290942359
Loss at iteration [343]: 0.0024088704041964042
Loss at iteration [344]: 0.002408734263058125
Loss at iteration [345]: 0.002408468959693756
Loss at iteration [346]: 0.0024081629269293785
Loss at iteration [347]: 0.0024080898912122255
Loss at iteration [348]: 0.0024080249827555275
Loss at iteration [349]: 0.0024078832724300763
Loss at iteration [350]: 0.002407781673750864
Loss at iteration [351]: 0.002407733405618087
Loss at iteration [352]: 0.002407733405618087
Loss at iteration [353]: 0.002407698268832798
Loss at iteration [354]: 0.0024075549136707455
Loss at iteration [355]: 0.0024074793095981363
Loss at iteration [356]: 0.002407452604692717
Loss at iteration [357]: 0.002407363363034443
Loss at iteration [358]: 0.0024073227759794247
Loss at iteration [359]: 0.0024071817566629593
Loss at iteration [360]: 0.0024067437414405546
Loss at iteration [361]: 0.002406427481271604
Loss at iteration [362]: 0.0024060847765590377
Loss at iteration [363]: 0.0024057374570822603
Loss at iteration [364]: 0.002405153476855095
Loss at iteration [365]: 0.002405153476855095
Loss at iteration [366]: 0.0024049238769115805
Loss at iteration [367]: 0.002404856577760816
Loss at iteration [368]: 0.002403842937750971
Loss at iteration [369]: 0.0024036793029271423
Loss at iteration [370]: 0.002402957992360518
Loss at iteration [371]: 0.0024018136807243185
Loss at iteration [372]: 0.0024016159288998036
Loss at iteration [373]: 0.0024013357136054886
Loss at iteration [374]: 0.002401193960697806
Loss at iteration [375]: 0.0024011270497252602
Loss at iteration [376]: 0.0024010698266652484
Loss at iteration [377]: 0.002400956986695076
Loss at iteration [378]: 0.0024007844245054347
Loss at iteration [379]: 0.0024007710818482715
Loss at iteration [380]: 0.002400696106916044
Loss at iteration [381]: 0.0024005792472806095
Loss at iteration [382]: 0.0024005131173111412
Loss at iteration [383]: 0.0024005131173111412
Loss at iteration [384]: 0.002400462210134418
Loss at iteration [385]: 0.0024004004978991442
Loss at iteration [386]: 0.0023999974668928994
Loss at iteration [387]: 0.0023998889307581383
Loss at iteration [388]: 0.0023997332613105776
Loss at iteration [389]: 0.002398554903893033
Loss at iteration [390]: 0.0023983942356110366
Loss at iteration [391]: 0.002398261789972543
Loss at iteration [392]: 0.002397535109120191
Loss at iteration [393]: 0.0023971543891451934
Loss at iteration [394]: 0.0023970313870732003
Loss at iteration [395]: 0.0023963956230653705
Loss at iteration [396]: 0.002395930790286582
Loss at iteration [397]: 0.002395930790286582
Loss at iteration [398]: 0.0023957686321896673
Loss at iteration [399]: 0.002395646440612137
Loss at iteration [400]: 0.0023952066699379983
Loss at iteration [401]: 0.0023948586738017754
Loss at iteration [402]: 0.002394636867170068
Loss at iteration [403]: 0.0023945455673976437
Loss at iteration [404]: 0.0023943369396980676
Loss at iteration [405]: 0.002393550290492263
Loss at iteration [406]: 0.002393406975054898
Loss at iteration [407]: 0.0023932622083394093
Loss at iteration [408]: 0.002392551127492397
Loss at iteration [409]: 0.0023922856292362157
Loss at iteration [410]: 0.002392079885561919
Loss at iteration [411]: 0.002391978281334179
Loss at iteration [412]: 0.002391978281334179
Loss at iteration [413]: 0.0023919495498327704
Loss at iteration [414]: 0.0023918339859230722
Loss at iteration [415]: 0.0023916347878278677
Loss at iteration [416]: 0.0023915415938941744
Loss at iteration [417]: 0.0023914204154494236
Loss at iteration [418]: 0.002391298861326219
Loss at iteration [419]: 0.0023910146838129662
Loss at iteration [420]: 0.0023908839932514974
Loss at iteration [421]: 0.0023907248530635607
Loss at iteration [422]: 0.0023906443688899047
Loss at iteration [423]: 0.002390546972196759
Loss at iteration [424]: 0.002390173425695239
Loss at iteration [425]: 0.0023900554239067976
Loss at iteration [426]: 0.002389789318802979
Loss at iteration [427]: 0.002389626636400755
Loss at iteration [428]: 0.0023894992622846434
Loss at iteration [429]: 0.0023889965665933204
Loss at iteration [430]: 0.0023889965665933204
Loss at iteration [431]: 0.002388676992781792
Loss at iteration [432]: 0.0023886221211658985
Loss at iteration [433]: 0.0023882396434735456
Loss at iteration [434]: 0.002388064098449178
Loss at iteration [435]: 0.002387650497691081
Loss at iteration [436]: 0.0023874620071607637
Loss at iteration [437]: 0.0023873736925807696
Loss at iteration [438]: 0.002387227474230257
Loss at iteration [439]: 0.0023871456720473186
Loss at iteration [440]: 0.002386944053902044
Loss at iteration [441]: 0.002386920361343172
Loss at iteration [442]: 0.002386920361343172
Loss at iteration [443]: 0.002386901612488199
Loss at iteration [444]: 0.0023867164039229095
Loss at iteration [445]: 0.002386697327450136
Loss at iteration [446]: 0.0023866093453783414
Loss at iteration [447]: 0.0023864088701805544
Loss at iteration [448]: 0.0023863749738962303
Loss at iteration [449]: 0.002386186386394199
Loss at iteration [450]: 0.002385437085384723
Loss at iteration [451]: 0.0023849411885048435
Loss at iteration [452]: 0.002384514511070411
Loss at iteration [453]: 0.002384266181094672
Loss at iteration [454]: 0.002383100013074425
Loss at iteration [455]: 0.0023813136425434047
Loss at iteration [456]: 0.0023812396329359106
Loss at iteration [457]: 0.0023810868502150352
Loss at iteration [458]: 0.0023810868502150352
Loss at iteration [459]: 0.002381012975457895
Loss at iteration [460]: 0.002380633129970909
Loss at iteration [461]: 0.002380074323496049
Loss at iteration [462]: 0.002379763249245248
Loss at iteration [463]: 0.0023794245016231564
Loss at iteration [464]: 0.002378846648842224
Loss at iteration [465]: 0.0023780021744010077
Loss at iteration [466]: 0.002377876880557125
Loss at iteration [467]: 0.002377597155623167
Loss at iteration [468]: 0.0023773149442110034
Loss at iteration [469]: 0.0023772320368352523
Loss at iteration [470]: 0.0023770639014061364
Loss at iteration [471]: 0.0023769496664197373
Loss at iteration [472]: 0.0023769496664197373
Loss at iteration [473]: 0.002376850744241881
Loss at iteration [474]: 0.0023764445963114296
Loss at iteration [475]: 0.0023763873753296313
Loss at iteration [476]: 0.0023752429125331663
Loss at iteration [477]: 0.002375165058898795
Loss at iteration [478]: 0.002374916933005172
Loss at iteration [479]: 0.002374277267250119
Loss at iteration [480]: 0.002374193184769393
Loss at iteration [481]: 0.002373873854623662
Loss at iteration [482]: 0.002373574721720967
Loss at iteration [483]: 0.002373458905830163
Loss at iteration [484]: 0.002373136802640877
Loss at iteration [485]: 0.002373136802640877
Loss at iteration [486]: 0.0023730331622880837
Loss at iteration [487]: 0.0023729658735009854
Loss at iteration [488]: 0.0023728050200534094
Loss at iteration [489]: 0.0023727087099434598
Loss at iteration [490]: 0.0023726432700358607
Loss at iteration [491]: 0.0023724823826621988
Loss at iteration [492]: 0.00237245986119751
Loss at iteration [493]: 0.0023723061592713485
Loss at iteration [494]: 0.00237202258415065
Loss at iteration [495]: 0.002371785929814352
Loss at iteration [496]: 0.0023716912748397967
Loss at iteration [497]: 0.002371462853670855
Loss at iteration [498]: 0.002371303139840673
Loss at iteration [499]: 0.002371303139840673
Loss at iteration [500]: 0.0023712224287610758
Loss at iteration [501]: 0.002370779426666185
Loss at iteration [502]: 0.0023705960428558174
Loss at iteration [503]: 0.0023704317147520025
Loss at iteration [504]: 0.0023703308053285503
Loss at iteration [505]: 0.002370206294088878
Loss at iteration [506]: 0.002370024427844918
Loss at iteration [507]: 0.002370012038868304
Loss at iteration [508]: 0.0023699246812670777
Loss at iteration [509]: 0.0023698503533994665
Loss at iteration [510]: 0.002369746567700044
Loss at iteration [511]: 0.002369746567700044
Loss at iteration [512]: 0.0023696821961686574
Loss at iteration [513]: 0.0023695921775605333
Loss at iteration [514]: 0.0023695088445807996
Loss at iteration [515]: 0.00236943570848438
Loss at iteration [516]: 0.0023693606765781347
Loss at iteration [517]: 0.0023692294591678327
Loss at iteration [518]: 0.002369160142820709
Loss at iteration [519]: 0.0023687955936661093
Loss at iteration [520]: 0.0023683905790881092
Loss at iteration [521]: 0.002368056559596812
Loss at iteration [522]: 0.00236784788389346
Loss at iteration [523]: 0.0023674524485400713
Loss at iteration [524]: 0.00236704066092173
Loss at iteration [525]: 0.0023662833729026825
Loss at iteration [526]: 0.002365249190057382
Loss at iteration [527]: 0.002365249190057382
Loss at iteration [528]: 0.002364536474667585
Loss at iteration [529]: 0.002364416775418514
Loss at iteration [530]: 0.0023624251432453275
Loss at iteration [531]: 0.0023622296419851816
Loss at iteration [532]: 0.0023619887512249934
Loss at iteration [533]: 0.0023611978102637534
Loss at iteration [534]: 0.0023605489851931394
Loss at iteration [535]: 0.002360154147486557
Loss at iteration [536]: 0.0023592885528080625
Loss at iteration [537]: 0.0023588894984638586
Loss at iteration [538]: 0.002358289187001328
Loss at iteration [539]: 0.002357897543847736
Loss at iteration [540]: 0.0023575186608517083
Loss at iteration [541]: 0.0023574407960319627
Loss at iteration [542]: 0.0023574407960319627
Loss at iteration [543]: 0.002357354399988405
Loss at iteration [544]: 0.0023568613955484356
Loss at iteration [545]: 0.0023566041218759035
Loss at iteration [546]: 0.0023560872311211845
Loss at iteration [547]: 0.0023556765584491564
Loss at iteration [548]: 0.0023555552404380723
Loss at iteration [549]: 0.0023548784364806267
Loss at iteration [550]: 0.0023547711531348606
Loss at iteration [551]: 0.002354644227526344
Loss at iteration [552]: 0.0023531438789349307
Loss at iteration [553]: 0.0023529107691562224
Loss at iteration [554]: 0.0023529107691562224
Loss at iteration [555]: 0.0023527727814279787
Loss at iteration [556]: 0.002352712357796404
Loss at iteration [557]: 0.002351531223919269
Loss at iteration [558]: 0.002351086043015646
Loss at iteration [559]: 0.002350960156663861
Loss at iteration [560]: 0.002350565591927417
Loss at iteration [561]: 0.0023503460256910987
Loss at iteration [562]: 0.0023502761476830547
Loss at iteration [563]: 0.0023500101429520886
Loss at iteration [564]: 0.002349411795953994
Loss at iteration [565]: 0.0023493841710985927
Loss at iteration [566]: 0.0023492948702879576
Loss at iteration [567]: 0.002349069171330473
Loss at iteration [568]: 0.002349069171330473
Loss at iteration [569]: 0.0023489249002052815
Loss at iteration [570]: 0.002348907430635825
Loss at iteration [571]: 0.002348156439055037
Loss at iteration [572]: 0.0023479494778954535
Loss at iteration [573]: 0.0023477636812506077
Loss at iteration [574]: 0.0023474717467783777
Loss at iteration [575]: 0.002347113266142777
Loss at iteration [576]: 0.0023470267793102677
Loss at iteration [577]: 0.0023469043532335708
Loss at iteration [578]: 0.00234666328863165
Loss at iteration [579]: 0.002346569845673482
Loss at iteration [580]: 0.0023461608574325337
Loss at iteration [581]: 0.002345875054695679
Loss at iteration [582]: 0.002345875054695679
Loss at iteration [583]: 0.0023458043431993435
Loss at iteration [584]: 0.0023446729427524142
Loss at iteration [585]: 0.002344413043022909
Loss at iteration [586]: 0.002344252933464482
Loss at iteration [587]: 0.0023429530545338475
Loss at iteration [588]: 0.0023427094900987746
Loss at iteration [589]: 0.002342642095966621
Loss at iteration [590]: 0.0023424161071404787
Loss at iteration [591]: 0.002342250629780739
Loss at iteration [592]: 0.0023421710918815944
Loss at iteration [593]: 0.002342122146398398
Loss at iteration [594]: 0.0023420440626692137
Loss at iteration [595]: 0.002341958582589438
Loss at iteration [596]: 0.002341958582589438
Loss at iteration [597]: 0.002341897159686165
Loss at iteration [598]: 0.002341866030587676
Loss at iteration [599]: 0.0023416343504131095
Loss at iteration [600]: 0.0023415017827531697
Loss at iteration [601]: 0.002341439268198021
Loss at iteration [602]: 0.002341276935439794
Loss at iteration [603]: 0.0023411966688664113
Loss at iteration [604]: 0.0023411521641668125
Loss at iteration [605]: 0.0023411078166217345
Loss at iteration [606]: 0.0023409952248306053
Loss at iteration [607]: 0.0023408111396237353
Loss at iteration [608]: 0.002340783759139117
Loss at iteration [609]: 0.0023407435812343234
Loss at iteration [610]: 0.002340717429277825
Loss at iteration [611]: 0.0023406266850786394
Loss at iteration [612]: 0.0023406266850786394
Loss at iteration [613]: 0.0023405826770312587
Loss at iteration [614]: 0.0023405561315081704
Loss at iteration [615]: 0.0023404800200435
Loss at iteration [616]: 0.002340422068503067
Loss at iteration [617]: 0.0023403996885616716
Loss at iteration [618]: 0.002340277239858161
Loss at iteration [619]: 0.002339553560792936
Loss at iteration [620]: 0.0023394978663652116
Loss at iteration [621]: 0.002339127303338186
Loss at iteration [622]: 0.0023390610180907805
Loss at iteration [623]: 0.002339021848168941
Loss at iteration [624]: 0.002338902055369393
Loss at iteration [625]: 0.0023388360619070463
Loss at iteration [626]: 0.002338759327292598
Loss at iteration [627]: 0.0023387163985229944
Loss at iteration [628]: 0.0023385109574526803
Loss at iteration [629]: 0.0023385109574526803
Loss at iteration [630]: 0.00233843774651551
Loss at iteration [631]: 0.002338421459963864
Loss at iteration [632]: 0.0023383184199377823
Loss at iteration [633]: 0.002338261638383973
Loss at iteration [634]: 0.0023382330530077634
Loss at iteration [635]: 0.002338028342871834
Loss at iteration [636]: 0.002337736168856183
Loss at iteration [637]: 0.0023373857234434262
Loss at iteration [638]: 0.0023373324469815227
Loss at iteration [639]: 0.0023372188768230754
Loss at iteration [640]: 0.002336562934286111
Loss at iteration [641]: 0.0023363280674086697
Loss at iteration [642]: 0.0023361559252077827
Loss at iteration [643]: 0.0023357312625832535
Loss at iteration [644]: 0.0023357312625832535
Loss at iteration [645]: 0.00233555028629508
Loss at iteration [646]: 0.00233550847765212
Loss at iteration [647]: 0.00233521505123417
Loss at iteration [648]: 0.002335182408228458
Loss at iteration [649]: 0.0023348648679138214
Loss at iteration [650]: 0.0023348156784322835
Loss at iteration [651]: 0.0023345379759205395
Loss at iteration [652]: 0.0023343972257279817
Loss at iteration [653]: 0.0023342459909791156
Loss at iteration [654]: 0.00233391542316075
Loss at iteration [655]: 0.0023337684113578882
Loss at iteration [656]: 0.002333395355761096
Loss at iteration [657]: 0.002333395355761096
Loss at iteration [658]: 0.0023332294540509666
Loss at iteration [659]: 0.0023331617182084517
Loss at iteration [660]: 0.002333038571101203
Loss at iteration [661]: 0.002332972852054674
Loss at iteration [662]: 0.002332939000963326
Loss at iteration [663]: 0.0023327215334420517
Loss at iteration [664]: 0.002332690248861634
Loss at iteration [665]: 0.0023324778097413507
Loss at iteration [666]: 0.0023319760438104704
Loss at iteration [667]: 0.0023318990639809396
Loss at iteration [668]: 0.002331820185168809
Loss at iteration [669]: 0.002331781434173816
Loss at iteration [670]: 0.002331749741718448
Loss at iteration [671]: 0.0023316924320477875
Loss at iteration [672]: 0.0023316924320477875
Loss at iteration [673]: 0.0023316685673559234
Loss at iteration [674]: 0.0023316520588135296
Loss at iteration [675]: 0.002331519049653141
Loss at iteration [676]: 0.0023314892126308894
Loss at iteration [677]: 0.0023313994498105717
Loss at iteration [678]: 0.002330994366780315
Loss at iteration [679]: 0.0023308542856397964
Loss at iteration [680]: 0.002330755496857037
Loss at iteration [681]: 0.0023306686620867267
Loss at iteration [682]: 0.0023302401774237917
Loss at iteration [683]: 0.002329348299413429
Loss at iteration [684]: 0.0023292095748015124
Loss at iteration [685]: 0.0023292095748015124
Loss at iteration [686]: 0.002329139460179792
Loss at iteration [687]: 0.0023287748878661188
Loss at iteration [688]: 0.0023287371089284795
Loss at iteration [689]: 0.002328654142611794
Loss at iteration [690]: 0.002328154954771136
Loss at iteration [691]: 0.0023281209995607835
Loss at iteration [692]: 0.002327858380843862
Loss at iteration [693]: 0.0023274580305022484
Loss at iteration [694]: 0.0023273792551471175
Loss at iteration [695]: 0.0023273009684254085
Loss at iteration [696]: 0.0023268203243982212
Loss at iteration [697]: 0.002326774802651778
Loss at iteration [698]: 0.0023267192783047023
Loss at iteration [699]: 0.002326526252442191
Loss at iteration [700]: 0.002326526252442191
Loss at iteration [701]: 0.002326474928352031
Loss at iteration [702]: 0.0023264420743898963
Loss at iteration [703]: 0.0023262164674456155
Loss at iteration [704]: 0.0023261906303562413
Loss at iteration [705]: 0.0023261490603754095
Loss at iteration [706]: 0.002325988611809355
Loss at iteration [707]: 0.002325962413379784
Loss at iteration [708]: 0.002325797482238758
Loss at iteration [709]: 0.0023254199529501624
Loss at iteration [710]: 0.0023252909257175398
Loss at iteration [711]: 0.0023251901136164626
Loss at iteration [712]: 0.0023249606505456742
Loss at iteration [713]: 0.002324932058067171
Loss at iteration [714]: 0.0023248515304864514
Loss at iteration [715]: 0.00232452647043379
Loss at iteration [716]: 0.00232452647043379
Loss at iteration [717]: 0.0023244865514298434
Loss at iteration [718]: 0.002324360756212362
Loss at iteration [719]: 0.00232430335114222
Loss at iteration [720]: 0.0023242806821222642
Loss at iteration [721]: 0.0023241843618857527
Loss at iteration [722]: 0.002324154767153441
Loss at iteration [723]: 0.0023239561755952383
Loss at iteration [724]: 0.002323714086454568
Loss at iteration [725]: 0.0023236568556699393
Loss at iteration [726]: 0.002323314281486083
Loss at iteration [727]: 0.0023224181783515615
Loss at iteration [728]: 0.002322393585252354
Loss at iteration [729]: 0.0023219133872456363
Loss at iteration [730]: 0.002320378223920873
Loss at iteration [731]: 0.0023195931876180526
Loss at iteration [732]: 0.0023195931876180526
Loss at iteration [733]: 0.002319435894146843
Loss at iteration [734]: 0.0023192370127475344
Loss at iteration [735]: 0.0023188729585111663
Loss at iteration [736]: 0.0023186531910097887
Loss at iteration [737]: 0.002318443752436195
Loss at iteration [738]: 0.0023183527874484963
Loss at iteration [739]: 0.0023181329397788924
Loss at iteration [740]: 0.0023177269010021878
Loss at iteration [741]: 0.0023176731364588326
Loss at iteration [742]: 0.002317548908347646
Loss at iteration [743]: 0.002317338213776464
Loss at iteration [744]: 0.00231723617921389
Loss at iteration [745]: 0.0023171887516593125
Loss at iteration [746]: 0.0023171081818566153
Loss at iteration [747]: 0.002317060469248171
Loss at iteration [748]: 0.0023166847244920834
Loss at iteration [749]: 0.0023166847244920834
Loss at iteration [750]: 0.002316596100777933
Loss at iteration [751]: 0.0023165285468394457
Loss at iteration [752]: 0.0023163438832233354
Loss at iteration [753]: 0.0023163143356783765
Loss at iteration [754]: 0.0023162800018099953
Loss at iteration [755]: 0.0023161870418095198
Loss at iteration [756]: 0.002315865550941576
Loss at iteration [757]: 0.0023158424235012144
Loss at iteration [758]: 0.0023157872431956847
Loss at iteration [759]: 0.002315637037163765
Loss at iteration [760]: 0.002315590587218421
Loss at iteration [761]: 0.0023155282823406603
Loss at iteration [762]: 0.0023155282823406603
Loss at iteration [763]: 0.002315511119213231
Loss at iteration [764]: 0.002315492604050988
Loss at iteration [765]: 0.002315430741504804
Loss at iteration [766]: 0.0023153898212422423
Loss at iteration [767]: 0.0023151780599542753
Loss at iteration [768]: 0.0023150070394968715
Loss at iteration [769]: 0.002314975446252535
Loss at iteration [770]: 0.002314725739357503
Loss at iteration [771]: 0.00231458466163269
Loss at iteration [772]: 0.002314556611950662
Loss at iteration [773]: 0.002314248374808487
Loss at iteration [774]: 0.0023142137600702475
Loss at iteration [775]: 0.002314100457686617
Loss at iteration [776]: 0.0023139560401540813
Loss at iteration [777]: 0.0023138784277860294
Loss at iteration [778]: 0.0023137216348828277
Loss at iteration [779]: 0.0023137216348828277
Loss at iteration [780]: 0.0023136126498714622
Loss at iteration [781]: 0.0023135875299306755
Loss at iteration [782]: 0.0023132696444139477
Loss at iteration [783]: 0.00231316092006019
Loss at iteration [784]: 0.0023131245420453515
Loss at iteration [785]: 0.0023129739804162775
Loss at iteration [786]: 0.0023125959011537685
Loss at iteration [787]: 0.0023125741820011598
Loss at iteration [788]: 0.0023125337141927764
Loss at iteration [789]: 0.0023124900096607925
Loss at iteration [790]: 0.002312459387176464
Loss at iteration [791]: 0.002312434402948129
Loss at iteration [792]: 0.0023123933113991606
Loss at iteration [793]: 0.002312379042882007
Loss at iteration [794]: 0.002312379042882007
Loss at iteration [795]: 0.0023123713991035637
Loss at iteration [796]: 0.002312258762476436
Loss at iteration [797]: 0.002312207496100956
Loss at iteration [798]: 0.0023121712919608856
Loss at iteration [799]: 0.0023116046571219993
Loss at iteration [800]: 0.0023111407163871724
Loss at iteration [801]: 0.002311001979324251
Loss at iteration [802]: 0.0023108713598448726
Loss at iteration [803]: 0.002310235860234947
Loss at iteration [804]: 0.002308805137610323
Loss at iteration [805]: 0.0023077700253290524
Loss at iteration [806]: 0.002305143316395654
Loss at iteration [807]: 0.002305143316395654
Loss at iteration [808]: 0.0023037168415381047
Loss at iteration [809]: 0.002301458944613396
Loss at iteration [810]: 0.002300055288813843
Loss at iteration [811]: 0.002298342137987908
Loss at iteration [812]: 0.0022969514241953227
Loss at iteration [813]: 0.002296780148820535
Loss at iteration [814]: 0.0022962557034151626
Loss at iteration [815]: 0.0022960501167848227
Loss at iteration [816]: 0.0022959848633868044
Loss at iteration [817]: 0.00229577543386869
Loss at iteration [818]: 0.0022951750588101312
Loss at iteration [819]: 0.0022948636442708097
Loss at iteration [820]: 0.0022946054334761386
Loss at iteration [821]: 0.0022946054334761386
Loss at iteration [822]: 0.0022944209323440216
Loss at iteration [823]: 0.0022939414760414626
Loss at iteration [824]: 0.002293734066946469
Loss at iteration [825]: 0.0022936066279795634
Loss at iteration [826]: 0.0022932260831044554
Loss at iteration [827]: 0.0022929906784676024
Loss at iteration [828]: 0.0022928863851524412
Loss at iteration [829]: 0.0022924199130666153
Loss at iteration [830]: 0.0022922669448871198
Loss at iteration [831]: 0.0022920572659085336
Loss at iteration [832]: 0.002291489743111973
Loss at iteration [833]: 0.002291368076598749
Loss at iteration [834]: 0.0022912451002910722
Loss at iteration [835]: 0.002290863309029505
Loss at iteration [836]: 0.0022907981196013585
Loss at iteration [837]: 0.0022906150924587635
Loss at iteration [838]: 0.0022906150924587635
Loss at iteration [839]: 0.002290513156661153
Loss at iteration [840]: 0.0022904195732200133
Loss at iteration [841]: 0.002290251283800319
Loss at iteration [842]: 0.0022901514264108427
Loss at iteration [843]: 0.002290015187211106
Loss at iteration [844]: 0.002289727329592002
Loss at iteration [845]: 0.002289055407365863
Loss at iteration [846]: 0.002288996682621252
Loss at iteration [847]: 0.0022888149823764798
Loss at iteration [848]: 0.0022885963714861547
Loss at iteration [849]: 0.0022885093616571827
Loss at iteration [850]: 0.002288066202149047
Loss at iteration [851]: 0.0022877784652052214
Loss at iteration [852]: 0.0022877784652052214
Loss at iteration [853]: 0.0022876844782228505
Loss at iteration [854]: 0.0022874121179214694
Loss at iteration [855]: 0.0022873548907738827
Loss at iteration [856]: 0.0022873407135806634
Loss at iteration [857]: 0.0022872951486178337
Loss at iteration [858]: 0.00228724886479647
Loss at iteration [859]: 0.0022870145576004827
Loss at iteration [860]: 0.002286918226362764
Loss at iteration [861]: 0.0022867918427424646
Loss at iteration [862]: 0.0022866601035978072
Loss at iteration [863]: 0.0022866174362901276
Loss at iteration [864]: 0.0022864968435171843
Loss at iteration [865]: 0.002286450500031706
Loss at iteration [866]: 0.002286411917208892
Loss at iteration [867]: 0.002286411917208892
Loss at iteration [868]: 0.002286387134344964
Loss at iteration [869]: 0.002286297737001986
Loss at iteration [870]: 0.0022862806894591455
Loss at iteration [871]: 0.0022860193808061065
Loss at iteration [872]: 0.002285657835326463
Loss at iteration [873]: 0.0022854173315673613
Loss at iteration [874]: 0.0022850466750121102
Loss at iteration [875]: 0.002284911462223949
Loss at iteration [876]: 0.0022846514094712026
Loss at iteration [877]: 0.002284483914921254
Loss at iteration [878]: 0.002284371538406139
Loss at iteration [879]: 0.0022837541139480288
Loss at iteration [880]: 0.002283533791955611
Loss at iteration [881]: 0.002283342819496193
Loss at iteration [882]: 0.002281891386922487
Loss at iteration [883]: 0.002281695105638036
Loss at iteration [884]: 0.002281695105638036
Loss at iteration [885]: 0.0022814907584938248
Loss at iteration [886]: 0.0022808666980071507
Loss at iteration [887]: 0.002280592386422275
Loss at iteration [888]: 0.002280455532634208
Loss at iteration [889]: 0.0022802608596484523
Loss at iteration [890]: 0.002280206731972595
Loss at iteration [891]: 0.0022800079431695747
Loss at iteration [892]: 0.002279881640767566
Loss at iteration [893]: 0.002279812393773746
Loss at iteration [894]: 0.0022793886676344285
Loss at iteration [895]: 0.0022793248686596634
Loss at iteration [896]: 0.002279248942294284
Loss at iteration [897]: 0.002279129297265761
Loss at iteration [898]: 0.0022790858229193604
Loss at iteration [899]: 0.0022790858229193604
Loss at iteration [900]: 0.0022790490157427474
Loss at iteration [901]: 0.002278774269114717
Loss at iteration [902]: 0.002278607111042682
Loss at iteration [903]: 0.0022785660326464638
Loss at iteration [904]: 0.0022783454495986953
Loss at iteration [905]: 0.0022782371284599872
Loss at iteration [906]: 0.0022781467938706042
Loss at iteration [907]: 0.002278082039831525
Loss at iteration [908]: 0.0022779838922677145
Loss at iteration [909]: 0.002277924178166709
Loss at iteration [910]: 0.0022778459691585496
Loss at iteration [911]: 0.0022777664305251915
Loss at iteration [912]: 0.002277699756728345
Loss at iteration [913]: 0.0022773725776429822
Loss at iteration [914]: 0.0022772315871181477
Loss at iteration [915]: 0.0022772315871181477
Loss at iteration [916]: 0.002277149188707438
Loss at iteration [917]: 0.0022768128314437116
Loss at iteration [918]: 0.0022764944954124225
Loss at iteration [919]: 0.0022764666608496614
Loss at iteration [920]: 0.0022763642077124895
Loss at iteration [921]: 0.002276298598214568
Loss at iteration [922]: 0.002276252568394235
Loss at iteration [923]: 0.0022761149573917254
Loss at iteration [924]: 0.0022760780101485404
Loss at iteration [925]: 0.0022760224046484514
Loss at iteration [926]: 0.0022759459370623823
Loss at iteration [927]: 0.002275899237695721
Loss at iteration [928]: 0.0022758123193863645
Loss at iteration [929]: 0.002275734459898999
Loss at iteration [930]: 0.002275407569677436
Loss at iteration [931]: 0.002275407569677436
Loss at iteration [932]: 0.002275372584386649
Loss at iteration [933]: 0.0022752717955703454
Loss at iteration [934]: 0.0022751414637355877
Loss at iteration [935]: 0.0022750796713690387
Loss at iteration [936]: 0.002275031227702292
Loss at iteration [937]: 0.0022749748007982566
Loss at iteration [938]: 0.0022748464389976144
Loss at iteration [939]: 0.0022747980120098273
Loss at iteration [940]: 0.0022744797754140266
Loss at iteration [941]: 0.0022743023566703545
Loss at iteration [942]: 0.0022741470399869654
Loss at iteration [943]: 0.0022739328961041
Loss at iteration [944]: 0.0022737447984181865
Loss at iteration [945]: 0.0022737447984181865
Loss at iteration [946]: 0.0022736318517732608
Loss at iteration [947]: 0.0022735809003771004
Loss at iteration [948]: 0.0022732067999399926
Loss at iteration [949]: 0.0022731494372724152
Loss at iteration [950]: 0.0022730183663211643
Loss at iteration [951]: 0.002272917216381136
Loss at iteration [952]: 0.0022728550258464264
Loss at iteration [953]: 0.0022726987673949857
Loss at iteration [954]: 0.0022726697824995055
Loss at iteration [955]: 0.0022725856838969783
Loss at iteration [956]: 0.002272504008391801
Loss at iteration [957]: 0.0022724521913620637
Loss at iteration [958]: 0.002272413312184113
Loss at iteration [959]: 0.0022723864901944358
Loss at iteration [960]: 0.002272344468643465
Loss at iteration [961]: 0.0022723198295582035
Loss at iteration [962]: 0.0022722782394209383
Loss at iteration [963]: 0.0022722782394209383
Loss at iteration [964]: 0.0022722660155147594
Loss at iteration [965]: 0.0022722279852115303
Loss at iteration [966]: 0.0022722053560976932
Loss at iteration [967]: 0.0022721155526318074
Loss at iteration [968]: 0.002271959872061885
Loss at iteration [969]: 0.0022718670717971796
Loss at iteration [970]: 0.002271688101054351
Loss at iteration [971]: 0.002271373553079252
Loss at iteration [972]: 0.0022704860592438914
Loss at iteration [973]: 0.002270297244383097
Loss at iteration [974]: 0.002269347970242986
Loss at iteration [975]: 0.002268585692044005
Loss at iteration [976]: 0.0022675637765068343
Loss at iteration [977]: 0.0022666571212458598
Loss at iteration [978]: 0.0022666571212458598
Loss at iteration [979]: 0.0022651116832728573
Loss at iteration [980]: 0.0022648221302849366
Loss at iteration [981]: 0.002263649278665537
Loss at iteration [982]: 0.0022628480714736534
Loss at iteration [983]: 0.0022609212688622995
Loss at iteration [984]: 0.002259707306646306
Loss at iteration [985]: 0.002259045808982674
Loss at iteration [986]: 0.002257939535871323
Loss at iteration [987]: 0.002257715388852659
Loss at iteration [988]: 0.0022572191465341906
Loss at iteration [989]: 0.0022570246343256283
Loss at iteration [990]: 0.0022568483414816378
Loss at iteration [991]: 0.0022559973304940805
Loss at iteration [992]: 0.002255839926461384
Loss at iteration [993]: 0.002255839926461384
Loss at iteration [994]: 0.0022556693845827416
Loss at iteration [995]: 0.0022553932019548683
Loss at iteration [996]: 0.0022547035024758338
Loss at iteration [997]: 0.002254208066399296
Loss at iteration [998]: 0.002254041367100417
Loss at iteration [999]: 0.002253814341984272
Loss at iteration [1000]: 0.0022532047583692667
Loss at iteration [1001]: 0.0022531250169584905
Loss at iteration [1002]: 0.002252978812268972
Loss at iteration [1003]: 0.002252484086388617
Loss at iteration [1004]: 0.0022521918305916508
Loss at iteration [1005]: 0.0022519920296506495
Loss at iteration [1006]: 0.0022518473811980843
Loss at iteration [1007]: 0.0022518473811980843
Loss at iteration [1008]: 0.002251715884428727
Loss at iteration [1009]: 0.002251476684069375
Loss at iteration [1010]: 0.0022510306580918325
Loss at iteration [1011]: 0.0022509940787460623
Loss at iteration [1012]: 0.0022508777118881414
Loss at iteration [1013]: 0.0022506520776749087
Loss at iteration [1014]: 0.0022505343735147792
Loss at iteration [1015]: 0.0022504101402586758
Loss at iteration [1016]: 0.0022498816595448038
Loss at iteration [1017]: 0.0022496488381975963
Loss at iteration [1018]: 0.002249324666148826
Loss at iteration [1019]: 0.002248985595512572
Loss at iteration [1020]: 0.0022487294104357788
Loss at iteration [1021]: 0.0022486500590386854
Loss at iteration [1022]: 0.0022486500590386854
Loss at iteration [1023]: 0.002248583139623031
Loss at iteration [1024]: 0.0022482557646165955
Loss at iteration [1025]: 0.002248048094816839
Loss at iteration [1026]: 0.002247954865115512
Loss at iteration [1027]: 0.002247704572102667
Loss at iteration [1028]: 0.0022476356658842657
Loss at iteration [1029]: 0.0022474586725524034
Loss at iteration [1030]: 0.0022472772655989185
Loss at iteration [1031]: 0.0022471851803836174
Loss at iteration [1032]: 0.0022471100767745378
Loss at iteration [1033]: 0.002247072099663401
Loss at iteration [1034]: 0.0022469001529381513
Loss at iteration [1035]: 0.0022468239775332703
Loss at iteration [1036]: 0.0022467208318531543
Loss at iteration [1037]: 0.0022466729131348055
Loss at iteration [1038]: 0.002246579352943546
Loss at iteration [1039]: 0.0022464761103943545
Loss at iteration [1040]: 0.0022464761103943545
Loss at iteration [1041]: 0.002246434431957089
Loss at iteration [1042]: 0.0022463048500471023
Loss at iteration [1043]: 0.0022462757185996657
Loss at iteration [1044]: 0.002246232183953988
Loss at iteration [1045]: 0.002246009939464459
Loss at iteration [1046]: 0.002245864790616413
Loss at iteration [1047]: 0.002245699722073842
Loss at iteration [1048]: 0.0022455888372107987
Loss at iteration [1049]: 0.002245431895205582
Loss at iteration [1050]: 0.0022451493742125313
Loss at iteration [1051]: 0.0022449905562270923
Loss at iteration [1052]: 0.002244528600378108
Loss at iteration [1053]: 0.0022444032553702625
Loss at iteration [1054]: 0.0022444032553702625
Loss at iteration [1055]: 0.0022443392256947595
Loss at iteration [1056]: 0.0022440764062784334
Loss at iteration [1057]: 0.0022439799640039328
Loss at iteration [1058]: 0.0022438378935113524
Loss at iteration [1059]: 0.0022437488811920822
Loss at iteration [1060]: 0.002243440201753085
Loss at iteration [1061]: 0.0022433489164705813
Loss at iteration [1062]: 0.0022432091984770993
Loss at iteration [1063]: 0.0022431169095942557
Loss at iteration [1064]: 0.0022427102463569277
Loss at iteration [1065]: 0.0022425840543346576
Loss at iteration [1066]: 0.002242342667635053
Loss at iteration [1067]: 0.002242193253227625
Loss at iteration [1068]: 0.002242105365990981
Loss at iteration [1069]: 0.002242105365990981
Loss at iteration [1070]: 0.0022420127461243266
Loss at iteration [1071]: 0.0022419174507202614
Loss at iteration [1072]: 0.002241607109251807
Loss at iteration [1073]: 0.002241570366465779
Loss at iteration [1074]: 0.0022412956326890157
Loss at iteration [1075]: 0.002241244085966833
Loss at iteration [1076]: 0.0022410117862130224
Loss at iteration [1077]: 0.0022409206441105197
Loss at iteration [1078]: 0.0022408658636150075
Loss at iteration [1079]: 0.0022407651325561584
Loss at iteration [1080]: 0.0022405631878310334
Loss at iteration [1081]: 0.0022404394887316115
Loss at iteration [1082]: 0.0022403805369375167
Loss at iteration [1083]: 0.0022403805369375167
Loss at iteration [1084]: 0.0022403554627263493
Loss at iteration [1085]: 0.0022401702083915116
Loss at iteration [1086]: 0.0022400645448583637
Loss at iteration [1087]: 0.002240026605086901
Loss at iteration [1088]: 0.0022399807021913224
Loss at iteration [1089]: 0.0022399545674905456
Loss at iteration [1090]: 0.002239897312181613
Loss at iteration [1091]: 0.002239871038549228
Loss at iteration [1092]: 0.0022398138033318713
Loss at iteration [1093]: 0.002239776742932359
Loss at iteration [1094]: 0.002239677909675566
Loss at iteration [1095]: 0.0022396241512399697
Loss at iteration [1096]: 0.002239580275084941
Loss at iteration [1097]: 0.002239517040269018
Loss at iteration [1098]: 0.0022394640316277473
Loss at iteration [1099]: 0.002239170878707184
Loss at iteration [1100]: 0.002239170878707184
Loss at iteration [1101]: 0.002239128296381072
Loss at iteration [1102]: 0.0022391004851039105
Loss at iteration [1103]: 0.0022389704178300933
Loss at iteration [1104]: 0.0022389521330662895
Loss at iteration [1105]: 0.0022389350740519435
Loss at iteration [1106]: 0.002238896182413051
Loss at iteration [1107]: 0.002238875587951652
Loss at iteration [1108]: 0.0022388035316780815
Loss at iteration [1109]: 0.002238749680702984
Loss at iteration [1110]: 0.0022386610347453805
Loss at iteration [1111]: 0.0022384843717722083
Loss at iteration [1112]: 0.002238270002022403
Loss at iteration [1113]: 0.002238176159590475
Loss at iteration [1114]: 0.002237968703847106
Loss at iteration [1115]: 0.002237441191748937
Loss at iteration [1116]: 0.002237441191748937
Loss at iteration [1117]: 0.002237257084246938
Loss at iteration [1118]: 0.0022371930898151676
Loss at iteration [1119]: 0.0022365042207273056
Loss at iteration [1120]: 0.0022364750568710677
Loss at iteration [1121]: 0.002236347006130062
Loss at iteration [1122]: 0.0022361320319698908
Loss at iteration [1123]: 0.0022360967821964594
Loss at iteration [1124]: 0.0022360550132806225
Loss at iteration [1125]: 0.0022360001113810014
Loss at iteration [1126]: 0.0022359121705213506
Loss at iteration [1127]: 0.0022358586384731744
Loss at iteration [1128]: 0.002235784760434883
Loss at iteration [1129]: 0.002235784760434883
Loss at iteration [1130]: 0.0022357229830841352
Loss at iteration [1131]: 0.0022356225070311064
Loss at iteration [1132]: 0.0022355830940702015
Loss at iteration [1133]: 0.002235552316989292
Loss at iteration [1134]: 0.002235519801858101
Loss at iteration [1135]: 0.0022354947782838495
Loss at iteration [1136]: 0.002235388547367984
Loss at iteration [1137]: 0.0022353416603362285
Loss at iteration [1138]: 0.002235300614153709
Loss at iteration [1139]: 0.0022350410975126404
Loss at iteration [1140]: 0.0022348921144640264
Loss at iteration [1141]: 0.0022345410764003297
Loss at iteration [1142]: 0.0022344951592537026
Loss at iteration [1143]: 0.0022343573437539448
Loss at iteration [1144]: 0.0022343573437539448
Loss at iteration [1145]: 0.002234291208884582
Loss at iteration [1146]: 0.002234252882197818
Loss at iteration [1147]: 0.002233999364857057
Loss at iteration [1148]: 0.002233957918026605
Loss at iteration [1149]: 0.0022337561708920483
Loss at iteration [1150]: 0.0022337039771552574
Loss at iteration [1151]: 0.002233655057679173
Loss at iteration [1152]: 0.002233496781759722
Loss at iteration [1153]: 0.0022334408970951358
Loss at iteration [1154]: 0.002233391962994106
Loss at iteration [1155]: 0.0022332648180080003
Loss at iteration [1156]: 0.0022332274630708095
Loss at iteration [1157]: 0.0022331104586586527
Loss at iteration [1158]: 0.002232979800539617
Loss at iteration [1159]: 0.002232979800539617
Loss at iteration [1160]: 0.0022329575520591265
Loss at iteration [1161]: 0.0022328796632812677
Loss at iteration [1162]: 0.002232827540465419
Loss at iteration [1163]: 0.0022327891909476477
Loss at iteration [1164]: 0.002232737250774037
Loss at iteration [1165]: 0.002232706624199081
Loss at iteration [1166]: 0.0022326532668236025
Loss at iteration [1167]: 0.00223261973134262
Loss at iteration [1168]: 0.0022325625190729383
Loss at iteration [1169]: 0.0022325395526533085
Loss at iteration [1170]: 0.002232503730222
Loss at iteration [1171]: 0.002232476284597577
Loss at iteration [1172]: 0.002232395077228869
Loss at iteration [1173]: 0.0022323673240764205
Loss at iteration [1174]: 0.0022323305200093613
Loss at iteration [1175]: 0.0022322091320291213
Loss at iteration [1176]: 0.002232165867028237
Loss at iteration [1177]: 0.002232165867028237
Loss at iteration [1178]: 0.0022321470338061093
Loss at iteration [1179]: 0.002232102361517636
Loss at iteration [1180]: 0.002232023298198878
Loss at iteration [1181]: 0.0022320037392988697
Loss at iteration [1182]: 0.0022319847288889126
Loss at iteration [1183]: 0.0022319638172246512
Loss at iteration [1184]: 0.002231934471595757
Loss at iteration [1185]: 0.0022318952969509745
Loss at iteration [1186]: 0.0022318638566478344
Loss at iteration [1187]: 0.002231793892987926
Loss at iteration [1188]: 0.0022316385993126704
Loss at iteration [1189]: 0.00223133746777843
Loss at iteration [1190]: 0.002230875427329198
Loss at iteration [1191]: 0.0022307059856718037
Loss at iteration [1192]: 0.002230195072373979
Loss at iteration [1193]: 0.002229385577357594
Loss at iteration [1194]: 0.002228153952345596
Loss at iteration [1195]: 0.002221582869268503
Loss at iteration [1196]: 0.002221582869268503
Loss at iteration [1197]: 0.002219868855249613
Loss at iteration [1198]: 0.002219201382698329
Loss at iteration [1199]: 0.002216748181756092
Loss at iteration [1200]: 0.002216515115442257
Loss at iteration [1201]: 0.0022162771605683577
Loss at iteration [1202]: 0.0022151361192859695
Loss at iteration [1203]: 0.0022140248828793575
Loss at iteration [1204]: 0.0022138655869847145
Loss at iteration [1205]: 0.0022134080693280147
Loss at iteration [1206]: 0.0022127656138953853
Loss at iteration [1207]: 0.002212697528286099
Loss at iteration [1208]: 0.002211542733225678
Loss at iteration [1209]: 0.0022113834707171934
Loss at iteration [1210]: 0.0022113834707171934
Loss at iteration [1211]: 0.0022112827101232854
Loss at iteration [1212]: 0.0022107897231795114
Loss at iteration [1213]: 0.0022107371724639463
Loss at iteration [1214]: 0.0022102161830008854
Loss at iteration [1215]: 0.0022099873696499175
Loss at iteration [1216]: 0.0022099415889189995
Loss at iteration [1217]: 0.002209496367483255
Loss at iteration [1218]: 0.0022093910657970885
Loss at iteration [1219]: 0.0022091346419039347
Loss at iteration [1220]: 0.002208900262725528
Loss at iteration [1221]: 0.0022087647687447183
Loss at iteration [1222]: 0.0022087647687447183
Loss at iteration [1223]: 0.0022086098112941085
Loss at iteration [1224]: 0.002208271537205757
Loss at iteration [1225]: 0.0022081435213040447
Loss at iteration [1226]: 0.0022080673993756994
Loss at iteration [1227]: 0.002207973120223407
Loss at iteration [1228]: 0.00220790989047154
Loss at iteration [1229]: 0.0022078729101059572
Loss at iteration [1230]: 0.0022077915456821325
Loss at iteration [1231]: 0.0022077197434847385
Loss at iteration [1232]: 0.0022076404010309084
Loss at iteration [1233]: 0.002207519104320863
Loss at iteration [1234]: 0.0022074264599447964
Loss at iteration [1235]: 0.0022073594869931813
Loss at iteration [1236]: 0.00220731608573561
Loss at iteration [1237]: 0.002207274039139485
Loss at iteration [1238]: 0.0022071832828360624
Loss at iteration [1239]: 0.002207109454951868
Loss at iteration [1240]: 0.002207109454951868
Loss at iteration [1241]: 0.0022070832508158536
Loss at iteration [1242]: 0.002207038384788997
Loss at iteration [1243]: 0.002206987916924056
Loss at iteration [1244]: 0.0022069686197727432
Loss at iteration [1245]: 0.002206945058266976
Loss at iteration [1246]: 0.002206913186277473
Loss at iteration [1247]: 0.0022068761884566513
Loss at iteration [1248]: 0.00220674515276768
Loss at iteration [1249]: 0.002206686678227478
Loss at iteration [1250]: 0.0022065405279913315
Loss at iteration [1251]: 0.0022063602016307907
Loss at iteration [1252]: 0.0022062715464199246
Loss at iteration [1253]: 0.0022060637075700133
Loss at iteration [1254]: 0.0022058585608267177
Loss at iteration [1255]: 0.002205624008185412
Loss at iteration [1256]: 0.00220511823512152
Loss at iteration [1257]: 0.0022048833987921845
Loss at iteration [1258]: 0.0022046884176892267
Loss at iteration [1259]: 0.0022046884176892267
Loss at iteration [1260]: 0.0022045256843846437
Loss at iteration [1261]: 0.002204403468095574
Loss at iteration [1262]: 0.0022036708853658575
Loss at iteration [1263]: 0.0022035741682164657
Loss at iteration [1264]: 0.0022035330017507763
Loss at iteration [1265]: 0.002203253184815303
Loss at iteration [1266]: 0.0022032126479090996
Loss at iteration [1267]: 0.0022029174984057954
Loss at iteration [1268]: 0.0022027077059618215
Loss at iteration [1269]: 0.002202491454318897
Loss at iteration [1270]: 0.002202406304439995
Loss at iteration [1271]: 0.0022021921600025533
Loss at iteration [1272]: 0.0022021921600025533
Loss at iteration [1273]: 0.002202177038298809
Loss at iteration [1274]: 0.0022021505497270867
Loss at iteration [1275]: 0.0022020819723435
Loss at iteration [1276]: 0.0022020150515044664
Loss at iteration [1277]: 0.0022019477925768766
Loss at iteration [1278]: 0.0022019226752418874
Loss at iteration [1279]: 0.002201866588239353
Loss at iteration [1280]: 0.002201780632380456
Loss at iteration [1281]: 0.0022016995839678117
Loss at iteration [1282]: 0.0022014583066397512
Loss at iteration [1283]: 0.002201362290048727
Loss at iteration [1284]: 0.002201045627842379
Loss at iteration [1285]: 0.002200925230290088
Loss at iteration [1286]: 0.0022007039123055016
Loss at iteration [1287]: 0.0022007039123055016
Loss at iteration [1288]: 0.0022006630526693566
Loss at iteration [1289]: 0.0022005235373286215
Loss at iteration [1290]: 0.0022004311448902024
Loss at iteration [1291]: 0.002200372942269988
Loss at iteration [1292]: 0.0022002784887422116
Loss at iteration [1293]: 0.002200168743491675
Loss at iteration [1294]: 0.0022000957430323397
Loss at iteration [1295]: 0.002200022995389105
Loss at iteration [1296]: 0.0021999645117691756
Loss at iteration [1297]: 0.0021999328591046363
Loss at iteration [1298]: 0.00219987265266697
Loss at iteration [1299]: 0.002199813672563983
Loss at iteration [1300]: 0.002199795392814141
Loss at iteration [1301]: 0.0021997611799256683
Loss at iteration [1302]: 0.00219968499929776
Loss at iteration [1303]: 0.002199636775685829
Loss at iteration [1304]: 0.002199596275780144
Loss at iteration [1305]: 0.0021995367578846524
Loss at iteration [1306]: 0.0021995367578846524
Loss at iteration [1307]: 0.002199512902844601
Loss at iteration [1308]: 0.0021994580724213455
Loss at iteration [1309]: 0.0021993941018055856
Loss at iteration [1310]: 0.002199360278492454
Loss at iteration [1311]: 0.0021993252207511645
Loss at iteration [1312]: 0.002199304803210484
Loss at iteration [1313]: 0.002199271377601211
Loss at iteration [1314]: 0.0021992437395625514
Loss at iteration [1315]: 0.0021992155898162683
Loss at iteration [1316]: 0.002199186563478352
Loss at iteration [1317]: 0.002199087921685354
Loss at iteration [1318]: 0.0021990195615807116
Loss at iteration [1319]: 0.0021989313957557826
Loss at iteration [1320]: 0.0021989313957557826
Loss at iteration [1321]: 0.002198911109112227
Loss at iteration [1322]: 0.002198807037692899
Loss at iteration [1323]: 0.00219879252121706
Loss at iteration [1324]: 0.002198767725437843
Loss at iteration [1325]: 0.002198736114631014
Loss at iteration [1326]: 0.0021987179881235155
Loss at iteration [1327]: 0.0021986776524399836
Loss at iteration [1328]: 0.002198649150300908
Loss at iteration [1329]: 0.0021986169864909415
Loss at iteration [1330]: 0.0021985908638381063
Loss at iteration [1331]: 0.002198539215998456
Loss at iteration [1332]: 0.0021983744631348264
Loss at iteration [1333]: 0.0021981274320132457
Loss at iteration [1334]: 0.0021980136581582965
Loss at iteration [1335]: 0.0021978758447688007
Loss at iteration [1336]: 0.0021978758447688007
Loss at iteration [1337]: 0.0021978166310795575
Loss at iteration [1338]: 0.0021974608007356163
Loss at iteration [1339]: 0.002197235828938393
Loss at iteration [1340]: 0.002197205287202138
Loss at iteration [1341]: 0.002197157697567336
Loss at iteration [1342]: 0.002197077322255432
Loss at iteration [1343]: 0.0021969543502847843
Loss at iteration [1344]: 0.00219693603898647
Loss at iteration [1345]: 0.0021967512017120002
Loss at iteration [1346]: 0.002196688961828782
Loss at iteration [1347]: 0.0021966392410025697
Loss at iteration [1348]: 0.0021966101384124272
Loss at iteration [1349]: 0.002196553716597577
Loss at iteration [1350]: 0.002196530188919864
Loss at iteration [1351]: 0.0021965152823408742
Loss at iteration [1352]: 0.0021965152823408742
Loss at iteration [1353]: 0.002196498014637209
Loss at iteration [1354]: 0.002196459778849148
Loss at iteration [1355]: 0.0021964179483926773
Loss at iteration [1356]: 0.002196396902738368
Loss at iteration [1357]: 0.00219638208107602
Loss at iteration [1358]: 0.0021963735358037258
Loss at iteration [1359]: 0.002196364654682783
Loss at iteration [1360]: 0.0021963479624585503
Loss at iteration [1361]: 0.0021963323558572613
Loss at iteration [1362]: 0.0021962559277108828
Loss at iteration [1363]: 0.002196228701713398
Loss at iteration [1364]: 0.0021961225072430635
Loss at iteration [1365]: 0.002196018503627397
Loss at iteration [1366]: 0.0021958500966584834
Loss at iteration [1367]: 0.0021958500966584834
Loss at iteration [1368]: 0.0021957743283637613
Loss at iteration [1369]: 0.00219572040737831
Loss at iteration [1370]: 0.0021955262762770994
Loss at iteration [1371]: 0.0021954946920154017
Loss at iteration [1372]: 0.002195391295693527
Loss at iteration [1373]: 0.002195343548933827
Loss at iteration [1374]: 0.002195323621822008
Loss at iteration [1375]: 0.0021952774043732456
Loss at iteration [1376]: 0.002195254737383142
Loss at iteration [1377]: 0.002195210893576245
Loss at iteration [1378]: 0.002195162901931653
Loss at iteration [1379]: 0.0021951268867131855
Loss at iteration [1380]: 0.0021951103250381
Loss at iteration [1381]: 0.002195008512755341
Loss at iteration [1382]: 0.002195008512755341
Loss at iteration [1383]: 0.002194988863707285
Loss at iteration [1384]: 0.00219482824576285
Loss at iteration [1385]: 0.002194812529674302
Loss at iteration [1386]: 0.002194795816547063
Loss at iteration [1387]: 0.0021947420172884957
Loss at iteration [1388]: 0.0021947184185571135
Loss at iteration [1389]: 0.0021946837382198197
Loss at iteration [1390]: 0.0021946637552527687
Loss at iteration [1391]: 0.002194644471510386
Loss at iteration [1392]: 0.002194617324852529
Loss at iteration [1393]: 0.0021945798587942344
Loss at iteration [1394]: 0.002194518514493988
Loss at iteration [1395]: 0.002194464452821529
Loss at iteration [1396]: 0.002194369944608106
Loss at iteration [1397]: 0.002194297442473704
Loss at iteration [1398]: 0.002193697370101256
Loss at iteration [1399]: 0.002193697370101256
Loss at iteration [1400]: 0.0021936377147376406
Loss at iteration [1401]: 0.002193380047512551
Loss at iteration [1402]: 0.0021933322305137007
Loss at iteration [1403]: 0.002193164337718967
Loss at iteration [1404]: 0.0021931116571508825
Loss at iteration [1405]: 0.0021930144198399858
Loss at iteration [1406]: 0.0021929847382149
Loss at iteration [1407]: 0.002192922704993142
Loss at iteration [1408]: 0.0021928641570291263
Loss at iteration [1409]: 0.002192815916909919
Loss at iteration [1410]: 0.002192728395676456
Loss at iteration [1411]: 0.0021927133367798395
Loss at iteration [1412]: 0.0021926737813238815
Loss at iteration [1413]: 0.002192557799084533
Loss at iteration [1414]: 0.0021925329902133545
Loss at iteration [1415]: 0.0021925329902133545
Loss at iteration [1416]: 0.0021925117756815935
Loss at iteration [1417]: 0.002192475099976741
Loss at iteration [1418]: 0.002192463268670377
Loss at iteration [1419]: 0.0021924409497360974
Loss at iteration [1420]: 0.002192413995292076
Loss at iteration [1421]: 0.002192375791481836
Loss at iteration [1422]: 0.0021923348945599823
Loss at iteration [1423]: 0.002192270036313963
Loss at iteration [1424]: 0.0021921978805557463
Loss at iteration [1425]: 0.002192081308751508
Loss at iteration [1426]: 0.0021919729991525124
Loss at iteration [1427]: 0.002191827279374192
Loss at iteration [1428]: 0.0021914586826490326
Loss at iteration [1429]: 0.002190892368352427
Loss at iteration [1430]: 0.0021907854279445385
Loss at iteration [1431]: 0.0021905236039848576
Loss at iteration [1432]: 0.002190277352626949
Loss at iteration [1433]: 0.002190277352626949
Loss at iteration [1434]: 0.0021901761816827403
Loss at iteration [1435]: 0.00219007559486494
Loss at iteration [1436]: 0.0021897050198897787
Loss at iteration [1437]: 0.002189513602019304
Loss at iteration [1438]: 0.0021893843214164576
Loss at iteration [1439]: 0.002189225097553964
Loss at iteration [1440]: 0.002189022438727924
Loss at iteration [1441]: 0.0021889583609301117
Loss at iteration [1442]: 0.0021889160251164935
Loss at iteration [1443]: 0.0021885603456308837
Loss at iteration [1444]: 0.0021884928981745315
Loss at iteration [1445]: 0.002188388039101024
Loss at iteration [1446]: 0.002188270609500118
Loss at iteration [1447]: 0.002188270609500118
Loss at iteration [1448]: 0.002188243734417168
Loss at iteration [1449]: 0.002188187743693257
Loss at iteration [1450]: 0.00218807701477674
Loss at iteration [1451]: 0.0021880408261157887
Loss at iteration [1452]: 0.0021879670206356055
Loss at iteration [1453]: 0.0021879521219707095
Loss at iteration [1454]: 0.0021878865179112304
Loss at iteration [1455]: 0.002187828215245954
Loss at iteration [1456]: 0.002187808849670092
Loss at iteration [1457]: 0.002187720372158275
Loss at iteration [1458]: 0.0021876339988662623
Loss at iteration [1459]: 0.002187595942393926
Loss at iteration [1460]: 0.0021875434766569233
Loss at iteration [1461]: 0.002187509224830766
Loss at iteration [1462]: 0.002187473804817278
Loss at iteration [1463]: 0.0021874654844014846
Loss at iteration [1464]: 0.0021874654844014846
Loss at iteration [1465]: 0.002187445004605922
Loss at iteration [1466]: 0.0021874208779235483
Loss at iteration [1467]: 0.0021874037007707644
Loss at iteration [1468]: 0.002187356723533615
Loss at iteration [1469]: 0.002187341286871096
Loss at iteration [1470]: 0.0021872333629700774
Loss at iteration [1471]: 0.002187184978748674
Loss at iteration [1472]: 0.002186805078622895
Loss at iteration [1473]: 0.0021866348285768406
Loss at iteration [1474]: 0.0021863079335940902
Loss at iteration [1475]: 0.002186019148745421
Loss at iteration [1476]: 0.0021857784433998713
Loss at iteration [1477]: 0.002185603027467806
Loss at iteration [1478]: 0.002184617734634092
Loss at iteration [1479]: 0.002184617734634092
Loss at iteration [1480]: 0.0021843567638914754
Loss at iteration [1481]: 0.002184259141307434
Loss at iteration [1482]: 0.002182080724723002
Loss at iteration [1483]: 0.0021819482344830857
Loss at iteration [1484]: 0.002181805059601823
Loss at iteration [1485]: 0.00218065465539847
Loss at iteration [1486]: 0.0021805054874215173
Loss at iteration [1487]: 0.0021801315942204585
Loss at iteration [1488]: 0.002179314244101971
Loss at iteration [1489]: 0.002179277176440447
Loss at iteration [1490]: 0.002179044875731105
Loss at iteration [1491]: 0.002178937758092129
Loss at iteration [1492]: 0.0021788813770090144
Loss at iteration [1493]: 0.0021788813770090144
Loss at iteration [1494]: 0.0021788404492997498
Loss at iteration [1495]: 0.002178675247105727
Loss at iteration [1496]: 0.0021785783167444918
Loss at iteration [1497]: 0.0021785134428694234
Loss at iteration [1498]: 0.002178492835659869
Loss at iteration [1499]: 0.002178476585986971
Loss at iteration [1500]: 0.002178360931797176
Loss at iteration [1501]: 0.0021781988162477917
Loss at iteration [1502]: 0.0021781527679186987
Loss at iteration [1503]: 0.002177902493977879
Loss at iteration [1504]: 0.0021777898301463196
Loss at iteration [1505]: 0.002177704984664418
Loss at iteration [1506]: 0.0021776111916689722
Loss at iteration [1507]: 0.002177561507712206
Loss at iteration [1508]: 0.002177561507712206
Loss at iteration [1509]: 0.0021775166123641173
Loss at iteration [1510]: 0.002177473132058698
Loss at iteration [1511]: 0.0021773024967660665
Loss at iteration [1512]: 0.0021772392940564134
Loss at iteration [1513]: 0.0021771255560071425
Loss at iteration [1514]: 0.002177086204026073
Loss at iteration [1515]: 0.002177020707074887
Loss at iteration [1516]: 0.0021769579952902914
Loss at iteration [1517]: 0.0021768784956852165
Loss at iteration [1518]: 0.002176809757437948
Loss at iteration [1519]: 0.0021767243795940898
Loss at iteration [1520]: 0.002176658443986779
Loss at iteration [1521]: 0.002176582224246919
Loss at iteration [1522]: 0.0021765201659656687
Loss at iteration [1523]: 0.002176434100387556
Loss at iteration [1524]: 0.002176434100387556
Loss at iteration [1525]: 0.0021763106049964742
Loss at iteration [1526]: 0.002176256720675682
Loss at iteration [1527]: 0.002175949828241838
Loss at iteration [1528]: 0.0021758982865041714
Loss at iteration [1529]: 0.002175854254563521
Loss at iteration [1530]: 0.0021757312475775246
Loss at iteration [1531]: 0.0021755569375683727
Loss at iteration [1532]: 0.0021755227247723602
Loss at iteration [1533]: 0.002175497889113699
Loss at iteration [1534]: 0.002175365402840095
Loss at iteration [1535]: 0.0021752740014224572
Loss at iteration [1536]: 0.0021752407274500812
Loss at iteration [1537]: 0.0021751764831232086
Loss at iteration [1538]: 0.002175103587720412
Loss at iteration [1539]: 0.0021750553411851487
Loss at iteration [1540]: 0.0021750553411851487
Loss at iteration [1541]: 0.0021750277843961283
Loss at iteration [1542]: 0.0021749931059249607
Loss at iteration [1543]: 0.002174949265441131
Loss at iteration [1544]: 0.0021749343929302425
Loss at iteration [1545]: 0.0021749059191233885
Loss at iteration [1546]: 0.002174869183915602
Loss at iteration [1547]: 0.0021748421235175007
Loss at iteration [1548]: 0.002174736739155819
Loss at iteration [1549]: 0.0021747172442423196
Loss at iteration [1550]: 0.0021746804135784254
Loss at iteration [1551]: 0.0021746647630965566
Loss at iteration [1552]: 0.002174646751936538
Loss at iteration [1553]: 0.002174631969534146
Loss at iteration [1554]: 0.0021746197492154237
Loss at iteration [1555]: 0.0021745984928400793
Loss at iteration [1556]: 0.0021745849833413817
Loss at iteration [1557]: 0.0021745849833413817
Loss at iteration [1558]: 0.0021745752256877183
Loss at iteration [1559]: 0.0021745654203661154
Loss at iteration [1560]: 0.0021745470068595483
Loss at iteration [1561]: 0.0021745390066300195
Loss at iteration [1562]: 0.002174525038439475
Loss at iteration [1563]: 0.002174507102711972
Loss at iteration [1564]: 0.0021744840269099434
Loss at iteration [1565]: 0.0021744641589343436
Loss at iteration [1566]: 0.00217442662657298
Loss at iteration [1567]: 0.002174349867268285
Loss at iteration [1568]: 0.0021742829036759575
Loss at iteration [1569]: 0.0021741613292207804
Loss at iteration [1570]: 0.002174058851732556
Loss at iteration [1571]: 0.002173872216248778
Loss at iteration [1572]: 0.0021735613910514526
Loss at iteration [1573]: 0.0021730304855640493
Loss at iteration [1574]: 0.0021729505716770606
Loss at iteration [1575]: 0.0021725920108748515
Loss at iteration [1576]: 0.0021723117349954617
Loss at iteration [1577]: 0.0021723117349954617
Loss at iteration [1578]: 0.002172226757615089
Loss at iteration [1579]: 0.002172046328960917
Loss at iteration [1580]: 0.0021718888423600947
Loss at iteration [1581]: 0.0021718350745640203
Loss at iteration [1582]: 0.0021717313568987745
Loss at iteration [1583]: 0.002171663480504296
Loss at iteration [1584]: 0.0021714389056860482
Loss at iteration [1585]: 0.0021714110031549657
Loss at iteration [1586]: 0.00217132600762527
Loss at iteration [1587]: 0.0021710536127402752
Loss at iteration [1588]: 0.0021709920852192974
Loss at iteration [1589]: 0.0021707854709261936
Loss at iteration [1590]: 0.0021707854709261936
Loss at iteration [1591]: 0.0021706809990830874
Loss at iteration [1592]: 0.002170643993166831
Loss at iteration [1593]: 0.0021704267072181235
Loss at iteration [1594]: 0.002170391004205036
Loss at iteration [1595]: 0.0021703687622446517
Loss at iteration [1596]: 0.002170316499556249
Loss at iteration [1597]: 0.0021702874686531743
Loss at iteration [1598]: 0.0021702436215899944
Loss at iteration [1599]: 0.0021701883033931092
Loss at iteration [1600]: 0.002170096800014342
Loss at iteration [1601]: 0.0021699934044969375
Loss at iteration [1602]: 0.0021698781372825643
Loss at iteration [1603]: 0.0021697267154027074
Loss at iteration [1604]: 0.0021697267154027074
Loss at iteration [1605]: 0.0021696624589328728
Loss at iteration [1606]: 0.0021695649423128585
Loss at iteration [1607]: 0.002169505755322272
Loss at iteration [1608]: 0.002169483464036876
Loss at iteration [1609]: 0.002169434173356053
Loss at iteration [1610]: 0.0021694004980002003
Loss at iteration [1611]: 0.0021693823441875314
Loss at iteration [1612]: 0.00216935278360617
Loss at iteration [1613]: 0.002169338606599297
Loss at iteration [1614]: 0.002169300044039395
Loss at iteration [1615]: 0.002169268887954459
Loss at iteration [1616]: 0.0021692127256986693
Loss at iteration [1617]: 0.0021691787621060054
Loss at iteration [1618]: 0.0021691435663322685
Loss at iteration [1619]: 0.0021691135965169026
Loss at iteration [1620]: 0.002169071245484515
Loss at iteration [1621]: 0.0021690330370184685
Loss at iteration [1622]: 0.0021689571556468166
Loss at iteration [1623]: 0.0021689571556468166
Loss at iteration [1624]: 0.0021689099006793745
Loss at iteration [1625]: 0.00216888389067949
Loss at iteration [1626]: 0.0021688625819302333
Loss at iteration [1627]: 0.002168849731888308
Loss at iteration [1628]: 0.0021688202798926023
Loss at iteration [1629]: 0.0021688032933662926
Loss at iteration [1630]: 0.002168790321012807
Loss at iteration [1631]: 0.002168748216664489
Loss at iteration [1632]: 0.002168703841563936
Loss at iteration [1633]: 0.002168665123397342
Loss at iteration [1634]: 0.002168312510709359
Loss at iteration [1635]: 0.0021682467778342336
Loss at iteration [1636]: 0.002167897597190919
Loss at iteration [1637]: 0.002167330445236607
Loss at iteration [1638]: 0.002167330445236607
Loss at iteration [1639]: 0.0021672279772414244
Loss at iteration [1640]: 0.0021668653286359956
Loss at iteration [1641]: 0.002166633329594916
Loss at iteration [1642]: 0.0021665467248829866
Loss at iteration [1643]: 0.0021663646260112255
Loss at iteration [1644]: 0.0021661740676256814
Loss at iteration [1645]: 0.002165886958917806
Loss at iteration [1646]: 0.0021658067696894052
Loss at iteration [1647]: 0.0021657773442691187
Loss at iteration [1648]: 0.0021657215091556207
Loss at iteration [1649]: 0.0021653491978717897
Loss at iteration [1650]: 0.0021653055168189125
Loss at iteration [1651]: 0.002165181162296561
Loss at iteration [1652]: 0.002165181162296561
Loss at iteration [1653]: 0.0021651374522261217
Loss at iteration [1654]: 0.0021650808666302
Loss at iteration [1655]: 0.002164891631951529
Loss at iteration [1656]: 0.0021648745326985196
Loss at iteration [1657]: 0.0021648378157104126
Loss at iteration [1658]: 0.002164819052145563
Loss at iteration [1659]: 0.002164776953609908
Loss at iteration [1660]: 0.0021647490072139266
Loss at iteration [1661]: 0.002164727249978996
Loss at iteration [1662]: 0.0021646801600716664
Loss at iteration [1663]: 0.00216465479078681
Loss at iteration [1664]: 0.0021646174511724355
Loss at iteration [1665]: 0.002164567342580167
Loss at iteration [1666]: 0.0021645259128364046
Loss at iteration [1667]: 0.002164438036314322
Loss at iteration [1668]: 0.002164336116797719
Loss at iteration [1669]: 0.002164215995658259
Loss at iteration [1670]: 0.002164215995658259
Loss at iteration [1671]: 0.002164168870520431
Loss at iteration [1672]: 0.0021641099623153272
Loss at iteration [1673]: 0.0021640225758455776
Loss at iteration [1674]: 0.002163972588907532
Loss at iteration [1675]: 0.002163828422700358
Loss at iteration [1676]: 0.0021637744465185954
Loss at iteration [1677]: 0.00216374828948236
Loss at iteration [1678]: 0.002163696963041666
Loss at iteration [1679]: 0.0021636817849731995
Loss at iteration [1680]: 0.002163649570754114
Loss at iteration [1681]: 0.002163615782974759
Loss at iteration [1682]: 0.0021635823689225417
Loss at iteration [1683]: 0.0021635518245245334
Loss at iteration [1684]: 0.0021634961058548618
Loss at iteration [1685]: 0.002163411951513258
Loss at iteration [1686]: 0.0021633545646242893
Loss at iteration [1687]: 0.0021633090425455265
Loss at iteration [1688]: 0.0021633090425455265
Loss at iteration [1689]: 0.002163285999158947
Loss at iteration [1690]: 0.0021632425198321653
Loss at iteration [1691]: 0.0021631903504524953
Loss at iteration [1692]: 0.002163151122599582
Loss at iteration [1693]: 0.002163132174870963
Loss at iteration [1694]: 0.002163113788293744
Loss at iteration [1695]: 0.0021630771461037513
Loss at iteration [1696]: 0.002163016512807633
Loss at iteration [1697]: 0.0021629969850907637
Loss at iteration [1698]: 0.0021629742421962295
Loss at iteration [1699]: 0.0021629468662662595
Loss at iteration [1700]: 0.0021629065569926213
Loss at iteration [1701]: 0.0021628868249959645
Loss at iteration [1702]: 0.002162858248271681
Loss at iteration [1703]: 0.0021628134869685544
Loss at iteration [1704]: 0.0021627865739797174
Loss at iteration [1705]: 0.002162720477606833
Loss at iteration [1706]: 0.002162720477606833
Loss at iteration [1707]: 0.002162678191984951
Loss at iteration [1708]: 0.002162648447640772
Loss at iteration [1709]: 0.002162627810436015
Loss at iteration [1710]: 0.0021626064789802414
Loss at iteration [1711]: 0.0021625876453658663
Loss at iteration [1712]: 0.002162574836662758
Loss at iteration [1713]: 0.002162555418050001
Loss at iteration [1714]: 0.0021625350488489667
Loss at iteration [1715]: 0.002162500870253229
Loss at iteration [1716]: 0.002162470813560825
Loss at iteration [1717]: 0.0021624487921707816
Loss at iteration [1718]: 0.002162409681545992
Loss at iteration [1719]: 0.002162319493776025
Loss at iteration [1720]: 0.002162278511623901
Loss at iteration [1721]: 0.002162173957323648
Loss at iteration [1722]: 0.002162092691160962
Loss at iteration [1723]: 0.0021619543993675826
Loss at iteration [1724]: 0.002161677551956268
Loss at iteration [1725]: 0.002161677551956268
Loss at iteration [1726]: 0.002161623024055546
Loss at iteration [1727]: 0.002161579363888096
Loss at iteration [1728]: 0.002161482298555889
Loss at iteration [1729]: 0.0021614396550323055
Loss at iteration [1730]: 0.0021614146060836615
Loss at iteration [1731]: 0.0021613856488392424
Loss at iteration [1732]: 0.0021613682677274963
Loss at iteration [1733]: 0.002161333330362242
Loss at iteration [1734]: 0.002161291020650312
Loss at iteration [1735]: 0.002161276068372803
Loss at iteration [1736]: 0.0021612454672603576
Loss at iteration [1737]: 0.0021612068564273845
Loss at iteration [1738]: 0.0021611861505031753
Loss at iteration [1739]: 0.002161166793530603
Loss at iteration [1740]: 0.0021611465237950807
Loss at iteration [1741]: 0.0021611377688707484
Loss at iteration [1742]: 0.0021611280599061608
Loss at iteration [1743]: 0.0021611280599061608
Loss at iteration [1744]: 0.0021611101900864344
Loss at iteration [1745]: 0.002161093001282385
Loss at iteration [1746]: 0.002161086394712152
Loss at iteration [1747]: 0.0021610789481413587
Loss at iteration [1748]: 0.0021610710083282956
Loss at iteration [1749]: 0.0021610601260479544
Loss at iteration [1750]: 0.0021610503671437003
Loss at iteration [1751]: 0.002161036820649753
Loss at iteration [1752]: 0.002161016788564565
Loss at iteration [1753]: 0.0021609912735823357
Loss at iteration [1754]: 0.002160958775259634
Loss at iteration [1755]: 0.002160905091981144
Loss at iteration [1756]: 0.0021608329525043242
Loss at iteration [1757]: 0.002160703671610693
Loss at iteration [1758]: 0.002160471308011195
Loss at iteration [1759]: 0.002160471308011195
Loss at iteration [1760]: 0.002160355919006993
Loss at iteration [1761]: 0.0021603137591540145
Loss at iteration [1762]: 0.0021601256510674323
Loss at iteration [1763]: 0.002160094410216855
Loss at iteration [1764]: 0.0021600509174395446
Loss at iteration [1765]: 0.0021600023008605065
Loss at iteration [1766]: 0.002159948806271654
Loss at iteration [1767]: 0.002159888405212837
Loss at iteration [1768]: 0.0021598606337654494
Loss at iteration [1769]: 0.0021598258306480623
Loss at iteration [1770]: 0.002159803368987248
Loss at iteration [1771]: 0.002159779508008453
Loss at iteration [1772]: 0.0021597655083546723
Loss at iteration [1773]: 0.002159750691563986
Loss at iteration [1774]: 0.002159750691563986
Loss at iteration [1775]: 0.0021597428812742954
Loss at iteration [1776]: 0.0021597365776661473
Loss at iteration [1777]: 0.0021597230445735654
Loss at iteration [1778]: 0.0021596992620095653
Loss at iteration [1779]: 0.0021596742096692597
Loss at iteration [1780]: 0.002159668109999415
Loss at iteration [1781]: 0.0021596493150038997
Loss at iteration [1782]: 0.0021595834298600994
Loss at iteration [1783]: 0.0021595048643177463
Loss at iteration [1784]: 0.002159387381008064
Loss at iteration [1785]: 0.002159273658257691
Loss at iteration [1786]: 0.002159138828426178
Loss at iteration [1787]: 0.0021588805417613083
Loss at iteration [1788]: 0.0021586213493506082
Loss at iteration [1789]: 0.0021580976716827917
Loss at iteration [1790]: 0.00215779192567793
Loss at iteration [1791]: 0.0021575872207545456
Loss at iteration [1792]: 0.0021569098209704264
Loss at iteration [1793]: 0.0021569098209704264
Loss at iteration [1794]: 0.0021565019866964445
Loss at iteration [1795]: 0.0021563799630142577
Loss at iteration [1796]: 0.0021538195252077284
Loss at iteration [1797]: 0.0021529431033778463
Loss at iteration [1798]: 0.002152184421500075
Loss at iteration [1799]: 0.002152020609242539
Loss at iteration [1800]: 0.002151006182293185
Loss at iteration [1801]: 0.0021507838640468786
Loss at iteration [1802]: 0.002150232682843383
Loss at iteration [1803]: 0.0021499883947823976
