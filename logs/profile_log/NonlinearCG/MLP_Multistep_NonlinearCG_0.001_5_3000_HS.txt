Model name                            : MLP_Multistep
The number of input features          : 5
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.001
Beta type                             :HS
Total number of function evaluations  : 1786
Total number of iterations            : 840
Max number of iterations              : 3000
Number of samples in training data    : 122
Number of samples in tests data       : 52
Total training time                   : 4.408173561096191
Total number of parameters            : 202302
Percentage of parameters < 1e-9       : 50.01631224604799%
Percentage of parameters < 1e-7       : 50.01631224604799%
Percentage of parameters < 1e-6       : 50.01680655653429%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.6511408931082471
Loss at iteration [2]: 0.6429605122223021
Loss at iteration [3]: 0.6396951459578716
Loss at iteration [4]: 0.6193100124394958
Loss at iteration [5]: 0.6093887478936093
Loss at iteration [6]: 0.5823993213248012
Loss at iteration [7]: 0.5793048186504364
Loss at iteration [8]: 0.5693639095302184
Loss at iteration [9]: 0.5693639095302184
Loss at iteration [10]: 0.5668009789095558
Loss at iteration [11]: 0.5632900332851378
Loss at iteration [12]: 0.5155208027665442
Loss at iteration [13]: 0.5047784439166624
Loss at iteration [14]: 0.4620904174247096
Loss at iteration [15]: 0.45121354850134865
Loss at iteration [16]: 0.43229776276228216
Loss at iteration [17]: 0.43229776276228216
Loss at iteration [18]: 0.4306775327227923
Loss at iteration [19]: 0.4090310200835355
Loss at iteration [20]: 0.39754251409892816
Loss at iteration [21]: 0.38689068051315684
Loss at iteration [22]: 0.35844162306480587
Loss at iteration [23]: 0.35529815784297697
Loss at iteration [24]: 0.3229292875954204
Loss at iteration [25]: 0.3229292875954204
Loss at iteration [26]: 0.3213264363387475
Loss at iteration [27]: 0.30682198355575374
Loss at iteration [28]: 0.2896158188242171
Loss at iteration [29]: 0.28808857519637904
Loss at iteration [30]: 0.2861380329974818
Loss at iteration [31]: 0.2856752423644531
Loss at iteration [32]: 0.28239163419938307
Loss at iteration [33]: 0.2820341104602243
Loss at iteration [34]: 0.2820341104602243
Loss at iteration [35]: 0.2815934077410285
Loss at iteration [36]: 0.2784315876330979
Loss at iteration [37]: 0.27774810360401125
Loss at iteration [38]: 0.26949693353931403
Loss at iteration [39]: 0.26438693780086503
Loss at iteration [40]: 0.263884499625259
Loss at iteration [41]: 0.2584876584296914
Loss at iteration [42]: 0.2584876584296914
Loss at iteration [43]: 0.2580747538434959
Loss at iteration [44]: 0.25627127562330965
Loss at iteration [45]: 0.2560312733990401
Loss at iteration [46]: 0.2544437855004315
Loss at iteration [47]: 0.2541919104217535
Loss at iteration [48]: 0.2535104404331182
Loss at iteration [49]: 0.25293176177833276
Loss at iteration [50]: 0.25236738576289075
Loss at iteration [51]: 0.25236738576289075
Loss at iteration [52]: 0.2522653262595366
Loss at iteration [53]: 0.25162866032602565
Loss at iteration [54]: 0.2513267006797817
Loss at iteration [55]: 0.2509145622722261
Loss at iteration [56]: 0.2506428914976078
Loss at iteration [57]: 0.24957938984197306
Loss at iteration [58]: 0.2489933909437077
Loss at iteration [59]: 0.2475470112001792
Loss at iteration [60]: 0.2452905549628989
Loss at iteration [61]: 0.2452905549628989
Loss at iteration [62]: 0.2446504487838357
Loss at iteration [63]: 0.2411661552400517
Loss at iteration [64]: 0.2410324596000517
Loss at iteration [65]: 0.24054007418177378
Loss at iteration [66]: 0.24021144406162542
Loss at iteration [67]: 0.239640433922368
Loss at iteration [68]: 0.23832190023150465
Loss at iteration [69]: 0.23821410687888755
Loss at iteration [70]: 0.23821410687888755
Loss at iteration [71]: 0.23808499426543184
Loss at iteration [72]: 0.23722775355236894
Loss at iteration [73]: 0.23692934661262816
Loss at iteration [74]: 0.23557734730478502
Loss at iteration [75]: 0.235444812615589
Loss at iteration [76]: 0.23459031730590693
Loss at iteration [77]: 0.23432476124623464
Loss at iteration [78]: 0.23409508192080142
Loss at iteration [79]: 0.23403264481393787
Loss at iteration [80]: 0.23403264481393787
Loss at iteration [81]: 0.23390550403213264
Loss at iteration [82]: 0.2337105834211975
Loss at iteration [83]: 0.23356277288088373
Loss at iteration [84]: 0.2334519121515976
Loss at iteration [85]: 0.23313581906561714
Loss at iteration [86]: 0.23300545106115184
Loss at iteration [87]: 0.23289343421802208
Loss at iteration [88]: 0.23283089950481795
Loss at iteration [89]: 0.2325845870774981
Loss at iteration [90]: 0.23252467132593824
Loss at iteration [91]: 0.2322172860300401
Loss at iteration [92]: 0.2322172860300401
Loss at iteration [93]: 0.23212317991731193
Loss at iteration [94]: 0.2319487577202897
Loss at iteration [95]: 0.2318729903367759
Loss at iteration [96]: 0.23169174195022926
Loss at iteration [97]: 0.2316687229899978
Loss at iteration [98]: 0.23158137290780526
Loss at iteration [99]: 0.23127739924284385
Loss at iteration [100]: 0.23120337669136723
Loss at iteration [101]: 0.23111822618521577
Loss at iteration [102]: 0.23111822618521577
Loss at iteration [103]: 0.2309591535015679
Loss at iteration [104]: 0.23084392457636513
Loss at iteration [105]: 0.23075352292674628
Loss at iteration [106]: 0.23069328644972342
Loss at iteration [107]: 0.23049403176355257
Loss at iteration [108]: 0.2304353447746603
Loss at iteration [109]: 0.23029106700786645
Loss at iteration [110]: 0.23024483505314303
Loss at iteration [111]: 0.2301547471742018
Loss at iteration [112]: 0.23005017941042458
Loss at iteration [113]: 0.23005017941042458
Loss at iteration [114]: 0.23001952359913613
Loss at iteration [115]: 0.22997347205911112
Loss at iteration [116]: 0.22992801387321674
Loss at iteration [117]: 0.22991594918789326
Loss at iteration [118]: 0.22985594650727795
Loss at iteration [119]: 0.2298231575893182
Loss at iteration [120]: 0.22976366478418958
Loss at iteration [121]: 0.22970524606178808
Loss at iteration [122]: 0.22956467865182506
Loss at iteration [123]: 0.2293477275694231
Loss at iteration [124]: 0.2290900990952205
Loss at iteration [125]: 0.22872974615555372
Loss at iteration [126]: 0.22853192230644995
Loss at iteration [127]: 0.22853192230644995
Loss at iteration [128]: 0.22837506671193517
Loss at iteration [129]: 0.22831725351171125
Loss at iteration [130]: 0.22825145539954703
Loss at iteration [131]: 0.2280065202489485
Loss at iteration [132]: 0.22790559245135508
Loss at iteration [133]: 0.22787685794271123
Loss at iteration [134]: 0.22771702458680604
Loss at iteration [135]: 0.22763309639534185
Loss at iteration [136]: 0.22722543601383882
Loss at iteration [137]: 0.2266985192554969
Loss at iteration [138]: 0.22559536835098742
Loss at iteration [139]: 0.22559536835098742
Loss at iteration [140]: 0.2252444763414536
Loss at iteration [141]: 0.2239119322212862
Loss at iteration [142]: 0.2232376942325807
Loss at iteration [143]: 0.22256429591294627
Loss at iteration [144]: 0.22248518174935353
Loss at iteration [145]: 0.2220814176295925
Loss at iteration [146]: 0.2219951326649871
Loss at iteration [147]: 0.22158277540388913
Loss at iteration [148]: 0.22143935511317167
Loss at iteration [149]: 0.22143935511317167
Loss at iteration [150]: 0.22130885871221953
Loss at iteration [151]: 0.22118010104005942
Loss at iteration [152]: 0.220959038302266
Loss at iteration [153]: 0.22084495343218857
Loss at iteration [154]: 0.22068346212233783
Loss at iteration [155]: 0.22064132848288348
Loss at iteration [156]: 0.2206032538104387
Loss at iteration [157]: 0.22040678400327157
Loss at iteration [158]: 0.22034048256229563
Loss at iteration [159]: 0.22020340707132185
Loss at iteration [160]: 0.22012048888927316
Loss at iteration [161]: 0.22012048888927316
Loss at iteration [162]: 0.22001719304084932
Loss at iteration [163]: 0.21998218936629282
Loss at iteration [164]: 0.2199073452422525
Loss at iteration [165]: 0.21986868550120886
Loss at iteration [166]: 0.2198040411221332
Loss at iteration [167]: 0.21966374364202298
Loss at iteration [168]: 0.21942075125972607
Loss at iteration [169]: 0.21891574114109547
Loss at iteration [170]: 0.21855398779328694
Loss at iteration [171]: 0.21855398779328694
Loss at iteration [172]: 0.21826098573297223
Loss at iteration [173]: 0.21797136747663284
Loss at iteration [174]: 0.21778606255141061
Loss at iteration [175]: 0.21764837764526018
Loss at iteration [176]: 0.21741806187521345
Loss at iteration [177]: 0.21721400406118788
Loss at iteration [178]: 0.2171551152653221
Loss at iteration [179]: 0.21690979354078208
Loss at iteration [180]: 0.21670455036618022
Loss at iteration [181]: 0.21670455036618022
Loss at iteration [182]: 0.21661542083591018
Loss at iteration [183]: 0.21648901739144205
Loss at iteration [184]: 0.2164183196781584
Loss at iteration [185]: 0.21631186526847937
Loss at iteration [186]: 0.2162165569670342
Loss at iteration [187]: 0.2160839534597476
Loss at iteration [188]: 0.21599650390035582
Loss at iteration [189]: 0.21580778435109274
Loss at iteration [190]: 0.2156468761794666
Loss at iteration [191]: 0.21513039896737612
Loss at iteration [192]: 0.21513039896737612
Loss at iteration [193]: 0.2148823665451067
Loss at iteration [194]: 0.2147549139779298
Loss at iteration [195]: 0.2146807642182843
Loss at iteration [196]: 0.21463425838325326
Loss at iteration [197]: 0.2146035778368525
Loss at iteration [198]: 0.21454023916792664
Loss at iteration [199]: 0.21448084402004378
Loss at iteration [200]: 0.2143871251778779
Loss at iteration [201]: 0.21435684549782125
Loss at iteration [202]: 0.21429901744176896
Loss at iteration [203]: 0.21429901744176896
Loss at iteration [204]: 0.2142676461617949
Loss at iteration [205]: 0.2142615136005756
Loss at iteration [206]: 0.2142414660605445
Loss at iteration [207]: 0.21422568297256306
Loss at iteration [208]: 0.21421242628017292
Loss at iteration [209]: 0.21419542019151894
Loss at iteration [210]: 0.21419333376239968
Loss at iteration [211]: 0.21415315772733756
Loss at iteration [212]: 0.21413215457192392
Loss at iteration [213]: 0.21410870486673522
Loss at iteration [214]: 0.2140810868507261
Loss at iteration [215]: 0.21403044588012968
Loss at iteration [216]: 0.2139283032253787
Loss at iteration [217]: 0.2137698560379681
Loss at iteration [218]: 0.2137698560379681
Loss at iteration [219]: 0.21361450824078607
Loss at iteration [220]: 0.21354679287819905
Loss at iteration [221]: 0.21349974728736829
Loss at iteration [222]: 0.21347253157775958
Loss at iteration [223]: 0.21341826985552942
Loss at iteration [224]: 0.21339323466579663
Loss at iteration [225]: 0.2133166687913328
Loss at iteration [226]: 0.21327780634412388
Loss at iteration [227]: 0.2132412535335559
Loss at iteration [228]: 0.213173432072868
Loss at iteration [229]: 0.21306931092909034
Loss at iteration [230]: 0.21306931092909034
Loss at iteration [231]: 0.21301566451907047
Loss at iteration [232]: 0.21300150300355197
Loss at iteration [233]: 0.21296724364471648
Loss at iteration [234]: 0.2129031843511995
Loss at iteration [235]: 0.2128879020574321
Loss at iteration [236]: 0.21281484502630815
Loss at iteration [237]: 0.21279754552050034
Loss at iteration [238]: 0.21274926804450092
Loss at iteration [239]: 0.21267234019439554
Loss at iteration [240]: 0.2125944318743479
Loss at iteration [241]: 0.21247213721046423
Loss at iteration [242]: 0.2123395887351768
Loss at iteration [243]: 0.21219558579577294
Loss at iteration [244]: 0.21219558579577294
Loss at iteration [245]: 0.21216353829595566
Loss at iteration [246]: 0.2121440123891599
Loss at iteration [247]: 0.21213601181617248
Loss at iteration [248]: 0.2121096552161377
Loss at iteration [249]: 0.21207367003913474
Loss at iteration [250]: 0.2120496034102876
Loss at iteration [251]: 0.21202383150599427
Loss at iteration [252]: 0.21197160753182334
Loss at iteration [253]: 0.21192209758600694
Loss at iteration [254]: 0.21185120737311763
Loss at iteration [255]: 0.21174013635777597
Loss at iteration [256]: 0.2115779791038853
Loss at iteration [257]: 0.21134414666697984
Loss at iteration [258]: 0.2110150028034243
Loss at iteration [259]: 0.2108417475833806
Loss at iteration [260]: 0.2108417475833806
Loss at iteration [261]: 0.21074545907934158
Loss at iteration [262]: 0.2106974621490855
Loss at iteration [263]: 0.2106152857370792
Loss at iteration [264]: 0.21047255495506398
Loss at iteration [265]: 0.2103708958189253
Loss at iteration [266]: 0.2103085723231756
Loss at iteration [267]: 0.2102746202291717
Loss at iteration [268]: 0.21019894872617795
Loss at iteration [269]: 0.21013064060324746
Loss at iteration [270]: 0.21002594205508093
Loss at iteration [271]: 0.21002594205508093
Loss at iteration [272]: 0.2099119238675069
Loss at iteration [273]: 0.20989522155157053
Loss at iteration [274]: 0.20980619148412175
Loss at iteration [275]: 0.20977256301375927
Loss at iteration [276]: 0.20972590169974728
Loss at iteration [277]: 0.20970726886265192
Loss at iteration [278]: 0.20969129833241262
Loss at iteration [279]: 0.20967459899790847
Loss at iteration [280]: 0.20964299236792502
Loss at iteration [281]: 0.20963258810567795
Loss at iteration [282]: 0.20960719104269818
Loss at iteration [283]: 0.20958249210684587
Loss at iteration [284]: 0.2095359155864266
Loss at iteration [285]: 0.20950833820592712
Loss at iteration [286]: 0.2094913127324151
Loss at iteration [287]: 0.20946938349666935
Loss at iteration [288]: 0.2093827314671206
Loss at iteration [289]: 0.20935486473512296
Loss at iteration [290]: 0.20932215366663012
Loss at iteration [291]: 0.20930520569870725
Loss at iteration [292]: 0.20930520569870725
Loss at iteration [293]: 0.20929676761958046
Loss at iteration [294]: 0.20928564645101413
Loss at iteration [295]: 0.20927569766626636
Loss at iteration [296]: 0.20925845905562682
Loss at iteration [297]: 0.20923253717879173
Loss at iteration [298]: 0.20922296191395964
Loss at iteration [299]: 0.20919627011177266
Loss at iteration [300]: 0.2090148511949761
Loss at iteration [301]: 0.20848838547139398
Loss at iteration [302]: 0.2081370096613024
Loss at iteration [303]: 0.20655029158199756
Loss at iteration [304]: 0.2021039329202434
Loss at iteration [305]: 0.2021039329202434
Loss at iteration [306]: 0.2005781365531085
Loss at iteration [307]: 0.1981645944323997
Loss at iteration [308]: 0.19778466027324218
Loss at iteration [309]: 0.19745148217328862
Loss at iteration [310]: 0.19710347562021852
Loss at iteration [311]: 0.19703099166120408
Loss at iteration [312]: 0.1968357649928403
Loss at iteration [313]: 0.1961010359124619
Loss at iteration [314]: 0.19590945453982822
Loss at iteration [315]: 0.19538535441264887
Loss at iteration [316]: 0.19527250051513154
Loss at iteration [317]: 0.19527250051513154
Loss at iteration [318]: 0.1952058862222556
Loss at iteration [319]: 0.19512575017068237
Loss at iteration [320]: 0.19510837805831985
Loss at iteration [321]: 0.19505667426085932
Loss at iteration [322]: 0.19499638739326444
Loss at iteration [323]: 0.19494275857437726
Loss at iteration [324]: 0.19454706015354642
Loss at iteration [325]: 0.1942811314428287
Loss at iteration [326]: 0.19359353368482649
Loss at iteration [327]: 0.19342508875269748
Loss at iteration [328]: 0.19342508875269748
Loss at iteration [329]: 0.19331653444841826
Loss at iteration [330]: 0.19316148539959424
Loss at iteration [331]: 0.19294713235982486
Loss at iteration [332]: 0.1927590149300394
Loss at iteration [333]: 0.19255054445404998
Loss at iteration [334]: 0.19247667762110546
Loss at iteration [335]: 0.19232468672294245
Loss at iteration [336]: 0.1922248798024595
Loss at iteration [337]: 0.192090714866692
Loss at iteration [338]: 0.1919902748869705
Loss at iteration [339]: 0.19172622034081366
Loss at iteration [340]: 0.19172622034081366
Loss at iteration [341]: 0.19161042182910795
Loss at iteration [342]: 0.19158154279286652
Loss at iteration [343]: 0.19154049132620127
Loss at iteration [344]: 0.19151703351608707
Loss at iteration [345]: 0.19150155786489387
Loss at iteration [346]: 0.1914712030239871
Loss at iteration [347]: 0.1914400728643014
Loss at iteration [348]: 0.19142724663637714
Loss at iteration [349]: 0.19142158046796645
Loss at iteration [350]: 0.19134413933269584
Loss at iteration [351]: 0.1911044707634559
Loss at iteration [352]: 0.19105211745305098
Loss at iteration [353]: 0.19101738641940993
Loss at iteration [354]: 0.19097664345359316
Loss at iteration [355]: 0.19091673220363586
Loss at iteration [356]: 0.19087990618762402
Loss at iteration [357]: 0.19081454658120145
Loss at iteration [358]: 0.19073246623379408
Loss at iteration [359]: 0.19073246623379408
Loss at iteration [360]: 0.1906181794342826
Loss at iteration [361]: 0.19057233359819573
Loss at iteration [362]: 0.19054947995468005
Loss at iteration [363]: 0.19054631133737088
Loss at iteration [364]: 0.19051846233383662
Loss at iteration [365]: 0.19050268864653405
Loss at iteration [366]: 0.1904776534729665
Loss at iteration [367]: 0.1904425933460518
Loss at iteration [368]: 0.19044122068314792
Loss at iteration [369]: 0.19039815224616308
Loss at iteration [370]: 0.19037862325178243
Loss at iteration [371]: 0.19035848855077034
Loss at iteration [372]: 0.19029693908145204
Loss at iteration [373]: 0.19022966840156605
Loss at iteration [374]: 0.19007169341531677
Loss at iteration [375]: 0.18995354824616062
Loss at iteration [376]: 0.18995354824616062
Loss at iteration [377]: 0.18981685297362946
Loss at iteration [378]: 0.1897203190681488
Loss at iteration [379]: 0.18967058348829607
Loss at iteration [380]: 0.1896424948975683
Loss at iteration [381]: 0.18959151141273742
Loss at iteration [382]: 0.18955673204483175
Loss at iteration [383]: 0.18953266458141044
Loss at iteration [384]: 0.18950072460765616
Loss at iteration [385]: 0.18949333621210526
Loss at iteration [386]: 0.18946643750569628
Loss at iteration [387]: 0.189457343538685
Loss at iteration [388]: 0.18944593390433856
Loss at iteration [389]: 0.18936040957656447
Loss at iteration [390]: 0.18932166279325294
Loss at iteration [391]: 0.1892399683997455
Loss at iteration [392]: 0.18899451735261052
Loss at iteration [393]: 0.18899451735261052
Loss at iteration [394]: 0.18892920936644306
Loss at iteration [395]: 0.188819476890862
Loss at iteration [396]: 0.1887945634624743
Loss at iteration [397]: 0.18878432743178133
Loss at iteration [398]: 0.18876436766934704
Loss at iteration [399]: 0.188747038440286
Loss at iteration [400]: 0.18869765342093836
Loss at iteration [401]: 0.18868074453822445
Loss at iteration [402]: 0.18864276487250475
Loss at iteration [403]: 0.18861863239209134
Loss at iteration [404]: 0.1886069437708305
Loss at iteration [405]: 0.1886024722574985
Loss at iteration [406]: 0.18853271747869207
Loss at iteration [407]: 0.1884959758275528
Loss at iteration [408]: 0.18847937139984075
Loss at iteration [409]: 0.18842991628511027
Loss at iteration [410]: 0.18835574580689055
Loss at iteration [411]: 0.18835574580689055
Loss at iteration [412]: 0.1882598279538906
Loss at iteration [413]: 0.1882555482203588
Loss at iteration [414]: 0.18824608794739497
Loss at iteration [415]: 0.18824228592978945
Loss at iteration [416]: 0.1882235111581813
Loss at iteration [417]: 0.18817983749542352
Loss at iteration [418]: 0.188170116137057
Loss at iteration [419]: 0.1881508971475348
Loss at iteration [420]: 0.18813872917656463
Loss at iteration [421]: 0.18812768054649306
Loss at iteration [422]: 0.18810240178546397
Loss at iteration [423]: 0.1880958183120624
Loss at iteration [424]: 0.18807581000205928
Loss at iteration [425]: 0.18804085363924278
Loss at iteration [426]: 0.18799116087395346
Loss at iteration [427]: 0.1879810339113302
Loss at iteration [428]: 0.18795953880642527
Loss at iteration [429]: 0.1878747609195479
Loss at iteration [430]: 0.1878747609195479
Loss at iteration [431]: 0.18771698916951113
Loss at iteration [432]: 0.18761503269306962
Loss at iteration [433]: 0.18753716353001718
Loss at iteration [434]: 0.187508786293476
Loss at iteration [435]: 0.187500047476755
Loss at iteration [436]: 0.18747617205642853
Loss at iteration [437]: 0.1874472530777785
Loss at iteration [438]: 0.1874163622993038
Loss at iteration [439]: 0.18737766727313188
Loss at iteration [440]: 0.18734261847174405
Loss at iteration [441]: 0.1873352620362431
Loss at iteration [442]: 0.1872785108124958
Loss at iteration [443]: 0.18721011546005098
Loss at iteration [444]: 0.1871764683185196
Loss at iteration [445]: 0.18711407752220657
Loss at iteration [446]: 0.18711407752220657
Loss at iteration [447]: 0.1870813286074975
Loss at iteration [448]: 0.18707351089395471
Loss at iteration [449]: 0.1870713338973909
Loss at iteration [450]: 0.18705130381375615
Loss at iteration [451]: 0.1870324350385718
Loss at iteration [452]: 0.18701063540150759
Loss at iteration [453]: 0.18700635409993344
Loss at iteration [454]: 0.1869997168228889
Loss at iteration [455]: 0.18698298331545393
Loss at iteration [456]: 0.18697633231346844
Loss at iteration [457]: 0.1869499696568524
Loss at iteration [458]: 0.18693255730120886
Loss at iteration [459]: 0.18691662090231909
Loss at iteration [460]: 0.1869058000266139
Loss at iteration [461]: 0.1868603121034671
Loss at iteration [462]: 0.18680316689063456
Loss at iteration [463]: 0.18660621931627466
Loss at iteration [464]: 0.18660621931627466
Loss at iteration [465]: 0.186504797853765
Loss at iteration [466]: 0.18640930047133636
Loss at iteration [467]: 0.18637529562421398
Loss at iteration [468]: 0.18631883196243507
Loss at iteration [469]: 0.1862793157428401
Loss at iteration [470]: 0.18626426963657047
Loss at iteration [471]: 0.18622268347525808
Loss at iteration [472]: 0.18619775295114596
Loss at iteration [473]: 0.18618391143947058
Loss at iteration [474]: 0.18617208283251818
Loss at iteration [475]: 0.18616137607407643
Loss at iteration [476]: 0.18614160610355748
Loss at iteration [477]: 0.18613977695983683
Loss at iteration [478]: 0.1861358846104395
Loss at iteration [479]: 0.1861225705690989
Loss at iteration [480]: 0.1861225705690989
Loss at iteration [481]: 0.18611487177533745
Loss at iteration [482]: 0.18611166066760404
Loss at iteration [483]: 0.18610778505824033
Loss at iteration [484]: 0.18610623536388807
Loss at iteration [485]: 0.1861041192807779
Loss at iteration [486]: 0.18610148809772334
Loss at iteration [487]: 0.1860966656307243
Loss at iteration [488]: 0.18609250896128282
Loss at iteration [489]: 0.18608582616111546
Loss at iteration [490]: 0.18607771917624208
Loss at iteration [491]: 0.18604957356656776
Loss at iteration [492]: 0.1860213017699878
Loss at iteration [493]: 0.1860213017699878
Loss at iteration [494]: 0.1860082204319483
Loss at iteration [495]: 0.1860059489991578
Loss at iteration [496]: 0.18600092073291025
Loss at iteration [497]: 0.1859969030688065
Loss at iteration [498]: 0.18599536048942977
Loss at iteration [499]: 0.1859930184294093
Loss at iteration [500]: 0.1859928718369319
Loss at iteration [501]: 0.18597861819271064
Loss at iteration [502]: 0.1859713663809079
Loss at iteration [503]: 0.18596648944438982
Loss at iteration [504]: 0.1859663000851762
Loss at iteration [505]: 0.185941515826372
Loss at iteration [506]: 0.18574246017477933
Loss at iteration [507]: 0.18574246017477933
Loss at iteration [508]: 0.18559404612595934
Loss at iteration [509]: 0.18556420054199133
Loss at iteration [510]: 0.1855544390557516
Loss at iteration [511]: 0.18551988983328974
Loss at iteration [512]: 0.18547052241968479
Loss at iteration [513]: 0.18546091001749257
Loss at iteration [514]: 0.18544422151844375
Loss at iteration [515]: 0.1854429358596022
Loss at iteration [516]: 0.18543261284812548
Loss at iteration [517]: 0.1854278537131766
Loss at iteration [518]: 0.18541223630077278
Loss at iteration [519]: 0.185377834291568
Loss at iteration [520]: 0.18535612396302337
Loss at iteration [521]: 0.18535612396302337
Loss at iteration [522]: 0.18533480607304045
Loss at iteration [523]: 0.1853140009404746
Loss at iteration [524]: 0.1853126892549924
Loss at iteration [525]: 0.18529840826873686
Loss at iteration [526]: 0.18529592642079468
Loss at iteration [527]: 0.185280767286438
Loss at iteration [528]: 0.18526767131961128
Loss at iteration [529]: 0.18526265224442157
Loss at iteration [530]: 0.1852595264846309
Loss at iteration [531]: 0.18525592913465672
Loss at iteration [532]: 0.18524070133437226
Loss at iteration [533]: 0.18521784747690728
Loss at iteration [534]: 0.1852054171335385
Loss at iteration [535]: 0.18518765454490543
Loss at iteration [536]: 0.18518765454490543
Loss at iteration [537]: 0.1851749977321223
Loss at iteration [538]: 0.18517220597281478
Loss at iteration [539]: 0.1851629539273904
Loss at iteration [540]: 0.18515805772455607
Loss at iteration [541]: 0.18515347702839877
Loss at iteration [542]: 0.18514345942578206
Loss at iteration [543]: 0.18513606572972305
Loss at iteration [544]: 0.18511835796377568
Loss at iteration [545]: 0.18507192086097676
Loss at iteration [546]: 0.18507028124634148
Loss at iteration [547]: 0.18504761031013742
Loss at iteration [548]: 0.18502645962186892
Loss at iteration [549]: 0.18502168298804345
Loss at iteration [550]: 0.18496274294927
Loss at iteration [551]: 0.18492377856848186
Loss at iteration [552]: 0.18484766101387765
Loss at iteration [553]: 0.18484766101387765
Loss at iteration [554]: 0.18476121164077966
Loss at iteration [555]: 0.1847527804533656
Loss at iteration [556]: 0.18467640026987425
Loss at iteration [557]: 0.1846717176138244
Loss at iteration [558]: 0.18465031216963881
Loss at iteration [559]: 0.18462868113173495
Loss at iteration [560]: 0.18460170937915285
Loss at iteration [561]: 0.18459019505177518
Loss at iteration [562]: 0.18456667716233083
Loss at iteration [563]: 0.18451237056129113
Loss at iteration [564]: 0.18444119348540997
Loss at iteration [565]: 0.18440828699353765
Loss at iteration [566]: 0.1843183679686798
Loss at iteration [567]: 0.18425600970166375
Loss at iteration [568]: 0.184199179776292
Loss at iteration [569]: 0.18418035300938523
Loss at iteration [570]: 0.1841614750102241
Loss at iteration [571]: 0.18415382780941197
Loss at iteration [572]: 0.18415382780941197
Loss at iteration [573]: 0.18413385451443212
Loss at iteration [574]: 0.18412757901887414
Loss at iteration [575]: 0.1841184139302303
Loss at iteration [576]: 0.18411772285075914
Loss at iteration [577]: 0.18411079513399065
Loss at iteration [578]: 0.18405232905904473
Loss at iteration [579]: 0.18402443534366725
Loss at iteration [580]: 0.18400242333201794
Loss at iteration [581]: 0.18393948499699334
Loss at iteration [582]: 0.18389837343119164
Loss at iteration [583]: 0.18382656054863367
Loss at iteration [584]: 0.183786793488741
Loss at iteration [585]: 0.18374600613667613
Loss at iteration [586]: 0.18370905949292052
Loss at iteration [587]: 0.18368881222668146
Loss at iteration [588]: 0.1835793512716127
Loss at iteration [589]: 0.1835793512716127
Loss at iteration [590]: 0.18354644401531742
Loss at iteration [591]: 0.18352995618383688
Loss at iteration [592]: 0.18352079653979722
Loss at iteration [593]: 0.18349921167429212
Loss at iteration [594]: 0.18348499995238415
Loss at iteration [595]: 0.18347605140788845
Loss at iteration [596]: 0.1834656553707333
Loss at iteration [597]: 0.183462437021652
Loss at iteration [598]: 0.18343692481639912
Loss at iteration [599]: 0.18341177339652176
Loss at iteration [600]: 0.18338248244504424
Loss at iteration [601]: 0.18336600326885866
Loss at iteration [602]: 0.18333874597370411
Loss at iteration [603]: 0.18331983439479574
Loss at iteration [604]: 0.18327343095452345
Loss at iteration [605]: 0.18326815075063896
Loss at iteration [606]: 0.1832351113675323
Loss at iteration [607]: 0.18318686642132762
Loss at iteration [608]: 0.18313861084588107
Loss at iteration [609]: 0.18313861084588107
Loss at iteration [610]: 0.1831211681128839
Loss at iteration [611]: 0.18311530821669925
Loss at iteration [612]: 0.1831115764782965
Loss at iteration [613]: 0.1831112694378838
Loss at iteration [614]: 0.18310002821992827
Loss at iteration [615]: 0.18309797310946366
Loss at iteration [616]: 0.1830807624708129
Loss at iteration [617]: 0.18307019087871756
Loss at iteration [618]: 0.18306380499858108
Loss at iteration [619]: 0.18304213562470037
Loss at iteration [620]: 0.1829989925384143
Loss at iteration [621]: 0.182962005088556
Loss at iteration [622]: 0.182921367975755
Loss at iteration [623]: 0.18290908991147448
Loss at iteration [624]: 0.18290879337907898
Loss at iteration [625]: 0.18284554142928394
Loss at iteration [626]: 0.18272441773842238
Loss at iteration [627]: 0.18272441773842238
Loss at iteration [628]: 0.18253294613703
Loss at iteration [629]: 0.18251808117272994
Loss at iteration [630]: 0.1824848845495672
Loss at iteration [631]: 0.18247421609119682
Loss at iteration [632]: 0.1824275998041314
Loss at iteration [633]: 0.18239343611026734
Loss at iteration [634]: 0.18238520357073412
Loss at iteration [635]: 0.18238024312915285
Loss at iteration [636]: 0.18236885888186555
Loss at iteration [637]: 0.18235617360023257
Loss at iteration [638]: 0.18234022328008262
Loss at iteration [639]: 0.18231979752113633
Loss at iteration [640]: 0.18230655435404478
Loss at iteration [641]: 0.18227335385945764
Loss at iteration [642]: 0.18225335012926971
Loss at iteration [643]: 0.18225335012926971
Loss at iteration [644]: 0.18224714041201423
Loss at iteration [645]: 0.18223982061602445
Loss at iteration [646]: 0.1822372245979033
Loss at iteration [647]: 0.1822341464779016
Loss at iteration [648]: 0.1822321712282199
Loss at iteration [649]: 0.1822208541723527
Loss at iteration [650]: 0.1822151119065588
Loss at iteration [651]: 0.18217954109180415
Loss at iteration [652]: 0.1821425702017867
Loss at iteration [653]: 0.18193569971358606
Loss at iteration [654]: 0.1815132230512326
Loss at iteration [655]: 0.16297113964429932
Loss at iteration [656]: 0.16297113964429932
Loss at iteration [657]: 0.16180143375583675
Loss at iteration [658]: 0.15336152357910782
Loss at iteration [659]: 0.15222213336464524
Loss at iteration [660]: 0.15024030417324427
Loss at iteration [661]: 0.15009393473955554
Loss at iteration [662]: 0.14814511923063256
Loss at iteration [663]: 0.1478921040984478
Loss at iteration [664]: 0.14694294780829745
Loss at iteration [665]: 0.14694294780829745
Loss at iteration [666]: 0.1461221329324609
Loss at iteration [667]: 0.14597255019382477
Loss at iteration [668]: 0.14573715786076333
Loss at iteration [669]: 0.14561707975982738
Loss at iteration [670]: 0.14544776921302144
Loss at iteration [671]: 0.1452335972777445
Loss at iteration [672]: 0.14487135217895722
Loss at iteration [673]: 0.14456502649926353
Loss at iteration [674]: 0.14421188907838114
Loss at iteration [675]: 0.1432853631356262
Loss at iteration [676]: 0.1432853631356262
Loss at iteration [677]: 0.14307035464804196
Loss at iteration [678]: 0.14261440673865455
Loss at iteration [679]: 0.1425379295472993
Loss at iteration [680]: 0.14238725385967974
Loss at iteration [681]: 0.1422423217846594
Loss at iteration [682]: 0.14169295728856812
Loss at iteration [683]: 0.1414542488766388
Loss at iteration [684]: 0.1412658157318801
Loss at iteration [685]: 0.14092501533732854
Loss at iteration [686]: 0.14022898944377138
Loss at iteration [687]: 0.14022898944377138
Loss at iteration [688]: 0.13990867860582823
Loss at iteration [689]: 0.1397549592056068
Loss at iteration [690]: 0.13899016859366578
Loss at iteration [691]: 0.13887740230430318
Loss at iteration [692]: 0.13879070427332285
Loss at iteration [693]: 0.13867217506924895
Loss at iteration [694]: 0.1382733541239007
Loss at iteration [695]: 0.13818177052309683
Loss at iteration [696]: 0.13803501017757264
Loss at iteration [697]: 0.13797418248628626
Loss at iteration [698]: 0.13783545562045527
Loss at iteration [699]: 0.13783545562045527
Loss at iteration [700]: 0.13778789283395126
Loss at iteration [701]: 0.13769697537625586
Loss at iteration [702]: 0.13766954237414358
Loss at iteration [703]: 0.1376436357753282
Loss at iteration [704]: 0.13760120414154736
Loss at iteration [705]: 0.1375525367184559
Loss at iteration [706]: 0.13749917316871343
Loss at iteration [707]: 0.13749414129607865
Loss at iteration [708]: 0.1373289081462955
Loss at iteration [709]: 0.13693678981070603
Loss at iteration [710]: 0.13657534483904216
Loss at iteration [711]: 0.13612259216825956
Loss at iteration [712]: 0.13565468699482086
Loss at iteration [713]: 0.13557493470622328
Loss at iteration [714]: 0.13557493470622328
Loss at iteration [715]: 0.13549200566411873
Loss at iteration [716]: 0.13531838131328605
Loss at iteration [717]: 0.13518372843871937
Loss at iteration [718]: 0.13508459166694514
Loss at iteration [719]: 0.1349714510246089
Loss at iteration [720]: 0.13482321360073374
Loss at iteration [721]: 0.13453509097083816
Loss at iteration [722]: 0.13443166256462985
Loss at iteration [723]: 0.13431994048120188
Loss at iteration [724]: 0.13426836537454911
Loss at iteration [725]: 0.1342173983474505
Loss at iteration [726]: 0.1342173983474505
Loss at iteration [727]: 0.1342118825593797
Loss at iteration [728]: 0.13414912699759485
Loss at iteration [729]: 0.13413940598618135
Loss at iteration [730]: 0.13402728228622665
Loss at iteration [731]: 0.13395556694978897
Loss at iteration [732]: 0.13390583520618543
Loss at iteration [733]: 0.13388426101036108
Loss at iteration [734]: 0.133807577935395
Loss at iteration [735]: 0.13373209330797103
Loss at iteration [736]: 0.13352751965204318
Loss at iteration [737]: 0.1331205122281867
Loss at iteration [738]: 0.1330820162519335
Loss at iteration [739]: 0.13294849746445003
Loss at iteration [740]: 0.13277922690170066
Loss at iteration [741]: 0.13277922690170066
Loss at iteration [742]: 0.13271130916622015
Loss at iteration [743]: 0.13267125155322002
Loss at iteration [744]: 0.13261513891336044
Loss at iteration [745]: 0.13258496145255194
Loss at iteration [746]: 0.1324756948799455
Loss at iteration [747]: 0.13247074538406647
Loss at iteration [748]: 0.13245060641768314
Loss at iteration [749]: 0.13235034026910591
Loss at iteration [750]: 0.1323201157719892
Loss at iteration [751]: 0.13225829725689703
Loss at iteration [752]: 0.13210469090916807
Loss at iteration [753]: 0.1320089022149949
Loss at iteration [754]: 0.13200437445732538
Loss at iteration [755]: 0.1319910305690328
Loss at iteration [756]: 0.13194147327475508
Loss at iteration [757]: 0.13194147327475508
Loss at iteration [758]: 0.13185289841327155
Loss at iteration [759]: 0.13178145688447296
Loss at iteration [760]: 0.1317746614572937
Loss at iteration [761]: 0.13177336802396952
Loss at iteration [762]: 0.13176774889915066
Loss at iteration [763]: 0.1317425243316395
Loss at iteration [764]: 0.1317194847193131
Loss at iteration [765]: 0.13168344019502645
Loss at iteration [766]: 0.13165922061173332
Loss at iteration [767]: 0.13162389475402583
Loss at iteration [768]: 0.13162374226522777
Loss at iteration [769]: 0.13155460961993068
Loss at iteration [770]: 0.13153764393063427
Loss at iteration [771]: 0.13144982540640848
Loss at iteration [772]: 0.1312417028942705
Loss at iteration [773]: 0.1312417028942705
Loss at iteration [774]: 0.1311804743916945
Loss at iteration [775]: 0.13106807268457252
Loss at iteration [776]: 0.13103831693500548
Loss at iteration [777]: 0.1309939037324736
Loss at iteration [778]: 0.13097340738865557
Loss at iteration [779]: 0.130953602574949
Loss at iteration [780]: 0.13091411279981446
Loss at iteration [781]: 0.13089472029053073
Loss at iteration [782]: 0.1308818462142854
Loss at iteration [783]: 0.1308174657291793
Loss at iteration [784]: 0.13081243038484858
Loss at iteration [785]: 0.13078618898981387
Loss at iteration [786]: 0.13078618898981387
Loss at iteration [787]: 0.13078359237838683
Loss at iteration [788]: 0.13076109038849404
Loss at iteration [789]: 0.13075140842423108
Loss at iteration [790]: 0.13074094866907038
Loss at iteration [791]: 0.13074041969611855
Loss at iteration [792]: 0.13071997291930795
Loss at iteration [793]: 0.13068353170262276
Loss at iteration [794]: 0.13064073231686954
Loss at iteration [795]: 0.13060707693049092
Loss at iteration [796]: 0.13050907360498815
Loss at iteration [797]: 0.13041574246468865
Loss at iteration [798]: 0.13006424410088221
Loss at iteration [799]: 0.1287533086758699
Loss at iteration [800]: 0.1287533086758699
Loss at iteration [801]: 0.12790630982251103
Loss at iteration [802]: 0.12743945813783628
Loss at iteration [803]: 0.12703193484381098
Loss at iteration [804]: 0.12677039580788899
Loss at iteration [805]: 0.1265819832470322
Loss at iteration [806]: 0.12626738635202203
Loss at iteration [807]: 0.12600973505177934
Loss at iteration [808]: 0.12596169658441878
Loss at iteration [809]: 0.12581032223406285
Loss at iteration [810]: 0.12577039853726113
Loss at iteration [811]: 0.12564838510896903
Loss at iteration [812]: 0.12545070062829866
Loss at iteration [813]: 0.12545070062829866
Loss at iteration [814]: 0.1253904060335494
Loss at iteration [815]: 0.12534394645548913
Loss at iteration [816]: 0.12534210922892747
Loss at iteration [817]: 0.1252923023634164
Loss at iteration [818]: 0.12523479209919325
Loss at iteration [819]: 0.12523249843873346
Loss at iteration [820]: 0.12518456039183024
Loss at iteration [821]: 0.12513965282422754
Loss at iteration [822]: 0.12509357930908616
Loss at iteration [823]: 0.1250769917199395
Loss at iteration [824]: 0.12506002898297292
Loss at iteration [825]: 0.12502187863587802
Loss at iteration [826]: 0.12497091847428898
Loss at iteration [827]: 0.12491304362187411
Loss at iteration [828]: 0.12485829809997978
Loss at iteration [829]: 0.12481314208889986
Loss at iteration [830]: 0.12480790741760417
Loss at iteration [831]: 0.12480790741760417
Loss at iteration [832]: 0.12477133586678166
Loss at iteration [833]: 0.12476896495951209
Loss at iteration [834]: 0.1247688919118374
Loss at iteration [835]: 0.12476539892110315
Loss at iteration [836]: 0.12475643886235994
Loss at iteration [837]: 0.12474894150199754
Loss at iteration [838]: 0.12474623600843528
Loss at iteration [839]: 0.12473653502358402
Loss at iteration [840]: 0.12472762600378749
Loss at iteration [841]: 0.1246951226675688
Loss at iteration [842]: 0.1246453686771459
Loss at iteration [843]: 0.12461117295690344
Loss at iteration [844]: 0.12461117295690344
Loss at iteration [845]: 0.12459752340014817
Loss at iteration [846]: 0.12459365208283052
Loss at iteration [847]: 0.12458368385670783
Loss at iteration [848]: 0.12457033224704642
Loss at iteration [849]: 0.12456988932378384
Loss at iteration [850]: 0.1245651140218147
Loss at iteration [851]: 0.12456129589928575
Loss at iteration [852]: 0.12455853206486062
Loss at iteration [853]: 0.1245447960975322
Loss at iteration [854]: 0.1245254232456328
Loss at iteration [855]: 0.12433413132330601
Loss at iteration [856]: 0.12433413132330601
Loss at iteration [857]: 0.12419396491149588
Loss at iteration [858]: 0.12418039602461738
Loss at iteration [859]: 0.12416526354308435
Loss at iteration [860]: 0.12414319671313119
Loss at iteration [861]: 0.12411373426219666
Loss at iteration [862]: 0.12411334777894013
Loss at iteration [863]: 0.12410586761143946
Loss at iteration [864]: 0.12402727247300913
Loss at iteration [865]: 0.12399214079077374
Loss at iteration [866]: 0.12392127129623859
Loss at iteration [867]: 0.12362436858807743
Loss at iteration [868]: 0.12361741808745227
Loss at iteration [869]: 0.12358920156147805
Loss at iteration [870]: 0.1235260223656491
Loss at iteration [871]: 0.12337723495763118
Loss at iteration [872]: 0.12337723495763118
Loss at iteration [873]: 0.12332665814356143
Loss at iteration [874]: 0.12314767177358844
Loss at iteration [875]: 0.12304758871935506
Loss at iteration [876]: 0.12300623806283262
Loss at iteration [877]: 0.12291704281240248
Loss at iteration [878]: 0.12287736597346693
Loss at iteration [879]: 0.12287405172713933
Loss at iteration [880]: 0.12286126775747917
Loss at iteration [881]: 0.12284576562269071
Loss at iteration [882]: 0.12282937101533196
Loss at iteration [883]: 0.12278858512619621
Loss at iteration [884]: 0.12276425338966722
Loss at iteration [885]: 0.12273530228609086
Loss at iteration [886]: 0.12273530228609086
Loss at iteration [887]: 0.12268668638650033
Loss at iteration [888]: 0.12268397414473996
Loss at iteration [889]: 0.12267744474390374
Loss at iteration [890]: 0.1226759491342703
Loss at iteration [891]: 0.12267510075259803
Loss at iteration [892]: 0.12267128873525807
Loss at iteration [893]: 0.12267050136195663
Loss at iteration [894]: 0.12267015584801574
Loss at iteration [895]: 0.12264963169746315
Loss at iteration [896]: 0.12263780778683223
Loss at iteration [897]: 0.12263780778683223
Loss at iteration [898]: 0.12260029445511957
Loss at iteration [899]: 0.1225984098010178
Loss at iteration [900]: 0.12258001015579366
Loss at iteration [901]: 0.12256377607303545
Loss at iteration [902]: 0.12255804418101733
Loss at iteration [903]: 0.1225548015938292
