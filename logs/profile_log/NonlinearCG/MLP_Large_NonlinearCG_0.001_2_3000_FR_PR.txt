Model name                            : MLP_Large
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : NonlinearCG
Learning rate                         : 0.001
Beta type                             :FR_PR
Total number of function evaluations  : 3050
Total number of iterations            : 733
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 42.50497055053711
Total number of parameters            : 402001
Percentage of parameters < 1e-9       : 49.87325902174373%
Percentage of parameters < 1e-7       : 49.87325902174373%
Percentage of parameters < 1e-6       : 49.87375653294394%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.0034829226094149875
Loss at iteration [2]: 0.0031807197729151037
Loss at iteration [3]: 0.003023803297744787
Loss at iteration [4]: 0.002822247331391069
Loss at iteration [5]: 0.0027998268932235056
Loss at iteration [6]: 0.002770379946320554
Loss at iteration [7]: 0.0026516150819622694
Loss at iteration [8]: 0.0026369909412732144
Loss at iteration [9]: 0.0026369909412732144
Loss at iteration [10]: 0.0026308635588465643
Loss at iteration [11]: 0.0026155368954268367
Loss at iteration [12]: 0.0026056764283367063
Loss at iteration [13]: 0.0025968673853856263
Loss at iteration [14]: 0.0025920340615557423
Loss at iteration [15]: 0.002581960656392104
Loss at iteration [16]: 0.0025768581898114582
Loss at iteration [17]: 0.0025768581898114582
Loss at iteration [18]: 0.002575006851269658
Loss at iteration [19]: 0.0025637000863029725
Loss at iteration [20]: 0.002554802107664707
Loss at iteration [21]: 0.002546086378656566
Loss at iteration [22]: 0.0025416251946683817
Loss at iteration [23]: 0.0025339513386313456
Loss at iteration [24]: 0.0025331558535508073
Loss at iteration [25]: 0.0025331558535508073
Loss at iteration [26]: 0.002532573179295833
Loss at iteration [27]: 0.0025308476430408624
Loss at iteration [28]: 0.002525497185138347
Loss at iteration [29]: 0.002522881278504629
Loss at iteration [30]: 0.002515185133559753
Loss at iteration [31]: 0.002504008453841431
Loss at iteration [32]: 0.002504008453841431
Loss at iteration [33]: 0.0025031940789951444
Loss at iteration [34]: 0.0025015727303174277
Loss at iteration [35]: 0.002501302133537922
Loss at iteration [36]: 0.0024988378094286624
Loss at iteration [37]: 0.002497385141501977
Loss at iteration [38]: 0.002495978420616684
Loss at iteration [39]: 0.002495978420616684
Loss at iteration [40]: 0.0024957710305741555
Loss at iteration [41]: 0.0024943614572377443
Loss at iteration [42]: 0.002494069105066448
Loss at iteration [43]: 0.0024918977486703907
Loss at iteration [44]: 0.002490760675305156
Loss at iteration [45]: 0.0024897625325819082
Loss at iteration [46]: 0.0024897625325819082
Loss at iteration [47]: 0.002488951215990733
Loss at iteration [48]: 0.0024882113318048134
Loss at iteration [49]: 0.0024876655118071596
Loss at iteration [50]: 0.0024872504863214444
Loss at iteration [51]: 0.0024869945888624343
Loss at iteration [52]: 0.002486717071570169
Loss at iteration [53]: 0.0024862434431478513
Loss at iteration [54]: 0.0024862434431478513
Loss at iteration [55]: 0.002486096932872332
Loss at iteration [56]: 0.002485634781568033
Loss at iteration [57]: 0.0024855110541228504
Loss at iteration [58]: 0.002485203949624485
Loss at iteration [59]: 0.002484949491867385
Loss at iteration [60]: 0.0024848865982073733
Loss at iteration [61]: 0.0024848865982073733
Loss at iteration [62]: 0.0024848318921669352
Loss at iteration [63]: 0.0024842781154026457
Loss at iteration [64]: 0.002484037470557446
Loss at iteration [65]: 0.0024825965665743717
Loss at iteration [66]: 0.002465916527125075
Loss at iteration [67]: 0.002464562516873802
Loss at iteration [68]: 0.002464562516873802
Loss at iteration [69]: 0.002463696249904529
Loss at iteration [70]: 0.0024619211505681675
Loss at iteration [71]: 0.0024610254145318072
Loss at iteration [72]: 0.0024609067183217533
Loss at iteration [73]: 0.0024607804768355707
Loss at iteration [74]: 0.002460175176283358
Loss at iteration [75]: 0.0024594623343782785
Loss at iteration [76]: 0.0024594623343782785
Loss at iteration [77]: 0.0024583907900087806
Loss at iteration [78]: 0.0024580701436983823
Loss at iteration [79]: 0.0024571804151824147
Loss at iteration [80]: 0.0024570016783482854
Loss at iteration [81]: 0.0024554955284620938
Loss at iteration [82]: 0.002454957892686148
Loss at iteration [83]: 0.002454957892686148
Loss at iteration [84]: 0.0024548345389011597
Loss at iteration [85]: 0.0024539608476464255
Loss at iteration [86]: 0.002453772623217202
Loss at iteration [87]: 0.0024535168428884992
Loss at iteration [88]: 0.0024529995165608453
Loss at iteration [89]: 0.002452928167220953
Loss at iteration [90]: 0.002452850178254659
Loss at iteration [91]: 0.002452850178254659
Loss at iteration [92]: 0.0024527407993179115
Loss at iteration [93]: 0.0024526856828857454
Loss at iteration [94]: 0.002450581548889025
Loss at iteration [95]: 0.002450389185616597
Loss at iteration [96]: 0.0024499800027323096
Loss at iteration [97]: 0.002448962746986955
Loss at iteration [98]: 0.002448962746986955
Loss at iteration [99]: 0.0024488516768118016
Loss at iteration [100]: 0.002448618090738489
Loss at iteration [101]: 0.002448134865569133
Loss at iteration [102]: 0.0024479010419199932
Loss at iteration [103]: 0.0024477849180559326
Loss at iteration [104]: 0.0024472918740500523
Loss at iteration [105]: 0.0024472918740500523
Loss at iteration [106]: 0.0024471370210516178
Loss at iteration [107]: 0.0024470614538782136
Loss at iteration [108]: 0.002446588517796134
Loss at iteration [109]: 0.002446541786705421
Loss at iteration [110]: 0.0024464019038251262
Loss at iteration [111]: 0.002446194941542674
Loss at iteration [112]: 0.002446194941542674
Loss at iteration [113]: 0.0024460130585934377
Loss at iteration [114]: 0.0024458402567937806
Loss at iteration [115]: 0.0024458052794141248
Loss at iteration [116]: 0.0024455221772344193
Loss at iteration [117]: 0.0024441807347421463
Loss at iteration [118]: 0.002444124187902046
Loss at iteration [119]: 0.002444124187902046
Loss at iteration [120]: 0.0024439558830921812
Loss at iteration [121]: 0.002443655099720443
Loss at iteration [122]: 0.0024435552404264986
Loss at iteration [123]: 0.002443315114358583
Loss at iteration [124]: 0.0024432625084068863
Loss at iteration [125]: 0.00244306129131645
Loss at iteration [126]: 0.0024428551979115195
Loss at iteration [127]: 0.0024428551979115195
Loss at iteration [128]: 0.002442804344489257
Loss at iteration [129]: 0.0024425605670610243
Loss at iteration [130]: 0.00244240492709569
Loss at iteration [131]: 0.00244236985615394
Loss at iteration [132]: 0.002442302253206779
Loss at iteration [133]: 0.002442082254488533
Loss at iteration [134]: 0.0024419929248187355
Loss at iteration [135]: 0.0024419929248187355
Loss at iteration [136]: 0.002441885478432672
Loss at iteration [137]: 0.002441784756432743
Loss at iteration [138]: 0.0024417537096367227
Loss at iteration [139]: 0.002441603330122305
Loss at iteration [140]: 0.002441540999054028
Loss at iteration [141]: 0.002441379717618383
Loss at iteration [142]: 0.002441206767777624
Loss at iteration [143]: 0.002441206767777624
Loss at iteration [144]: 0.002441174962381779
Loss at iteration [145]: 0.002440808087775107
Loss at iteration [146]: 0.002440773288226419
Loss at iteration [147]: 0.0024406650769030285
Loss at iteration [148]: 0.002440340773208576
Loss at iteration [149]: 0.0024402754912096532
Loss at iteration [150]: 0.0024401280188303294
Loss at iteration [151]: 0.0024401280188303294
Loss at iteration [152]: 0.0024400896079222454
Loss at iteration [153]: 0.0024400598115431327
Loss at iteration [154]: 0.0024398973799347485
Loss at iteration [155]: 0.0024397734123154323
Loss at iteration [156]: 0.002439705484928906
Loss at iteration [157]: 0.002439601328556943
Loss at iteration [158]: 0.002439601328556943
Loss at iteration [159]: 0.0024395181573833506
Loss at iteration [160]: 0.0024394831121704484
Loss at iteration [161]: 0.0024393046513563168
Loss at iteration [162]: 0.002439260666768516
Loss at iteration [163]: 0.0024391422282483166
Loss at iteration [164]: 0.0024391062929463793
Loss at iteration [165]: 0.0024389514590478795
Loss at iteration [166]: 0.0024389514590478795
Loss at iteration [167]: 0.00243885455754976
Loss at iteration [168]: 0.0024388299923447216
Loss at iteration [169]: 0.00243865012322127
Loss at iteration [170]: 0.00243859839860899
Loss at iteration [171]: 0.002438531243391232
Loss at iteration [172]: 0.002438394570824449
Loss at iteration [173]: 0.002438394570824449
Loss at iteration [174]: 0.0024383584914131357
Loss at iteration [175]: 0.002438328686802556
Loss at iteration [176]: 0.0024382735496267377
Loss at iteration [177]: 0.0024381809864793508
Loss at iteration [178]: 0.0024380820888068445
Loss at iteration [179]: 0.002437627625677046
Loss at iteration [180]: 0.002437627625677046
Loss at iteration [181]: 0.0024373646657794516
Loss at iteration [182]: 0.002437288320311961
Loss at iteration [183]: 0.0024370746767574053
Loss at iteration [184]: 0.002437044539049723
Loss at iteration [185]: 0.002436963882049416
Loss at iteration [186]: 0.002436568526979393
Loss at iteration [187]: 0.0024365325415451533
Loss at iteration [188]: 0.0024365325415451533
Loss at iteration [189]: 0.002436495951187513
Loss at iteration [190]: 0.0024363379753552746
Loss at iteration [191]: 0.0024361269241245246
Loss at iteration [192]: 0.0024360397454660913
Loss at iteration [193]: 0.002435999184046401
Loss at iteration [194]: 0.002435844730190785
Loss at iteration [195]: 0.0024356617625581035
Loss at iteration [196]: 0.0024356617625581035
Loss at iteration [197]: 0.0024356257981675905
Loss at iteration [198]: 0.0024354462991026267
Loss at iteration [199]: 0.0024354075442539363
Loss at iteration [200]: 0.00243522000786326
Loss at iteration [201]: 0.002435185157730737
Loss at iteration [202]: 0.002434941835359955
Loss at iteration [203]: 0.002434941835359955
Loss at iteration [204]: 0.0024348282846291688
Loss at iteration [205]: 0.002434808853867317
Loss at iteration [206]: 0.0024346721698005774
Loss at iteration [207]: 0.0024346285477442184
Loss at iteration [208]: 0.002434510637713271
Loss at iteration [209]: 0.0024342184083690596
Loss at iteration [210]: 0.0024342184083690596
Loss at iteration [211]: 0.002434138931426114
Loss at iteration [212]: 0.002434061404836719
Loss at iteration [213]: 0.0024339071014886308
Loss at iteration [214]: 0.0024338155256880675
Loss at iteration [215]: 0.0024337471513747764
Loss at iteration [216]: 0.002433700469465842
Loss at iteration [217]: 0.002433700469465842
Loss at iteration [218]: 0.0024336568407068463
Loss at iteration [219]: 0.0024335235252185236
Loss at iteration [220]: 0.0024333306621072016
Loss at iteration [221]: 0.002433284171153203
Loss at iteration [222]: 0.002433252211593506
Loss at iteration [223]: 0.002433179537696229
Loss at iteration [224]: 0.002433179537696229
Loss at iteration [225]: 0.002433160028316366
Loss at iteration [226]: 0.0024331045126473063
Loss at iteration [227]: 0.0024330202015266683
Loss at iteration [228]: 0.002432905494822406
Loss at iteration [229]: 0.0024325044208478195
Loss at iteration [230]: 0.002432150895268584
Loss at iteration [231]: 0.002432150895268584
Loss at iteration [232]: 0.002432071087656013
Loss at iteration [233]: 0.0024318538690617096
Loss at iteration [234]: 0.0024315708732454656
Loss at iteration [235]: 0.00243155024548475
Loss at iteration [236]: 0.0024314605555181283
Loss at iteration [237]: 0.0024313130308256247
Loss at iteration [238]: 0.002431259441089446
Loss at iteration [239]: 0.002431259441089446
Loss at iteration [240]: 0.002431209571362588
Loss at iteration [241]: 0.0024311124018239656
Loss at iteration [242]: 0.00243104816983951
Loss at iteration [243]: 0.002431031152616232
Loss at iteration [244]: 0.002430998476150531
Loss at iteration [245]: 0.002430953500556607
Loss at iteration [246]: 0.002430953500556607
Loss at iteration [247]: 0.0024309001867514066
Loss at iteration [248]: 0.0024308759714916825
Loss at iteration [249]: 0.002430797559591537
Loss at iteration [250]: 0.0024307272935296703
Loss at iteration [251]: 0.0024306623827381178
Loss at iteration [252]: 0.002430602789166549
Loss at iteration [253]: 0.002430541047003428
Loss at iteration [254]: 0.002430541047003428
Loss at iteration [255]: 0.002430528889605082
Loss at iteration [256]: 0.002430477674941812
Loss at iteration [257]: 0.002430303970481316
Loss at iteration [258]: 0.002429881010761144
Loss at iteration [259]: 0.002429558522056415
Loss at iteration [260]: 0.002429365024864867
Loss at iteration [261]: 0.002429365024864867
Loss at iteration [262]: 0.0024292024482563974
Loss at iteration [263]: 0.0024290559730930964
Loss at iteration [264]: 0.002428759268587209
Loss at iteration [265]: 0.002428560759169472
Loss at iteration [266]: 0.002428406869485931
Loss at iteration [267]: 0.002428340862405181
Loss at iteration [268]: 0.002428141526259956
Loss at iteration [269]: 0.002428141526259956
Loss at iteration [270]: 0.002428118371173755
Loss at iteration [271]: 0.0024280718270419297
Loss at iteration [272]: 0.0024278930874484087
Loss at iteration [273]: 0.002427821666649758
Loss at iteration [274]: 0.002427786465616689
Loss at iteration [275]: 0.002427658366718291
Loss at iteration [276]: 0.002427658366718291
Loss at iteration [277]: 0.002427575518813221
Loss at iteration [278]: 0.002427560710971036
Loss at iteration [279]: 0.0024274496252286843
Loss at iteration [280]: 0.0024273161199367082
Loss at iteration [281]: 0.0024272545104266695
Loss at iteration [282]: 0.002427177272325795
Loss at iteration [283]: 0.0024271114351512063
Loss at iteration [284]: 0.0024271114351512063
Loss at iteration [285]: 0.0024270842149962967
Loss at iteration [286]: 0.0024270437062212033
Loss at iteration [287]: 0.0024269406239704095
Loss at iteration [288]: 0.0024268980980506148
Loss at iteration [289]: 0.002426858232663319
Loss at iteration [290]: 0.0024265909037153467
Loss at iteration [291]: 0.0024265909037153467
Loss at iteration [292]: 0.0024265558348311096
Loss at iteration [293]: 0.0024265343505173375
Loss at iteration [294]: 0.002426338093931518
Loss at iteration [295]: 0.0024262842799013746
Loss at iteration [296]: 0.0024262425664158573
Loss at iteration [297]: 0.002426168213872519
Loss at iteration [298]: 0.002426168213872519
Loss at iteration [299]: 0.002426146553986065
Loss at iteration [300]: 0.0024261227292410284
Loss at iteration [301]: 0.002426074173422588
Loss at iteration [302]: 0.0024260107264590636
Loss at iteration [303]: 0.002425973713766536
Loss at iteration [304]: 0.0024258993903278083
Loss at iteration [305]: 0.0024254411358109037
Loss at iteration [306]: 0.0024254411358109037
Loss at iteration [307]: 0.0024253960614811754
Loss at iteration [308]: 0.0024252799125213387
Loss at iteration [309]: 0.002425195473459813
Loss at iteration [310]: 0.0024251562150670626
Loss at iteration [311]: 0.0024250369829343314
Loss at iteration [312]: 0.0024249831628911688
Loss at iteration [313]: 0.0024249412981331014
Loss at iteration [314]: 0.0024249412981331014
Loss at iteration [315]: 0.0024249161819140507
Loss at iteration [316]: 0.0024248747479314503
Loss at iteration [317]: 0.0024247986000288466
Loss at iteration [318]: 0.002424749161996725
Loss at iteration [319]: 0.002424722193106423
Loss at iteration [320]: 0.002424680826376516
Loss at iteration [321]: 0.002424547169201125
Loss at iteration [322]: 0.002424547169201125
Loss at iteration [323]: 0.0024245043450248443
Loss at iteration [324]: 0.002424467602669598
Loss at iteration [325]: 0.002424436878114909
Loss at iteration [326]: 0.0024243793512160627
Loss at iteration [327]: 0.002424323137379288
Loss at iteration [328]: 0.0024241892551801285
Loss at iteration [329]: 0.0024241892551801285
Loss at iteration [330]: 0.0024241258112956414
Loss at iteration [331]: 0.002424080943404724
Loss at iteration [332]: 0.0024240064551371595
Loss at iteration [333]: 0.0024239559535702442
Loss at iteration [334]: 0.0024239257861146603
Loss at iteration [335]: 0.0024238717661361846
Loss at iteration [336]: 0.002423828043822168
Loss at iteration [337]: 0.002423828043822168
Loss at iteration [338]: 0.0024237978711666238
Loss at iteration [339]: 0.00242375638948048
Loss at iteration [340]: 0.002423718367865595
Loss at iteration [341]: 0.0024236675731673877
Loss at iteration [342]: 0.0024235931910645543
Loss at iteration [343]: 0.002423420093535212
Loss at iteration [344]: 0.002423420093535212
Loss at iteration [345]: 0.0024233327515372914
Loss at iteration [346]: 0.0024233145313355114
Loss at iteration [347]: 0.002423222754104106
Loss at iteration [348]: 0.0024232026030488523
Loss at iteration [349]: 0.002423152345728627
Loss at iteration [350]: 0.002423029253786407
Loss at iteration [351]: 0.002423029253786407
Loss at iteration [352]: 0.0024230057499042093
Loss at iteration [353]: 0.002422902753831214
Loss at iteration [354]: 0.002422879551546904
Loss at iteration [355]: 0.0024228243767083846
Loss at iteration [356]: 0.0024226851170772385
Loss at iteration [357]: 0.002422615138444169
Loss at iteration [358]: 0.002422615138444169
Loss at iteration [359]: 0.002422565565301268
Loss at iteration [360]: 0.0024224733429518137
Loss at iteration [361]: 0.0024224532568423384
Loss at iteration [362]: 0.0024223543090812344
Loss at iteration [363]: 0.0024223005936154385
Loss at iteration [364]: 0.0024222739163086765
Loss at iteration [365]: 0.0024221488667165512
Loss at iteration [366]: 0.0024221488667165512
Loss at iteration [367]: 0.0024221005007318327
Loss at iteration [368]: 0.0024220094002956384
Loss at iteration [369]: 0.002421948005540314
Loss at iteration [370]: 0.0024219087875737362
Loss at iteration [371]: 0.0024218519326956334
Loss at iteration [372]: 0.0024218519326956334
Loss at iteration [373]: 0.0024218120227843414
Loss at iteration [374]: 0.0024217419815571167
Loss at iteration [375]: 0.0024217286555813598
Loss at iteration [376]: 0.002421706651921109
Loss at iteration [377]: 0.0024216073569173126
Loss at iteration [378]: 0.0024215063913515062
Loss at iteration [379]: 0.002421439698262306
Loss at iteration [380]: 0.002421439698262306
Loss at iteration [381]: 0.00242141105824008
Loss at iteration [382]: 0.002421325683218369
Loss at iteration [383]: 0.0024211817114316476
Loss at iteration [384]: 0.002421126275847543
Loss at iteration [385]: 0.0024210952394992363
Loss at iteration [386]: 0.0024210670162478666
Loss at iteration [387]: 0.0024210670162478666
Loss at iteration [388]: 0.002421051873944805
Loss at iteration [389]: 0.0024210342570856157
Loss at iteration [390]: 0.0024209977338040868
Loss at iteration [391]: 0.002420933633329002
Loss at iteration [392]: 0.0024208813111669127
Loss at iteration [393]: 0.002420850719344514
Loss at iteration [394]: 0.0024207920266775713
Loss at iteration [395]: 0.0024207920266775713
Loss at iteration [396]: 0.002420761731117568
Loss at iteration [397]: 0.0024207464867382123
Loss at iteration [398]: 0.0024206811151825233
Loss at iteration [399]: 0.0024206285936371292
Loss at iteration [400]: 0.0024204824804987487
Loss at iteration [401]: 0.0024201290837649607
Loss at iteration [402]: 0.0024198114372171705
Loss at iteration [403]: 0.0024198114372171705
Loss at iteration [404]: 0.0024197479646450933
Loss at iteration [405]: 0.0024196196021070322
Loss at iteration [406]: 0.002419390842809643
Loss at iteration [407]: 0.0024193380593527463
Loss at iteration [408]: 0.002419249582521662
Loss at iteration [409]: 0.0024190813033545208
Loss at iteration [410]: 0.0024190813033545208
Loss at iteration [411]: 0.002419058262980747
Loss at iteration [412]: 0.002419004432987062
Loss at iteration [413]: 0.0024188965412055975
Loss at iteration [414]: 0.00241883055646361
Loss at iteration [415]: 0.0024187378744997983
Loss at iteration [416]: 0.0024184740806137486
Loss at iteration [417]: 0.0024184740806137486
Loss at iteration [418]: 0.002418396869080678
Loss at iteration [419]: 0.0024183658998675065
Loss at iteration [420]: 0.00241829745675887
Loss at iteration [421]: 0.0024181907860227657
Loss at iteration [422]: 0.0024181769052898238
Loss at iteration [423]: 0.0024181341803246477
Loss at iteration [424]: 0.0024181341803246477
Loss at iteration [425]: 0.0024181161812856246
Loss at iteration [426]: 0.0024180800089938772
Loss at iteration [427]: 0.002418024217461554
Loss at iteration [428]: 0.002418000892396676
Loss at iteration [429]: 0.0024179353684817234
Loss at iteration [430]: 0.0024178198425527015
Loss at iteration [431]: 0.0024178198425527015
Loss at iteration [432]: 0.0024177842250371747
Loss at iteration [433]: 0.0024177487607471666
Loss at iteration [434]: 0.002417645302114961
Loss at iteration [435]: 0.0024176186160178768
Loss at iteration [436]: 0.002417592272722072
Loss at iteration [437]: 0.002417499156526783
Loss at iteration [438]: 0.002417499156526783
Loss at iteration [439]: 0.002417484839964857
Loss at iteration [440]: 0.002417388579157449
Loss at iteration [441]: 0.002417353815030672
Loss at iteration [442]: 0.0024172208076028824
Loss at iteration [443]: 0.0024164865365000816
Loss at iteration [444]: 0.0024159224597629127
Loss at iteration [445]: 0.0024159224597629127
Loss at iteration [446]: 0.0024157751320719504
Loss at iteration [447]: 0.00241555565213601
Loss at iteration [448]: 0.0024152931831068632
Loss at iteration [449]: 0.0024152310133848274
Loss at iteration [450]: 0.002415060766858049
Loss at iteration [451]: 0.0024149481391744733
Loss at iteration [452]: 0.0024146788320494783
Loss at iteration [453]: 0.0024146788320494783
Loss at iteration [454]: 0.0024145597705911284
Loss at iteration [455]: 0.002414517563272043
Loss at iteration [456]: 0.0024144570313583183
Loss at iteration [457]: 0.002414347659148184
Loss at iteration [458]: 0.002414302983967724
Loss at iteration [459]: 0.0024142385955279837
Loss at iteration [460]: 0.0024141550915949064
Loss at iteration [461]: 0.0024141550915949064
Loss at iteration [462]: 0.0024140304758927538
Loss at iteration [463]: 0.002413919031282942
Loss at iteration [464]: 0.0024138783588978706
Loss at iteration [465]: 0.0024138048652066046
Loss at iteration [466]: 0.0024137858859542612
Loss at iteration [467]: 0.002413770202444244
Loss at iteration [468]: 0.002413770202444244
Loss at iteration [469]: 0.0024137580026813675
Loss at iteration [470]: 0.002413708617302846
Loss at iteration [471]: 0.0024136595198706963
Loss at iteration [472]: 0.002413599768525917
Loss at iteration [473]: 0.002413481139150269
Loss at iteration [474]: 0.0024134154217517766
Loss at iteration [475]: 0.0024132720923352334
Loss at iteration [476]: 0.0024132720923352334
Loss at iteration [477]: 0.0024132170552062147
Loss at iteration [478]: 0.0024131768242574405
Loss at iteration [479]: 0.002413146805321702
Loss at iteration [480]: 0.0024130608695197247
Loss at iteration [481]: 0.002412976154542916
Loss at iteration [482]: 0.0024128393476753776
Loss at iteration [483]: 0.0024128393476753776
Loss at iteration [484]: 0.0024127895830289444
Loss at iteration [485]: 0.002412734374053531
Loss at iteration [486]: 0.0024126590717858335
Loss at iteration [487]: 0.002412643847032116
Loss at iteration [488]: 0.0024126229360514626
Loss at iteration [489]: 0.0024125751838451072
Loss at iteration [490]: 0.0024125751838451072
Loss at iteration [491]: 0.002412529193576718
Loss at iteration [492]: 0.002412508004927432
Loss at iteration [493]: 0.0024124480436147028
Loss at iteration [494]: 0.0024123491897011283
Loss at iteration [495]: 0.0024122511754258377
Loss at iteration [496]: 0.00241216243625329
Loss at iteration [497]: 0.00241216243625329
Loss at iteration [498]: 0.0024120925639804524
Loss at iteration [499]: 0.002412065945343903
Loss at iteration [500]: 0.0024119744847476863
Loss at iteration [501]: 0.0024119413264458924
Loss at iteration [502]: 0.0024118465977849388
Loss at iteration [503]: 0.002411784259996725
Loss at iteration [504]: 0.0024117289366676208
Loss at iteration [505]: 0.0024117289366676208
Loss at iteration [506]: 0.002411697099955689
Loss at iteration [507]: 0.002411659347422559
Loss at iteration [508]: 0.0024116224158460056
Loss at iteration [509]: 0.002411592937282385
Loss at iteration [510]: 0.002411469201153224
Loss at iteration [511]: 0.0024114158333929008
Loss at iteration [512]: 0.0024114158333929008
Loss at iteration [513]: 0.0024113697124796773
Loss at iteration [514]: 0.002411352545144445
Loss at iteration [515]: 0.0024112902515488134
Loss at iteration [516]: 0.002411256121867358
Loss at iteration [517]: 0.0024112287564432436
Loss at iteration [518]: 0.0024112078754494996
Loss at iteration [519]: 0.0024112078754494996
Loss at iteration [520]: 0.002411197997863292
Loss at iteration [521]: 0.0024111823641115126
Loss at iteration [522]: 0.0024111292160184446
Loss at iteration [523]: 0.002411044454351812
Loss at iteration [524]: 0.002410906502673781
Loss at iteration [525]: 0.0024107835640176855
Loss at iteration [526]: 0.002410392488776552
Loss at iteration [527]: 0.002410392488776552
Loss at iteration [528]: 0.0024101313680791442
Loss at iteration [529]: 0.002410094359463454
Loss at iteration [530]: 0.0024099333072081773
Loss at iteration [531]: 0.0024099100360248926
Loss at iteration [532]: 0.002409832448256221
Loss at iteration [533]: 0.002409772686919541
Loss at iteration [534]: 0.002409772686919541
Loss at iteration [535]: 0.002409734223824147
Loss at iteration [536]: 0.0024096956939929715
Loss at iteration [537]: 0.002409657236517877
Loss at iteration [538]: 0.0024096447897566115
Loss at iteration [539]: 0.0024096218672299843
Loss at iteration [540]: 0.002409597864521048
Loss at iteration [541]: 0.0024095575205411238
Loss at iteration [542]: 0.0024095575205411238
Loss at iteration [543]: 0.0024095276082245856
Loss at iteration [544]: 0.00240950510364771
Loss at iteration [545]: 0.0024094929762016517
Loss at iteration [546]: 0.0024094715550668244
Loss at iteration [547]: 0.002409440224292681
Loss at iteration [548]: 0.002409380263040113
Loss at iteration [549]: 0.002409380263040113
Loss at iteration [550]: 0.0024093515000262506
Loss at iteration [551]: 0.002409281288532888
Loss at iteration [552]: 0.0024092558544906756
Loss at iteration [553]: 0.0024092154662039397
Loss at iteration [554]: 0.0024091515814024115
Loss at iteration [555]: 0.0024090868073605087
Loss at iteration [556]: 0.0024090868073605087
Loss at iteration [557]: 0.0024090592815090993
Loss at iteration [558]: 0.002409029015244407
Loss at iteration [559]: 0.0024089900680219615
Loss at iteration [560]: 0.002408974980936964
Loss at iteration [561]: 0.002408891557977022
Loss at iteration [562]: 0.0024088401286949854
Loss at iteration [563]: 0.0024087641031808014
Loss at iteration [564]: 0.0024087641031808014
Loss at iteration [565]: 0.0024087364150515637
Loss at iteration [566]: 0.0024086196577318706
Loss at iteration [567]: 0.0024085588688770514
Loss at iteration [568]: 0.0024085331181596275
Loss at iteration [569]: 0.0024085080043640718
Loss at iteration [570]: 0.0024084824018028206
Loss at iteration [571]: 0.0024084824018028206
Loss at iteration [572]: 0.0024084701581460082
Loss at iteration [573]: 0.0024084531297591657
Loss at iteration [574]: 0.0024084052826002494
Loss at iteration [575]: 0.002408374666298961
Loss at iteration [576]: 0.002408257012186391
Loss at iteration [577]: 0.002407775258492767
Loss at iteration [578]: 0.002407775258492767
Loss at iteration [579]: 0.0024075547507832434
Loss at iteration [580]: 0.002407446857653087
Loss at iteration [581]: 0.00240716087897617
Loss at iteration [582]: 0.002407112865309724
Loss at iteration [583]: 0.0024070690141785814
Loss at iteration [584]: 0.002407016401967222
Loss at iteration [585]: 0.00240696615777028
Loss at iteration [586]: 0.00240696615777028
Loss at iteration [587]: 0.002406909230304118
Loss at iteration [588]: 0.0024068522259250756
Loss at iteration [589]: 0.0024068154985853562
Loss at iteration [590]: 0.002406698022839162
Loss at iteration [591]: 0.002406604153500204
Loss at iteration [592]: 0.0024065387833247724
Loss at iteration [593]: 0.0024065387833247724
Loss at iteration [594]: 0.002406505328981507
Loss at iteration [595]: 0.002406486872729945
Loss at iteration [596]: 0.0024064314815180747
Loss at iteration [597]: 0.0024063621870794682
Loss at iteration [598]: 0.0024063096093426893
Loss at iteration [599]: 0.002406080009028553
Loss at iteration [600]: 0.002405959780585526
Loss at iteration [601]: 0.002405959780585526
Loss at iteration [602]: 0.002405837765091843
Loss at iteration [603]: 0.00240580861570169
Loss at iteration [604]: 0.002405655557029909
Loss at iteration [605]: 0.0024056106968909133
Loss at iteration [606]: 0.0024055256347892515
Loss at iteration [607]: 0.0024054869544437255
Loss at iteration [608]: 0.0024054463891576465
Loss at iteration [609]: 0.0024054463891576465
Loss at iteration [610]: 0.0024054295512404454
Loss at iteration [611]: 0.0024053896501200433
Loss at iteration [612]: 0.0024053525186950382
Loss at iteration [613]: 0.0024053082899447324
Loss at iteration [614]: 0.0024050364465806
Loss at iteration [615]: 0.0024049459706613767
Loss at iteration [616]: 0.0024049459706613767
Loss at iteration [617]: 0.0024049149515128223
Loss at iteration [618]: 0.0024048683303068874
Loss at iteration [619]: 0.002404754709248718
Loss at iteration [620]: 0.0024047301984975334
Loss at iteration [621]: 0.002404678403027783
Loss at iteration [622]: 0.0024046397818372114
Loss at iteration [623]: 0.0024046095979560872
Loss at iteration [624]: 0.0024046095979560872
Loss at iteration [625]: 0.0024045936074025475
Loss at iteration [626]: 0.0024045414129743974
Loss at iteration [627]: 0.002404486215188077
Loss at iteration [628]: 0.002404377385045017
Loss at iteration [629]: 0.0024043202509409774
Loss at iteration [630]: 0.0024042477563042514
Loss at iteration [631]: 0.0024042477563042514
Loss at iteration [632]: 0.002404234718836257
Loss at iteration [633]: 0.0024041908397728824
Loss at iteration [634]: 0.0024041625196600407
Loss at iteration [635]: 0.002404118508484197
Loss at iteration [636]: 0.002403935764806387
Loss at iteration [637]: 0.0024038737687184196
Loss at iteration [638]: 0.0024038737687184196
Loss at iteration [639]: 0.0024038337063305142
Loss at iteration [640]: 0.0024037786872881293
Loss at iteration [641]: 0.0024036869064395206
Loss at iteration [642]: 0.0024036647818939712
Loss at iteration [643]: 0.00240361599317023
Loss at iteration [644]: 0.0024036014352900505
Loss at iteration [645]: 0.002403533257651711
Loss at iteration [646]: 0.002403533257651711
Loss at iteration [647]: 0.0024034961762100077
Loss at iteration [648]: 0.0024034803339676764
Loss at iteration [649]: 0.002403454153265583
Loss at iteration [650]: 0.0024034259350957754
Loss at iteration [651]: 0.0024033643836977136
Loss at iteration [652]: 0.0024033046266149637
Loss at iteration [653]: 0.002403059509972442
Loss at iteration [654]: 0.002403059509972442
Loss at iteration [655]: 0.002402727887583023
Loss at iteration [656]: 0.002402652799148527
Loss at iteration [657]: 0.00240241502840583
Loss at iteration [658]: 0.0024023300531310307
Loss at iteration [659]: 0.002402160120640133
Loss at iteration [660]: 0.0024020250481184722
Loss at iteration [661]: 0.0024020250481184722
Loss at iteration [662]: 0.0024019761381455043
Loss at iteration [663]: 0.0024018401550819166
Loss at iteration [664]: 0.0024017181348688875
Loss at iteration [665]: 0.0024016776209721817
Loss at iteration [666]: 0.002401610810314963
Loss at iteration [667]: 0.002401477323184035
Loss at iteration [668]: 0.002401477323184035
Loss at iteration [669]: 0.0024014515165844885
Loss at iteration [670]: 0.0024014099675285466
Loss at iteration [671]: 0.0024013781880938096
Loss at iteration [672]: 0.00240132605605343
Loss at iteration [673]: 0.0024012834008835435
Loss at iteration [674]: 0.002401271020865275
Loss at iteration [675]: 0.0024011800337992136
Loss at iteration [676]: 0.0024011800337992136
Loss at iteration [677]: 0.002401164178009841
Loss at iteration [678]: 0.0024011361132702867
Loss at iteration [679]: 0.0024010976087380127
Loss at iteration [680]: 0.002401066575680718
Loss at iteration [681]: 0.0024009323554136063
Loss at iteration [682]: 0.002400770675295341
Loss at iteration [683]: 0.002400770675295341
Loss at iteration [684]: 0.0024007289163077736
Loss at iteration [685]: 0.002400590888660982
Loss at iteration [686]: 0.0024004773598567644
Loss at iteration [687]: 0.0024004429393091786
Loss at iteration [688]: 0.0024003343095798787
Loss at iteration [689]: 0.0024003123339392703
Loss at iteration [690]: 0.0024002224985933203
Loss at iteration [691]: 0.0024002224985933203
Loss at iteration [692]: 0.002400206831301457
Loss at iteration [693]: 0.002400185843483222
Loss at iteration [694]: 0.002400129016236081
Loss at iteration [695]: 0.0024000956321684717
Loss at iteration [696]: 0.0024000556219263575
Loss at iteration [697]: 0.002400031484756886
Loss at iteration [698]: 0.0023999971202285863
Loss at iteration [699]: 0.0023999971202285863
Loss at iteration [700]: 0.002399983992151066
Loss at iteration [701]: 0.0023999639656989576
Loss at iteration [702]: 0.0023999267619320237
Loss at iteration [703]: 0.002399881679689832
Loss at iteration [704]: 0.0023998532733442105
Loss at iteration [705]: 0.002399816523043379
Loss at iteration [706]: 0.002399816523043379
Loss at iteration [707]: 0.0023998035572665374
Loss at iteration [708]: 0.002399791080475594
Loss at iteration [709]: 0.0023997740810534998
Loss at iteration [710]: 0.0023997488263133855
Loss at iteration [711]: 0.002399654238313423
Loss at iteration [712]: 0.0023995053733627037
Loss at iteration [713]: 0.002399159711842899
Loss at iteration [714]: 0.002399159711842899
Loss at iteration [715]: 0.002398999681824912
Loss at iteration [716]: 0.002398950755253206
Loss at iteration [717]: 0.0023988349035354143
Loss at iteration [718]: 0.002398799579159349
Loss at iteration [719]: 0.0023986930862435825
Loss at iteration [720]: 0.0023985523605350202
Loss at iteration [721]: 0.0023985523605350202
Loss at iteration [722]: 0.0023985312814857863
Loss at iteration [723]: 0.0023985054535215393
Loss at iteration [724]: 0.002398465748517151
Loss at iteration [725]: 0.0023983935364583313
Loss at iteration [726]: 0.0023983488761529182
Loss at iteration [727]: 0.0023983180660905844
Loss at iteration [728]: 0.002398230400357829
Loss at iteration [729]: 0.002398230400357829
Loss at iteration [730]: 0.0023982016288752006
Loss at iteration [731]: 0.0023981672592855137
Loss at iteration [732]: 0.0023981378032409775
Loss at iteration [733]: 0.0023980936076079115
Loss at iteration [734]: 0.002398043943571199
Loss at iteration [735]: 0.0023978744363862313
Loss at iteration [736]: 0.0023978744363862313
Loss at iteration [737]: 0.0023978270662510987
Loss at iteration [738]: 0.00239778825652691
Loss at iteration [739]: 0.002397689054156933
Loss at iteration [740]: 0.002397540363081112
Loss at iteration [741]: 0.0023975062643109613
Loss at iteration [742]: 0.0023974731640831787
Loss at iteration [743]: 0.0023974731640831787
Loss at iteration [744]: 0.002397452206857724
Loss at iteration [745]: 0.0023974200822660524
Loss at iteration [746]: 0.0023973526487855936
Loss at iteration [747]: 0.002397299723104994
Loss at iteration [748]: 0.0023972520303795863
Loss at iteration [749]: 0.002397225896641185
Loss at iteration [750]: 0.0023971903234147394
Loss at iteration [751]: 0.0023971903234147394
Loss at iteration [752]: 0.002397169151619505
Loss at iteration [753]: 0.0023971583637412345
Loss at iteration [754]: 0.0023971059325627766
Loss at iteration [755]: 0.0023970653871210864
Loss at iteration [756]: 0.002397008462207894
Loss at iteration [757]: 0.0023968164691620174
Loss at iteration [758]: 0.0023968164691620174
Loss at iteration [759]: 0.0023967914469487338
Loss at iteration [760]: 0.0023967024307425576
Loss at iteration [761]: 0.002396655761145638
Loss at iteration [762]: 0.002396636164232516
Loss at iteration [763]: 0.002396582565163233
Loss at iteration [764]: 0.002396544364013703
Loss at iteration [765]: 0.002396502220231688
Loss at iteration [766]: 0.002396502220231688
Loss at iteration [767]: 0.0023964838960040787
Loss at iteration [768]: 0.0023964565841614336
Loss at iteration [769]: 0.0023964207924038797
Loss at iteration [770]: 0.002396387290078219
Loss at iteration [771]: 0.002396325832184823
Loss at iteration [772]: 0.002396104842420138
Loss at iteration [773]: 0.002396104842420138
Loss at iteration [774]: 0.0023960585459557203
Loss at iteration [775]: 0.0023960171345730886
Loss at iteration [776]: 0.0023959312683408413
Loss at iteration [777]: 0.002395879694237002
Loss at iteration [778]: 0.002395845990808408
Loss at iteration [779]: 0.00239581120932078
Loss at iteration [780]: 0.0023957668860912235
Loss at iteration [781]: 0.0023957668860912235
Loss at iteration [782]: 0.002395755027530635
Loss at iteration [783]: 0.002395728876442418
Loss at iteration [784]: 0.0023956981661181634
Loss at iteration [785]: 0.0023956805204162056
Loss at iteration [786]: 0.002395651056384343
Loss at iteration [787]: 0.0023956264242967263
Loss at iteration [788]: 0.0023956264242967263
Loss at iteration [789]: 0.002395602659692969
Loss at iteration [790]: 0.0023955827485745702
Loss at iteration [791]: 0.002395558758308524
Loss at iteration [792]: 0.002395535040426123
Loss at iteration [793]: 0.0023955019431507515
Loss at iteration [794]: 0.002395253476183565
Loss at iteration [795]: 0.002395253476183565
Loss at iteration [796]: 0.0023951392468477984
Loss at iteration [797]: 0.002395111859011712
Loss at iteration [798]: 0.0023950083788338273
Loss at iteration [799]: 0.002394961302475131
Loss at iteration [800]: 0.0023949315725853015
Loss at iteration [801]: 0.002394879571087117
Loss at iteration [802]: 0.002394859646924014
Loss at iteration [803]: 0.002394859646924014
Loss at iteration [804]: 0.0023948451009487104
Loss at iteration [805]: 0.002394802021380028
Loss at iteration [806]: 0.0023947600299503613
Loss at iteration [807]: 0.0023946851423070938
Loss at iteration [808]: 0.0023946498677446665
Loss at iteration [809]: 0.002394584539906657
Loss at iteration [810]: 0.002394584539906657
Loss at iteration [811]: 0.002394534403849608
Loss at iteration [812]: 0.002394509364294555
Loss at iteration [813]: 0.002394478799210921
Loss at iteration [814]: 0.0023944118885368794
Loss at iteration [815]: 0.0023943592118547256
Loss at iteration [816]: 0.0023943230719596386
Loss at iteration [817]: 0.0023942619444376825
Loss at iteration [818]: 0.0023942619444376825
Loss at iteration [819]: 0.002394250013831756
Loss at iteration [820]: 0.0023941973613039297
Loss at iteration [821]: 0.0023941834690592244
Loss at iteration [822]: 0.002394164165984605
Loss at iteration [823]: 0.002394132156746548
Loss at iteration [824]: 0.0023941119455508117
Loss at iteration [825]: 0.0023940631318884018
Loss at iteration [826]: 0.0023940631318884018
Loss at iteration [827]: 0.0023940144580068172
Loss at iteration [828]: 0.0023939932712609344
Loss at iteration [829]: 0.0023939725781092604
Loss at iteration [830]: 0.002393954685477784
Loss at iteration [831]: 0.0023939359634235213
Loss at iteration [832]: 0.0023939163842663994
Loss at iteration [833]: 0.0023938590218034466
Loss at iteration [834]: 0.0023938590218034466
Loss at iteration [835]: 0.0023938326725882445
Loss at iteration [836]: 0.002393811322466846
Loss at iteration [837]: 0.002393780400876115
Loss at iteration [838]: 0.0023937562859112495
Loss at iteration [839]: 0.002393735621359372
Loss at iteration [840]: 0.0023937158665285944
