Model name                            : MLP_Multistep
The number of input features          : 3
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.001
Beta type                             :FR_PR
Total number of function evaluations  : 3042
Total number of iterations            : 1920
Max number of iterations              : 3000
Number of samples in training data    : 171
Number of samples in tests data       : 73
Total training time                   : 9.823447942733765
Total number of parameters            : 201902
Percentage of parameters < 1e-9       : 50.17483729730265%
Percentage of parameters < 1e-7       : 50.17483729730265%
Percentage of parameters < 1e-6       : 50.17533258709671%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.2580942585480166
Loss at iteration [2]: 1.2546249519121266
Loss at iteration [3]: 1.2488794179714722
Loss at iteration [4]: 1.2406481848422994
Loss at iteration [5]: 1.2344848816216896
Loss at iteration [6]: 1.2183274888026512
Loss at iteration [7]: 1.2183274888026512
Loss at iteration [8]: 1.211807697698455
Loss at iteration [9]: 1.2056324466973634
Loss at iteration [10]: 1.196161544181041
Loss at iteration [11]: 1.1914259570745944
Loss at iteration [12]: 1.1657083942275983
Loss at iteration [13]: 1.1570281625297787
Loss at iteration [14]: 1.1570281625297787
Loss at iteration [15]: 1.1532095483715559
Loss at iteration [16]: 1.1458678214189721
Loss at iteration [17]: 1.1433131712112634
Loss at iteration [18]: 1.1363479211836491
Loss at iteration [19]: 1.130653309743227
Loss at iteration [20]: 1.1267923267992228
Loss at iteration [21]: 1.1236107441381546
Loss at iteration [22]: 1.1236107441381546
Loss at iteration [23]: 1.121121730494662
Loss at iteration [24]: 1.1164897811419152
Loss at iteration [25]: 1.111936599210268
Loss at iteration [26]: 1.094893950371053
Loss at iteration [27]: 1.0853137551024716
Loss at iteration [28]: 1.070355851992506
Loss at iteration [29]: 1.0566664493575801
Loss at iteration [30]: 1.0566664493575801
Loss at iteration [31]: 1.0538170306418944
Loss at iteration [32]: 1.0460154432086126
Loss at iteration [33]: 1.0432955596494677
Loss at iteration [34]: 1.0347065575286534
Loss at iteration [35]: 1.0334922226153596
Loss at iteration [36]: 1.026848008424223
Loss at iteration [37]: 1.0232786362502944
Loss at iteration [38]: 1.0172821007352069
Loss at iteration [39]: 1.0172821007352069
Loss at iteration [40]: 1.016268282965699
Loss at iteration [41]: 1.0118037656508703
Loss at iteration [42]: 1.010685854554745
Loss at iteration [43]: 1.0068144727716266
Loss at iteration [44]: 1.0054013444106047
Loss at iteration [45]: 0.9968919154512184
Loss at iteration [46]: 0.9914094584972544
Loss at iteration [47]: 0.9914094584972544
Loss at iteration [48]: 0.9893687850247773
Loss at iteration [49]: 0.9856715694592808
Loss at iteration [50]: 0.9842890314973117
Loss at iteration [51]: 0.9817141739948742
Loss at iteration [52]: 0.9793554721889248
Loss at iteration [53]: 0.9770868532002454
Loss at iteration [54]: 0.9729242776940349
Loss at iteration [55]: 0.9729242776940349
Loss at iteration [56]: 0.9719545248389191
Loss at iteration [57]: 0.9684435831160978
Loss at iteration [58]: 0.9678062266128827
Loss at iteration [59]: 0.9653368660737459
Loss at iteration [60]: 0.9640692975250224
Loss at iteration [61]: 0.9580547500228486
Loss at iteration [62]: 0.9499288740949001
Loss at iteration [63]: 0.9499288740949001
Loss at iteration [64]: 0.9487606300426689
Loss at iteration [65]: 0.9465086163453065
Loss at iteration [66]: 0.9443784600845881
Loss at iteration [67]: 0.9436127047080922
Loss at iteration [68]: 0.9414121381549609
Loss at iteration [69]: 0.9406029759448419
Loss at iteration [70]: 0.9378581423781324
Loss at iteration [71]: 0.9367331675304433
Loss at iteration [72]: 0.9367331675304433
Loss at iteration [73]: 0.9358935198268676
Loss at iteration [74]: 0.9350283900223035
Loss at iteration [75]: 0.934355516445471
Loss at iteration [76]: 0.9332566855302095
Loss at iteration [77]: 0.9307101388762445
Loss at iteration [78]: 0.9289746383267822
Loss at iteration [79]: 0.9281168696104393
Loss at iteration [80]: 0.9249764293826165
Loss at iteration [81]: 0.9249764293826165
Loss at iteration [82]: 0.9239209685595982
Loss at iteration [83]: 0.9221587506003458
Loss at iteration [84]: 0.9211112439114473
Loss at iteration [85]: 0.9205190730014379
Loss at iteration [86]: 0.9186019545676622
Loss at iteration [87]: 0.917554664826326
Loss at iteration [88]: 0.9119083687893125
Loss at iteration [89]: 0.8971845300283716
Loss at iteration [90]: 0.8936662115848136
Loss at iteration [91]: 0.8936662115848136
Loss at iteration [92]: 0.8920051827375685
Loss at iteration [93]: 0.8826338909715168
Loss at iteration [94]: 0.8801541319565827
Loss at iteration [95]: 0.8759535829099948
Loss at iteration [96]: 0.8752102858246011
Loss at iteration [97]: 0.8735449365879557
Loss at iteration [98]: 0.873079196822594
Loss at iteration [99]: 0.8699437948610402
Loss at iteration [100]: 0.8690144847534238
Loss at iteration [101]: 0.8690144847534238
Loss at iteration [102]: 0.86842569293118
Loss at iteration [103]: 0.8674587872427717
Loss at iteration [104]: 0.8669971005822735
Loss at iteration [105]: 0.8655215955454295
Loss at iteration [106]: 0.8641759402906805
Loss at iteration [107]: 0.8636121875337488
Loss at iteration [108]: 0.8623329985698126
Loss at iteration [109]: 0.8615026671790965
Loss at iteration [110]: 0.8597449422794815
Loss at iteration [111]: 0.8597449422794815
Loss at iteration [112]: 0.8581541902134368
Loss at iteration [113]: 0.8571658329948126
Loss at iteration [114]: 0.8566567241767588
Loss at iteration [115]: 0.8561226161850347
Loss at iteration [116]: 0.8553571708070448
Loss at iteration [117]: 0.8550198682713922
Loss at iteration [118]: 0.8545522798280275
Loss at iteration [119]: 0.8539733792053781
Loss at iteration [120]: 0.8535042502925813
Loss at iteration [121]: 0.8535042502925813
Loss at iteration [122]: 0.8532651368319708
Loss at iteration [123]: 0.8529344517310394
Loss at iteration [124]: 0.8527600971259643
Loss at iteration [125]: 0.8523595247813607
Loss at iteration [126]: 0.8521239967168527
Loss at iteration [127]: 0.8518932175528151
Loss at iteration [128]: 0.851762620667056
Loss at iteration [129]: 0.8516060501619079
Loss at iteration [130]: 0.8513571580219725
Loss at iteration [131]: 0.8510100157193756
Loss at iteration [132]: 0.8510100157193756
Loss at iteration [133]: 0.8509184692294668
Loss at iteration [134]: 0.8508661980807293
Loss at iteration [135]: 0.8508233694414192
Loss at iteration [136]: 0.8506444582917755
Loss at iteration [137]: 0.8503952981463332
Loss at iteration [138]: 0.8501272456144404
Loss at iteration [139]: 0.849928522230462
Loss at iteration [140]: 0.8497361944980619
Loss at iteration [141]: 0.8494343208004163
Loss at iteration [142]: 0.848325755354444
Loss at iteration [143]: 0.8474928377709668
Loss at iteration [144]: 0.8474928377709668
Loss at iteration [145]: 0.8470609900783118
Loss at iteration [146]: 0.8466340517176858
Loss at iteration [147]: 0.8463917474307765
Loss at iteration [148]: 0.8461673401246648
Loss at iteration [149]: 0.8459288627405067
Loss at iteration [150]: 0.8457128762260013
Loss at iteration [151]: 0.8455316874018315
Loss at iteration [152]: 0.8451374877015599
Loss at iteration [153]: 0.8446966556803067
Loss at iteration [154]: 0.8433712612437465
Loss at iteration [155]: 0.8433712612437465
Loss at iteration [156]: 0.8426569723450213
Loss at iteration [157]: 0.8419778683253181
Loss at iteration [158]: 0.8417703598345483
Loss at iteration [159]: 0.8414424536842325
Loss at iteration [160]: 0.8412316193205333
Loss at iteration [161]: 0.8410219582650864
Loss at iteration [162]: 0.8408020997681229
Loss at iteration [163]: 0.8405504426070312
Loss at iteration [164]: 0.8403045808189196
Loss at iteration [165]: 0.8399056816181231
Loss at iteration [166]: 0.8399056816181231
Loss at iteration [167]: 0.8396649976569549
Loss at iteration [168]: 0.8395151337395104
Loss at iteration [169]: 0.8394427844068875
Loss at iteration [170]: 0.8393098974365236
Loss at iteration [171]: 0.8390716857524265
Loss at iteration [172]: 0.8386754492369147
Loss at iteration [173]: 0.8383532086033662
Loss at iteration [174]: 0.8381449333436466
Loss at iteration [175]: 0.837972078274552
Loss at iteration [176]: 0.8375920971871538
Loss at iteration [177]: 0.8375920971871538
Loss at iteration [178]: 0.8374198763971783
Loss at iteration [179]: 0.8372992031093364
Loss at iteration [180]: 0.8372263194215452
Loss at iteration [181]: 0.8370563587231452
Loss at iteration [182]: 0.8369441521984948
Loss at iteration [183]: 0.8368341665819555
Loss at iteration [184]: 0.836686191091685
Loss at iteration [185]: 0.8364410889828983
Loss at iteration [186]: 0.8361509565748788
Loss at iteration [187]: 0.8361509565748788
Loss at iteration [188]: 0.8360040811085947
Loss at iteration [189]: 0.8359435820905701
Loss at iteration [190]: 0.8358821085358265
Loss at iteration [191]: 0.8358141633068381
Loss at iteration [192]: 0.8357072741589167
Loss at iteration [193]: 0.8354167310064344
Loss at iteration [194]: 0.8348082241727962
Loss at iteration [195]: 0.8341751269103157
Loss at iteration [196]: 0.8325894483656782
Loss at iteration [197]: 0.8300919277586354
Loss at iteration [198]: 0.8300919277586354
Loss at iteration [199]: 0.8296272924178003
Loss at iteration [200]: 0.8292460730889933
Loss at iteration [201]: 0.8290129550056009
Loss at iteration [202]: 0.8287553939905206
Loss at iteration [203]: 0.8285865330535246
Loss at iteration [204]: 0.8282783958040241
Loss at iteration [205]: 0.828150507887739
Loss at iteration [206]: 0.8279729858783352
Loss at iteration [207]: 0.8278011585276502
Loss at iteration [208]: 0.8275819534537966
Loss at iteration [209]: 0.8275819534537966
Loss at iteration [210]: 0.8273405361135501
Loss at iteration [211]: 0.827227766072257
Loss at iteration [212]: 0.8271394249434736
Loss at iteration [213]: 0.827007115656819
Loss at iteration [214]: 0.8265953433633786
Loss at iteration [215]: 0.8262509975954699
Loss at iteration [216]: 0.8254839363036454
Loss at iteration [217]: 0.8250681208474525
Loss at iteration [218]: 0.8244707474740709
Loss at iteration [219]: 0.8244707474740709
Loss at iteration [220]: 0.824191641019158
Loss at iteration [221]: 0.8240387581204498
Loss at iteration [222]: 0.8239225359367662
Loss at iteration [223]: 0.8237820795848275
Loss at iteration [224]: 0.823711531499299
Loss at iteration [225]: 0.8236254441247427
Loss at iteration [226]: 0.8235204287655065
Loss at iteration [227]: 0.8232729756963344
Loss at iteration [228]: 0.8230938618672233
Loss at iteration [229]: 0.8228032789533453
Loss at iteration [230]: 0.8227003467957041
Loss at iteration [231]: 0.8227003467957041
Loss at iteration [232]: 0.8225883812508418
Loss at iteration [233]: 0.8225558869721667
Loss at iteration [234]: 0.8224892406400068
Loss at iteration [235]: 0.822455685322264
Loss at iteration [236]: 0.8224033611307318
Loss at iteration [237]: 0.8223089002537235
Loss at iteration [238]: 0.8220635957386261
Loss at iteration [239]: 0.8217077614887676
Loss at iteration [240]: 0.8213238910495982
Loss at iteration [241]: 0.8210094120505225
Loss at iteration [242]: 0.8208045400960076
Loss at iteration [243]: 0.8206290256088302
Loss at iteration [244]: 0.8205279455420746
Loss at iteration [245]: 0.8205279455420746
Loss at iteration [246]: 0.820442959921008
Loss at iteration [247]: 0.8203967506117783
Loss at iteration [248]: 0.8203212217360977
Loss at iteration [249]: 0.8202883545439638
Loss at iteration [250]: 0.8202539863647478
Loss at iteration [251]: 0.8202288137994124
Loss at iteration [252]: 0.8201909442468849
Loss at iteration [253]: 0.8201389350587386
Loss at iteration [254]: 0.8200981479043559
Loss at iteration [255]: 0.8200587638991836
Loss at iteration [256]: 0.8200198667321746
Loss at iteration [257]: 0.8199902895964151
Loss at iteration [258]: 0.819854353768378
Loss at iteration [259]: 0.8192019906178873
Loss at iteration [260]: 0.8171424742504615
Loss at iteration [261]: 0.8161663367038197
Loss at iteration [262]: 0.8161663367038197
Loss at iteration [263]: 0.8156410169813966
Loss at iteration [264]: 0.8149109302119468
Loss at iteration [265]: 0.8146238040062376
Loss at iteration [266]: 0.8141638861006014
Loss at iteration [267]: 0.8138034246634067
Loss at iteration [268]: 0.8136770427833686
Loss at iteration [269]: 0.8135895037271428
Loss at iteration [270]: 0.8135299467928693
Loss at iteration [271]: 0.8133843905051135
Loss at iteration [272]: 0.8133243028992638
Loss at iteration [273]: 0.8132219961316998
Loss at iteration [274]: 0.8132219961316998
Loss at iteration [275]: 0.8131684533247197
Loss at iteration [276]: 0.8131362373736615
Loss at iteration [277]: 0.8131005760127018
Loss at iteration [278]: 0.8130682008182064
Loss at iteration [279]: 0.8130372570869336
Loss at iteration [280]: 0.8130111953953942
Loss at iteration [281]: 0.8128649509404662
Loss at iteration [282]: 0.812641455780866
Loss at iteration [283]: 0.8122608914496144
Loss at iteration [284]: 0.8118705307790607
Loss at iteration [285]: 0.8101483312235911
Loss at iteration [286]: 0.8060653613463156
Loss at iteration [287]: 0.8060653613463156
Loss at iteration [288]: 0.805060736588604
Loss at iteration [289]: 0.7995721643265452
Loss at iteration [290]: 0.7990723247427755
Loss at iteration [291]: 0.7978317351628245
Loss at iteration [292]: 0.7976078447844989
Loss at iteration [293]: 0.7968260260721475
Loss at iteration [294]: 0.7961083047655245
Loss at iteration [295]: 0.7956909220000924
Loss at iteration [296]: 0.7950836117249545
Loss at iteration [297]: 0.7950836117249545
Loss at iteration [298]: 0.7946098978857625
Loss at iteration [299]: 0.7937469104144669
Loss at iteration [300]: 0.7935095411279381
Loss at iteration [301]: 0.7929922389679405
Loss at iteration [302]: 0.7928394435216758
Loss at iteration [303]: 0.792682253610901
Loss at iteration [304]: 0.7924826384206483
Loss at iteration [305]: 0.792284707003038
Loss at iteration [306]: 0.7920948217739415
Loss at iteration [307]: 0.7919204182946884
Loss at iteration [308]: 0.7919204182946884
Loss at iteration [309]: 0.7917852959358948
Loss at iteration [310]: 0.7917403981902407
Loss at iteration [311]: 0.7916607270596796
Loss at iteration [312]: 0.7916321396620793
Loss at iteration [313]: 0.7915844693378901
Loss at iteration [314]: 0.7915357370378053
Loss at iteration [315]: 0.7913850419989962
Loss at iteration [316]: 0.7910901174751687
Loss at iteration [317]: 0.7908155660108455
Loss at iteration [318]: 0.7906301040086394
Loss at iteration [319]: 0.7904414564357128
Loss at iteration [320]: 0.7903424396010613
Loss at iteration [321]: 0.7901652630790746
Loss at iteration [322]: 0.7901652630790746
Loss at iteration [323]: 0.7900788849408737
Loss at iteration [324]: 0.7900000506151892
Loss at iteration [325]: 0.7899612890570608
Loss at iteration [326]: 0.7898990648936075
Loss at iteration [327]: 0.7898443317782493
Loss at iteration [328]: 0.7897975119194033
Loss at iteration [329]: 0.7897511214544141
Loss at iteration [330]: 0.7897194270395268
Loss at iteration [331]: 0.7896418994187986
Loss at iteration [332]: 0.789359325489021
Loss at iteration [333]: 0.7890249948953896
Loss at iteration [334]: 0.7887102262555981
Loss at iteration [335]: 0.7885958171885303
Loss at iteration [336]: 0.7885958171885303
Loss at iteration [337]: 0.7884108154771655
Loss at iteration [338]: 0.7883498648701521
Loss at iteration [339]: 0.7882637811258423
Loss at iteration [340]: 0.7881820120562658
Loss at iteration [341]: 0.7880815402152714
Loss at iteration [342]: 0.7880351520455201
Loss at iteration [343]: 0.787981009677446
Loss at iteration [344]: 0.7879531640471472
Loss at iteration [345]: 0.7879246323580493
Loss at iteration [346]: 0.7878944692381852
Loss at iteration [347]: 0.7878627778537146
Loss at iteration [348]: 0.7878302570665459
Loss at iteration [349]: 0.787802202686525
Loss at iteration [350]: 0.7877615586390214
Loss at iteration [351]: 0.7877246326069597
Loss at iteration [352]: 0.7876894574499873
Loss at iteration [353]: 0.7876633093866671
Loss at iteration [354]: 0.7876633093866671
Loss at iteration [355]: 0.7876325610486768
Loss at iteration [356]: 0.7876232494821251
Loss at iteration [357]: 0.7876132315698295
Loss at iteration [358]: 0.7875954585531694
Loss at iteration [359]: 0.7875752802410563
Loss at iteration [360]: 0.7875365089107136
Loss at iteration [361]: 0.787498353270254
Loss at iteration [362]: 0.7874678883104305
Loss at iteration [363]: 0.787446076712348
Loss at iteration [364]: 0.787402232722925
Loss at iteration [365]: 0.7873304544937609
Loss at iteration [366]: 0.7872414573447573
Loss at iteration [367]: 0.7870491104718641
Loss at iteration [368]: 0.7867521686899953
Loss at iteration [369]: 0.7862173851044049
Loss at iteration [370]: 0.7852798219784874
Loss at iteration [371]: 0.7852798219784874
Loss at iteration [372]: 0.7844901616493309
Loss at iteration [373]: 0.7841443701998247
Loss at iteration [374]: 0.7837365345285705
Loss at iteration [375]: 0.7834235040220338
Loss at iteration [376]: 0.7832525163392321
Loss at iteration [377]: 0.7830733180909527
Loss at iteration [378]: 0.7829422208305001
Loss at iteration [379]: 0.782864431750366
Loss at iteration [380]: 0.7828055970921016
Loss at iteration [381]: 0.7827607215350331
Loss at iteration [382]: 0.7827333987272632
Loss at iteration [383]: 0.7827333987272632
Loss at iteration [384]: 0.7827045559474226
Loss at iteration [385]: 0.7826810854995856
Loss at iteration [386]: 0.782670994573376
Loss at iteration [387]: 0.7826607509234688
Loss at iteration [388]: 0.7826003402670244
Loss at iteration [389]: 0.7825290716503236
Loss at iteration [390]: 0.7824880593503628
Loss at iteration [391]: 0.7824332687209088
Loss at iteration [392]: 0.7823986154646376
Loss at iteration [393]: 0.7823521144296054
Loss at iteration [394]: 0.7823118588398547
Loss at iteration [395]: 0.782291641352983
Loss at iteration [396]: 0.7822675807074627
Loss at iteration [397]: 0.7821841901304785
Loss at iteration [398]: 0.7819860144865716
Loss at iteration [399]: 0.7813191627557642
Loss at iteration [400]: 0.780647821984524
Loss at iteration [401]: 0.780647821984524
Loss at iteration [402]: 0.7803998483298273
Loss at iteration [403]: 0.7801577047986692
Loss at iteration [404]: 0.7798849344409501
Loss at iteration [405]: 0.7797757503136213
Loss at iteration [406]: 0.7796523956711773
Loss at iteration [407]: 0.7795833143934999
Loss at iteration [408]: 0.7792982745427954
Loss at iteration [409]: 0.7790979755445666
Loss at iteration [410]: 0.7789549004167353
Loss at iteration [411]: 0.7788264388161104
Loss at iteration [412]: 0.7786506671436243
Loss at iteration [413]: 0.7784524265136243
Loss at iteration [414]: 0.7784524265136243
Loss at iteration [415]: 0.7783575265533835
Loss at iteration [416]: 0.7783049177806005
Loss at iteration [417]: 0.7782045504428732
Loss at iteration [418]: 0.7781426387650132
Loss at iteration [419]: 0.7780908696333366
Loss at iteration [420]: 0.7780605959237398
Loss at iteration [421]: 0.7780029906176263
Loss at iteration [422]: 0.7779575158913615
Loss at iteration [423]: 0.7779207115037723
Loss at iteration [424]: 0.7778839992300167
Loss at iteration [425]: 0.777835810214987
Loss at iteration [426]: 0.7778129873620594
Loss at iteration [427]: 0.7777944964280713
Loss at iteration [428]: 0.7777370775011863
Loss at iteration [429]: 0.7776294936339521
Loss at iteration [430]: 0.7775136646366504
Loss at iteration [431]: 0.7775136646366504
Loss at iteration [432]: 0.7774581118955646
Loss at iteration [433]: 0.777403970071216
Loss at iteration [434]: 0.7773808202391456
Loss at iteration [435]: 0.7773604465154048
Loss at iteration [436]: 0.777347439986906
Loss at iteration [437]: 0.7773070124640148
Loss at iteration [438]: 0.7772689965345028
Loss at iteration [439]: 0.7772426249331902
Loss at iteration [440]: 0.7772043539410654
Loss at iteration [441]: 0.7771684342724301
Loss at iteration [442]: 0.7771421812558047
Loss at iteration [443]: 0.777111958731949
Loss at iteration [444]: 0.7770792073195226
Loss at iteration [445]: 0.7770214236771564
Loss at iteration [446]: 0.776985216758171
Loss at iteration [447]: 0.7769672193464854
Loss at iteration [448]: 0.7769376412951126
Loss at iteration [449]: 0.776904650188919
Loss at iteration [450]: 0.776857990698758
Loss at iteration [451]: 0.7768142320919461
Loss at iteration [452]: 0.7768142320919461
Loss at iteration [453]: 0.7767854901291772
Loss at iteration [454]: 0.7767789251374679
Loss at iteration [455]: 0.7767703918379001
Loss at iteration [456]: 0.7767637647668076
Loss at iteration [457]: 0.7767441895945153
Loss at iteration [458]: 0.7767270360864509
Loss at iteration [459]: 0.7766904714205851
Loss at iteration [460]: 0.7766625173781042
Loss at iteration [461]: 0.7766400529999724
Loss at iteration [462]: 0.776605235306219
Loss at iteration [463]: 0.7765531231599304
Loss at iteration [464]: 0.7765028996407145
Loss at iteration [465]: 0.7764688689055123
Loss at iteration [466]: 0.7764404513576595
Loss at iteration [467]: 0.7763958522558849
Loss at iteration [468]: 0.7763585213338587
Loss at iteration [469]: 0.7763341841898249
Loss at iteration [470]: 0.7763025727223716
Loss at iteration [471]: 0.7762495711027392
Loss at iteration [472]: 0.77621290756663
Loss at iteration [473]: 0.77621290756663
Loss at iteration [474]: 0.7761895851613003
Loss at iteration [475]: 0.7761849114658319
Loss at iteration [476]: 0.7761690983652183
Loss at iteration [477]: 0.7761603575691357
Loss at iteration [478]: 0.7761528585371363
Loss at iteration [479]: 0.7761462163840238
Loss at iteration [480]: 0.7761282157670458
Loss at iteration [481]: 0.7760870984879441
Loss at iteration [482]: 0.7760462032425003
Loss at iteration [483]: 0.776013885295481
Loss at iteration [484]: 0.7759841833105242
Loss at iteration [485]: 0.7759392125533063
Loss at iteration [486]: 0.7758921962794999
Loss at iteration [487]: 0.7758530446545151
Loss at iteration [488]: 0.7758168294110998
Loss at iteration [489]: 0.7757783378021857
Loss at iteration [490]: 0.7757341279405439
Loss at iteration [491]: 0.7756953771280344
Loss at iteration [492]: 0.7756489334250876
Loss at iteration [493]: 0.775616414983789
Loss at iteration [494]: 0.775616414983789
Loss at iteration [495]: 0.7755810906361338
Loss at iteration [496]: 0.7755725309179662
Loss at iteration [497]: 0.7755658704341523
Loss at iteration [498]: 0.7755570028652765
Loss at iteration [499]: 0.7755430096288412
Loss at iteration [500]: 0.7755347534204675
Loss at iteration [501]: 0.775533896587029
Loss at iteration [502]: 0.7755101222130052
Loss at iteration [503]: 0.7754624733316064
Loss at iteration [504]: 0.7754308534620149
Loss at iteration [505]: 0.7754010492057438
Loss at iteration [506]: 0.7753615999053547
Loss at iteration [507]: 0.7753379317059346
Loss at iteration [508]: 0.7752808425522099
Loss at iteration [509]: 0.7752390367873322
Loss at iteration [510]: 0.7751933059684711
Loss at iteration [511]: 0.775160479721537
Loss at iteration [512]: 0.7751246556421236
Loss at iteration [513]: 0.7750731278614518
Loss at iteration [514]: 0.7750731278614518
Loss at iteration [515]: 0.775029640022562
Loss at iteration [516]: 0.7750047332620916
Loss at iteration [517]: 0.7749993199816466
Loss at iteration [518]: 0.7749852297562946
Loss at iteration [519]: 0.7749779158730746
Loss at iteration [520]: 0.7749689482219317
Loss at iteration [521]: 0.7749555998625434
Loss at iteration [522]: 0.7749519630202986
Loss at iteration [523]: 0.7749389069207
Loss at iteration [524]: 0.7748969806243278
Loss at iteration [525]: 0.7748597448936638
Loss at iteration [526]: 0.7748201498205892
Loss at iteration [527]: 0.7748048386707537
Loss at iteration [528]: 0.774767500837203
Loss at iteration [529]: 0.7747152370704755
Loss at iteration [530]: 0.7746871164202065
Loss at iteration [531]: 0.7746658795088918
Loss at iteration [532]: 0.774632600465571
Loss at iteration [533]: 0.774632600465571
Loss at iteration [534]: 0.7745997785894065
Loss at iteration [535]: 0.774592397119548
Loss at iteration [536]: 0.7745829653476545
Loss at iteration [537]: 0.7745739854238741
Loss at iteration [538]: 0.7745562736495605
Loss at iteration [539]: 0.7745378538923376
Loss at iteration [540]: 0.7745077533744638
Loss at iteration [541]: 0.7744638230454888
Loss at iteration [542]: 0.7744425103320759
Loss at iteration [543]: 0.7744120226925593
Loss at iteration [544]: 0.7743682054733252
Loss at iteration [545]: 0.7743211033797791
Loss at iteration [546]: 0.7742869900418218
Loss at iteration [547]: 0.774270968295508
Loss at iteration [548]: 0.7742396271259939
Loss at iteration [549]: 0.7741781086725306
Loss at iteration [550]: 0.7741409739245917
Loss at iteration [551]: 0.7741018357299032
Loss at iteration [552]: 0.7740643537026622
Loss at iteration [553]: 0.774048355007645
Loss at iteration [554]: 0.774048355007645
Loss at iteration [555]: 0.7740252612111024
Loss at iteration [556]: 0.7740136712355671
Loss at iteration [557]: 0.7739989247869821
Loss at iteration [558]: 0.7739868216151854
Loss at iteration [559]: 0.7739679544780702
Loss at iteration [560]: 0.7739356652254948
Loss at iteration [561]: 0.7738979560406792
Loss at iteration [562]: 0.7738602413420764
Loss at iteration [563]: 0.7738574319799324
Loss at iteration [564]: 0.7738418024150328
Loss at iteration [565]: 0.7737895495574204
Loss at iteration [566]: 0.7737354571908691
Loss at iteration [567]: 0.773695837809158
Loss at iteration [568]: 0.7736785736096318
Loss at iteration [569]: 0.7736561712150383
Loss at iteration [570]: 0.7736255099315041
Loss at iteration [571]: 0.7735661267145865
Loss at iteration [572]: 0.7735233084011229
Loss at iteration [573]: 0.7734928336418033
Loss at iteration [574]: 0.773472920033813
Loss at iteration [575]: 0.773472920033813
Loss at iteration [576]: 0.7734393742954363
Loss at iteration [577]: 0.7734270165637981
Loss at iteration [578]: 0.773424014669646
Loss at iteration [579]: 0.773417966006257
Loss at iteration [580]: 0.7734068746776236
Loss at iteration [581]: 0.7733846014262769
Loss at iteration [582]: 0.7733558958125466
Loss at iteration [583]: 0.7733291285806223
Loss at iteration [584]: 0.7732967772518351
Loss at iteration [585]: 0.7732698835191907
Loss at iteration [586]: 0.7732515611703621
Loss at iteration [587]: 0.7732296101396577
Loss at iteration [588]: 0.7731837647280448
Loss at iteration [589]: 0.7731421860596919
Loss at iteration [590]: 0.7731104843846639
Loss at iteration [591]: 0.7731064538675244
Loss at iteration [592]: 0.7730709985311274
Loss at iteration [593]: 0.77304240981452
Loss at iteration [594]: 0.7730175361864423
Loss at iteration [595]: 0.7729775447008895
Loss at iteration [596]: 0.7729775447008895
Loss at iteration [597]: 0.7729629350582514
Loss at iteration [598]: 0.7729541733576628
Loss at iteration [599]: 0.7729376304867526
Loss at iteration [600]: 0.7729289462873884
Loss at iteration [601]: 0.7729210133483801
Loss at iteration [602]: 0.7729092835810892
Loss at iteration [603]: 0.7729013642166379
Loss at iteration [604]: 0.77289627054175
Loss at iteration [605]: 0.7728735822299156
Loss at iteration [606]: 0.7728424213442596
Loss at iteration [607]: 0.7728013507526275
Loss at iteration [608]: 0.7727520537833473
Loss at iteration [609]: 0.772706074510406
Loss at iteration [610]: 0.77265943188751
Loss at iteration [611]: 0.7726184360389736
Loss at iteration [612]: 0.772553435087017
Loss at iteration [613]: 0.7719865503175797
Loss at iteration [614]: 0.7719865503175797
Loss at iteration [615]: 0.7717116874920799
Loss at iteration [616]: 0.771479144944466
Loss at iteration [617]: 0.771393031767076
Loss at iteration [618]: 0.771301014217036
Loss at iteration [619]: 0.7712653482350789
Loss at iteration [620]: 0.7711589551729918
Loss at iteration [621]: 0.7710778382019545
Loss at iteration [622]: 0.7710139193721651
Loss at iteration [623]: 0.7709453604843929
Loss at iteration [624]: 0.7708448488298802
Loss at iteration [625]: 0.7707435461339582
Loss at iteration [626]: 0.7707435461339582
Loss at iteration [627]: 0.7706917974036857
Loss at iteration [628]: 0.7706710419804211
Loss at iteration [629]: 0.7706519426652021
Loss at iteration [630]: 0.770625040650154
Loss at iteration [631]: 0.7705906018724741
Loss at iteration [632]: 0.770581898563778
Loss at iteration [633]: 0.7705673904290085
Loss at iteration [634]: 0.7705302031079528
Loss at iteration [635]: 0.7704837947349926
Loss at iteration [636]: 0.7704557569254018
Loss at iteration [637]: 0.7704264907925659
Loss at iteration [638]: 0.7703925215820148
Loss at iteration [639]: 0.7703646223672462
Loss at iteration [640]: 0.7703338813515818
Loss at iteration [641]: 0.7703034811626366
Loss at iteration [642]: 0.7702584968027315
Loss at iteration [643]: 0.7702217696585242
Loss at iteration [644]: 0.77017809607858
Loss at iteration [645]: 0.7700695682090211
Loss at iteration [646]: 0.7700023440818785
Loss at iteration [647]: 0.7700023440818785
Loss at iteration [648]: 0.7699668348387888
Loss at iteration [649]: 0.7699459463210965
Loss at iteration [650]: 0.7699393733904408
Loss at iteration [651]: 0.7699224877186921
Loss at iteration [652]: 0.7698941633799891
Loss at iteration [653]: 0.7698669308258057
Loss at iteration [654]: 0.7698492791351735
Loss at iteration [655]: 0.7698085000280601
Loss at iteration [656]: 0.7697721910002692
Loss at iteration [657]: 0.7697420827867284
Loss at iteration [658]: 0.7697075145669785
Loss at iteration [659]: 0.7696488290132335
Loss at iteration [660]: 0.7696260623548932
Loss at iteration [661]: 0.7695866731254297
Loss at iteration [662]: 0.7695411091546479
Loss at iteration [663]: 0.7695110382807557
Loss at iteration [664]: 0.7694829981688803
Loss at iteration [665]: 0.7693979562107838
Loss at iteration [666]: 0.7692204701753251
Loss at iteration [667]: 0.7688155126832956
Loss at iteration [668]: 0.7688155126832956
Loss at iteration [669]: 0.7686730076744559
Loss at iteration [670]: 0.7686043892604838
Loss at iteration [671]: 0.7685224396594503
Loss at iteration [672]: 0.7684752202299997
Loss at iteration [673]: 0.7684111371177031
Loss at iteration [674]: 0.7683716456659146
Loss at iteration [675]: 0.7683441558852873
Loss at iteration [676]: 0.7683031828314419
Loss at iteration [677]: 0.7682738620084134
Loss at iteration [678]: 0.7682411641209511
Loss at iteration [679]: 0.7682110520100466
Loss at iteration [680]: 0.7681643126047945
Loss at iteration [681]: 0.76812589070574
Loss at iteration [682]: 0.7681045669949763
Loss at iteration [683]: 0.7680872526865009
Loss at iteration [684]: 0.7680534133279918
Loss at iteration [685]: 0.7680105662112041
Loss at iteration [686]: 0.7679673015804573
Loss at iteration [687]: 0.767946234617659
Loss at iteration [688]: 0.7679260355131455
Loss at iteration [689]: 0.7679260355131455
Loss at iteration [690]: 0.7678974402875433
Loss at iteration [691]: 0.7678860830987473
Loss at iteration [692]: 0.7678742596469181
Loss at iteration [693]: 0.7678621890656082
Loss at iteration [694]: 0.7678429746614608
Loss at iteration [695]: 0.7678075330337656
Loss at iteration [696]: 0.7677613083106136
Loss at iteration [697]: 0.7677360414973414
Loss at iteration [698]: 0.767705419205429
Loss at iteration [699]: 0.7676606930905884
Loss at iteration [700]: 0.7676198994187385
Loss at iteration [701]: 0.7675670420170464
Loss at iteration [702]: 0.767548170695403
Loss at iteration [703]: 0.7675135426301732
Loss at iteration [704]: 0.7674603408649553
Loss at iteration [705]: 0.7674296755627044
Loss at iteration [706]: 0.7674180951312864
Loss at iteration [707]: 0.7673716535098604
Loss at iteration [708]: 0.7673329584046645
Loss at iteration [709]: 0.7673010325769656
Loss at iteration [710]: 0.7673010325769656
Loss at iteration [711]: 0.7672758706401313
Loss at iteration [712]: 0.7672604651920333
Loss at iteration [713]: 0.767248653096218
Loss at iteration [714]: 0.7672429614492147
Loss at iteration [715]: 0.7672333350274116
Loss at iteration [716]: 0.7672205935834113
Loss at iteration [717]: 0.7672091818748216
Loss at iteration [718]: 0.7671972539696411
Loss at iteration [719]: 0.7671906549371166
Loss at iteration [720]: 0.7670561243411961
Loss at iteration [721]: 0.7668963680862195
Loss at iteration [722]: 0.7665768077832273
Loss at iteration [723]: 0.7659984072365172
Loss at iteration [724]: 0.7653551764321733
Loss at iteration [725]: 0.7653551764321733
Loss at iteration [726]: 0.7650803619026797
Loss at iteration [727]: 0.764752054252617
Loss at iteration [728]: 0.7646441897461079
Loss at iteration [729]: 0.7645023638417044
Loss at iteration [730]: 0.764413373315883
Loss at iteration [731]: 0.7643670132893846
Loss at iteration [732]: 0.7642714326947934
Loss at iteration [733]: 0.7642369376568401
Loss at iteration [734]: 0.7641918924678156
Loss at iteration [735]: 0.7641623438767752
Loss at iteration [736]: 0.7641259802436452
Loss at iteration [737]: 0.7640787683692083
Loss at iteration [738]: 0.7640349667486837
Loss at iteration [739]: 0.7639967321367942
Loss at iteration [740]: 0.7639967321367942
Loss at iteration [741]: 0.7639729050256714
Loss at iteration [742]: 0.7639619243200695
Loss at iteration [743]: 0.763945673868972
Loss at iteration [744]: 0.7639141974491489
Loss at iteration [745]: 0.7638629359635596
Loss at iteration [746]: 0.7638386099445735
Loss at iteration [747]: 0.7638167307341883
Loss at iteration [748]: 0.7637773370797545
Loss at iteration [749]: 0.7637146552939345
Loss at iteration [750]: 0.7636740146830296
Loss at iteration [751]: 0.7636283920200753
Loss at iteration [752]: 0.7635989310391494
Loss at iteration [753]: 0.7635598524893156
Loss at iteration [754]: 0.7635171428339955
Loss at iteration [755]: 0.7634516653511599
Loss at iteration [756]: 0.7633885641582433
Loss at iteration [757]: 0.7633491072237585
Loss at iteration [758]: 0.7633085639639972
Loss at iteration [759]: 0.7632746904131995
Loss at iteration [760]: 0.7632298610534632
Loss at iteration [761]: 0.7632298610534632
Loss at iteration [762]: 0.7631973190549862
Loss at iteration [763]: 0.7631822240467312
Loss at iteration [764]: 0.7631724668963029
Loss at iteration [765]: 0.7631510189761597
Loss at iteration [766]: 0.7631118672631602
Loss at iteration [767]: 0.7630762449289513
Loss at iteration [768]: 0.7630534609841889
Loss at iteration [769]: 0.7630141152404318
Loss at iteration [770]: 0.762970765604193
Loss at iteration [771]: 0.7629423669564049
Loss at iteration [772]: 0.7629040502443462
Loss at iteration [773]: 0.7628655818972191
Loss at iteration [774]: 0.7628186877072042
Loss at iteration [775]: 0.7627731876917855
Loss at iteration [776]: 0.7627096054270851
Loss at iteration [777]: 0.7626740171368416
Loss at iteration [778]: 0.7626410150097637
Loss at iteration [779]: 0.7624101742747403
Loss at iteration [780]: 0.7622054197292163
Loss at iteration [781]: 0.7618131516885839
Loss at iteration [782]: 0.7618131516885839
Loss at iteration [783]: 0.7617143666609975
Loss at iteration [784]: 0.7616682378996716
Loss at iteration [785]: 0.7616145871336256
Loss at iteration [786]: 0.7615724547334487
Loss at iteration [787]: 0.7615447251328145
Loss at iteration [788]: 0.761499711903586
Loss at iteration [789]: 0.761438831245357
Loss at iteration [790]: 0.7613916851117989
Loss at iteration [791]: 0.7613832286283668
Loss at iteration [792]: 0.7613497136928606
Loss at iteration [793]: 0.7613020755683144
Loss at iteration [794]: 0.7612553710023339
Loss at iteration [795]: 0.7612017394305884
Loss at iteration [796]: 0.7611438021537467
Loss at iteration [797]: 0.7611028514963948
Loss at iteration [798]: 0.7610597109181266
Loss at iteration [799]: 0.7610095202841646
Loss at iteration [800]: 0.7609634039825647
Loss at iteration [801]: 0.7609228009138771
Loss at iteration [802]: 0.7608900106324166
Loss at iteration [803]: 0.7608900106324166
Loss at iteration [804]: 0.7608573347518763
Loss at iteration [805]: 0.7608452131556278
Loss at iteration [806]: 0.7608257092370841
Loss at iteration [807]: 0.7608199065637212
Loss at iteration [808]: 0.7608020632319186
Loss at iteration [809]: 0.7607788655134599
Loss at iteration [810]: 0.760748746041842
Loss at iteration [811]: 0.7607021688566978
Loss at iteration [812]: 0.7606527048900904
Loss at iteration [813]: 0.7606134345623043
Loss at iteration [814]: 0.7605715917909329
Loss at iteration [815]: 0.7605201156996285
Loss at iteration [816]: 0.7604733973755858
Loss at iteration [817]: 0.760436303672971
Loss at iteration [818]: 0.7603899226127581
Loss at iteration [819]: 0.7603500567412619
Loss at iteration [820]: 0.7603043808584937
Loss at iteration [821]: 0.7602559632957439
Loss at iteration [822]: 0.760189409852647
Loss at iteration [823]: 0.7601614988279464
Loss at iteration [824]: 0.7601614988279464
Loss at iteration [825]: 0.7601397727889726
Loss at iteration [826]: 0.760125083160923
Loss at iteration [827]: 0.7601077686694326
Loss at iteration [828]: 0.7600959638001711
Loss at iteration [829]: 0.7600589426130167
Loss at iteration [830]: 0.7599995799516794
Loss at iteration [831]: 0.7599620965934174
Loss at iteration [832]: 0.7599266974573498
Loss at iteration [833]: 0.7598818972715048
Loss at iteration [834]: 0.7598405363244369
Loss at iteration [835]: 0.7597900984375341
Loss at iteration [836]: 0.7597455003610161
Loss at iteration [837]: 0.7596923757603774
Loss at iteration [838]: 0.7596482637235524
Loss at iteration [839]: 0.7596023738739847
Loss at iteration [840]: 0.7595556717223537
Loss at iteration [841]: 0.759492960524839
Loss at iteration [842]: 0.759426410399052
Loss at iteration [843]: 0.7593893709541987
Loss at iteration [844]: 0.7593527813134071
Loss at iteration [845]: 0.7593527813134071
Loss at iteration [846]: 0.7593114383330611
Loss at iteration [847]: 0.7592875880710781
Loss at iteration [848]: 0.759277591100419
Loss at iteration [849]: 0.7592646662180284
Loss at iteration [850]: 0.7592521159727128
Loss at iteration [851]: 0.7592442022743244
Loss at iteration [852]: 0.7592336194275913
Loss at iteration [853]: 0.7591866927183359
Loss at iteration [854]: 0.7591236492685943
Loss at iteration [855]: 0.7591065503355906
Loss at iteration [856]: 0.7591057081653372
Loss at iteration [857]: 0.7590712572208046
Loss at iteration [858]: 0.7589244322585299
Loss at iteration [859]: 0.758624093968593
Loss at iteration [860]: 0.7583526559146063
Loss at iteration [861]: 0.7581602020784098
Loss at iteration [862]: 0.7581602020784098
Loss at iteration [863]: 0.757935953719436
Loss at iteration [864]: 0.7577255032566346
Loss at iteration [865]: 0.7576766796785298
Loss at iteration [866]: 0.757600917942521
Loss at iteration [867]: 0.7575518578947162
Loss at iteration [868]: 0.7575113848567139
Loss at iteration [869]: 0.7574525782061565
Loss at iteration [870]: 0.7574127931532376
Loss at iteration [871]: 0.7573794403176043
Loss at iteration [872]: 0.7573613649243421
Loss at iteration [873]: 0.7573173298861822
Loss at iteration [874]: 0.7572773354702927
Loss at iteration [875]: 0.7572391874766243
Loss at iteration [876]: 0.7571845351942069
Loss at iteration [877]: 0.7571356761361645
Loss at iteration [878]: 0.7571090793261666
Loss at iteration [879]: 0.7571090793261666
Loss at iteration [880]: 0.7570725615409213
Loss at iteration [881]: 0.7570620167497505
Loss at iteration [882]: 0.7570522990755133
Loss at iteration [883]: 0.7570357927413822
Loss at iteration [884]: 0.7570085599389696
Loss at iteration [885]: 0.7569688474340583
Loss at iteration [886]: 0.7569148647919834
Loss at iteration [887]: 0.7568788851465038
Loss at iteration [888]: 0.7568402740562212
Loss at iteration [889]: 0.7568064901868992
Loss at iteration [890]: 0.7567630309422689
Loss at iteration [891]: 0.7567304955131126
Loss at iteration [892]: 0.7565922544320282
Loss at iteration [893]: 0.7563870138396958
Loss at iteration [894]: 0.7558953463169175
Loss at iteration [895]: 0.7553282369222218
Loss at iteration [896]: 0.7545550135129501
Loss at iteration [897]: 0.7545550135129501
Loss at iteration [898]: 0.7541602115603944
Loss at iteration [899]: 0.7538117565420769
Loss at iteration [900]: 0.7537623497821709
Loss at iteration [901]: 0.7536422351949658
Loss at iteration [902]: 0.7535457359452048
Loss at iteration [903]: 0.753508272772934
Loss at iteration [904]: 0.7534487536152024
Loss at iteration [905]: 0.7533968195580761
Loss at iteration [906]: 0.7533550638569887
Loss at iteration [907]: 0.7533330467375704
Loss at iteration [908]: 0.753292672517429
Loss at iteration [909]: 0.7532228921859128
Loss at iteration [910]: 0.7531708957263591
Loss at iteration [911]: 0.7531350117007457
Loss at iteration [912]: 0.7530995398261058
Loss at iteration [913]: 0.7530624466264526
Loss at iteration [914]: 0.7530059301489058
Loss at iteration [915]: 0.7529356984931191
Loss at iteration [916]: 0.752842615174736
Loss at iteration [917]: 0.752842615174736
Loss at iteration [918]: 0.7527874687017106
Loss at iteration [919]: 0.7527547851864987
Loss at iteration [920]: 0.7527536753371701
Loss at iteration [921]: 0.752733070866129
Loss at iteration [922]: 0.7526886759115481
Loss at iteration [923]: 0.7526569494429476
Loss at iteration [924]: 0.7526441082292465
Loss at iteration [925]: 0.7526060031028996
Loss at iteration [926]: 0.7525635412548117
Loss at iteration [927]: 0.7525280665603088
Loss at iteration [928]: 0.7525010297363985
Loss at iteration [929]: 0.7524631585336736
Loss at iteration [930]: 0.7524156718385525
Loss at iteration [931]: 0.7523914559408866
Loss at iteration [932]: 0.7523641638108871
Loss at iteration [933]: 0.7523143930840454
Loss at iteration [934]: 0.7522908353077904
Loss at iteration [935]: 0.7522625421040473
Loss at iteration [936]: 0.7522074494215327
Loss at iteration [937]: 0.7521756035824017
Loss at iteration [938]: 0.7521756035824017
Loss at iteration [939]: 0.7521565479380041
Loss at iteration [940]: 0.7521510315204115
Loss at iteration [941]: 0.7521326395173317
Loss at iteration [942]: 0.752119383996924
Loss at iteration [943]: 0.7521151721068611
Loss at iteration [944]: 0.7520777233500505
Loss at iteration [945]: 0.7520297349035442
Loss at iteration [946]: 0.7520010432849851
Loss at iteration [947]: 0.75195425016127
Loss at iteration [948]: 0.7519171277816119
Loss at iteration [949]: 0.7518972340221771
Loss at iteration [950]: 0.7518634190975312
Loss at iteration [951]: 0.7518134795553048
Loss at iteration [952]: 0.7517311030615454
Loss at iteration [953]: 0.7516860040018294
Loss at iteration [954]: 0.751674690729491
Loss at iteration [955]: 0.7515863203086586
Loss at iteration [956]: 0.7514440391172148
Loss at iteration [957]: 0.7514440391172148
Loss at iteration [958]: 0.7513870948559179
Loss at iteration [959]: 0.7513137397999099
Loss at iteration [960]: 0.7512560792071176
Loss at iteration [961]: 0.7511919501808607
Loss at iteration [962]: 0.7511433202663718
Loss at iteration [963]: 0.7511166445027406
Loss at iteration [964]: 0.7510954765873534
Loss at iteration [965]: 0.7510549118619907
Loss at iteration [966]: 0.7510138581606501
Loss at iteration [967]: 0.750974764397847
Loss at iteration [968]: 0.7509516489856
Loss at iteration [969]: 0.7509298697058643
Loss at iteration [970]: 0.7508745972426993
Loss at iteration [971]: 0.7508285829702706
Loss at iteration [972]: 0.7507874005799388
Loss at iteration [973]: 0.7507553783369989
Loss at iteration [974]: 0.7507103707066085
Loss at iteration [975]: 0.7506625633526389
Loss at iteration [976]: 0.7506336120660518
Loss at iteration [977]: 0.7506051971637349
Loss at iteration [978]: 0.7506051971637349
Loss at iteration [979]: 0.7505591703314288
Loss at iteration [980]: 0.750544032413984
Loss at iteration [981]: 0.7505366893160796
Loss at iteration [982]: 0.7505229861562882
Loss at iteration [983]: 0.7505179955188592
Loss at iteration [984]: 0.7505140476159197
Loss at iteration [985]: 0.7504924230665738
Loss at iteration [986]: 0.7504510698042461
Loss at iteration [987]: 0.7503995630642875
Loss at iteration [988]: 0.7503528072652581
Loss at iteration [989]: 0.7503335987801246
Loss at iteration [990]: 0.7502836113404244
Loss at iteration [991]: 0.7502045244179508
Loss at iteration [992]: 0.7501339717847366
Loss at iteration [993]: 0.7500955757708717
Loss at iteration [994]: 0.7500574634498626
Loss at iteration [995]: 0.7500192252045245
Loss at iteration [996]: 0.7499738406451322
Loss at iteration [997]: 0.7499738406451322
Loss at iteration [998]: 0.7499381019542999
Loss at iteration [999]: 0.7499303548019054
Loss at iteration [1000]: 0.7499220379200584
Loss at iteration [1001]: 0.749897897302327
Loss at iteration [1002]: 0.7498566410331284
Loss at iteration [1003]: 0.7498334667105185
Loss at iteration [1004]: 0.7498106765482687
Loss at iteration [1005]: 0.7497649872327764
Loss at iteration [1006]: 0.7497377063002566
Loss at iteration [1007]: 0.749704727908865
Loss at iteration [1008]: 0.7496564353066645
Loss at iteration [1009]: 0.7496400836431135
Loss at iteration [1010]: 0.7495899385273284
Loss at iteration [1011]: 0.7495311483598798
Loss at iteration [1012]: 0.749471598889543
Loss at iteration [1013]: 0.749446909881554
Loss at iteration [1014]: 0.7494285919272313
Loss at iteration [1015]: 0.7493857774962986
Loss at iteration [1016]: 0.7493325643321109
Loss at iteration [1017]: 0.7492950038931546
Loss at iteration [1018]: 0.7492950038931546
Loss at iteration [1019]: 0.7492650439221556
Loss at iteration [1020]: 0.749255255007985
Loss at iteration [1021]: 0.7492329025739288
Loss at iteration [1022]: 0.7492223393776742
Loss at iteration [1023]: 0.749214275129125
Loss at iteration [1024]: 0.7492024648211301
Loss at iteration [1025]: 0.7491986564946169
Loss at iteration [1026]: 0.7491827813303911
Loss at iteration [1027]: 0.7491368310834265
Loss at iteration [1028]: 0.7490859540596104
Loss at iteration [1029]: 0.7490642036087286
Loss at iteration [1030]: 0.7490572226150477
Loss at iteration [1031]: 0.7490124407388797
Loss at iteration [1032]: 0.748960805316932
Loss at iteration [1033]: 0.7489237553420013
Loss at iteration [1034]: 0.748909514943943
Loss at iteration [1035]: 0.7488539572447153
Loss at iteration [1036]: 0.7488132249300694
Loss at iteration [1037]: 0.7487893962428299
Loss at iteration [1038]: 0.7487893962428299
Loss at iteration [1039]: 0.7487629510198418
Loss at iteration [1040]: 0.7487591671363184
Loss at iteration [1041]: 0.7487484976230947
Loss at iteration [1042]: 0.748738910526468
Loss at iteration [1043]: 0.7487206609369363
Loss at iteration [1044]: 0.7486994330718645
Loss at iteration [1045]: 0.7486704344255911
Loss at iteration [1046]: 0.7486426567622496
Loss at iteration [1047]: 0.748600676479812
Loss at iteration [1048]: 0.7485728908054237
Loss at iteration [1049]: 0.7485287230538552
Loss at iteration [1050]: 0.7484886805063585
Loss at iteration [1051]: 0.7484423405075232
Loss at iteration [1052]: 0.7484004463748781
Loss at iteration [1053]: 0.7483454954779336
Loss at iteration [1054]: 0.7483078690929854
Loss at iteration [1055]: 0.7482586600304647
Loss at iteration [1056]: 0.7482044807205731
Loss at iteration [1057]: 0.7481745182770735
Loss at iteration [1058]: 0.7481358066525325
Loss at iteration [1059]: 0.7481358066525325
Loss at iteration [1060]: 0.7480812531903924
Loss at iteration [1061]: 0.7480600624132507
Loss at iteration [1062]: 0.748046477426645
Loss at iteration [1063]: 0.7480300122562433
Loss at iteration [1064]: 0.7480178282095494
Loss at iteration [1065]: 0.7480091002806177
Loss at iteration [1066]: 0.7480030247743494
Loss at iteration [1067]: 0.7479818217247131
Loss at iteration [1068]: 0.7479235828743159
Loss at iteration [1069]: 0.7478828350756183
Loss at iteration [1070]: 0.7478656726449514
Loss at iteration [1071]: 0.7478342875956421
Loss at iteration [1072]: 0.7478057628718124
Loss at iteration [1073]: 0.7477719790095652
Loss at iteration [1074]: 0.7477137671187358
Loss at iteration [1075]: 0.7476608829518455
Loss at iteration [1076]: 0.7476382064853309
Loss at iteration [1077]: 0.7475950088492167
Loss at iteration [1078]: 0.7475950088492167
Loss at iteration [1079]: 0.7475667442453522
Loss at iteration [1080]: 0.7475576620263767
Loss at iteration [1081]: 0.7475392762091491
Loss at iteration [1082]: 0.7475306669188299
Loss at iteration [1083]: 0.7475206679642316
Loss at iteration [1084]: 0.7475091172265176
Loss at iteration [1085]: 0.7474986643274222
Loss at iteration [1086]: 0.7474906781924768
Loss at iteration [1087]: 0.7474669297607428
Loss at iteration [1088]: 0.7474354327408175
Loss at iteration [1089]: 0.7473773876358403
Loss at iteration [1090]: 0.7473261164535495
Loss at iteration [1091]: 0.7472943147151885
Loss at iteration [1092]: 0.7472634640749029
Loss at iteration [1093]: 0.7472238595140307
Loss at iteration [1094]: 0.7471511559085484
Loss at iteration [1095]: 0.7471029607416888
Loss at iteration [1096]: 0.7470695975721592
Loss at iteration [1097]: 0.7470695975721592
Loss at iteration [1098]: 0.7470410837525907
Loss at iteration [1099]: 0.7470303060445398
Loss at iteration [1100]: 0.7470178313217085
Loss at iteration [1101]: 0.7470043342923819
Loss at iteration [1102]: 0.7469659454949336
Loss at iteration [1103]: 0.7469620317540502
Loss at iteration [1104]: 0.7469408453537432
Loss at iteration [1105]: 0.7468910377050761
Loss at iteration [1106]: 0.7468529633086185
Loss at iteration [1107]: 0.7468407959667337
Loss at iteration [1108]: 0.7467926463134424
Loss at iteration [1109]: 0.7467195662458607
Loss at iteration [1110]: 0.7466793692471084
Loss at iteration [1111]: 0.7466659251095307
Loss at iteration [1112]: 0.7466533999994681
Loss at iteration [1113]: 0.7466194717772617
Loss at iteration [1114]: 0.7465628969397171
Loss at iteration [1115]: 0.7464949558828571
Loss at iteration [1116]: 0.7464431832320275
Loss at iteration [1117]: 0.7464207878499507
Loss at iteration [1118]: 0.7464207878499507
Loss at iteration [1119]: 0.7463995342405388
Loss at iteration [1120]: 0.7463912385660235
Loss at iteration [1121]: 0.7463845399049677
Loss at iteration [1122]: 0.746370307408177
Loss at iteration [1123]: 0.7463532640338711
Loss at iteration [1124]: 0.7463415222387434
Loss at iteration [1125]: 0.7463413200672806
Loss at iteration [1126]: 0.7463221762038692
Loss at iteration [1127]: 0.7462846475240033
Loss at iteration [1128]: 0.7462517199317997
Loss at iteration [1129]: 0.7462188862582226
Loss at iteration [1130]: 0.7461777274485926
Loss at iteration [1131]: 0.7461371847324939
Loss at iteration [1132]: 0.7461058144627413
Loss at iteration [1133]: 0.7460573801556348
Loss at iteration [1134]: 0.7460045754023124
Loss at iteration [1135]: 0.7459682509683065
Loss at iteration [1136]: 0.7459403949329055
Loss at iteration [1137]: 0.7459403949329055
Loss at iteration [1138]: 0.7459044141980355
Loss at iteration [1139]: 0.7458952072345988
Loss at iteration [1140]: 0.7458863262850184
Loss at iteration [1141]: 0.7458762984587478
Loss at iteration [1142]: 0.7458528744909383
Loss at iteration [1143]: 0.7458287829644005
Loss at iteration [1144]: 0.745798491525075
Loss at iteration [1145]: 0.7457693199342337
Loss at iteration [1146]: 0.7457181429365405
Loss at iteration [1147]: 0.745691223102197
Loss at iteration [1148]: 0.7456826435448961
Loss at iteration [1149]: 0.74563107150375
Loss at iteration [1150]: 0.7455697427957374
Loss at iteration [1151]: 0.7455505476750182
Loss at iteration [1152]: 0.7455446015232513
Loss at iteration [1153]: 0.7455240249859629
Loss at iteration [1154]: 0.7454938481289619
Loss at iteration [1155]: 0.7454700586655104
Loss at iteration [1156]: 0.7454490667211718
Loss at iteration [1157]: 0.7453989560509856
Loss at iteration [1158]: 0.7453989560509856
Loss at iteration [1159]: 0.7453929712782148
Loss at iteration [1160]: 0.7453823795305866
Loss at iteration [1161]: 0.745356013824571
Loss at iteration [1162]: 0.7453461878883555
Loss at iteration [1163]: 0.7453408091228485
Loss at iteration [1164]: 0.7453272018848693
Loss at iteration [1165]: 0.7452940620062738
Loss at iteration [1166]: 0.74525627782896
Loss at iteration [1167]: 0.7452273180180089
Loss at iteration [1168]: 0.7451929197807582
Loss at iteration [1169]: 0.7451497521982495
Loss at iteration [1170]: 0.7451039606236756
Loss at iteration [1171]: 0.7450689770668667
Loss at iteration [1172]: 0.7450540568128629
Loss at iteration [1173]: 0.7450076789300006
Loss at iteration [1174]: 0.7449498033708349
Loss at iteration [1175]: 0.7449198609274673
Loss at iteration [1176]: 0.7448996744389371
Loss at iteration [1177]: 0.7448587551751483
Loss at iteration [1178]: 0.7448138950326055
Loss at iteration [1179]: 0.7448138950326055
Loss at iteration [1180]: 0.7447867757262188
Loss at iteration [1181]: 0.7447783631796462
Loss at iteration [1182]: 0.7447633153413311
Loss at iteration [1183]: 0.7447501742082684
Loss at iteration [1184]: 0.744731726249767
Loss at iteration [1185]: 0.7447039808688216
Loss at iteration [1186]: 0.7446936608988054
Loss at iteration [1187]: 0.7446738480372496
Loss at iteration [1188]: 0.7446300590627793
Loss at iteration [1189]: 0.7445747519958638
Loss at iteration [1190]: 0.7445644245705396
Loss at iteration [1191]: 0.7445491700146559
Loss at iteration [1192]: 0.744498268023026
Loss at iteration [1193]: 0.7444413198926261
Loss at iteration [1194]: 0.7444104492380703
Loss at iteration [1195]: 0.7443827148670181
Loss at iteration [1196]: 0.7443514592996399
Loss at iteration [1197]: 0.7443173521381632
Loss at iteration [1198]: 0.7442827657745157
Loss at iteration [1199]: 0.7442624533606336
Loss at iteration [1200]: 0.7442624533606336
Loss at iteration [1201]: 0.7442296939724018
Loss at iteration [1202]: 0.744220426349454
Loss at iteration [1203]: 0.7442019205709672
Loss at iteration [1204]: 0.7441919830646484
Loss at iteration [1205]: 0.7441853804717368
Loss at iteration [1206]: 0.7441777110056923
Loss at iteration [1207]: 0.744165266258726
Loss at iteration [1208]: 0.744159285970767
Loss at iteration [1209]: 0.7441428355482576
Loss at iteration [1210]: 0.7440739869655751
Loss at iteration [1211]: 0.7440178844301294
Loss at iteration [1212]: 0.7439977195259224
Loss at iteration [1213]: 0.7439620712940689
Loss at iteration [1214]: 0.7439119806128417
Loss at iteration [1215]: 0.7438453959986969
Loss at iteration [1216]: 0.7438087194523879
Loss at iteration [1217]: 0.7437939170225217
Loss at iteration [1218]: 0.7437939170225217
Loss at iteration [1219]: 0.74375835221654
Loss at iteration [1220]: 0.7437519992749025
Loss at iteration [1221]: 0.7437368283433528
Loss at iteration [1222]: 0.7437189205185784
Loss at iteration [1223]: 0.7437099282274936
Loss at iteration [1224]: 0.743698629983979
Loss at iteration [1225]: 0.743683496585344
Loss at iteration [1226]: 0.743660274595348
Loss at iteration [1227]: 0.7436342234041979
Loss at iteration [1228]: 0.7435767207679391
Loss at iteration [1229]: 0.7435084199232601
Loss at iteration [1230]: 0.7434562951176509
Loss at iteration [1231]: 0.7434060155449946
Loss at iteration [1232]: 0.7433773436478749
Loss at iteration [1233]: 0.743361408323645
Loss at iteration [1234]: 0.7433101096279109
Loss at iteration [1235]: 0.743251777591783
Loss at iteration [1236]: 0.7432068135309208
Loss at iteration [1237]: 0.7431968599859413
Loss at iteration [1238]: 0.7431968599859413
Loss at iteration [1239]: 0.743137004741567
Loss at iteration [1240]: 0.7431170265273003
Loss at iteration [1241]: 0.7431097820526914
Loss at iteration [1242]: 0.7431004881770159
Loss at iteration [1243]: 0.7430898909230473
Loss at iteration [1244]: 0.7430786236041131
Loss at iteration [1245]: 0.74306326389874
Loss at iteration [1246]: 0.7430525646564752
Loss at iteration [1247]: 0.7430456784601067
Loss at iteration [1248]: 0.7430271928008263
Loss at iteration [1249]: 0.7429825088823705
Loss at iteration [1250]: 0.7429342978138741
Loss at iteration [1251]: 0.7429106176051202
Loss at iteration [1252]: 0.7428648362539935
Loss at iteration [1253]: 0.742824090899582
Loss at iteration [1254]: 0.7427763728521701
Loss at iteration [1255]: 0.742708663591484
Loss at iteration [1256]: 0.742708663591484
Loss at iteration [1257]: 0.7426820204761999
Loss at iteration [1258]: 0.7426637984463799
Loss at iteration [1259]: 0.7426486996244023
Loss at iteration [1260]: 0.7426354973246553
Loss at iteration [1261]: 0.7426250155756086
Loss at iteration [1262]: 0.7426149919186605
Loss at iteration [1263]: 0.7426085755272327
Loss at iteration [1264]: 0.7426077166569143
Loss at iteration [1265]: 0.7425938960421306
Loss at iteration [1266]: 0.7425556855500818
Loss at iteration [1267]: 0.7425167917772675
Loss at iteration [1268]: 0.7424875237162485
Loss at iteration [1269]: 0.7424637689711342
Loss at iteration [1270]: 0.742411608469339
Loss at iteration [1271]: 0.7423606814983125
Loss at iteration [1272]: 0.7423270291420381
Loss at iteration [1273]: 0.7423073883098942
Loss at iteration [1274]: 0.7423073883098942
Loss at iteration [1275]: 0.742248479239268
Loss at iteration [1276]: 0.7422262489600568
Loss at iteration [1277]: 0.7422159398554941
Loss at iteration [1278]: 0.7422038228890772
Loss at iteration [1279]: 0.7421915142230152
Loss at iteration [1280]: 0.7421800093620812
Loss at iteration [1281]: 0.7421676566983095
Loss at iteration [1282]: 0.7421575858948551
Loss at iteration [1283]: 0.7421521811712787
Loss at iteration [1284]: 0.7420980384538318
Loss at iteration [1285]: 0.7420609834957465
Loss at iteration [1286]: 0.7420198563210928
Loss at iteration [1287]: 0.7419795006809137
Loss at iteration [1288]: 0.741922442144707
Loss at iteration [1289]: 0.7418866620893608
Loss at iteration [1290]: 0.7418479996396045
Loss at iteration [1291]: 0.7417931997119693
Loss at iteration [1292]: 0.7417931997119693
Loss at iteration [1293]: 0.7417630680799979
Loss at iteration [1294]: 0.7417529158493615
Loss at iteration [1295]: 0.7417422772006421
Loss at iteration [1296]: 0.7417319870427268
Loss at iteration [1297]: 0.7416838276411574
Loss at iteration [1298]: 0.7416270761983919
Loss at iteration [1299]: 0.7416193088178851
Loss at iteration [1300]: 0.7415810266369587
Loss at iteration [1301]: 0.7415258232174888
Loss at iteration [1302]: 0.7415078155209904
Loss at iteration [1303]: 0.7414873081170414
Loss at iteration [1304]: 0.7414518088815563
Loss at iteration [1305]: 0.7413959193690911
Loss at iteration [1306]: 0.7413315644154262
Loss at iteration [1307]: 0.7412995921704548
Loss at iteration [1308]: 0.741273286586944
Loss at iteration [1309]: 0.7412177579260645
Loss at iteration [1310]: 0.7411946212774122
Loss at iteration [1311]: 0.7411809085281907
Loss at iteration [1312]: 0.741139833622983
Loss at iteration [1313]: 0.741139833622983
Loss at iteration [1314]: 0.7411096603140341
Loss at iteration [1315]: 0.7410998858257317
Loss at iteration [1316]: 0.7410750293178971
Loss at iteration [1317]: 0.7410688006059151
Loss at iteration [1318]: 0.7410623447411171
Loss at iteration [1319]: 0.7410535011201242
Loss at iteration [1320]: 0.7410369823089793
Loss at iteration [1321]: 0.7410237562727775
Loss at iteration [1322]: 0.7410094712011629
Loss at iteration [1323]: 0.741001808501431
Loss at iteration [1324]: 0.7409838282470205
Loss at iteration [1325]: 0.7409786539711222
Loss at iteration [1326]: 0.7409227598934237
Loss at iteration [1327]: 0.7408634617428745
Loss at iteration [1328]: 0.7408634617428745
Loss at iteration [1329]: 0.7408420522936114
Loss at iteration [1330]: 0.7408323722696688
Loss at iteration [1331]: 0.7408108761823974
Loss at iteration [1332]: 0.7407957909345715
Loss at iteration [1333]: 0.7407881102411523
Loss at iteration [1334]: 0.7407711314578789
Loss at iteration [1335]: 0.7407584421074953
Loss at iteration [1336]: 0.7407482651972132
Loss at iteration [1337]: 0.7407300583571836
Loss at iteration [1338]: 0.7407143736471952
Loss at iteration [1339]: 0.7406895556970803
Loss at iteration [1340]: 0.7406352862687061
Loss at iteration [1341]: 0.7405667336180417
Loss at iteration [1342]: 0.7405371199143257
Loss at iteration [1343]: 0.7405103753003737
Loss at iteration [1344]: 0.7404685217352075
Loss at iteration [1345]: 0.7404215397479823
Loss at iteration [1346]: 0.7404215397479823
Loss at iteration [1347]: 0.7403871860960715
Loss at iteration [1348]: 0.740373449257988
Loss at iteration [1349]: 0.7403519557901803
Loss at iteration [1350]: 0.7403430478784998
Loss at iteration [1351]: 0.7403373092887476
Loss at iteration [1352]: 0.7403249853719387
Loss at iteration [1353]: 0.7403207079328932
Loss at iteration [1354]: 0.7403056122327732
Loss at iteration [1355]: 0.7402609902009668
Loss at iteration [1356]: 0.740187508156152
Loss at iteration [1357]: 0.7401466952530543
Loss at iteration [1358]: 0.7401246995819535
Loss at iteration [1359]: 0.7400876537584794
Loss at iteration [1360]: 0.7400361458215386
Loss at iteration [1361]: 0.7399918296518551
Loss at iteration [1362]: 0.7399458507589481
Loss at iteration [1363]: 0.7399037287451141
Loss at iteration [1364]: 0.7398569588860376
Loss at iteration [1365]: 0.7398386836598242
Loss at iteration [1366]: 0.7398386836598242
Loss at iteration [1367]: 0.7397877565732323
Loss at iteration [1368]: 0.7397741032360454
Loss at iteration [1369]: 0.7397604699346032
Loss at iteration [1370]: 0.7397488668836225
Loss at iteration [1371]: 0.7397414892135867
Loss at iteration [1372]: 0.7397332195932791
Loss at iteration [1373]: 0.7397190230457619
Loss at iteration [1374]: 0.7397123216729875
Loss at iteration [1375]: 0.7396896459933449
Loss at iteration [1376]: 0.7396424858331861
Loss at iteration [1377]: 0.7395908828648515
Loss at iteration [1378]: 0.7395085160352868
Loss at iteration [1379]: 0.7394697518772396
Loss at iteration [1380]: 0.7394179859545318
Loss at iteration [1381]: 0.73935501880496
Loss at iteration [1382]: 0.7392884320069018
Loss at iteration [1383]: 0.73925391719653
Loss at iteration [1384]: 0.7392244159375203
Loss at iteration [1385]: 0.7392244159375203
Loss at iteration [1386]: 0.7391752250617609
Loss at iteration [1387]: 0.7391576731053785
Loss at iteration [1388]: 0.7391449564189727
Loss at iteration [1389]: 0.7391345867740913
Loss at iteration [1390]: 0.7391215114677941
Loss at iteration [1391]: 0.7390922414299317
Loss at iteration [1392]: 0.739040494070195
Loss at iteration [1393]: 0.7390135066485971
Loss at iteration [1394]: 0.7389860277082864
Loss at iteration [1395]: 0.7389367201931446
Loss at iteration [1396]: 0.7388990949701445
Loss at iteration [1397]: 0.7388663584795365
Loss at iteration [1398]: 0.7388330047194315
Loss at iteration [1399]: 0.7388015601194056
Loss at iteration [1400]: 0.7387634857933917
Loss at iteration [1401]: 0.7387048220015682
Loss at iteration [1402]: 0.7386604959948045
Loss at iteration [1403]: 0.7386133109447185
Loss at iteration [1404]: 0.7385682009502108
Loss at iteration [1405]: 0.7385425126870098
Loss at iteration [1406]: 0.7385425126870098
Loss at iteration [1407]: 0.7385154563537977
Loss at iteration [1408]: 0.7385107219088031
Loss at iteration [1409]: 0.7384896687117999
Loss at iteration [1410]: 0.7384786566171446
Loss at iteration [1411]: 0.7384666621516746
Loss at iteration [1412]: 0.7384379111392007
Loss at iteration [1413]: 0.7384117782322885
Loss at iteration [1414]: 0.7383917342619121
Loss at iteration [1415]: 0.7383432551906022
Loss at iteration [1416]: 0.7382867351573481
Loss at iteration [1417]: 0.738232534803152
Loss at iteration [1418]: 0.7381812260305073
Loss at iteration [1419]: 0.7381516048051923
Loss at iteration [1420]: 0.7381105661566405
Loss at iteration [1421]: 0.7380558807826295
Loss at iteration [1422]: 0.7380200982852785
Loss at iteration [1423]: 0.7379837565982929
Loss at iteration [1424]: 0.7379308249426909
Loss at iteration [1425]: 0.7378824348633032
Loss at iteration [1426]: 0.7378352025291024
Loss at iteration [1427]: 0.7378352025291024
Loss at iteration [1428]: 0.7378012912833147
Loss at iteration [1429]: 0.7377930105511866
Loss at iteration [1430]: 0.7377853747483619
Loss at iteration [1431]: 0.7377719381130513
Loss at iteration [1432]: 0.7377701051135994
Loss at iteration [1433]: 0.737752487606317
Loss at iteration [1434]: 0.7377131574014281
Loss at iteration [1435]: 0.7376647525887373
Loss at iteration [1436]: 0.7376425327208895
Loss at iteration [1437]: 0.7375914331237271
Loss at iteration [1438]: 0.7375597990900242
Loss at iteration [1439]: 0.7375370959776897
Loss at iteration [1440]: 0.7374876591801528
Loss at iteration [1441]: 0.737426542188752
Loss at iteration [1442]: 0.7374138691773408
Loss at iteration [1443]: 0.7373959549515159
Loss at iteration [1444]: 0.7373745706790158
Loss at iteration [1445]: 0.7372622491285497
Loss at iteration [1446]: 0.7370806439990532
Loss at iteration [1447]: 0.7370806439990532
Loss at iteration [1448]: 0.7370039289699956
Loss at iteration [1449]: 0.7369503889247114
Loss at iteration [1450]: 0.736946340368435
Loss at iteration [1451]: 0.7369287357324762
Loss at iteration [1452]: 0.7368967683679053
Loss at iteration [1453]: 0.7368418024104446
Loss at iteration [1454]: 0.7367963810793057
Loss at iteration [1455]: 0.7367639726659788
Loss at iteration [1456]: 0.7367150080745501
Loss at iteration [1457]: 0.7366897665218196
Loss at iteration [1458]: 0.7366629793645212
Loss at iteration [1459]: 0.7366201016153955
Loss at iteration [1460]: 0.7365640022684549
Loss at iteration [1461]: 0.7365136089563926
Loss at iteration [1462]: 0.7364538820412129
Loss at iteration [1463]: 0.7364017057698498
Loss at iteration [1464]: 0.7363676022964984
Loss at iteration [1465]: 0.7363474281083128
Loss at iteration [1466]: 0.7362938710655333
Loss at iteration [1467]: 0.7362219923463739
Loss at iteration [1468]: 0.7362219923463739
Loss at iteration [1469]: 0.7361990844477793
Loss at iteration [1470]: 0.7361812137581917
Loss at iteration [1471]: 0.7361627175236529
Loss at iteration [1472]: 0.736154925355203
Loss at iteration [1473]: 0.7361423186254364
Loss at iteration [1474]: 0.7361221432133781
Loss at iteration [1475]: 0.7361121463249107
Loss at iteration [1476]: 0.7361089972156182
Loss at iteration [1477]: 0.7360739923874622
Loss at iteration [1478]: 0.7360522254947756
Loss at iteration [1479]: 0.7360152320766764
Loss at iteration [1480]: 0.7359449479064192
Loss at iteration [1481]: 0.7358880375328514
Loss at iteration [1482]: 0.735863691804225
Loss at iteration [1483]: 0.7358212688992137
Loss at iteration [1484]: 0.7357692456632375
Loss at iteration [1485]: 0.7357083006340522
Loss at iteration [1486]: 0.7356494919505006
Loss at iteration [1487]: 0.7356494919505006
Loss at iteration [1488]: 0.7356184829087942
Loss at iteration [1489]: 0.7356118234905098
Loss at iteration [1490]: 0.7356044367844964
Loss at iteration [1491]: 0.7355958629035524
Loss at iteration [1492]: 0.7355859681352925
Loss at iteration [1493]: 0.7355754354819289
Loss at iteration [1494]: 0.7355668548700754
Loss at iteration [1495]: 0.7355413250923897
Loss at iteration [1496]: 0.735488634779581
Loss at iteration [1497]: 0.7354346863168897
Loss at iteration [1498]: 0.7353801781619617
Loss at iteration [1499]: 0.7353424402922989
Loss at iteration [1500]: 0.7353239115427228
Loss at iteration [1501]: 0.7352761875947862
Loss at iteration [1502]: 0.7352573334486572
Loss at iteration [1503]: 0.7351245782381123
Loss at iteration [1504]: 0.7351245782381123
Loss at iteration [1505]: 0.7349512968859122
Loss at iteration [1506]: 0.7348745266138674
Loss at iteration [1507]: 0.7347816853224457
Loss at iteration [1508]: 0.7347236929429167
Loss at iteration [1509]: 0.7346924458840058
Loss at iteration [1510]: 0.7346703337018041
Loss at iteration [1511]: 0.7346624013162573
Loss at iteration [1512]: 0.7346521997297497
Loss at iteration [1513]: 0.7346063269453456
Loss at iteration [1514]: 0.7345735202466552
Loss at iteration [1515]: 0.7345573399481619
Loss at iteration [1516]: 0.7345165662262931
Loss at iteration [1517]: 0.734461750852987
Loss at iteration [1518]: 0.7344288293638717
Loss at iteration [1519]: 0.7344080608944119
Loss at iteration [1520]: 0.7343699540034679
Loss at iteration [1521]: 0.7343242634644609
Loss at iteration [1522]: 0.7342888476342576
Loss at iteration [1523]: 0.7342338144875766
Loss at iteration [1524]: 0.7342157374180676
Loss at iteration [1525]: 0.7342157374180676
Loss at iteration [1526]: 0.7341750731712723
Loss at iteration [1527]: 0.7341603971555256
Loss at iteration [1528]: 0.7341538377468206
Loss at iteration [1529]: 0.7341427687478018
Loss at iteration [1530]: 0.7341298344242633
Loss at iteration [1531]: 0.7341167855080084
Loss at iteration [1532]: 0.7340964909941751
Loss at iteration [1533]: 0.7340854257448391
Loss at iteration [1534]: 0.734066422875795
Loss at iteration [1535]: 0.7340405207091711
Loss at iteration [1536]: 0.7339804023859978
Loss at iteration [1537]: 0.7339179916292645
Loss at iteration [1538]: 0.7338640237548681
Loss at iteration [1539]: 0.7337989417092141
Loss at iteration [1540]: 0.7337282840685041
Loss at iteration [1541]: 0.7336860507357843
Loss at iteration [1542]: 0.7336314450595507
Loss at iteration [1543]: 0.7336314450595507
Loss at iteration [1544]: 0.7335646039065746
Loss at iteration [1545]: 0.7335430329210351
Loss at iteration [1546]: 0.7335302037196924
Loss at iteration [1547]: 0.7335149222254366
Loss at iteration [1548]: 0.7335023063725001
Loss at iteration [1549]: 0.7334898545458937
Loss at iteration [1550]: 0.7334733786516602
Loss at iteration [1551]: 0.7334594372493312
Loss at iteration [1552]: 0.7334558948806064
Loss at iteration [1553]: 0.7334461526442758
Loss at iteration [1554]: 0.7333723540326281
Loss at iteration [1555]: 0.7332993034675701
Loss at iteration [1556]: 0.7332536850041335
Loss at iteration [1557]: 0.7332343237096783
Loss at iteration [1558]: 0.7332142951382662
Loss at iteration [1559]: 0.733166493413464
Loss at iteration [1560]: 0.7330925794658758
Loss at iteration [1561]: 0.7330925794658758
Loss at iteration [1562]: 0.7330777871750704
Loss at iteration [1563]: 0.7330698464467609
Loss at iteration [1564]: 0.7330402786985415
Loss at iteration [1565]: 0.7330246125439059
Loss at iteration [1566]: 0.7330064538643127
Loss at iteration [1567]: 0.7329627042359204
Loss at iteration [1568]: 0.7329217914412237
Loss at iteration [1569]: 0.732903852581302
Loss at iteration [1570]: 0.7328563417600512
Loss at iteration [1571]: 0.7328065843886152
Loss at iteration [1572]: 0.7327825553968016
Loss at iteration [1573]: 0.7327388711242954
Loss at iteration [1574]: 0.7326904843472839
Loss at iteration [1575]: 0.732655026172896
Loss at iteration [1576]: 0.732596965211361
Loss at iteration [1577]: 0.7325808232516293
Loss at iteration [1578]: 0.7325363976237851
Loss at iteration [1579]: 0.7324736829726911
Loss at iteration [1580]: 0.7324454357542233
Loss at iteration [1581]: 0.7324317716349925
Loss at iteration [1582]: 0.7324317716349925
Loss at iteration [1583]: 0.7323988403546808
Loss at iteration [1584]: 0.7323897331336867
Loss at iteration [1585]: 0.732374380644489
Loss at iteration [1586]: 0.7323627790890674
Loss at iteration [1587]: 0.7323521927715653
Loss at iteration [1588]: 0.7323391344880102
Loss at iteration [1589]: 0.7323062672551056
Loss at iteration [1590]: 0.7322511017495608
Loss at iteration [1591]: 0.7322125160494065
Loss at iteration [1592]: 0.7321696636489415
Loss at iteration [1593]: 0.732129736884982
Loss at iteration [1594]: 0.7320781280664024
Loss at iteration [1595]: 0.7320114485113913
Loss at iteration [1596]: 0.7319479841884434
Loss at iteration [1597]: 0.7319274181080089
Loss at iteration [1598]: 0.7319146730392367
Loss at iteration [1599]: 0.7318691288071361
Loss at iteration [1600]: 0.7317925776115215
Loss at iteration [1601]: 0.7317384693152292
Loss at iteration [1602]: 0.731727439148795
Loss at iteration [1603]: 0.731727439148795
Loss at iteration [1604]: 0.731678611089137
Loss at iteration [1605]: 0.7316665191509271
Loss at iteration [1606]: 0.7316569534224262
Loss at iteration [1607]: 0.7316407283600648
Loss at iteration [1608]: 0.7316353009544297
Loss at iteration [1609]: 0.7316260235456746
Loss at iteration [1610]: 0.7316129461550347
Loss at iteration [1611]: 0.7315943590247522
Loss at iteration [1612]: 0.7315320732588949
Loss at iteration [1613]: 0.7314741195868038
Loss at iteration [1614]: 0.7314215978967157
Loss at iteration [1615]: 0.7313600000771474
Loss at iteration [1616]: 0.7313040432970557
Loss at iteration [1617]: 0.7309255606763538
Loss at iteration [1618]: 0.7305043189882147
Loss at iteration [1619]: 0.7305043189882147
Loss at iteration [1620]: 0.7303670079069757
Loss at iteration [1621]: 0.7302413565879894
Loss at iteration [1622]: 0.730186806949592
Loss at iteration [1623]: 0.7301330409114992
Loss at iteration [1624]: 0.7300781433122723
Loss at iteration [1625]: 0.730036405166187
Loss at iteration [1626]: 0.7300119336412937
Loss at iteration [1627]: 0.7299588101370753
Loss at iteration [1628]: 0.7299007584840969
Loss at iteration [1629]: 0.7298705661353501
Loss at iteration [1630]: 0.7298310805426236
Loss at iteration [1631]: 0.7297737331705632
Loss at iteration [1632]: 0.7297206476514415
Loss at iteration [1633]: 0.7296787847349255
Loss at iteration [1634]: 0.7296400875375292
Loss at iteration [1635]: 0.7295898845908119
Loss at iteration [1636]: 0.7295292443824365
Loss at iteration [1637]: 0.7295068543884801
Loss at iteration [1638]: 0.7294798787467864
Loss at iteration [1639]: 0.729431576672094
Loss at iteration [1640]: 0.729431576672094
Loss at iteration [1641]: 0.7292727486662655
Loss at iteration [1642]: 0.7292049450797319
Loss at iteration [1643]: 0.7291429479271382
Loss at iteration [1644]: 0.7291322364556322
Loss at iteration [1645]: 0.7291082509483809
Loss at iteration [1646]: 0.7290877610449292
Loss at iteration [1647]: 0.729064092425666
Loss at iteration [1648]: 0.729017092088569
Loss at iteration [1649]: 0.7289763354962406
Loss at iteration [1650]: 0.7289459780269876
Loss at iteration [1651]: 0.728891387973475
Loss at iteration [1652]: 0.7288502245081887
Loss at iteration [1653]: 0.7288125384147628
Loss at iteration [1654]: 0.7287828163459936
Loss at iteration [1655]: 0.7287527576892197
Loss at iteration [1656]: 0.7286768272579877
Loss at iteration [1657]: 0.7286140149940519
Loss at iteration [1658]: 0.7285521364391453
Loss at iteration [1659]: 0.7285109699268135
Loss at iteration [1660]: 0.7284867622074732
Loss at iteration [1661]: 0.7284867622074732
Loss at iteration [1662]: 0.7284532672247539
Loss at iteration [1663]: 0.7284345057388482
Loss at iteration [1664]: 0.728416541775294
Loss at iteration [1665]: 0.7284112659456098
Loss at iteration [1666]: 0.7284027343308845
Loss at iteration [1667]: 0.7283987653228634
Loss at iteration [1668]: 0.728391751038904
Loss at iteration [1669]: 0.7283604708697645
Loss at iteration [1670]: 0.7283322481272324
Loss at iteration [1671]: 0.7282993909327911
Loss at iteration [1672]: 0.7282491684792777
Loss at iteration [1673]: 0.7282071927928858
Loss at iteration [1674]: 0.7281708877152523
Loss at iteration [1675]: 0.7280975941137435
Loss at iteration [1676]: 0.7280315452893091
Loss at iteration [1677]: 0.7279954303079104
Loss at iteration [1678]: 0.7279576219550564
Loss at iteration [1679]: 0.7279120008810089
Loss at iteration [1680]: 0.7278496129428992
Loss at iteration [1681]: 0.7278496129428992
Loss at iteration [1682]: 0.7278041654319493
Loss at iteration [1683]: 0.7277760011394575
Loss at iteration [1684]: 0.7277679746841678
Loss at iteration [1685]: 0.7277580869622527
Loss at iteration [1686]: 0.7277458147536611
Loss at iteration [1687]: 0.7277390686178274
Loss at iteration [1688]: 0.7277271212234038
Loss at iteration [1689]: 0.7277103045525377
Loss at iteration [1690]: 0.7276939372186401
Loss at iteration [1691]: 0.727659771513261
Loss at iteration [1692]: 0.727626771457749
Loss at iteration [1693]: 0.7275693710454417
Loss at iteration [1694]: 0.7275346682224118
Loss at iteration [1695]: 0.7274830636319239
Loss at iteration [1696]: 0.7274289075610458
Loss at iteration [1697]: 0.7273890553700096
Loss at iteration [1698]: 0.7273435529017879
Loss at iteration [1699]: 0.7273435529017879
Loss at iteration [1700]: 0.7273007166734562
Loss at iteration [1701]: 0.7272734979365624
Loss at iteration [1702]: 0.7272563081293376
Loss at iteration [1703]: 0.7272436370707109
Loss at iteration [1704]: 0.7272324838585319
Loss at iteration [1705]: 0.7272276878919908
Loss at iteration [1706]: 0.7272075821981725
Loss at iteration [1707]: 0.7272038615368889
Loss at iteration [1708]: 0.7271853242566767
Loss at iteration [1709]: 0.7271571447114185
Loss at iteration [1710]: 0.727094876788773
Loss at iteration [1711]: 0.7270399804320664
Loss at iteration [1712]: 0.7270072392129542
Loss at iteration [1713]: 0.7269930268819293
Loss at iteration [1714]: 0.7269647309093914
Loss at iteration [1715]: 0.7268947745508966
Loss at iteration [1716]: 0.7268469480581262
Loss at iteration [1717]: 0.72682263686733
Loss at iteration [1718]: 0.72682263686733
Loss at iteration [1719]: 0.7267813235010412
Loss at iteration [1720]: 0.7267658726107203
Loss at iteration [1721]: 0.7267533148679158
Loss at iteration [1722]: 0.7267314540117654
Loss at iteration [1723]: 0.7267249110454741
Loss at iteration [1724]: 0.726715850534453
Loss at iteration [1725]: 0.726696992762216
Loss at iteration [1726]: 0.7266914139881187
Loss at iteration [1727]: 0.7266804931986532
Loss at iteration [1728]: 0.7266646915662491
Loss at iteration [1729]: 0.7266524586120036
Loss at iteration [1730]: 0.7266488837063027
Loss at iteration [1731]: 0.7266035235133699
Loss at iteration [1732]: 0.7265478865840831
Loss at iteration [1733]: 0.7265478865840831
Loss at iteration [1734]: 0.726496100161891
Loss at iteration [1735]: 0.7264907036776206
Loss at iteration [1736]: 0.7264705736347096
Loss at iteration [1737]: 0.7264616560081818
Loss at iteration [1738]: 0.7264544847550192
Loss at iteration [1739]: 0.7264388007275492
Loss at iteration [1740]: 0.7264232448425836
Loss at iteration [1741]: 0.7264192404903155
Loss at iteration [1742]: 0.7264090210433825
Loss at iteration [1743]: 0.7263905383505318
Loss at iteration [1744]: 0.7263834879607095
Loss at iteration [1745]: 0.7263627351234069
Loss at iteration [1746]: 0.726333792826187
Loss at iteration [1747]: 0.7263107176729198
Loss at iteration [1748]: 0.7263107176729198
Loss at iteration [1749]: 0.7262482439315998
Loss at iteration [1750]: 0.7262306990917179
Loss at iteration [1751]: 0.7262161868562592
Loss at iteration [1752]: 0.726204940165961
Loss at iteration [1753]: 0.7261904036496397
Loss at iteration [1754]: 0.7261813330422785
Loss at iteration [1755]: 0.7261670370291802
Loss at iteration [1756]: 0.7261545242044659
Loss at iteration [1757]: 0.72614723457054
Loss at iteration [1758]: 0.7261378551979323
Loss at iteration [1759]: 0.7261177637155349
Loss at iteration [1760]: 0.7260753955965534
Loss at iteration [1761]: 0.7260228422788202
Loss at iteration [1762]: 0.7259715296700385
Loss at iteration [1763]: 0.7259372420923299
Loss at iteration [1764]: 0.7259372420923299
Loss at iteration [1765]: 0.7259150585509057
Loss at iteration [1766]: 0.7259046318582474
Loss at iteration [1767]: 0.7258733258793201
Loss at iteration [1768]: 0.7258612571559891
Loss at iteration [1769]: 0.7258462893623759
Loss at iteration [1770]: 0.7258024569713467
Loss at iteration [1771]: 0.7258010497121458
Loss at iteration [1772]: 0.7257524358343237
Loss at iteration [1773]: 0.7257153080919505
Loss at iteration [1774]: 0.725653684593132
Loss at iteration [1775]: 0.7256079362794764
Loss at iteration [1776]: 0.72559518954344
Loss at iteration [1777]: 0.7255555764303213
Loss at iteration [1778]: 0.7255113476835446
Loss at iteration [1779]: 0.7254784175828106
Loss at iteration [1780]: 0.7254447050431913
Loss at iteration [1781]: 0.7253640798205112
Loss at iteration [1782]: 0.7253037261724862
Loss at iteration [1783]: 0.7252991486359253
Loss at iteration [1784]: 0.7252556092273275
Loss at iteration [1785]: 0.7252556092273275
Loss at iteration [1786]: 0.7252181311370918
Loss at iteration [1787]: 0.7252027359851964
Loss at iteration [1788]: 0.7251755642207494
Loss at iteration [1789]: 0.7251616119397544
Loss at iteration [1790]: 0.7251479763098141
Loss at iteration [1791]: 0.725132403831635
Loss at iteration [1792]: 0.7251157693444868
Loss at iteration [1793]: 0.7251044572252713
Loss at iteration [1794]: 0.7250856129074494
Loss at iteration [1795]: 0.7250830013739749
Loss at iteration [1796]: 0.7250711612472094
Loss at iteration [1797]: 0.7250330382890208
Loss at iteration [1798]: 0.7250110019531151
Loss at iteration [1799]: 0.7249935570648706
Loss at iteration [1800]: 0.7249508730158739
Loss at iteration [1801]: 0.7248898190672279
Loss at iteration [1802]: 0.7248898190672279
Loss at iteration [1803]: 0.7248488703578322
Loss at iteration [1804]: 0.7248433159568924
Loss at iteration [1805]: 0.7248276088665631
Loss at iteration [1806]: 0.724798896128073
Loss at iteration [1807]: 0.724781987540252
Loss at iteration [1808]: 0.7247624497949605
Loss at iteration [1809]: 0.7247510536511934
Loss at iteration [1810]: 0.7247283017954262
Loss at iteration [1811]: 0.7247065413431633
Loss at iteration [1812]: 0.7246558894185234
Loss at iteration [1813]: 0.7245881895751525
Loss at iteration [1814]: 0.724553418603401
Loss at iteration [1815]: 0.724531722543561
Loss at iteration [1816]: 0.724468081711807
Loss at iteration [1817]: 0.7239410353912009
Loss at iteration [1818]: 0.7233725092385103
Loss at iteration [1819]: 0.7233725092385103
Loss at iteration [1820]: 0.7230966526745061
Loss at iteration [1821]: 0.7227474567519696
Loss at iteration [1822]: 0.722561675504107
Loss at iteration [1823]: 0.7224481561175039
Loss at iteration [1824]: 0.7223928405098397
Loss at iteration [1825]: 0.7223138859816082
Loss at iteration [1826]: 0.7222407323143912
Loss at iteration [1827]: 0.7221977796351774
Loss at iteration [1828]: 0.7221618954163933
Loss at iteration [1829]: 0.7221215970149629
Loss at iteration [1830]: 0.7220388702262399
Loss at iteration [1831]: 0.721971210625379
Loss at iteration [1832]: 0.7219376012078332
Loss at iteration [1833]: 0.7219216824628035
Loss at iteration [1834]: 0.7218695314037757
Loss at iteration [1835]: 0.7218130532358346
Loss at iteration [1836]: 0.7217844721021724
Loss at iteration [1837]: 0.7217537825894111
Loss at iteration [1838]: 0.7217100901890872
Loss at iteration [1839]: 0.7216602621289484
Loss at iteration [1840]: 0.7216602621289484
Loss at iteration [1841]: 0.721602373364963
Loss at iteration [1842]: 0.7215901586947954
Loss at iteration [1843]: 0.7215829939562338
Loss at iteration [1844]: 0.7215764931866399
Loss at iteration [1845]: 0.7215442017029886
Loss at iteration [1846]: 0.7215126466563209
Loss at iteration [1847]: 0.7214712397288477
Loss at iteration [1848]: 0.7214218009921876
Loss at iteration [1849]: 0.7213846164290489
Loss at iteration [1850]: 0.7213187032019892
Loss at iteration [1851]: 0.7212562678288059
Loss at iteration [1852]: 0.7212324840502847
Loss at iteration [1853]: 0.721182694051913
Loss at iteration [1854]: 0.7211257535121868
Loss at iteration [1855]: 0.7210756315825422
Loss at iteration [1856]: 0.7210622515225711
Loss at iteration [1857]: 0.7210105942477532
Loss at iteration [1858]: 0.7209324924663878
Loss at iteration [1859]: 0.7208744425548709
Loss at iteration [1860]: 0.7208466760306499
Loss at iteration [1861]: 0.7208466760306499
Loss at iteration [1862]: 0.720802252407503
Loss at iteration [1863]: 0.7207879514727855
Loss at iteration [1864]: 0.7207741062025188
Loss at iteration [1865]: 0.7207622996550048
Loss at iteration [1866]: 0.7207450844964421
Loss at iteration [1867]: 0.7207346926830166
Loss at iteration [1868]: 0.7207324206725421
Loss at iteration [1869]: 0.7206786729496929
Loss at iteration [1870]: 0.7206386493175337
Loss at iteration [1871]: 0.720622736102121
Loss at iteration [1872]: 0.7206003328891675
Loss at iteration [1873]: 0.7205854865524615
Loss at iteration [1874]: 0.7205644425571001
Loss at iteration [1875]: 0.7205388206281228
Loss at iteration [1876]: 0.720517062110661
Loss at iteration [1877]: 0.7204419103247787
Loss at iteration [1878]: 0.7204174602950293
Loss at iteration [1879]: 0.7203868079533536
Loss at iteration [1880]: 0.7203284868737329
Loss at iteration [1881]: 0.7203284868737329
Loss at iteration [1882]: 0.7202937355151197
Loss at iteration [1883]: 0.7202793753974898
Loss at iteration [1884]: 0.7202625690476206
Loss at iteration [1885]: 0.7202488127396294
Loss at iteration [1886]: 0.7202311185043232
Loss at iteration [1887]: 0.720222168487364
Loss at iteration [1888]: 0.7202088570347087
Loss at iteration [1889]: 0.7202044745100225
Loss at iteration [1890]: 0.7201953665645279
Loss at iteration [1891]: 0.7201858685389542
Loss at iteration [1892]: 0.720181697240901
Loss at iteration [1893]: 0.7201582640932822
Loss at iteration [1894]: 0.7200985029825344
Loss at iteration [1895]: 0.720020251190369
Loss at iteration [1896]: 0.7199931881198701
Loss at iteration [1897]: 0.7199931881198701
Loss at iteration [1898]: 0.7199578267146921
Loss at iteration [1899]: 0.7199425189187456
Loss at iteration [1900]: 0.7199170459500922
Loss at iteration [1901]: 0.7199121931248426
Loss at iteration [1902]: 0.7199072137694692
Loss at iteration [1903]: 0.7198919918306463
Loss at iteration [1904]: 0.7198796347820529
Loss at iteration [1905]: 0.719867929215377
Loss at iteration [1906]: 0.7198564481449528
Loss at iteration [1907]: 0.7198461779036311
Loss at iteration [1908]: 0.7198364047269374
Loss at iteration [1909]: 0.7198243906673488
Loss at iteration [1910]: 0.7198119350352533
Loss at iteration [1911]: 0.7198119350352533
Loss at iteration [1912]: 0.7197961828388997
Loss at iteration [1913]: 0.7197953990360154
Loss at iteration [1914]: 0.7197904906710807
Loss at iteration [1915]: 0.7197886102093699
Loss at iteration [1916]: 0.7197737497782626
Loss at iteration [1917]: 0.7197646882947625
Loss at iteration [1918]: 0.7197544091527586
Loss at iteration [1919]: 0.7197442143898839
Loss at iteration [1920]: 0.7197302746525658
Loss at iteration [1921]: 0.7196804803503815
Loss at iteration [1922]: 0.719604977302967
Loss at iteration [1923]: 0.7195759427595168
Loss at iteration [1924]: 0.7195648448195143
Loss at iteration [1925]: 0.7194993469143586
Loss at iteration [1926]: 0.7194367143776071
Loss at iteration [1927]: 0.7194089798896631
Loss at iteration [1928]: 0.7193605853083336
Loss at iteration [1929]: 0.7193605853083336
Loss at iteration [1930]: 0.7193257824395733
Loss at iteration [1931]: 0.7192973264902708
Loss at iteration [1932]: 0.7192740138938618
Loss at iteration [1933]: 0.7192685142090852
Loss at iteration [1934]: 0.7192551378325535
Loss at iteration [1935]: 0.7192335068319907
Loss at iteration [1936]: 0.7192189771733495
Loss at iteration [1937]: 0.7192143953980895
Loss at iteration [1938]: 0.7191839404402443
Loss at iteration [1939]: 0.7191273655140529
Loss at iteration [1940]: 0.7190686255303063
Loss at iteration [1941]: 0.7190406425872449
Loss at iteration [1942]: 0.7190024035949406
Loss at iteration [1943]: 0.7189522656227072
Loss at iteration [1944]: 0.7188921312921573
Loss at iteration [1945]: 0.71885697459286
Loss at iteration [1946]: 0.7188066371209064
Loss at iteration [1947]: 0.7187488322159037
Loss at iteration [1948]: 0.718704281870003
Loss at iteration [1949]: 0.718704281870003
Loss at iteration [1950]: 0.7186762934935556
Loss at iteration [1951]: 0.7186650040402933
Loss at iteration [1952]: 0.7186479169267701
Loss at iteration [1953]: 0.7186428838637247
Loss at iteration [1954]: 0.718618183762016
Loss at iteration [1955]: 0.7185809808573665
Loss at iteration [1956]: 0.7185187405776643
Loss at iteration [1957]: 0.7185100880535875
Loss at iteration [1958]: 0.7184890715004237
Loss at iteration [1959]: 0.7184476285745539
Loss at iteration [1960]: 0.7183947100535566
Loss at iteration [1961]: 0.7183567978597484
Loss at iteration [1962]: 0.7183380056899563
Loss at iteration [1963]: 0.7183111284803385
Loss at iteration [1964]: 0.7182400227794267
Loss at iteration [1965]: 0.7181945583237189
Loss at iteration [1966]: 0.718154009477735
Loss at iteration [1967]: 0.71809405012091
Loss at iteration [1968]: 0.7180683982248126
Loss at iteration [1969]: 0.718055670978452
Loss at iteration [1970]: 0.718055670978452
Loss at iteration [1971]: 0.7179904615644819
Loss at iteration [1972]: 0.7179689634251637
Loss at iteration [1973]: 0.7179547609142027
Loss at iteration [1974]: 0.7179443047666195
Loss at iteration [1975]: 0.7179359623291296
Loss at iteration [1976]: 0.7179232120886739
Loss at iteration [1977]: 0.7179114339960543
Loss at iteration [1978]: 0.7179043051814388
Loss at iteration [1979]: 0.7179025705359514
Loss at iteration [1980]: 0.7178739270334226
Loss at iteration [1981]: 0.7178363334596346
Loss at iteration [1982]: 0.717790438927943
Loss at iteration [1983]: 0.7177275922069795
Loss at iteration [1984]: 0.7176896771666365
Loss at iteration [1985]: 0.7176537359742623
Loss at iteration [1986]: 0.7175903597219842
Loss at iteration [1987]: 0.7174996095258256
Loss at iteration [1988]: 0.7174996095258256
Loss at iteration [1989]: 0.7174729639783423
Loss at iteration [1990]: 0.7174572448992199
Loss at iteration [1991]: 0.7174340588707878
Loss at iteration [1992]: 0.7174268641672769
Loss at iteration [1993]: 0.7174193014585439
Loss at iteration [1994]: 0.7174043191564523
Loss at iteration [1995]: 0.7173887329597105
Loss at iteration [1996]: 0.717370187566826
Loss at iteration [1997]: 0.7173508409997472
Loss at iteration [1998]: 0.7173383375825758
Loss at iteration [1999]: 0.7173197976797131
Loss at iteration [2000]: 0.7173056868934513
Loss at iteration [2001]: 0.717293960265383
Loss at iteration [2002]: 0.717293960265383
Loss at iteration [2003]: 0.7172749604886381
Loss at iteration [2004]: 0.7172683955282748
Loss at iteration [2005]: 0.7172671803897449
Loss at iteration [2006]: 0.7172629785266376
Loss at iteration [2007]: 0.7172607429875354
Loss at iteration [2008]: 0.7172552147038219
Loss at iteration [2009]: 0.7172481892010981
Loss at iteration [2010]: 0.7172474883018725
Loss at iteration [2011]: 0.7172088230493038
Loss at iteration [2012]: 0.7171438367800974
Loss at iteration [2013]: 0.7171110092828087
Loss at iteration [2014]: 0.7170411710077678
Loss at iteration [2015]: 0.716972494900774
Loss at iteration [2016]: 0.7169108522164991
Loss at iteration [2017]: 0.7169108522164991
Loss at iteration [2018]: 0.7168828762214181
Loss at iteration [2019]: 0.7168705043646598
Loss at iteration [2020]: 0.7168520771129248
Loss at iteration [2021]: 0.7168307476319583
Loss at iteration [2022]: 0.7168238849233873
Loss at iteration [2023]: 0.7167979105743888
Loss at iteration [2024]: 0.7167734688406542
Loss at iteration [2025]: 0.716753445088902
Loss at iteration [2026]: 0.7167268955968601
Loss at iteration [2027]: 0.7166812568126876
Loss at iteration [2028]: 0.7166218987668255
Loss at iteration [2029]: 0.7165792552167415
Loss at iteration [2030]: 0.7165650444082514
Loss at iteration [2031]: 0.7165263583931978
Loss at iteration [2032]: 0.7164600334713769
Loss at iteration [2033]: 0.7163937945366355
Loss at iteration [2034]: 0.7163385437289115
Loss at iteration [2035]: 0.7162853877924957
Loss at iteration [2036]: 0.7162615139613591
Loss at iteration [2037]: 0.7161817814521162
