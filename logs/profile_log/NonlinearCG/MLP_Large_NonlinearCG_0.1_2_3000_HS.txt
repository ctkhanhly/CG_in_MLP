Model name                            : MLP_Large
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : NonlinearCG
Learning rate                         : 0.1
Beta type                             :HS
Total number of function evaluations  : 3050
Total number of iterations            : 1752
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 46.293368339538574
Total number of parameters            : 402001
Percentage of parameters < 1e-9       : 49.89689080375422%
Percentage of parameters < 1e-7       : 49.89713955935433%
Percentage of parameters < 1e-6       : 49.89763707055455%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.0027210562738144246
Loss at iteration [2]: 0.002710431742794753
Loss at iteration [3]: 0.0026940794472557266
Loss at iteration [4]: 0.002626386410977649
Loss at iteration [5]: 0.0026128038582073744
Loss at iteration [6]: 0.0026016518452272918
Loss at iteration [7]: 0.0025933598582111423
Loss at iteration [8]: 0.0025913839824497982
Loss at iteration [9]: 0.0025876977646582403
Loss at iteration [10]: 0.0025859235094277937
Loss at iteration [11]: 0.002583448693238507
Loss at iteration [12]: 0.002578201895469802
Loss at iteration [13]: 0.002575344016946302
Loss at iteration [14]: 0.0025670793857818066
Loss at iteration [15]: 0.0025424075095194427
Loss at iteration [16]: 0.002538135379680442
Loss at iteration [17]: 0.002538135379680442
Loss at iteration [18]: 0.002536528221309828
Loss at iteration [19]: 0.0025338974001278165
Loss at iteration [20]: 0.002526038470539903
Loss at iteration [21]: 0.0025254725766843435
Loss at iteration [22]: 0.002524328442927137
Loss at iteration [23]: 0.0025230396494536566
Loss at iteration [24]: 0.0025213320720406025
Loss at iteration [25]: 0.002520304044187044
Loss at iteration [26]: 0.0025197060753757773
Loss at iteration [27]: 0.0025189586049286206
Loss at iteration [28]: 0.002517538387132277
Loss at iteration [29]: 0.002517332677494993
Loss at iteration [30]: 0.002516932206264981
Loss at iteration [31]: 0.0025128025868388355
Loss at iteration [32]: 0.0025118083298339474
Loss at iteration [33]: 0.0025113298455750675
Loss at iteration [34]: 0.0025059663754428262
Loss at iteration [35]: 0.0025059663754428262
Loss at iteration [36]: 0.0025054490409952106
Loss at iteration [37]: 0.0025047084319216595
Loss at iteration [38]: 0.0025034652898591053
Loss at iteration [39]: 0.0025029384937954816
Loss at iteration [40]: 0.0025025685334321593
Loss at iteration [41]: 0.0025023708548727462
Loss at iteration [42]: 0.0025002747644893436
Loss at iteration [43]: 0.002499053127080599
Loss at iteration [44]: 0.002498803841485826
Loss at iteration [45]: 0.0024957156778696466
Loss at iteration [46]: 0.002491088303790387
Loss at iteration [47]: 0.0024896570196672584
Loss at iteration [48]: 0.0024887194079761836
Loss at iteration [49]: 0.002482578305814241
Loss at iteration [50]: 0.002482578305814241
Loss at iteration [51]: 0.0024812587781913157
Loss at iteration [52]: 0.002480921701937644
Loss at iteration [53]: 0.0024790061961996973
Loss at iteration [54]: 0.00247831181184952
Loss at iteration [55]: 0.002476331963263523
Loss at iteration [56]: 0.002474917437102371
Loss at iteration [57]: 0.0024748397436534673
Loss at iteration [58]: 0.0024742062663738345
Loss at iteration [59]: 0.0024738105608757624
Loss at iteration [60]: 0.002473688763110033
Loss at iteration [61]: 0.0024719228576906708
Loss at iteration [62]: 0.0024713670146271046
Loss at iteration [63]: 0.002471219194384879
Loss at iteration [64]: 0.0024706397282895356
Loss at iteration [65]: 0.0024706397282895356
Loss at iteration [66]: 0.002470257697091544
Loss at iteration [67]: 0.002470109525559095
Loss at iteration [68]: 0.0024695333722275954
Loss at iteration [69]: 0.0024693245960480605
Loss at iteration [70]: 0.002467792944707558
Loss at iteration [71]: 0.0024672891660332107
Loss at iteration [72]: 0.002466946568838073
Loss at iteration [73]: 0.002464862756664608
Loss at iteration [74]: 0.0024642135279293806
Loss at iteration [75]: 0.002463670615344922
Loss at iteration [76]: 0.002461118711151339
Loss at iteration [77]: 0.0024607091949754587
Loss at iteration [78]: 0.0024603272631463368
Loss at iteration [79]: 0.0024603272631463368
Loss at iteration [80]: 0.0024601221296076553
Loss at iteration [81]: 0.002459522708217222
Loss at iteration [82]: 0.002458551424748975
Loss at iteration [83]: 0.0024581311642648093
Loss at iteration [84]: 0.002455987013031396
Loss at iteration [85]: 0.002455249039448354
Loss at iteration [86]: 0.00245475466236595
Loss at iteration [87]: 0.0024539589117974834
Loss at iteration [88]: 0.0024533868569201317
Loss at iteration [89]: 0.0024531746938668587
Loss at iteration [90]: 0.0024526945701240604
Loss at iteration [91]: 0.002452470006026655
Loss at iteration [92]: 0.0024521301755843737
Loss at iteration [93]: 0.0024512788722877337
Loss at iteration [94]: 0.0024506126154494705
Loss at iteration [95]: 0.0024494485798395534
Loss at iteration [96]: 0.002449369902002564
Loss at iteration [97]: 0.002449369902002564
Loss at iteration [98]: 0.0024493338241799115
Loss at iteration [99]: 0.002448809324615172
Loss at iteration [100]: 0.002448648460733608
Loss at iteration [101]: 0.00244784388913057
Loss at iteration [102]: 0.0024475957014451987
Loss at iteration [103]: 0.002447449535551247
Loss at iteration [104]: 0.0024471838115543458
Loss at iteration [105]: 0.0024462858142546185
Loss at iteration [106]: 0.0024450049099603273
Loss at iteration [107]: 0.0024449040412594307
Loss at iteration [108]: 0.0024445087321850294
Loss at iteration [109]: 0.002444203618102796
Loss at iteration [110]: 0.0024441248925671766
Loss at iteration [111]: 0.002444032290898096
Loss at iteration [112]: 0.002444032290898096
Loss at iteration [113]: 0.002443967768686741
Loss at iteration [114]: 0.002443915118308552
Loss at iteration [115]: 0.002443585301802047
Loss at iteration [116]: 0.002443475320433494
Loss at iteration [117]: 0.0024429060268961605
Loss at iteration [118]: 0.0024425805303413374
Loss at iteration [119]: 0.002442428902448933
Loss at iteration [120]: 0.0024415128315033213
Loss at iteration [121]: 0.002441465525203181
Loss at iteration [122]: 0.002440472590953403
Loss at iteration [123]: 0.00244041290423967
Loss at iteration [124]: 0.0024401012792720253
Loss at iteration [125]: 0.0024396861618886222
Loss at iteration [126]: 0.0024396451297735108
Loss at iteration [127]: 0.0024396451297735108
Loss at iteration [128]: 0.0024396136140114964
Loss at iteration [129]: 0.002439446882961906
Loss at iteration [130]: 0.002439263698572704
Loss at iteration [131]: 0.0024392230112677956
Loss at iteration [132]: 0.00243909770061835
Loss at iteration [133]: 0.0024390211167357196
Loss at iteration [134]: 0.002438920493973927
Loss at iteration [135]: 0.0024386209539020904
Loss at iteration [136]: 0.002437838069409766
Loss at iteration [137]: 0.0024369697121407823
Loss at iteration [138]: 0.002436242447811483
Loss at iteration [139]: 0.002435932082459426
Loss at iteration [140]: 0.002434881378142674
Loss at iteration [141]: 0.002434698187531295
Loss at iteration [142]: 0.002434698187531295
Loss at iteration [143]: 0.0024345034653994965
Loss at iteration [144]: 0.002433957155110233
Loss at iteration [145]: 0.002433782525419419
Loss at iteration [146]: 0.0024329931895205642
Loss at iteration [147]: 0.00243290692293515
Loss at iteration [148]: 0.0024316295570243067
Loss at iteration [149]: 0.002431479927592013
Loss at iteration [150]: 0.002431336579138988
Loss at iteration [151]: 0.0024302637249966987
Loss at iteration [152]: 0.002430208188784708
Loss at iteration [153]: 0.002430064598241291
Loss at iteration [154]: 0.002429542947062289
Loss at iteration [155]: 0.002429542947062289
Loss at iteration [156]: 0.002429409170747603
Loss at iteration [157]: 0.0024291945369091265
Loss at iteration [158]: 0.0024290876739919746
Loss at iteration [159]: 0.0024290233496613647
Loss at iteration [160]: 0.0024289912719056253
Loss at iteration [161]: 0.0024289613567589994
Loss at iteration [162]: 0.0024289407731979216
Loss at iteration [163]: 0.002428875478211631
Loss at iteration [164]: 0.002428804603854552
Loss at iteration [165]: 0.0024287251442623777
Loss at iteration [166]: 0.0024285283370117997
Loss at iteration [167]: 0.0024281358731789104
Loss at iteration [168]: 0.002427780514086735
Loss at iteration [169]: 0.002427780514086735
Loss at iteration [170]: 0.002427690527681731
Loss at iteration [171]: 0.0024275885166197926
Loss at iteration [172]: 0.0024271509663997297
Loss at iteration [173]: 0.0024271179562559042
Loss at iteration [174]: 0.0024270297619363237
Loss at iteration [175]: 0.002426994503537419
Loss at iteration [176]: 0.0024268707849144982
Loss at iteration [177]: 0.0024268233027071305
Loss at iteration [178]: 0.00242642285612574
Loss at iteration [179]: 0.0024259136250020584
Loss at iteration [180]: 0.0024256420828338648
Loss at iteration [181]: 0.0024254038850861264
Loss at iteration [182]: 0.0024247460966176923
Loss at iteration [183]: 0.0024246134497222763
Loss at iteration [184]: 0.0024246134497222763
Loss at iteration [185]: 0.002424516981899797
Loss at iteration [186]: 0.0024241234849857857
Loss at iteration [187]: 0.0024238678469608605
Loss at iteration [188]: 0.00242373368297789
Loss at iteration [189]: 0.002422829194934568
Loss at iteration [190]: 0.0024224291378424595
Loss at iteration [191]: 0.002422183148751706
Loss at iteration [192]: 0.0024220256692514385
Loss at iteration [193]: 0.0024215480387600693
Loss at iteration [194]: 0.0024214647081344377
Loss at iteration [195]: 0.002421348598997342
Loss at iteration [196]: 0.0024212163029323406
Loss at iteration [197]: 0.002420984631786787
Loss at iteration [198]: 0.0024208604598371045
Loss at iteration [199]: 0.0024208604598371045
Loss at iteration [200]: 0.0024207357322885634
Loss at iteration [201]: 0.0024207081949285526
Loss at iteration [202]: 0.0024205939867348
Loss at iteration [203]: 0.002420542776982793
Loss at iteration [204]: 0.002420395363521587
Loss at iteration [205]: 0.002420126162697636
Loss at iteration [206]: 0.002420014336937242
Loss at iteration [207]: 0.0024194790928808905
Loss at iteration [208]: 0.002419279314569494
Loss at iteration [209]: 0.002418871988186864
Loss at iteration [210]: 0.0024187386144377005
Loss at iteration [211]: 0.002418403838505123
Loss at iteration [212]: 0.002418261457840646
Loss at iteration [213]: 0.002418261457840646
Loss at iteration [214]: 0.0024181926925184814
Loss at iteration [215]: 0.0024181442996279666
Loss at iteration [216]: 0.0024178855432610727
Loss at iteration [217]: 0.0024176956858030806
Loss at iteration [218]: 0.0024176138980951897
Loss at iteration [219]: 0.0024175318401128227
Loss at iteration [220]: 0.00241741223578403
Loss at iteration [221]: 0.002417184719978629
Loss at iteration [222]: 0.002417057039166547
Loss at iteration [223]: 0.002416918696532177
Loss at iteration [224]: 0.002416378793590442
Loss at iteration [225]: 0.0024158416474716286
Loss at iteration [226]: 0.0024156760089899232
Loss at iteration [227]: 0.0024154807194092637
Loss at iteration [228]: 0.0024153047101906594
Loss at iteration [229]: 0.0024153047101906594
Loss at iteration [230]: 0.0024152663642173673
Loss at iteration [231]: 0.0024149725306808474
Loss at iteration [232]: 0.002414689504800152
Loss at iteration [233]: 0.0024145683770506925
Loss at iteration [234]: 0.002414175058406688
Loss at iteration [235]: 0.002413954639458623
Loss at iteration [236]: 0.00241385435658827
Loss at iteration [237]: 0.0024135873760228795
Loss at iteration [238]: 0.0024135512531016927
Loss at iteration [239]: 0.002413420347788529
Loss at iteration [240]: 0.0024131624844517304
Loss at iteration [241]: 0.0024124854424826063
Loss at iteration [242]: 0.002412281500550364
Loss at iteration [243]: 0.002412190207365503
Loss at iteration [244]: 0.002411660842186429
Loss at iteration [245]: 0.002411660842186429
Loss at iteration [246]: 0.0024116388807824385
Loss at iteration [247]: 0.0024114988301555612
Loss at iteration [248]: 0.0024113790477635006
Loss at iteration [249]: 0.0024113251082655647
Loss at iteration [250]: 0.0024111844480343195
Loss at iteration [251]: 0.0024109752260214274
Loss at iteration [252]: 0.0024109141923925707
Loss at iteration [253]: 0.0024106020976323236
Loss at iteration [254]: 0.002410520344334177
Loss at iteration [255]: 0.0024104433618016463
Loss at iteration [256]: 0.0024103452989763367
Loss at iteration [257]: 0.0024096591083557282
Loss at iteration [258]: 0.0024094282606731913
Loss at iteration [259]: 0.0024093427572560353
Loss at iteration [260]: 0.0024080420990729152
Loss at iteration [261]: 0.0024080420990729152
Loss at iteration [262]: 0.0024075719828752884
Loss at iteration [263]: 0.002407433124623532
Loss at iteration [264]: 0.00240654077882954
Loss at iteration [265]: 0.002406434846904139
Loss at iteration [266]: 0.0024062322803088424
Loss at iteration [267]: 0.002406096729196347
Loss at iteration [268]: 0.0024060503473855234
Loss at iteration [269]: 0.002405737554150081
Loss at iteration [270]: 0.002405479097058786
Loss at iteration [271]: 0.0024052779599029266
Loss at iteration [272]: 0.002405147270019404
Loss at iteration [273]: 0.0024050746705557083
Loss at iteration [274]: 0.0024047602766836046
Loss at iteration [275]: 0.0024046226083848507
Loss at iteration [276]: 0.0024046226083848507
Loss at iteration [277]: 0.002404242925502366
Loss at iteration [278]: 0.0024039391867026866
Loss at iteration [279]: 0.002403711408732423
Loss at iteration [280]: 0.0024036709524830027
Loss at iteration [281]: 0.0024035211685350237
Loss at iteration [282]: 0.0024032634431448113
Loss at iteration [283]: 0.002402310777385217
Loss at iteration [284]: 0.0024020134973870865
Loss at iteration [285]: 0.0024019310372043867
Loss at iteration [286]: 0.0024016344329393954
Loss at iteration [287]: 0.002401599362973557
Loss at iteration [288]: 0.0024013260402594985
Loss at iteration [289]: 0.0024011185816508137
Loss at iteration [290]: 0.0024010043816090876
Loss at iteration [291]: 0.002400934371906298
Loss at iteration [292]: 0.002400864657085076
Loss at iteration [293]: 0.002400864657085076
Loss at iteration [294]: 0.0024008386502122896
Loss at iteration [295]: 0.0024007919677689394
Loss at iteration [296]: 0.0024006267041129046
Loss at iteration [297]: 0.0024005764022904806
Loss at iteration [298]: 0.002400444472237239
Loss at iteration [299]: 0.0024001083061774113
Loss at iteration [300]: 0.002399882317974078
Loss at iteration [301]: 0.0023996313390748747
Loss at iteration [302]: 0.0023994014876784356
Loss at iteration [303]: 0.0023991060722167294
Loss at iteration [304]: 0.0023989637096538843
Loss at iteration [305]: 0.0023987726060921027
Loss at iteration [306]: 0.002398523556410347
Loss at iteration [307]: 0.0023983684895351664
Loss at iteration [308]: 0.002398225532987968
Loss at iteration [309]: 0.0023974899621614794
Loss at iteration [310]: 0.0023974899621614794
Loss at iteration [311]: 0.0023969154552970894
Loss at iteration [312]: 0.0023966997871866266
Loss at iteration [313]: 0.0023965822814863715
Loss at iteration [314]: 0.002396264977058194
Loss at iteration [315]: 0.002396189220952865
Loss at iteration [316]: 0.002395213127250287
Loss at iteration [317]: 0.0023950535037830433
Loss at iteration [318]: 0.0023948086791637973
Loss at iteration [319]: 0.002394727974220758
Loss at iteration [320]: 0.002394664731859785
Loss at iteration [321]: 0.002394400565523898
Loss at iteration [322]: 0.002394247989948148
Loss at iteration [323]: 0.0023939696231704715
Loss at iteration [324]: 0.002393779503320436
Loss at iteration [325]: 0.002393704892717029
Loss at iteration [326]: 0.002393704892717029
Loss at iteration [327]: 0.0023936604248865167
Loss at iteration [328]: 0.0023935244402689634
Loss at iteration [329]: 0.0023933491430298353
Loss at iteration [330]: 0.0023933224048296137
Loss at iteration [331]: 0.002393284883186226
Loss at iteration [332]: 0.0023931884632354167
Loss at iteration [333]: 0.0023930991353888647
Loss at iteration [334]: 0.0023929828068852727
Loss at iteration [335]: 0.002392908016499955
Loss at iteration [336]: 0.002392634016917698
Loss at iteration [337]: 0.002392578590781996
Loss at iteration [338]: 0.0023924596518613405
Loss at iteration [339]: 0.002392345054936217
Loss at iteration [340]: 0.0023921339979509145
Loss at iteration [341]: 0.002391954111024904
Loss at iteration [342]: 0.002391917799200376
Loss at iteration [343]: 0.002391917799200376
Loss at iteration [344]: 0.0023918940599360504
Loss at iteration [345]: 0.002391748770672792
Loss at iteration [346]: 0.002391710819550349
Loss at iteration [347]: 0.0023916265405627304
Loss at iteration [348]: 0.002391518683084556
Loss at iteration [349]: 0.002391427681764707
Loss at iteration [350]: 0.002391207505946246
Loss at iteration [351]: 0.002391146020738909
Loss at iteration [352]: 0.0023910589497302915
Loss at iteration [353]: 0.0023908662824342107
Loss at iteration [354]: 0.0023908141078362666
Loss at iteration [355]: 0.002390646592338343
Loss at iteration [356]: 0.002390615747662569
Loss at iteration [357]: 0.0023903792778890314
Loss at iteration [358]: 0.002390299339030627
Loss at iteration [359]: 0.002390299339030627
Loss at iteration [360]: 0.0023902673261634267
Loss at iteration [361]: 0.002390201400472369
Loss at iteration [362]: 0.00239016668384585
Loss at iteration [363]: 0.00239011620140169
Loss at iteration [364]: 0.0023900462143466666
Loss at iteration [365]: 0.0023900203823542
Loss at iteration [366]: 0.002389956508076239
Loss at iteration [367]: 0.0023899197620135776
Loss at iteration [368]: 0.0023898960137830804
Loss at iteration [369]: 0.0023898517238395197
Loss at iteration [370]: 0.0023898214769555925
Loss at iteration [371]: 0.0023887885570151542
Loss at iteration [372]: 0.0023886512821280374
Loss at iteration [373]: 0.0023875700205475883
Loss at iteration [374]: 0.0023838914211693728
Loss at iteration [375]: 0.0023838914211693728
Loss at iteration [376]: 0.0023825341751060047
Loss at iteration [377]: 0.002381359906568648
Loss at iteration [378]: 0.0023791141762103257
Loss at iteration [379]: 0.002378654074406334
Loss at iteration [380]: 0.0023783115831780446
Loss at iteration [381]: 0.0023778249408419267
Loss at iteration [382]: 0.002377594278956784
Loss at iteration [383]: 0.002376881452891083
Loss at iteration [384]: 0.002375341475589285
Loss at iteration [385]: 0.0023752382896726123
Loss at iteration [386]: 0.002375115301996246
Loss at iteration [387]: 0.0023749337611798887
Loss at iteration [388]: 0.0023749337611798887
Loss at iteration [389]: 0.002374858893185568
Loss at iteration [390]: 0.002374390245957529
Loss at iteration [391]: 0.0023738943216037624
Loss at iteration [392]: 0.0023738517031628137
Loss at iteration [393]: 0.0023738016467365073
Loss at iteration [394]: 0.0023737443911836906
Loss at iteration [395]: 0.002373230277044031
Loss at iteration [396]: 0.0023730871346847077
Loss at iteration [397]: 0.0023727485916512597
Loss at iteration [398]: 0.002372506767861095
Loss at iteration [399]: 0.0023722876654321042
Loss at iteration [400]: 0.0023721525222617666
Loss at iteration [401]: 0.002371880942651889
Loss at iteration [402]: 0.0023717785095912105
Loss at iteration [403]: 0.0023717785095912105
Loss at iteration [404]: 0.0023716878780589757
Loss at iteration [405]: 0.002371592541089793
Loss at iteration [406]: 0.0023715566009009804
Loss at iteration [407]: 0.0023714619580079135
Loss at iteration [408]: 0.002371278508514096
Loss at iteration [409]: 0.002371163793142128
Loss at iteration [410]: 0.0023711031327393666
Loss at iteration [411]: 0.0023709753456137737
Loss at iteration [412]: 0.0023706609131476943
Loss at iteration [413]: 0.002370517762668805
Loss at iteration [414]: 0.002370342256031231
Loss at iteration [415]: 0.00237019824835571
Loss at iteration [416]: 0.002370015244538132
Loss at iteration [417]: 0.0023694506901934735
Loss at iteration [418]: 0.0023694093365230024
Loss at iteration [419]: 0.0023694093365230024
Loss at iteration [420]: 0.0023693683233998496
Loss at iteration [421]: 0.0023692510965759124
Loss at iteration [422]: 0.002369150069439412
Loss at iteration [423]: 0.002369093799912468
Loss at iteration [424]: 0.0023688935360121417
Loss at iteration [425]: 0.0023685939287642183
Loss at iteration [426]: 0.002368548216470597
Loss at iteration [427]: 0.002368348520669764
Loss at iteration [428]: 0.0023682417049161663
Loss at iteration [429]: 0.002368099202745259
Loss at iteration [430]: 0.00236779300822672
Loss at iteration [431]: 0.002367612110525458
Loss at iteration [432]: 0.002367612110525458
Loss at iteration [433]: 0.0023675588272103797
Loss at iteration [434]: 0.0023675210601357705
Loss at iteration [435]: 0.0023672113662103977
Loss at iteration [436]: 0.0023671841005519943
Loss at iteration [437]: 0.0023670542884547453
Loss at iteration [438]: 0.002366975427377239
Loss at iteration [439]: 0.0023669396721860718
Loss at iteration [440]: 0.002366865255936185
Loss at iteration [441]: 0.002366801534132029
Loss at iteration [442]: 0.0023666678375774144
Loss at iteration [443]: 0.0023666060626612107
Loss at iteration [444]: 0.0023664026819850002
Loss at iteration [445]: 0.002366314329602208
Loss at iteration [446]: 0.0023661006588570786
Loss at iteration [447]: 0.00236599128840453
Loss at iteration [448]: 0.00236599128840453
Loss at iteration [449]: 0.0023659508104474534
Loss at iteration [450]: 0.002365857103686016
Loss at iteration [451]: 0.002365784848943189
Loss at iteration [452]: 0.0023657238752762015
Loss at iteration [453]: 0.002365637906796983
Loss at iteration [454]: 0.002365552632609859
Loss at iteration [455]: 0.0023655274637112453
Loss at iteration [456]: 0.0023654169274277903
Loss at iteration [457]: 0.0023653498496565527
Loss at iteration [458]: 0.0023652216329390087
Loss at iteration [459]: 0.0023651949809503363
Loss at iteration [460]: 0.002365075928092572
Loss at iteration [461]: 0.0023649457696876424
Loss at iteration [462]: 0.002364466159484699
Loss at iteration [463]: 0.002364041644773773
Loss at iteration [464]: 0.002364041644773773
Loss at iteration [465]: 0.0023636472234325853
Loss at iteration [466]: 0.0023633204723959296
Loss at iteration [467]: 0.0023630460287691894
Loss at iteration [468]: 0.0023630144038683945
Loss at iteration [469]: 0.0023628521497107364
Loss at iteration [470]: 0.002362634502151778
Loss at iteration [471]: 0.002362477466584805
Loss at iteration [472]: 0.002362418518892671
Loss at iteration [473]: 0.002362358214934236
Loss at iteration [474]: 0.002362278354153975
Loss at iteration [475]: 0.002362117286999867
Loss at iteration [476]: 0.00236204264783006
Loss at iteration [477]: 0.002361974212311153
Loss at iteration [478]: 0.002361832683978628
Loss at iteration [479]: 0.0023617433957934153
Loss at iteration [480]: 0.0023616702923702285
Loss at iteration [481]: 0.0023616702923702285
Loss at iteration [482]: 0.002361633267487904
Loss at iteration [483]: 0.002361578325472996
Loss at iteration [484]: 0.002361499747986011
Loss at iteration [485]: 0.0023614611851761227
Loss at iteration [486]: 0.0023614235432381403
Loss at iteration [487]: 0.00236139020898585
Loss at iteration [488]: 0.0023611898859240837
Loss at iteration [489]: 0.0023611170135279733
Loss at iteration [490]: 0.0023610346255742262
Loss at iteration [491]: 0.00236038053696722
Loss at iteration [492]: 0.0023599530829188243
Loss at iteration [493]: 0.0023597257183879837
Loss at iteration [494]: 0.0023590049194337622
Loss at iteration [495]: 0.0023581626246312127
Loss at iteration [496]: 0.0023578393667969414
Loss at iteration [497]: 0.0023578393667969414
Loss at iteration [498]: 0.0023575806639139383
Loss at iteration [499]: 0.0023573838209162046
Loss at iteration [500]: 0.002356636391546248
Loss at iteration [501]: 0.0023563974136167143
Loss at iteration [502]: 0.002356175931362276
Loss at iteration [503]: 0.002355497532235106
Loss at iteration [504]: 0.0023551077433216785
Loss at iteration [505]: 0.0023548217880043558
Loss at iteration [506]: 0.0023546291896547455
Loss at iteration [507]: 0.0023545111345637903
Loss at iteration [508]: 0.0023544016757582388
Loss at iteration [509]: 0.002354311925927787
Loss at iteration [510]: 0.002354311925927787
Loss at iteration [511]: 0.0023542655292791577
Loss at iteration [512]: 0.0023542315204722066
Loss at iteration [513]: 0.0023538247880749395
Loss at iteration [514]: 0.00235376653199815
Loss at iteration [515]: 0.0023533571308406442
Loss at iteration [516]: 0.0023532505204276995
Loss at iteration [517]: 0.0023531433971063307
Loss at iteration [518]: 0.0023526952794363128
Loss at iteration [519]: 0.002352530297929469
Loss at iteration [520]: 0.0023522586242394135
Loss at iteration [521]: 0.002352154708038522
Loss at iteration [522]: 0.0023520158878745233
Loss at iteration [523]: 0.0023519201597255552
Loss at iteration [524]: 0.0023517718249163352
Loss at iteration [525]: 0.0023514847253404488
Loss at iteration [526]: 0.002350580270189216
Loss at iteration [527]: 0.002349951684615855
Loss at iteration [528]: 0.002349951684615855
Loss at iteration [529]: 0.0023497152797731773
Loss at iteration [530]: 0.002349566472728412
Loss at iteration [531]: 0.0023488422676533937
Loss at iteration [532]: 0.0023487672475127064
Loss at iteration [533]: 0.002347588759214893
Loss at iteration [534]: 0.002347409016795828
Loss at iteration [535]: 0.0023473504437665957
Loss at iteration [536]: 0.002347153524793686
Loss at iteration [537]: 0.0023467157786265158
Loss at iteration [538]: 0.0023465629267022826
Loss at iteration [539]: 0.0023464651106703447
Loss at iteration [540]: 0.0023462404596389205
Loss at iteration [541]: 0.002345722003109274
Loss at iteration [542]: 0.002345722003109274
Loss at iteration [543]: 0.002345674204858016
Loss at iteration [544]: 0.0023452328396966846
Loss at iteration [545]: 0.0023451919734676684
Loss at iteration [546]: 0.0023450503652142672
Loss at iteration [547]: 0.002344998084448049
Loss at iteration [548]: 0.0023449570784262086
Loss at iteration [549]: 0.002344881419497724
Loss at iteration [550]: 0.0023448436310176375
Loss at iteration [551]: 0.0023446040071378664
Loss at iteration [552]: 0.0023445109593265446
Loss at iteration [553]: 0.0023444114622367166
Loss at iteration [554]: 0.0023439146519435316
Loss at iteration [555]: 0.002343700909350966
Loss at iteration [556]: 0.0023435873022340844
Loss at iteration [557]: 0.0023435873022340844
Loss at iteration [558]: 0.002343502079358076
Loss at iteration [559]: 0.0023433373358689833
Loss at iteration [560]: 0.0023431314720282273
Loss at iteration [561]: 0.0023430845146866866
Loss at iteration [562]: 0.002343005611322478
Loss at iteration [563]: 0.002342974831295073
Loss at iteration [564]: 0.0023427311051758886
Loss at iteration [565]: 0.0023426639140708993
Loss at iteration [566]: 0.0023426003326412347
Loss at iteration [567]: 0.002342392066313185
Loss at iteration [568]: 0.002342195623798947
Loss at iteration [569]: 0.0023420266421718453
Loss at iteration [570]: 0.002341984808629371
Loss at iteration [571]: 0.002341984808629371
Loss at iteration [572]: 0.0023419546097057484
Loss at iteration [573]: 0.002341887867358441
Loss at iteration [574]: 0.002341759992512038
Loss at iteration [575]: 0.002341689176945829
Loss at iteration [576]: 0.002341603454464428
Loss at iteration [577]: 0.0023415481213730576
Loss at iteration [578]: 0.0023414596597066462
Loss at iteration [579]: 0.0023413628871547516
Loss at iteration [580]: 0.0023412740050723175
Loss at iteration [581]: 0.0023410707326634033
Loss at iteration [582]: 0.0023406029098151783
Loss at iteration [583]: 0.002340456859297792
Loss at iteration [584]: 0.0023401173433791906
Loss at iteration [585]: 0.002339578474840345
Loss at iteration [586]: 0.0023393383103248633
Loss at iteration [587]: 0.0023381976535417036
Loss at iteration [588]: 0.0023381976535417036
Loss at iteration [589]: 0.0023378136417418005
Loss at iteration [590]: 0.002337056205850574
Loss at iteration [591]: 0.002335800377686876
Loss at iteration [592]: 0.00233574944321211
Loss at iteration [593]: 0.002335269015603094
Loss at iteration [594]: 0.0023350798425945396
Loss at iteration [595]: 0.0023350034218840667
Loss at iteration [596]: 0.002334535456649503
Loss at iteration [597]: 0.0023344449008452597
Loss at iteration [598]: 0.0023340698185021205
Loss at iteration [599]: 0.002333800264216885
Loss at iteration [600]: 0.0023336607306599136
Loss at iteration [601]: 0.0023336607306599136
Loss at iteration [602]: 0.0023335548939929594
Loss at iteration [603]: 0.002333467144454181
Loss at iteration [604]: 0.002333280235272402
Loss at iteration [605]: 0.0023331978761007544
Loss at iteration [606]: 0.002333101313139237
Loss at iteration [607]: 0.0023329950460836725
Loss at iteration [608]: 0.002332970063554357
Loss at iteration [609]: 0.002332356430891159
Loss at iteration [610]: 0.002332002645506086
Loss at iteration [611]: 0.0023318008087218566
Loss at iteration [612]: 0.0023315670303841324
Loss at iteration [613]: 0.0023314306160669607
Loss at iteration [614]: 0.002331041545802817
Loss at iteration [615]: 0.0023307809455901433
Loss at iteration [616]: 0.0023307809455901433
Loss at iteration [617]: 0.0023306758867042104
Loss at iteration [618]: 0.0023303907738278337
Loss at iteration [619]: 0.0023303435226647924
Loss at iteration [620]: 0.0023301804632345404
Loss at iteration [621]: 0.002330035840100607
Loss at iteration [622]: 0.0023299673788034943
Loss at iteration [623]: 0.002329444936058655
Loss at iteration [624]: 0.0023292971152759703
Loss at iteration [625]: 0.002329069366469427
Loss at iteration [626]: 0.002328872520274095
Loss at iteration [627]: 0.002328736583181169
Loss at iteration [628]: 0.0023286496775261193
Loss at iteration [629]: 0.002328537909434877
Loss at iteration [630]: 0.0023285189709506297
Loss at iteration [631]: 0.0023284476073425833
Loss at iteration [632]: 0.0023284476073425833
Loss at iteration [633]: 0.002328412645780887
Loss at iteration [634]: 0.002328333756935339
Loss at iteration [635]: 0.002328174710246712
Loss at iteration [636]: 0.002328119849933143
Loss at iteration [637]: 0.00232804177902744
Loss at iteration [638]: 0.0023277421194184272
Loss at iteration [639]: 0.0023275792845745507
Loss at iteration [640]: 0.0023275086580531092
Loss at iteration [641]: 0.0023272789008785357
Loss at iteration [642]: 0.002327236516382939
Loss at iteration [643]: 0.002327064541365316
Loss at iteration [644]: 0.002326843759285531
Loss at iteration [645]: 0.0023268028042327553
Loss at iteration [646]: 0.002326715871984828
Loss at iteration [647]: 0.002326642974653906
Loss at iteration [648]: 0.0023265847687530673
Loss at iteration [649]: 0.0023265847687530673
Loss at iteration [650]: 0.0023265611291374395
Loss at iteration [651]: 0.0023265452904554064
Loss at iteration [652]: 0.002326407738935754
Loss at iteration [653]: 0.0023263586694478437
Loss at iteration [654]: 0.0023261654649113306
Loss at iteration [655]: 0.0023260818492451462
Loss at iteration [656]: 0.0023258683488768498
Loss at iteration [657]: 0.002325372625394231
Loss at iteration [658]: 0.0023250629396457585
Loss at iteration [659]: 0.0023247381843109296
Loss at iteration [660]: 0.0023243958804619247
Loss at iteration [661]: 0.0023243958804619247
Loss at iteration [662]: 0.0023238783522385427
Loss at iteration [663]: 0.0023236677212191835
Loss at iteration [664]: 0.0023223128059070585
Loss at iteration [665]: 0.0023214642080530124
Loss at iteration [666]: 0.0023213345779004918
Loss at iteration [667]: 0.0023211683798515068
Loss at iteration [668]: 0.002320828795640699
Loss at iteration [669]: 0.00232069900375413
Loss at iteration [670]: 0.002320508773701812
Loss at iteration [671]: 0.0023199445803986653
Loss at iteration [672]: 0.0023198597022343463
Loss at iteration [673]: 0.0023196404217605527
Loss at iteration [674]: 0.002319600207711339
Loss at iteration [675]: 0.0023195527175016682
Loss at iteration [676]: 0.0023195026481695954
Loss at iteration [677]: 0.0023195026481695954
Loss at iteration [678]: 0.0023194760709733865
Loss at iteration [679]: 0.002319388166236086
Loss at iteration [680]: 0.002319349534201558
Loss at iteration [681]: 0.0023191000890472294
Loss at iteration [682]: 0.0023186478166234738
Loss at iteration [683]: 0.002318448948153134
Loss at iteration [684]: 0.0023179416550921455
Loss at iteration [685]: 0.002317894196383742
Loss at iteration [686]: 0.0023177083549078487
Loss at iteration [687]: 0.0023175556951899466
Loss at iteration [688]: 0.0023174877896973206
Loss at iteration [689]: 0.0023174877896973206
Loss at iteration [690]: 0.002317434624450912
Loss at iteration [691]: 0.002317335779320474
Loss at iteration [692]: 0.0023172884696183323
Loss at iteration [693]: 0.002317193638559621
Loss at iteration [694]: 0.002317157377577509
Loss at iteration [695]: 0.002317082821162854
Loss at iteration [696]: 0.002316884535422276
Loss at iteration [697]: 0.0023167104775915783
Loss at iteration [698]: 0.002316486014146975
Loss at iteration [699]: 0.002316255056780027
Loss at iteration [700]: 0.0023161124238815748
Loss at iteration [701]: 0.00231580811336345
Loss at iteration [702]: 0.0023157362819414776
Loss at iteration [703]: 0.0023156809127222707
Loss at iteration [704]: 0.0023156809127222707
Loss at iteration [705]: 0.002315627616487914
Loss at iteration [706]: 0.002315571588703604
Loss at iteration [707]: 0.002315483001125819
Loss at iteration [708]: 0.0023154538186203988
Loss at iteration [709]: 0.0023153150513845642
Loss at iteration [710]: 0.00231528413728439
Loss at iteration [711]: 0.002315232615242172
Loss at iteration [712]: 0.0023151643299449257
Loss at iteration [713]: 0.0023151244854379503
Loss at iteration [714]: 0.002314989546727943
Loss at iteration [715]: 0.002314854025450659
Loss at iteration [716]: 0.0023147852667128464
Loss at iteration [717]: 0.0023143799154220746
Loss at iteration [718]: 0.002314329117376536
Loss at iteration [719]: 0.002314329117376536
Loss at iteration [720]: 0.0023142927802912274
Loss at iteration [721]: 0.0023140933179383
Loss at iteration [722]: 0.0023139889947550642
Loss at iteration [723]: 0.0023139300169373847
Loss at iteration [724]: 0.0023136890133000046
Loss at iteration [725]: 0.0023136295373107274
Loss at iteration [726]: 0.002313555647239009
Loss at iteration [727]: 0.0023133852380032667
Loss at iteration [728]: 0.0023133434730062234
Loss at iteration [729]: 0.002313106376294169
Loss at iteration [730]: 0.002313057579567313
Loss at iteration [731]: 0.002312954461715191
Loss at iteration [732]: 0.002312341984039855
Loss at iteration [733]: 0.002312341984039855
Loss at iteration [734]: 0.0023122182228466483
Loss at iteration [735]: 0.002312153210408075
Loss at iteration [736]: 0.002311952600134692
Loss at iteration [737]: 0.0023118777148769683
Loss at iteration [738]: 0.002311786544510937
Loss at iteration [739]: 0.0023115969523884463
Loss at iteration [740]: 0.002311533360401059
Loss at iteration [741]: 0.002311295101952938
Loss at iteration [742]: 0.0023110477169330074
Loss at iteration [743]: 0.002311011925459724
Loss at iteration [744]: 0.0023107956762546114
Loss at iteration [745]: 0.00231068194760056
Loss at iteration [746]: 0.002310221071745627
Loss at iteration [747]: 0.002310159609096846
Loss at iteration [748]: 0.002310159609096846
Loss at iteration [749]: 0.002309988188853673
Loss at iteration [750]: 0.002309723969493466
Loss at iteration [751]: 0.002309637383340415
Loss at iteration [752]: 0.0023095722909448595
Loss at iteration [753]: 0.002309363452981324
Loss at iteration [754]: 0.0023090738318389393
Loss at iteration [755]: 0.0023089328300105174
Loss at iteration [756]: 0.002308827597642577
Loss at iteration [757]: 0.002308757155071041
Loss at iteration [758]: 0.0023085191617132424
Loss at iteration [759]: 0.002308274195156444
Loss at iteration [760]: 0.0023081834582188514
Loss at iteration [761]: 0.0023080875542258925
Loss at iteration [762]: 0.002307954321762837
Loss at iteration [763]: 0.0023078948578438966
Loss at iteration [764]: 0.0023078224041168213
Loss at iteration [765]: 0.0023078029211927894
Loss at iteration [766]: 0.0023078029211927894
Loss at iteration [767]: 0.002307742500087608
Loss at iteration [768]: 0.0023076611828455546
Loss at iteration [769]: 0.0023076066830794674
Loss at iteration [770]: 0.0023075705323339136
Loss at iteration [771]: 0.002307552908349627
Loss at iteration [772]: 0.0023075185103044733
Loss at iteration [773]: 0.0023074104236406874
Loss at iteration [774]: 0.0023073578226857835
Loss at iteration [775]: 0.0023071994929578102
Loss at iteration [776]: 0.002307112817016413
Loss at iteration [777]: 0.002306986041363392
Loss at iteration [778]: 0.0023064795739801735
Loss at iteration [779]: 0.0023061932467981247
Loss at iteration [780]: 0.0023061932467981247
Loss at iteration [781]: 0.002306067112084064
Loss at iteration [782]: 0.002305851178424492
Loss at iteration [783]: 0.00230532967834263
Loss at iteration [784]: 0.002305258725177476
Loss at iteration [785]: 0.0023049966848560973
Loss at iteration [786]: 0.0023049199463781476
Loss at iteration [787]: 0.0023048318785012776
Loss at iteration [788]: 0.002304535078589342
Loss at iteration [789]: 0.002304428402050494
Loss at iteration [790]: 0.002304155611145147
Loss at iteration [791]: 0.002303798146664811
Loss at iteration [792]: 0.0023036953388704162
Loss at iteration [793]: 0.002303315165419176
Loss at iteration [794]: 0.0023031973553547546
Loss at iteration [795]: 0.0023031973553547546
Loss at iteration [796]: 0.0023031483378302877
Loss at iteration [797]: 0.0023029920412007965
Loss at iteration [798]: 0.0023028045545170103
Loss at iteration [799]: 0.002302745910274709
Loss at iteration [800]: 0.0023027227815079028
Loss at iteration [801]: 0.002302659307779901
Loss at iteration [802]: 0.0023025515139512005
Loss at iteration [803]: 0.00230237354391888
Loss at iteration [804]: 0.002302212405338579
Loss at iteration [805]: 0.002302043978627082
Loss at iteration [806]: 0.002301799539072625
Loss at iteration [807]: 0.002301668113566452
Loss at iteration [808]: 0.002301463787071826
Loss at iteration [809]: 0.0023011106679095036
Loss at iteration [810]: 0.0023011106679095036
Loss at iteration [811]: 0.002301080646142659
Loss at iteration [812]: 0.002300958063583255
Loss at iteration [813]: 0.002300908776674094
Loss at iteration [814]: 0.002300761830432961
Loss at iteration [815]: 0.002300626151580367
Loss at iteration [816]: 0.0023005250700801286
Loss at iteration [817]: 0.0023003508025458254
Loss at iteration [818]: 0.002300273955712378
Loss at iteration [819]: 0.0023001021739370068
Loss at iteration [820]: 0.0023000008552583754
Loss at iteration [821]: 0.0022999317086096873
Loss at iteration [822]: 0.002299829357600767
Loss at iteration [823]: 0.002299750398112587
Loss at iteration [824]: 0.0022996331932578565
Loss at iteration [825]: 0.0022994977174640723
Loss at iteration [826]: 0.0022993622660692054
Loss at iteration [827]: 0.002299286509758062
Loss at iteration [828]: 0.002299286509758062
Loss at iteration [829]: 0.002299213295805008
Loss at iteration [830]: 0.0022991234985527196
Loss at iteration [831]: 0.002299043459727722
Loss at iteration [832]: 0.0022990217198304848
Loss at iteration [833]: 0.0022989005110449425
Loss at iteration [834]: 0.0022988591695594085
Loss at iteration [835]: 0.0022987272705330456
Loss at iteration [836]: 0.0022986795186387397
Loss at iteration [837]: 0.0022986125529835754
Loss at iteration [838]: 0.0022984891640609175
Loss at iteration [839]: 0.0022984353479358617
Loss at iteration [840]: 0.0022983511342172676
Loss at iteration [841]: 0.0022980707151595272
Loss at iteration [842]: 0.0022980252939093504
Loss at iteration [843]: 0.0022979661860993185
Loss at iteration [844]: 0.0022979311522704628
Loss at iteration [845]: 0.002297898200116495
Loss at iteration [846]: 0.002297898200116495
Loss at iteration [847]: 0.0022978667391067775
Loss at iteration [848]: 0.0022978405221158234
Loss at iteration [849]: 0.0022977928646351884
Loss at iteration [850]: 0.0022977398162924278
Loss at iteration [851]: 0.0022976815680934475
Loss at iteration [852]: 0.0022976516589748026
Loss at iteration [853]: 0.002297512515418384
Loss at iteration [854]: 0.002297471915710599
Loss at iteration [855]: 0.002297409509530601
Loss at iteration [856]: 0.0022972023348975103
Loss at iteration [857]: 0.0022971358622403387
Loss at iteration [858]: 0.0022970594168408446
Loss at iteration [859]: 0.002296991487479625
Loss at iteration [860]: 0.002296909706708835
Loss at iteration [861]: 0.0022966871414396624
Loss at iteration [862]: 0.0022964706191848368
Loss at iteration [863]: 0.0022964706191848368
Loss at iteration [864]: 0.002296302962831581
Loss at iteration [865]: 0.0022962172821289007
Loss at iteration [866]: 0.002295779069206558
Loss at iteration [867]: 0.0022957084364134414
Loss at iteration [868]: 0.0022956475060988213
Loss at iteration [869]: 0.0022955385157076035
Loss at iteration [870]: 0.002295463731978184
Loss at iteration [871]: 0.0022954154733205905
Loss at iteration [872]: 0.002295360211123619
Loss at iteration [873]: 0.0022951824235564605
Loss at iteration [874]: 0.0022949027775661353
Loss at iteration [875]: 0.002294809852710878
Loss at iteration [876]: 0.0022946985437309842
Loss at iteration [877]: 0.002294388245052696
Loss at iteration [878]: 0.002294388245052696
Loss at iteration [879]: 0.002294301237956325
Loss at iteration [880]: 0.0022942270159393226
Loss at iteration [881]: 0.0022941351334182197
Loss at iteration [882]: 0.002294078987591434
Loss at iteration [883]: 0.0022940317352889363
Loss at iteration [884]: 0.002293912220056713
Loss at iteration [885]: 0.0022938809431375423
Loss at iteration [886]: 0.0022937568516441273
Loss at iteration [887]: 0.002293691467914991
Loss at iteration [888]: 0.002293634573096231
Loss at iteration [889]: 0.0022933725932117927
Loss at iteration [890]: 0.0022933190044278047
Loss at iteration [891]: 0.002293273255864155
Loss at iteration [892]: 0.002293238976656186
Loss at iteration [893]: 0.002293238976656186
Loss at iteration [894]: 0.0022932140856340337
Loss at iteration [895]: 0.002293194714631615
Loss at iteration [896]: 0.0022931697471954464
Loss at iteration [897]: 0.002293095502694016
Loss at iteration [898]: 0.002293073365856668
Loss at iteration [899]: 0.002293035895643397
Loss at iteration [900]: 0.0022929056548254656
Loss at iteration [901]: 0.002292710450535878
Loss at iteration [902]: 0.0022925612021978026
Loss at iteration [903]: 0.0022923625079388408
Loss at iteration [904]: 0.0022918896013786943
Loss at iteration [905]: 0.0022908138603031252
Loss at iteration [906]: 0.0022900951328013743
Loss at iteration [907]: 0.0022894011268770244
Loss at iteration [908]: 0.0022894011268770244
Loss at iteration [909]: 0.0022891129452459595
Loss at iteration [910]: 0.0022885807454386723
Loss at iteration [911]: 0.0022868354241993333
Loss at iteration [912]: 0.0022863845247681424
Loss at iteration [913]: 0.002285750611517869
Loss at iteration [914]: 0.002285155183035729
Loss at iteration [915]: 0.0022850109449523135
Loss at iteration [916]: 0.0022839752648041714
Loss at iteration [917]: 0.0022831249390478005
Loss at iteration [918]: 0.002282865582267394
Loss at iteration [919]: 0.0022824968494497477
Loss at iteration [920]: 0.0022820710027710795
Loss at iteration [921]: 0.002281497382746404
Loss at iteration [922]: 0.0022813442637027717
Loss at iteration [923]: 0.0022813442637027717
Loss at iteration [924]: 0.0022812771669249612
Loss at iteration [925]: 0.0022810063880423104
Loss at iteration [926]: 0.0022807200376468006
Loss at iteration [927]: 0.0022804148487665654
Loss at iteration [928]: 0.002280226389135032
Loss at iteration [929]: 0.0022801076973766525
Loss at iteration [930]: 0.0022799809227125882
Loss at iteration [931]: 0.0022799101147283926
Loss at iteration [932]: 0.0022798755441661846
Loss at iteration [933]: 0.002279655211940398
Loss at iteration [934]: 0.0022792601931661606
Loss at iteration [935]: 0.002278949965136368
Loss at iteration [936]: 0.002278674485906285
Loss at iteration [937]: 0.0022786064521029604
Loss at iteration [938]: 0.0022786064521029604
Loss at iteration [939]: 0.0022785607309883642
Loss at iteration [940]: 0.0022781241689547047
Loss at iteration [941]: 0.002277936139385954
Loss at iteration [942]: 0.0022777866116829347
Loss at iteration [943]: 0.0022777132371275166
Loss at iteration [944]: 0.002277575478550551
Loss at iteration [945]: 0.002277355353602843
Loss at iteration [946]: 0.0022772711061926237
Loss at iteration [947]: 0.0022771784371263797
Loss at iteration [948]: 0.0022770785109557873
Loss at iteration [949]: 0.0022770242929344366
Loss at iteration [950]: 0.0022769712461957405
Loss at iteration [951]: 0.0022769055554770876
Loss at iteration [952]: 0.002276820231062063
Loss at iteration [953]: 0.00227678072453433
Loss at iteration [954]: 0.002276752595771449
Loss at iteration [955]: 0.002276752595771449
Loss at iteration [956]: 0.002276727653144466
Loss at iteration [957]: 0.002276699845558284
Loss at iteration [958]: 0.0022766762989962566
Loss at iteration [959]: 0.0022766294460139303
Loss at iteration [960]: 0.0022765955166366278
Loss at iteration [961]: 0.0022764288792657497
Loss at iteration [962]: 0.0022763384791767657
Loss at iteration [963]: 0.002276137200233663
Loss at iteration [964]: 0.0022759212945669535
Loss at iteration [965]: 0.002275767433905679
Loss at iteration [966]: 0.0022752682758889354
Loss at iteration [967]: 0.0022751019096608847
Loss at iteration [968]: 0.0022746506294736885
Loss at iteration [969]: 0.002272394518822703
Loss at iteration [970]: 0.0022704607418021594
Loss at iteration [971]: 0.0022701803848181996
Loss at iteration [972]: 0.002268359573441508
Loss at iteration [973]: 0.002267601737625279
Loss at iteration [974]: 0.002264529182163484
Loss at iteration [975]: 0.0022631184091049367
Loss at iteration [976]: 0.0022631184091049367
Loss at iteration [977]: 0.002260983516074957
Loss at iteration [978]: 0.0022606174597117907
Loss at iteration [979]: 0.0022563569549567727
Loss at iteration [980]: 0.002255642257428633
Loss at iteration [981]: 0.0022542355413131057
Loss at iteration [982]: 0.0022530992555964404
Loss at iteration [983]: 0.0022524474298898766
Loss at iteration [984]: 0.002250526807375863
Loss at iteration [985]: 0.002249923622585944
Loss at iteration [986]: 0.0022490595392206676
Loss at iteration [987]: 0.0022486696302848248
Loss at iteration [988]: 0.002248421448615965
Loss at iteration [989]: 0.0022479810090763833
Loss at iteration [990]: 0.0022473290823611
Loss at iteration [991]: 0.002244680763395809
Loss at iteration [992]: 0.002244680763395809
Loss at iteration [993]: 0.00224416098408122
Loss at iteration [994]: 0.0022437100546775983
Loss at iteration [995]: 0.002243140130742198
Loss at iteration [996]: 0.0022429347010364765
Loss at iteration [997]: 0.0022426449634789657
Loss at iteration [998]: 0.0022416290059167057
Loss at iteration [999]: 0.0022400679872683874
Loss at iteration [1000]: 0.002239950286665421
Loss at iteration [1001]: 0.00223845112227336
Loss at iteration [1002]: 0.002238317815732337
Loss at iteration [1003]: 0.0022378774249999654
Loss at iteration [1004]: 0.0022374284453521424
Loss at iteration [1005]: 0.002236792351239999
Loss at iteration [1006]: 0.002235009103285577
Loss at iteration [1007]: 0.002234776498413812
Loss at iteration [1008]: 0.0022339429299367435
Loss at iteration [1009]: 0.0022339429299367435
Loss at iteration [1010]: 0.0022335916208422795
Loss at iteration [1011]: 0.0022333140002330893
Loss at iteration [1012]: 0.0022319969023776778
Loss at iteration [1013]: 0.0022318231211470555
Loss at iteration [1014]: 0.0022314214965656353
Loss at iteration [1015]: 0.0022309263333195194
Loss at iteration [1016]: 0.002230693514212216
Loss at iteration [1017]: 0.0022304256394586764
Loss at iteration [1018]: 0.0022297573438871355
Loss at iteration [1019]: 0.002229573112060662
Loss at iteration [1020]: 0.0022291298195959387
Loss at iteration [1021]: 0.0022286552689961777
Loss at iteration [1022]: 0.0022282896789783766
Loss at iteration [1023]: 0.002228186520773139
Loss at iteration [1024]: 0.0022281216937998327
Loss at iteration [1025]: 0.0022281216937998327
Loss at iteration [1026]: 0.0022280844840072028
Loss at iteration [1027]: 0.0022277129013270284
Loss at iteration [1028]: 0.0022274389630632203
Loss at iteration [1029]: 0.002227392398950843
Loss at iteration [1030]: 0.002226629453081563
Loss at iteration [1031]: 0.0022261273346148667
Loss at iteration [1032]: 0.0022258766416173585
Loss at iteration [1033]: 0.002225729072577065
Loss at iteration [1034]: 0.0022251116948745556
Loss at iteration [1035]: 0.002224993967333867
Loss at iteration [1036]: 0.002224857300549065
Loss at iteration [1037]: 0.002224682576072886
Loss at iteration [1038]: 0.002224682576072886
Loss at iteration [1039]: 0.0022246074775237024
Loss at iteration [1040]: 0.0022244927575911975
Loss at iteration [1041]: 0.002224289891379398
Loss at iteration [1042]: 0.0022242226394164283
Loss at iteration [1043]: 0.00222410634749089
Loss at iteration [1044]: 0.002224009899751208
Loss at iteration [1045]: 0.002223830352376251
Loss at iteration [1046]: 0.002223763739571418
Loss at iteration [1047]: 0.002223450867125266
Loss at iteration [1048]: 0.0022232733435684085
Loss at iteration [1049]: 0.002223045114995598
Loss at iteration [1050]: 0.0022227160249340067
Loss at iteration [1051]: 0.0022223815913068215
Loss at iteration [1052]: 0.0022222132560642425
Loss at iteration [1053]: 0.002221782562944115
Loss at iteration [1054]: 0.002221398915245214
Loss at iteration [1055]: 0.002221398915245214
Loss at iteration [1056]: 0.0022212161056511114
Loss at iteration [1057]: 0.0022202649814086926
Loss at iteration [1058]: 0.0022201059241395114
Loss at iteration [1059]: 0.002219621113796442
Loss at iteration [1060]: 0.0022188560119667734
Loss at iteration [1061]: 0.0022187408622415636
Loss at iteration [1062]: 0.0022184197076178004
Loss at iteration [1063]: 0.0022179711434115773
Loss at iteration [1064]: 0.0022178699189416484
Loss at iteration [1065]: 0.002217566438609227
Loss at iteration [1066]: 0.002217494475242345
Loss at iteration [1067]: 0.002217291306033618
Loss at iteration [1068]: 0.00221698165876609
Loss at iteration [1069]: 0.0022169177787317684
Loss at iteration [1070]: 0.0022165273124210953
Loss at iteration [1071]: 0.0022164337781812584
Loss at iteration [1072]: 0.002216314004846119
Loss at iteration [1073]: 0.002216314004846119
Loss at iteration [1074]: 0.0022161957196650257
Loss at iteration [1075]: 0.0022161463332491505
Loss at iteration [1076]: 0.0022160083456109854
Loss at iteration [1077]: 0.0022159672332302985
Loss at iteration [1078]: 0.0022159105591739703
Loss at iteration [1079]: 0.002215856326949287
Loss at iteration [1080]: 0.002215811992341465
Loss at iteration [1081]: 0.0022156041507569025
Loss at iteration [1082]: 0.0022155643892291118
Loss at iteration [1083]: 0.002215298967571124
Loss at iteration [1084]: 0.002214950714394042
Loss at iteration [1085]: 0.0022148739776459312
Loss at iteration [1086]: 0.002214583526331159
Loss at iteration [1087]: 0.002214583526331159
Loss at iteration [1088]: 0.0022144758083373086
Loss at iteration [1089]: 0.0022143889305232733
Loss at iteration [1090]: 0.002214105320462137
Loss at iteration [1091]: 0.0022140471301955096
Loss at iteration [1092]: 0.0022140078971035052
Loss at iteration [1093]: 0.0022138952841854894
Loss at iteration [1094]: 0.0022138693096409342
Loss at iteration [1095]: 0.0022138067405005194
Loss at iteration [1096]: 0.0022136823420276404
Loss at iteration [1097]: 0.0022136216041931055
Loss at iteration [1098]: 0.0022132962592827108
Loss at iteration [1099]: 0.002213176171854378
Loss at iteration [1100]: 0.002213057637400145
Loss at iteration [1101]: 0.002213057637400145
Loss at iteration [1102]: 0.002212974223535129
Loss at iteration [1103]: 0.0022128207033319616
Loss at iteration [1104]: 0.002212483471646782
Loss at iteration [1105]: 0.0022124389561107762
Loss at iteration [1106]: 0.0022122975980135877
Loss at iteration [1107]: 0.0022121926625055573
Loss at iteration [1108]: 0.0022121548916171807
Loss at iteration [1109]: 0.002211991894042049
Loss at iteration [1110]: 0.0022119310988830887
Loss at iteration [1111]: 0.0022118154285041547
Loss at iteration [1112]: 0.0022117533827546885
Loss at iteration [1113]: 0.0022117067028369244
Loss at iteration [1114]: 0.00221159921711274
Loss at iteration [1115]: 0.0022115715248435127
Loss at iteration [1116]: 0.0022114436890974644
Loss at iteration [1117]: 0.0022114436890974644
Loss at iteration [1118]: 0.002211392770530545
Loss at iteration [1119]: 0.0022113799410585612
Loss at iteration [1120]: 0.0022113321379032473
Loss at iteration [1121]: 0.002211305504526663
Loss at iteration [1122]: 0.002211261355710116
Loss at iteration [1123]: 0.00221119104697956
Loss at iteration [1124]: 0.002211102258424807
Loss at iteration [1125]: 0.0022108715238476073
Loss at iteration [1126]: 0.0022107723470381566
Loss at iteration [1127]: 0.0022105311168987883
Loss at iteration [1128]: 0.00221019230524335
Loss at iteration [1129]: 0.0022099330103806086
Loss at iteration [1130]: 0.002209225318774702
Loss at iteration [1131]: 0.0022088991858203433
Loss at iteration [1132]: 0.0022088991858203433
Loss at iteration [1133]: 0.0022086741921251993
Loss at iteration [1134]: 0.002207995961089203
Loss at iteration [1135]: 0.0022078113199062942
Loss at iteration [1136]: 0.0022075161042670417
Loss at iteration [1137]: 0.00220662840268542
Loss at iteration [1138]: 0.0022065195865773974
Loss at iteration [1139]: 0.0022063569553852675
Loss at iteration [1140]: 0.0022062108725423176
Loss at iteration [1141]: 0.0022060427362042166
Loss at iteration [1142]: 0.0022057204113489163
Loss at iteration [1143]: 0.00220561344738681
Loss at iteration [1144]: 0.0022054101502190565
Loss at iteration [1145]: 0.002205328478204757
Loss at iteration [1146]: 0.002204781119643844
Loss at iteration [1147]: 0.0022047267648252584
Loss at iteration [1148]: 0.0022044833106456786
Loss at iteration [1149]: 0.0022044833106456786
Loss at iteration [1150]: 0.002204356203618995
Loss at iteration [1151]: 0.0022042672686961714
Loss at iteration [1152]: 0.002204047210682198
Loss at iteration [1153]: 0.0022039714042668694
Loss at iteration [1154]: 0.002203799570659202
Loss at iteration [1155]: 0.0022037199317217317
Loss at iteration [1156]: 0.0022036395643002583
Loss at iteration [1157]: 0.0022035638218581696
Loss at iteration [1158]: 0.002203461562449942
Loss at iteration [1159]: 0.002203437665613566
Loss at iteration [1160]: 0.002203321600935504
Loss at iteration [1161]: 0.0022032247800317776
Loss at iteration [1162]: 0.0022031404844388347
Loss at iteration [1163]: 0.0022029203562780107
Loss at iteration [1164]: 0.002202783574903073
Loss at iteration [1165]: 0.002202633858229916
Loss at iteration [1166]: 0.002202633858229916
Loss at iteration [1167]: 0.0022025015231564105
Loss at iteration [1168]: 0.002202349188171835
Loss at iteration [1169]: 0.0022022444056169405
Loss at iteration [1170]: 0.0022022152016646333
Loss at iteration [1171]: 0.0022021391154115285
Loss at iteration [1172]: 0.0022020374823337385
Loss at iteration [1173]: 0.0022019782930721753
Loss at iteration [1174]: 0.002201944589288559
Loss at iteration [1175]: 0.0022017949400372125
Loss at iteration [1176]: 0.002201675209445913
Loss at iteration [1177]: 0.0022015219188258224
Loss at iteration [1178]: 0.002201341537118343
Loss at iteration [1179]: 0.0022012405764317037
Loss at iteration [1180]: 0.0022011465904671307
Loss at iteration [1181]: 0.0022011465904671307
Loss at iteration [1182]: 0.0022010959545745654
Loss at iteration [1183]: 0.002200951477463322
Loss at iteration [1184]: 0.0022005418283127165
Loss at iteration [1185]: 0.0022004637166347326
Loss at iteration [1186]: 0.0022003131589568826
Loss at iteration [1187]: 0.002200112760583976
Loss at iteration [1188]: 0.002200025808355805
Loss at iteration [1189]: 0.0021998837324298595
Loss at iteration [1190]: 0.0021996929880775933
Loss at iteration [1191]: 0.0021996417545295274
Loss at iteration [1192]: 0.0021995184009762367
Loss at iteration [1193]: 0.0021994655921844454
Loss at iteration [1194]: 0.002199401064034388
Loss at iteration [1195]: 0.00219928401877276
Loss at iteration [1196]: 0.0021991527714979578
Loss at iteration [1197]: 0.0021991527714979578
Loss at iteration [1198]: 0.002199061899716049
Loss at iteration [1199]: 0.0021990115351873066
Loss at iteration [1200]: 0.0021989395429668833
Loss at iteration [1201]: 0.0021988925776310455
Loss at iteration [1202]: 0.002198822354983972
Loss at iteration [1203]: 0.0021987482900832057
Loss at iteration [1204]: 0.002198666059945691
Loss at iteration [1205]: 0.0021986130768600538
Loss at iteration [1206]: 0.002198570298062392
Loss at iteration [1207]: 0.0021984816846572094
Loss at iteration [1208]: 0.0021984412209059183
Loss at iteration [1209]: 0.00219828494218035
Loss at iteration [1210]: 0.0021982341439202146
Loss at iteration [1211]: 0.00219804167354245
Loss at iteration [1212]: 0.0021979532596830063
Loss at iteration [1213]: 0.0021978652758095525
Loss at iteration [1214]: 0.0021977036810773166
Loss at iteration [1215]: 0.00219764619045471
Loss at iteration [1216]: 0.00219764619045471
Loss at iteration [1217]: 0.002197606997305366
Loss at iteration [1218]: 0.0021975580726802395
Loss at iteration [1219]: 0.0021975133556006855
Loss at iteration [1220]: 0.0021974838036306747
Loss at iteration [1221]: 0.0021974461064123937
Loss at iteration [1222]: 0.00219739260933134
Loss at iteration [1223]: 0.0021973515229425206
Loss at iteration [1224]: 0.0021972943656667237
Loss at iteration [1225]: 0.0021972373033961254
Loss at iteration [1226]: 0.002197128934282639
Loss at iteration [1227]: 0.002197006388133932
Loss at iteration [1228]: 0.002196928922387175
Loss at iteration [1229]: 0.002196570770266326
Loss at iteration [1230]: 0.0021962606734868737
Loss at iteration [1231]: 0.0021962606734868737
Loss at iteration [1232]: 0.002196041426722747
Loss at iteration [1233]: 0.002195902930327742
Loss at iteration [1234]: 0.0021952702043090454
Loss at iteration [1235]: 0.002195194476107478
Loss at iteration [1236]: 0.002195042851495788
Loss at iteration [1237]: 0.0021948308289697596
Loss at iteration [1238]: 0.0021947479160902717
Loss at iteration [1239]: 0.002194662534925387
Loss at iteration [1240]: 0.0021944777931782854
Loss at iteration [1241]: 0.002194366125651619
Loss at iteration [1242]: 0.00219423974747068
Loss at iteration [1243]: 0.0021941772928268694
Loss at iteration [1244]: 0.002194053944870504
Loss at iteration [1245]: 0.002193953519402187
Loss at iteration [1246]: 0.002193953519402187
Loss at iteration [1247]: 0.002193890627696292
Loss at iteration [1248]: 0.0021938219086437673
Loss at iteration [1249]: 0.002193678196328893
Loss at iteration [1250]: 0.002193639971241908
Loss at iteration [1251]: 0.0021935707553209795
Loss at iteration [1252]: 0.002193532608577203
Loss at iteration [1253]: 0.0021935010752856046
Loss at iteration [1254]: 0.0021933999942939757
Loss at iteration [1255]: 0.0021933449451303324
Loss at iteration [1256]: 0.002193301967753197
Loss at iteration [1257]: 0.002193167519763898
Loss at iteration [1258]: 0.0021930415629571242
Loss at iteration [1259]: 0.0021929639624535214
Loss at iteration [1260]: 0.002192628073055847
Loss at iteration [1261]: 0.00219247166573349
Loss at iteration [1262]: 0.0021922742678620807
Loss at iteration [1263]: 0.0021922742678620807
Loss at iteration [1264]: 0.0021920617405747408
Loss at iteration [1265]: 0.002191975191978941
Loss at iteration [1266]: 0.0021917334946402987
Loss at iteration [1267]: 0.002191633884358145
Loss at iteration [1268]: 0.002191514412795403
Loss at iteration [1269]: 0.002191325225238784
Loss at iteration [1270]: 0.002191280477115629
Loss at iteration [1271]: 0.002191170962496323
Loss at iteration [1272]: 0.0021910956460261177
Loss at iteration [1273]: 0.0021909736359818238
Loss at iteration [1274]: 0.0021908938711479344
Loss at iteration [1275]: 0.002190826727987113
Loss at iteration [1276]: 0.002190641779309671
Loss at iteration [1277]: 0.002190607777368951
Loss at iteration [1278]: 0.002190607777368951
Loss at iteration [1279]: 0.0021905848669315823
Loss at iteration [1280]: 0.0021905479609899024
Loss at iteration [1281]: 0.002190516025062596
Loss at iteration [1282]: 0.002190434355359876
Loss at iteration [1283]: 0.002190381808937224
Loss at iteration [1284]: 0.0021903337265971323
Loss at iteration [1285]: 0.0021902581889239625
Loss at iteration [1286]: 0.002190157624089372
Loss at iteration [1287]: 0.002189947297221239
Loss at iteration [1288]: 0.0021898696105804374
Loss at iteration [1289]: 0.0021893640706550904
Loss at iteration [1290]: 0.0021892136956475467
Loss at iteration [1291]: 0.0021891460783641783
Loss at iteration [1292]: 0.0021884012229719174
Loss at iteration [1293]: 0.0021882967378447733
Loss at iteration [1294]: 0.0021882967378447733
Loss at iteration [1295]: 0.002188201325514482
Loss at iteration [1296]: 0.002187876045482242
Loss at iteration [1297]: 0.002187747865371285
Loss at iteration [1298]: 0.002187580644929769
Loss at iteration [1299]: 0.0021873696218078875
Loss at iteration [1300]: 0.0021872006070844793
Loss at iteration [1301]: 0.0021871164387323823
Loss at iteration [1302]: 0.0021870159292208843
Loss at iteration [1303]: 0.0021869382172071865
Loss at iteration [1304]: 0.002186901659669113
Loss at iteration [1305]: 0.0021868220775574272
Loss at iteration [1306]: 0.0021867687251427145
Loss at iteration [1307]: 0.002186610558791007
Loss at iteration [1308]: 0.0021865770265769033
Loss at iteration [1309]: 0.0021865164329281793
Loss at iteration [1310]: 0.00218645365034835
Loss at iteration [1311]: 0.00218645365034835
Loss at iteration [1312]: 0.0021864209097536224
Loss at iteration [1313]: 0.0021862985637733905
Loss at iteration [1314]: 0.002186273926074571
Loss at iteration [1315]: 0.0021862383552396438
Loss at iteration [1316]: 0.0021861761598428162
Loss at iteration [1317]: 0.0021861576227547685
Loss at iteration [1318]: 0.0021861169229186747
Loss at iteration [1319]: 0.002186086471745297
Loss at iteration [1320]: 0.0021860482614552224
Loss at iteration [1321]: 0.002185995305010314
Loss at iteration [1322]: 0.002185823430991075
Loss at iteration [1323]: 0.0021857544767231586
Loss at iteration [1324]: 0.0021856433781291206
Loss at iteration [1325]: 0.0021853114376443415
Loss at iteration [1326]: 0.0021853114376443415
Loss at iteration [1327]: 0.002185045695611356
Loss at iteration [1328]: 0.002184918016865258
Loss at iteration [1329]: 0.002184216114515229
Loss at iteration [1330]: 0.0021841182491980516
Loss at iteration [1331]: 0.0021839528129285104
Loss at iteration [1332]: 0.002183579543019939
Loss at iteration [1333]: 0.002183538237220826
Loss at iteration [1334]: 0.0021832550369831148
Loss at iteration [1335]: 0.002183120598567294
Loss at iteration [1336]: 0.002182961217311574
Loss at iteration [1337]: 0.002182786305264148
Loss at iteration [1338]: 0.0021827123151845038
Loss at iteration [1339]: 0.002182629344349159
Loss at iteration [1340]: 0.002182629344349159
Loss at iteration [1341]: 0.0021825210191781445
Loss at iteration [1342]: 0.002182424605675545
Loss at iteration [1343]: 0.002182288846479604
Loss at iteration [1344]: 0.0021821850251199384
Loss at iteration [1345]: 0.0021821000859055966
Loss at iteration [1346]: 0.0021820275764622946
Loss at iteration [1347]: 0.002181885005150833
Loss at iteration [1348]: 0.0021818138236974973
Loss at iteration [1349]: 0.002181745337688435
Loss at iteration [1350]: 0.00218165453944997
Loss at iteration [1351]: 0.0021815986957235836
Loss at iteration [1352]: 0.0021814677164701405
Loss at iteration [1353]: 0.002181398146831181
Loss at iteration [1354]: 0.0021812900914576607
Loss at iteration [1355]: 0.0021812900914576607
Loss at iteration [1356]: 0.002181228148784245
Loss at iteration [1357]: 0.002181186469183097
Loss at iteration [1358]: 0.002181057623582939
Loss at iteration [1359]: 0.0021810091162342412
Loss at iteration [1360]: 0.002180970071219979
Loss at iteration [1361]: 0.0021808971582031127
Loss at iteration [1362]: 0.0021808550622374728
Loss at iteration [1363]: 0.0021808202006601304
Loss at iteration [1364]: 0.002180737903734079
Loss at iteration [1365]: 0.0021806952885571333
Loss at iteration [1366]: 0.0021806081605513514
Loss at iteration [1367]: 0.002180458695032823
Loss at iteration [1368]: 0.002180364331022598
Loss at iteration [1369]: 0.002180159667406209
Loss at iteration [1370]: 0.002180064513336645
Loss at iteration [1371]: 0.002180064513336645
Loss at iteration [1372]: 0.0021800054599259103
Loss at iteration [1373]: 0.002179942127673576
Loss at iteration [1374]: 0.002179854289827018
Loss at iteration [1375]: 0.0021797535333298295
Loss at iteration [1376]: 0.0021797072539364295
Loss at iteration [1377]: 0.0021796707024533085
Loss at iteration [1378]: 0.0021796058381129096
Loss at iteration [1379]: 0.0021795736326558073
Loss at iteration [1380]: 0.0021794927721394096
Loss at iteration [1381]: 0.0021794626879563204
Loss at iteration [1382]: 0.0021793979364434207
Loss at iteration [1383]: 0.002179309938664583
Loss at iteration [1384]: 0.0021792866385889607
Loss at iteration [1385]: 0.0021792152632125928
Loss at iteration [1386]: 0.002179162406602236
Loss at iteration [1387]: 0.002179162406602236
Loss at iteration [1388]: 0.002179132044782614
Loss at iteration [1389]: 0.002179109530892294
Loss at iteration [1390]: 0.002179082956634211
Loss at iteration [1391]: 0.002179062263109853
Loss at iteration [1392]: 0.0021790372523866758
Loss at iteration [1393]: 0.002179009609858573
Loss at iteration [1394]: 0.0021789642640867636
Loss at iteration [1395]: 0.002178911839142797
Loss at iteration [1396]: 0.0021787581799698344
Loss at iteration [1397]: 0.0021786839775807467
Loss at iteration [1398]: 0.0021784170205696083
Loss at iteration [1399]: 0.002178338126285234
Loss at iteration [1400]: 0.002178247684942466
Loss at iteration [1401]: 0.0021778147393556185
Loss at iteration [1402]: 0.0021775737989171234
Loss at iteration [1403]: 0.0021775737989171234
Loss at iteration [1404]: 0.0021774715516518976
Loss at iteration [1405]: 0.0021773925034221805
Loss at iteration [1406]: 0.00217722218871995
Loss at iteration [1407]: 0.0021771751796006446
Loss at iteration [1408]: 0.0021771274189819937
Loss at iteration [1409]: 0.002177030015843511
Loss at iteration [1410]: 0.002176994902374176
Loss at iteration [1411]: 0.0021768752945589068
Loss at iteration [1412]: 0.00217681353318709
Loss at iteration [1413]: 0.0021767756592796367
Loss at iteration [1414]: 0.0021766518010388333
Loss at iteration [1415]: 0.0021766122267115316
Loss at iteration [1416]: 0.002176582114758727
Loss at iteration [1417]: 0.0021765069113961165
Loss at iteration [1418]: 0.0021764729086971462
Loss at iteration [1419]: 0.0021764729086971462
Loss at iteration [1420]: 0.0021764473730483003
Loss at iteration [1421]: 0.002176422624417999
Loss at iteration [1422]: 0.0021763964996591246
Loss at iteration [1423]: 0.0021763651343132723
Loss at iteration [1424]: 0.00217633419717641
Loss at iteration [1425]: 0.002176279719805154
Loss at iteration [1426]: 0.002176227663050193
Loss at iteration [1427]: 0.002176125402888964
Loss at iteration [1428]: 0.0021760034449069326
Loss at iteration [1429]: 0.0021758643294684135
Loss at iteration [1430]: 0.002175752557964052
Loss at iteration [1431]: 0.002175568239994027
Loss at iteration [1432]: 0.002175249916512667
Loss at iteration [1433]: 0.002174937289037101
Loss at iteration [1434]: 0.0021747556135743133
Loss at iteration [1435]: 0.0021747556135743133
Loss at iteration [1436]: 0.002174556727377791
Loss at iteration [1437]: 0.002174423957675443
Loss at iteration [1438]: 0.0021740438421159964
Loss at iteration [1439]: 0.0021739876789393007
Loss at iteration [1440]: 0.002173931034494206
Loss at iteration [1441]: 0.0021737927157661394
Loss at iteration [1442]: 0.0021737497764718256
Loss at iteration [1443]: 0.002173709371751835
Loss at iteration [1444]: 0.0021735622779419173
Loss at iteration [1445]: 0.002173515395040006
Loss at iteration [1446]: 0.002173441218248363
Loss at iteration [1447]: 0.002173373612990383
Loss at iteration [1448]: 0.0021733401094312836
Loss at iteration [1449]: 0.0021732162861700472
Loss at iteration [1450]: 0.0021732162861700472
Loss at iteration [1451]: 0.002173187823441436
Loss at iteration [1452]: 0.0021731612564451844
Loss at iteration [1453]: 0.002173115792002968
Loss at iteration [1454]: 0.002173091944487055
Loss at iteration [1455]: 0.002173042376982985
Loss at iteration [1456]: 0.0021730232723939447
Loss at iteration [1457]: 0.002172957817916691
Loss at iteration [1458]: 0.002172854558151207
Loss at iteration [1459]: 0.002172669328036136
Loss at iteration [1460]: 0.002172525760365494
Loss at iteration [1461]: 0.002172363619462299
Loss at iteration [1462]: 0.0021722359577553596
Loss at iteration [1463]: 0.002172141326316555
Loss at iteration [1464]: 0.0021720278398154706
Loss at iteration [1465]: 0.002171874784973549
Loss at iteration [1466]: 0.002171874784973549
Loss at iteration [1467]: 0.002171739082596203
Loss at iteration [1468]: 0.0021716893479848368
Loss at iteration [1469]: 0.0021713759887962243
Loss at iteration [1470]: 0.0021713450648704388
Loss at iteration [1471]: 0.0021712100267728303
Loss at iteration [1472]: 0.0021710663505639187
Loss at iteration [1473]: 0.0021710208467248214
Loss at iteration [1474]: 0.002170949328842967
Loss at iteration [1475]: 0.0021709139903624665
Loss at iteration [1476]: 0.0021708556408324095
Loss at iteration [1477]: 0.002170694315206423
Loss at iteration [1478]: 0.0021706363601059556
Loss at iteration [1479]: 0.002170533090906408
Loss at iteration [1480]: 0.002170458668564805
Loss at iteration [1481]: 0.0021703278852732385
Loss at iteration [1482]: 0.0021703278852732385
Loss at iteration [1483]: 0.002170273394965656
Loss at iteration [1484]: 0.0021702385119056733
Loss at iteration [1485]: 0.002170186110594798
Loss at iteration [1486]: 0.0021701461757518414
Loss at iteration [1487]: 0.0021700771491035492
Loss at iteration [1488]: 0.002170062955358072
Loss at iteration [1489]: 0.00216998827625425
Loss at iteration [1490]: 0.0021699108382801516
Loss at iteration [1491]: 0.0021698843018852663
Loss at iteration [1492]: 0.0021698408248860645
Loss at iteration [1493]: 0.002169799211929661
Loss at iteration [1494]: 0.0021697680388902416
Loss at iteration [1495]: 0.0021696391681453315
Loss at iteration [1496]: 0.002169580190518758
Loss at iteration [1497]: 0.002169580190518758
Loss at iteration [1498]: 0.0021695228416699565
Loss at iteration [1499]: 0.0021693708870112473
Loss at iteration [1500]: 0.0021693364396303347
Loss at iteration [1501]: 0.0021692687640302195
Loss at iteration [1502]: 0.0021692113578064883
Loss at iteration [1503]: 0.0021691772857233295
Loss at iteration [1504]: 0.0021691569348469006
Loss at iteration [1505]: 0.002169140934015566
Loss at iteration [1506]: 0.002169091603592714
Loss at iteration [1507]: 0.002169051456079929
Loss at iteration [1508]: 0.002169008887671908
Loss at iteration [1509]: 0.0021689787000728
Loss at iteration [1510]: 0.0021689186632027815
Loss at iteration [1511]: 0.002168892698311905
Loss at iteration [1512]: 0.0021688685220088533
Loss at iteration [1513]: 0.0021688685220088533
Loss at iteration [1514]: 0.0021688415048217655
Loss at iteration [1515]: 0.0021688253746933233
Loss at iteration [1516]: 0.0021688114809467825
Loss at iteration [1517]: 0.0021687989830722907
Loss at iteration [1518]: 0.0021687872066934095
Loss at iteration [1519]: 0.0021687512033617697
Loss at iteration [1520]: 0.0021687000354744155
Loss at iteration [1521]: 0.002168672415043885
Loss at iteration [1522]: 0.0021685603126736864
Loss at iteration [1523]: 0.0021682019861784555
Loss at iteration [1524]: 0.0021680494353523015
Loss at iteration [1525]: 0.0021678013127434427
Loss at iteration [1526]: 0.002165434370991401
Loss at iteration [1527]: 0.002164669271288621
Loss at iteration [1528]: 0.002164669271288621
Loss at iteration [1529]: 0.002164372174311815
Loss at iteration [1530]: 0.00216393672420096
Loss at iteration [1531]: 0.0021626308484253526
Loss at iteration [1532]: 0.0021623527286615644
Loss at iteration [1533]: 0.0021622119252362924
Loss at iteration [1534]: 0.002162124697824145
Loss at iteration [1535]: 0.0021619683255924985
Loss at iteration [1536]: 0.0021619004341880653
Loss at iteration [1537]: 0.0021617482068960335
Loss at iteration [1538]: 0.0021615074308567912
Loss at iteration [1539]: 0.0021614357279882393
Loss at iteration [1540]: 0.0021610483716072207
Loss at iteration [1541]: 0.002160721061220449
Loss at iteration [1542]: 0.0021606401179112057
Loss at iteration [1543]: 0.0021606401179112057
Loss at iteration [1544]: 0.0021605138324018083
Loss at iteration [1545]: 0.0021603343721747145
Loss at iteration [1546]: 0.0021601379218914034
Loss at iteration [1547]: 0.0021600454949525045
Loss at iteration [1548]: 0.002159918166758648
Loss at iteration [1549]: 0.002159789387449585
Loss at iteration [1550]: 0.0021597184454270188
Loss at iteration [1551]: 0.002159541101615576
Loss at iteration [1552]: 0.002159311422882946
Loss at iteration [1553]: 0.002159165057559603
Loss at iteration [1554]: 0.002159032346709071
Loss at iteration [1555]: 0.0021589658935725333
Loss at iteration [1556]: 0.0021588712286548933
Loss at iteration [1557]: 0.0021587884068829007
Loss at iteration [1558]: 0.002158773604123171
Loss at iteration [1559]: 0.002158773604123171
Loss at iteration [1560]: 0.002158747711132218
Loss at iteration [1561]: 0.0021586832508696686
Loss at iteration [1562]: 0.0021586482914455166
Loss at iteration [1563]: 0.0021586152410667794
Loss at iteration [1564]: 0.0021585657052983144
Loss at iteration [1565]: 0.002158472234899328
Loss at iteration [1566]: 0.0021583919504344195
Loss at iteration [1567]: 0.0021582261303924205
Loss at iteration [1568]: 0.002158142788943046
Loss at iteration [1569]: 0.00215786337846023
Loss at iteration [1570]: 0.002157817653323688
Loss at iteration [1571]: 0.0021576720292072692
Loss at iteration [1572]: 0.0021575784017223787
Loss at iteration [1573]: 0.002157505388827016
Loss at iteration [1574]: 0.0021574249422371414
Loss at iteration [1575]: 0.002157390615861931
Loss at iteration [1576]: 0.002157390615861931
Loss at iteration [1577]: 0.002157356301245461
Loss at iteration [1578]: 0.0021573258742746447
Loss at iteration [1579]: 0.0021572447058879883
Loss at iteration [1580]: 0.002157220170098126
Loss at iteration [1581]: 0.0021571939686391896
Loss at iteration [1582]: 0.002157139419899734
Loss at iteration [1583]: 0.0021571023759503374
Loss at iteration [1584]: 0.0021569579494183557
Loss at iteration [1585]: 0.0021569214401746762
Loss at iteration [1586]: 0.002156804061792935
Loss at iteration [1587]: 0.00215657651323094
Loss at iteration [1588]: 0.0021564642741468873
Loss at iteration [1589]: 0.002156189079871305
Loss at iteration [1590]: 0.002156081650131557
Loss at iteration [1591]: 0.002155842553452142
Loss at iteration [1592]: 0.0021554075164958424
Loss at iteration [1593]: 0.0021554075164958424
Loss at iteration [1594]: 0.0021552932490860105
Loss at iteration [1595]: 0.002155171191197556
Loss at iteration [1596]: 0.0021547769124867708
Loss at iteration [1597]: 0.002154681929622995
Loss at iteration [1598]: 0.0021545394649003713
Loss at iteration [1599]: 0.00215441093320606
Loss at iteration [1600]: 0.002154293116431112
Loss at iteration [1601]: 0.002154228317579322
Loss at iteration [1602]: 0.0021541622346941945
Loss at iteration [1603]: 0.0021540777611466283
Loss at iteration [1604]: 0.0021540413545390654
Loss at iteration [1605]: 0.0021539434489074713
Loss at iteration [1606]: 0.002153892291676312
Loss at iteration [1607]: 0.002153833693359672
Loss at iteration [1608]: 0.002153833693359672
Loss at iteration [1609]: 0.0021537665057766225
Loss at iteration [1610]: 0.0021537164904092813
Loss at iteration [1611]: 0.002153658579682945
Loss at iteration [1612]: 0.002153635851637716
Loss at iteration [1613]: 0.002153580377816637
Loss at iteration [1614]: 0.002153541166607253
Loss at iteration [1615]: 0.0021535047266559573
Loss at iteration [1616]: 0.0021534822200664897
Loss at iteration [1617]: 0.0021534036130098264
Loss at iteration [1618]: 0.0021533339801663343
Loss at iteration [1619]: 0.002153290196468878
Loss at iteration [1620]: 0.0021531578107421316
Loss at iteration [1621]: 0.002153052992652964
Loss at iteration [1622]: 0.0021528655372415207
Loss at iteration [1623]: 0.0021526835499001097
Loss at iteration [1624]: 0.002152530907318834
Loss at iteration [1625]: 0.002152530907318834
Loss at iteration [1626]: 0.002152404798055328
Loss at iteration [1627]: 0.0021521974659974084
Loss at iteration [1628]: 0.00215212903782653
Loss at iteration [1629]: 0.0021520562148087045
Loss at iteration [1630]: 0.0021519705035019094
Loss at iteration [1631]: 0.0021519158663374787
Loss at iteration [1632]: 0.00215175522995625
Loss at iteration [1633]: 0.0021517170096194546
Loss at iteration [1634]: 0.002151632056601578
Loss at iteration [1635]: 0.0021515430046916543
Loss at iteration [1636]: 0.0021514775594441834
Loss at iteration [1637]: 0.002151375595633511
Loss at iteration [1638]: 0.002151250848032791
Loss at iteration [1639]: 0.0021511952176186807
Loss at iteration [1640]: 0.0021511952176186807
Loss at iteration [1641]: 0.002151154070289136
Loss at iteration [1642]: 0.002151017330333043
Loss at iteration [1643]: 0.0021510035094883533
Loss at iteration [1644]: 0.0021509688550080635
Loss at iteration [1645]: 0.0021509394382154155
Loss at iteration [1646]: 0.0021509089169563455
Loss at iteration [1647]: 0.002150828949759608
Loss at iteration [1648]: 0.0021507443731230732
Loss at iteration [1649]: 0.0021506726991689755
Loss at iteration [1650]: 0.0021505461863059318
Loss at iteration [1651]: 0.0021505012538834633
Loss at iteration [1652]: 0.002150417716691291
Loss at iteration [1653]: 0.002150295001192208
Loss at iteration [1654]: 0.0021502267706809642
Loss at iteration [1655]: 0.0021502267706809642
Loss at iteration [1656]: 0.002150193377856419
Loss at iteration [1657]: 0.0021501469546978272
Loss at iteration [1658]: 0.0021501231462564083
Loss at iteration [1659]: 0.0021500913841934646
Loss at iteration [1660]: 0.0021500486411787883
Loss at iteration [1661]: 0.002149972907388106
Loss at iteration [1662]: 0.002149889569947694
Loss at iteration [1663]: 0.0021498267685332285
Loss at iteration [1664]: 0.0021498018611767803
Loss at iteration [1665]: 0.002149743444276528
Loss at iteration [1666]: 0.0021496775158682483
Loss at iteration [1667]: 0.0021496347742971347
Loss at iteration [1668]: 0.0021495843172882573
Loss at iteration [1669]: 0.002149451131889037
Loss at iteration [1670]: 0.0021494023540695475
Loss at iteration [1671]: 0.0021494023540695475
Loss at iteration [1672]: 0.0021493121366181716
Loss at iteration [1673]: 0.0021491532237779784
Loss at iteration [1674]: 0.002149092384915618
Loss at iteration [1675]: 0.0021490706461616263
Loss at iteration [1676]: 0.002149003215793058
Loss at iteration [1677]: 0.0021489720714976484
Loss at iteration [1678]: 0.0021489114834435125
Loss at iteration [1679]: 0.0021488761488667844
Loss at iteration [1680]: 0.0021488309556394864
Loss at iteration [1681]: 0.0021487875651965273
Loss at iteration [1682]: 0.0021487424652306755
Loss at iteration [1683]: 0.002148709176009967
Loss at iteration [1684]: 0.0021486673872593057
Loss at iteration [1685]: 0.0021485751886140833
Loss at iteration [1686]: 0.002148487064157542
Loss at iteration [1687]: 0.002148487064157542
Loss at iteration [1688]: 0.0021484327262979654
Loss at iteration [1689]: 0.00214838130720942
Loss at iteration [1690]: 0.0021483513963918713
Loss at iteration [1691]: 0.0021483124710658524
Loss at iteration [1692]: 0.0021482528213247172
Loss at iteration [1693]: 0.0021482364566667296
Loss at iteration [1694]: 0.0021482092010865696
Loss at iteration [1695]: 0.0021481727587753198
Loss at iteration [1696]: 0.0021481156866594623
Loss at iteration [1697]: 0.002148061127513411
Loss at iteration [1698]: 0.0021480171722492534
Loss at iteration [1699]: 0.0021479648728563528
Loss at iteration [1700]: 0.0021479187929994872
Loss at iteration [1701]: 0.0021478706896220427
Loss at iteration [1702]: 0.0021477946945296813
Loss at iteration [1703]: 0.0021477197089169128
Loss at iteration [1704]: 0.0021477197089169128
Loss at iteration [1705]: 0.0021476805203475965
Loss at iteration [1706]: 0.0021475742825211113
Loss at iteration [1707]: 0.0021475419142169302
Loss at iteration [1708]: 0.002147510932396683
Loss at iteration [1709]: 0.002147485603328322
Loss at iteration [1710]: 0.002147460284622037
Loss at iteration [1711]: 0.002147433467285724
Loss at iteration [1712]: 0.0021473991792998904
Loss at iteration [1713]: 0.002147332745993556
Loss at iteration [1714]: 0.0021473011280604215
Loss at iteration [1715]: 0.002147248645117449
Loss at iteration [1716]: 0.002147198554154152
Loss at iteration [1717]: 0.0021471381611964965
Loss at iteration [1718]: 0.0021471006223105576
Loss at iteration [1719]: 0.0021470082007590033
Loss at iteration [1720]: 0.0021468740835249456
Loss at iteration [1721]: 0.0021468740835249456
Loss at iteration [1722]: 0.002146819835254291
Loss at iteration [1723]: 0.0021467496698737267
Loss at iteration [1724]: 0.002146719404264631
Loss at iteration [1725]: 0.002146682458279984
Loss at iteration [1726]: 0.0021466192433653945
Loss at iteration [1727]: 0.0021465846421495844
Loss at iteration [1728]: 0.0021465616461156765
Loss at iteration [1729]: 0.002146519070310964
Loss at iteration [1730]: 0.0021464789230585682
Loss at iteration [1731]: 0.0021464398394514007
Loss at iteration [1732]: 0.0021464136938305306
Loss at iteration [1733]: 0.002146378388182211
Loss at iteration [1734]: 0.002146319560704581
Loss at iteration [1735]: 0.002146141697971815
Loss at iteration [1736]: 0.002146141697971815
Loss at iteration [1737]: 0.0021459572683319547
Loss at iteration [1738]: 0.0021458480404822258
Loss at iteration [1739]: 0.002145741503117645
Loss at iteration [1740]: 0.002145690272232454
Loss at iteration [1741]: 0.002145619799267599
Loss at iteration [1742]: 0.0021455769958942596
Loss at iteration [1743]: 0.0021455403706028787
Loss at iteration [1744]: 0.0021454963991524097
Loss at iteration [1745]: 0.00214546727137979
Loss at iteration [1746]: 0.00214544160768692
Loss at iteration [1747]: 0.0021454109937754755
Loss at iteration [1748]: 0.0021453737400669564
Loss at iteration [1749]: 0.0021453517614816713
Loss at iteration [1750]: 0.002145300153377502
Loss at iteration [1751]: 0.0021452777749918967
Loss at iteration [1752]: 0.0021452777749918967
Loss at iteration [1753]: 0.0021452390661002465
Loss at iteration [1754]: 0.0021452194882482516
Loss at iteration [1755]: 0.0021452008084075205
Loss at iteration [1756]: 0.002145186417975918
Loss at iteration [1757]: 0.002145169379047821
Loss at iteration [1758]: 0.0021451555880804218
Loss at iteration [1759]: 0.0021451372935470214
Loss at iteration [1760]: 0.002145122877470152
Loss at iteration [1761]: 0.002145079333205707
Loss at iteration [1762]: 0.0021450428094155483
Loss at iteration [1763]: 0.0021449780436291503
Loss at iteration [1764]: 0.0021448808558777815
Loss at iteration [1765]: 0.002144787679708596
Loss at iteration [1766]: 0.0021440399935728155
Loss at iteration [1767]: 0.0021440399935728155
Loss at iteration [1768]: 0.002143723375691411
Loss at iteration [1769]: 0.0021435640482832213
Loss at iteration [1770]: 0.0021433701428976095
Loss at iteration [1771]: 0.002143310734621292
Loss at iteration [1772]: 0.002143189803284048
Loss at iteration [1773]: 0.002142981332737386
Loss at iteration [1774]: 0.002142912430262543
Loss at iteration [1775]: 0.0021428374565649563
Loss at iteration [1776]: 0.002142796284632291
Loss at iteration [1777]: 0.002142644805590966
Loss at iteration [1778]: 0.002142576359156791
Loss at iteration [1779]: 0.0021425148019339553
Loss at iteration [1780]: 0.002142334850899316
Loss at iteration [1781]: 0.00214229480579558
Loss at iteration [1782]: 0.002142242943840645
Loss at iteration [1783]: 0.002142242943840645
Loss at iteration [1784]: 0.0021421956911631687
Loss at iteration [1785]: 0.0021421303195767755
Loss at iteration [1786]: 0.0021420745693359446
Loss at iteration [1787]: 0.0021420419709970405
Loss at iteration [1788]: 0.0021420062513370836
Loss at iteration [1789]: 0.00214195805045768
Loss at iteration [1790]: 0.0021419123654270846
Loss at iteration [1791]: 0.0021418808402397767
Loss at iteration [1792]: 0.0021418458488517717
Loss at iteration [1793]: 0.0021418240198823203
Loss at iteration [1794]: 0.002141801904688022
Loss at iteration [1795]: 0.0021417539158282914
Loss at iteration [1796]: 0.0021417367763260585
Loss at iteration [1797]: 0.0021417078689268294
Loss at iteration [1798]: 0.0021417078689268294
Loss at iteration [1799]: 0.0021416878301274414
Loss at iteration [1800]: 0.002141678051228106
Loss at iteration [1801]: 0.0021416638632612813
Loss at iteration [1802]: 0.0021416541112182
Loss at iteration [1803]: 0.0021416481369854992
Loss at iteration [1804]: 0.0021416257995324635
Loss at iteration [1805]: 0.0021415879180860836
Loss at iteration [1806]: 0.0021415149791311782
Loss at iteration [1807]: 0.002141472260571376
Loss at iteration [1808]: 0.0021413667427422375
Loss at iteration [1809]: 0.002141144701498076
Loss at iteration [1810]: 0.0021406681786775242
Loss at iteration [1811]: 0.002140169514787312
Loss at iteration [1812]: 0.0021397075447952083
Loss at iteration [1813]: 0.0021397075447952083
Loss at iteration [1814]: 0.0021395492837702154
Loss at iteration [1815]: 0.0021393303581427785
Loss at iteration [1816]: 0.0021385925578744384
Loss at iteration [1817]: 0.0021384888334223333
Loss at iteration [1818]: 0.002138348670305919
Loss at iteration [1819]: 0.0021381148506919344
Loss at iteration [1820]: 0.002137918717874049
Loss at iteration [1821]: 0.002137817433947341
Loss at iteration [1822]: 0.0021374904234010687
Loss at iteration [1823]: 0.0021374049096121515
Loss at iteration [1824]: 0.002137339955149708
Loss at iteration [1825]: 0.0021371123616326063
Loss at iteration [1826]: 0.0021370729587617
Loss at iteration [1827]: 0.002137002197765518
Loss at iteration [1828]: 0.002136911735251677
Loss at iteration [1829]: 0.002136911735251677
Loss at iteration [1830]: 0.0021368702234432382
Loss at iteration [1831]: 0.002136810552972088
Loss at iteration [1832]: 0.002136747771324235
Loss at iteration [1833]: 0.0021367283003940977
Loss at iteration [1834]: 0.0021366457014975722
Loss at iteration [1835]: 0.00213661249370148
Loss at iteration [1836]: 0.002136541649791042
Loss at iteration [1837]: 0.002136508530965892
Loss at iteration [1838]: 0.002136203560849553
Loss at iteration [1839]: 0.002136154042399662
Loss at iteration [1840]: 0.002136073227107054
Loss at iteration [1841]: 0.002135922326817015
Loss at iteration [1842]: 0.002135749974891907
Loss at iteration [1843]: 0.002135749974891907
Loss at iteration [1844]: 0.002135684627163063
Loss at iteration [1845]: 0.002135645011798872
Loss at iteration [1846]: 0.002135540938024872
Loss at iteration [1847]: 0.0021355165032897095
Loss at iteration [1848]: 0.002135451476140885
Loss at iteration [1849]: 0.002135413032198729
Loss at iteration [1850]: 0.0021353698967643644
Loss at iteration [1851]: 0.00213532344538968
Loss at iteration [1852]: 0.002135295825792166
Loss at iteration [1853]: 0.0021352659299704617
Loss at iteration [1854]: 0.0021352158093847413
Loss at iteration [1855]: 0.0021351847104197556
Loss at iteration [1856]: 0.0021351210306099974
Loss at iteration [1857]: 0.002135080183699088
Loss at iteration [1858]: 0.0021349428569913485
