Model name                            : MLP_Multistep
The number of input features          : 5
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.0001
Beta type                             :HS
Total number of function evaluations  : 2738
Total number of iterations            : 938
Max number of iterations              : 3000
Number of samples in training data    : 122
Number of samples in tests data       : 52
Total training time                   : 5.882600545883179
Total number of parameters            : 202302
Percentage of parameters < 1e-9       : 49.89075738252711%
Percentage of parameters < 1e-7       : 49.891251693013416%
Percentage of parameters < 1e-6       : 49.89174600349972%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.6352062897182624
Loss at iteration [2]: 0.6199878962317843
Loss at iteration [3]: 0.5900065072178224
Loss at iteration [4]: 0.5568382091222768
Loss at iteration [5]: 0.5502603470004956
Loss at iteration [6]: 0.5489981101365482
Loss at iteration [7]: 0.5489981101365482
Loss at iteration [8]: 0.5473668675045067
Loss at iteration [9]: 0.5365681414713245
Loss at iteration [10]: 0.5241857595316824
Loss at iteration [11]: 0.5131273132563587
Loss at iteration [12]: 0.5040330446091675
Loss at iteration [13]: 0.5023290694266187
Loss at iteration [14]: 0.5023290694266187
Loss at iteration [15]: 0.5007863718145074
Loss at iteration [16]: 0.49306741945415705
Loss at iteration [17]: 0.4880733430355283
Loss at iteration [18]: 0.4799810383105051
Loss at iteration [19]: 0.4779885734447612
Loss at iteration [20]: 0.4779885734447612
Loss at iteration [21]: 0.47653881873647197
Loss at iteration [22]: 0.47129674246525166
Loss at iteration [23]: 0.4684057340920525
Loss at iteration [24]: 0.42396859795952896
Loss at iteration [25]: 0.37914965793774646
Loss at iteration [26]: 0.37914965793774646
Loss at iteration [27]: 0.34962180343368965
Loss at iteration [28]: 0.33319020201375305
Loss at iteration [29]: 0.3284928332958026
Loss at iteration [30]: 0.30384058185039864
Loss at iteration [31]: 0.3030613310756079
Loss at iteration [32]: 0.299180283859923
Loss at iteration [33]: 0.299180283859923
Loss at iteration [34]: 0.29806371406088067
Loss at iteration [35]: 0.29102978536766944
Loss at iteration [36]: 0.2904385121615305
Loss at iteration [37]: 0.2871361157374339
Loss at iteration [38]: 0.2841423957618704
Loss at iteration [39]: 0.28033464437560945
Loss at iteration [40]: 0.2788380476881253
Loss at iteration [41]: 0.2788380476881253
Loss at iteration [42]: 0.2780368898270607
Loss at iteration [43]: 0.2754886426445017
Loss at iteration [44]: 0.27534890865728
Loss at iteration [45]: 0.27497878500574696
Loss at iteration [46]: 0.27454043705091113
Loss at iteration [47]: 0.273733743590115
Loss at iteration [48]: 0.273733743590115
Loss at iteration [49]: 0.27327945666473746
Loss at iteration [50]: 0.27265312267311015
Loss at iteration [51]: 0.2718040908734758
Loss at iteration [52]: 0.27089164891044004
Loss at iteration [53]: 0.2704922691940316
Loss at iteration [54]: 0.2671774199410187
Loss at iteration [55]: 0.2666353779301618
Loss at iteration [56]: 0.2666353779301618
Loss at iteration [57]: 0.26642312941437823
Loss at iteration [58]: 0.2654066243796461
Loss at iteration [59]: 0.26511270648629104
Loss at iteration [60]: 0.262514137279126
Loss at iteration [61]: 0.26225102886275453
Loss at iteration [62]: 0.26098858424569493
Loss at iteration [63]: 0.26098858424569493
Loss at iteration [64]: 0.26028614352532653
Loss at iteration [65]: 0.2596724172294553
Loss at iteration [66]: 0.25956057972637314
Loss at iteration [67]: 0.2592057458392013
Loss at iteration [68]: 0.25894127925550164
Loss at iteration [69]: 0.25825744106736825
Loss at iteration [70]: 0.2571744797175646
Loss at iteration [71]: 0.25594391253441817
Loss at iteration [72]: 0.25594391253441817
Loss at iteration [73]: 0.2551369267386406
Loss at iteration [74]: 0.25380053053748297
Loss at iteration [75]: 0.2535308944929662
Loss at iteration [76]: 0.25331760741936676
Loss at iteration [77]: 0.25289531084414324
Loss at iteration [78]: 0.25259943412576774
Loss at iteration [79]: 0.2516738450673439
Loss at iteration [80]: 0.2516738450673439
Loss at iteration [81]: 0.25092627904542647
Loss at iteration [82]: 0.25083262251228006
Loss at iteration [83]: 0.2501428369153583
Loss at iteration [84]: 0.2491498481778275
Loss at iteration [85]: 0.24883930272863072
Loss at iteration [86]: 0.24394906953110232
Loss at iteration [87]: 0.24394906953110232
Loss at iteration [88]: 0.2435602110654841
Loss at iteration [89]: 0.2394490485748362
Loss at iteration [90]: 0.2393458554261045
Loss at iteration [91]: 0.23802268345239427
Loss at iteration [92]: 0.2372326786809144
Loss at iteration [93]: 0.23585146434873377
Loss at iteration [94]: 0.23585146434873377
Loss at iteration [95]: 0.23574798110494022
Loss at iteration [96]: 0.23467171250673635
Loss at iteration [97]: 0.2344786510578251
Loss at iteration [98]: 0.23439006663106166
Loss at iteration [99]: 0.2342136531800229
Loss at iteration [100]: 0.2334278258091344
Loss at iteration [101]: 0.23321432680717455
Loss at iteration [102]: 0.23321432680717455
Loss at iteration [103]: 0.23310452627074615
Loss at iteration [104]: 0.23238118647727338
Loss at iteration [105]: 0.232278087115965
Loss at iteration [106]: 0.23205638515774413
Loss at iteration [107]: 0.23169501172176477
Loss at iteration [108]: 0.23146459354059531
Loss at iteration [109]: 0.23146459354059531
Loss at iteration [110]: 0.231377390324346
Loss at iteration [111]: 0.23111987613605534
Loss at iteration [112]: 0.23100974827911866
Loss at iteration [113]: 0.2308214799586105
Loss at iteration [114]: 0.23069189888823838
Loss at iteration [115]: 0.2304694078193762
Loss at iteration [116]: 0.23019171894863005
Loss at iteration [117]: 0.2285796398583828
Loss at iteration [118]: 0.2285796398583828
Loss at iteration [119]: 0.22842159992620026
Loss at iteration [120]: 0.2277066281505838
Loss at iteration [121]: 0.22763354477081316
Loss at iteration [122]: 0.22732876374711056
Loss at iteration [123]: 0.22726530209321674
Loss at iteration [124]: 0.2269698714680949
Loss at iteration [125]: 0.22681469229483597
Loss at iteration [126]: 0.22681469229483597
Loss at iteration [127]: 0.22673575960269549
Loss at iteration [128]: 0.22655782188398527
Loss at iteration [129]: 0.22649414406590784
Loss at iteration [130]: 0.22644804682606567
Loss at iteration [131]: 0.2262203032095132
Loss at iteration [132]: 0.2254397501379684
Loss at iteration [133]: 0.2254397501379684
Loss at iteration [134]: 0.2252981407012522
Loss at iteration [135]: 0.2248378930256505
Loss at iteration [136]: 0.2244906429957731
Loss at iteration [137]: 0.22439045870022412
Loss at iteration [138]: 0.224295781257852
Loss at iteration [139]: 0.22416907503613565
Loss at iteration [140]: 0.22367417847202006
Loss at iteration [141]: 0.22367417847202006
Loss at iteration [142]: 0.22354544777658092
Loss at iteration [143]: 0.22284131564090265
Loss at iteration [144]: 0.22268957922776283
Loss at iteration [145]: 0.22256478159718868
Loss at iteration [146]: 0.22244159821962844
Loss at iteration [147]: 0.22221937639879566
Loss at iteration [148]: 0.22221937639879566
Loss at iteration [149]: 0.22211808837617064
Loss at iteration [150]: 0.22183498714055022
Loss at iteration [151]: 0.2217749254352766
Loss at iteration [152]: 0.2215769410969976
Loss at iteration [153]: 0.22147024755743597
Loss at iteration [154]: 0.22144625623485378
Loss at iteration [155]: 0.2213518192109173
Loss at iteration [156]: 0.22121239152504693
Loss at iteration [157]: 0.22121239152504693
Loss at iteration [158]: 0.22118732410714168
Loss at iteration [159]: 0.22114339629679602
Loss at iteration [160]: 0.2210288655494528
Loss at iteration [161]: 0.22100104839342666
Loss at iteration [162]: 0.22091983615895697
Loss at iteration [163]: 0.22065687962393105
Loss at iteration [164]: 0.22056116386745586
Loss at iteration [165]: 0.2202071236018253
Loss at iteration [166]: 0.2202071236018253
Loss at iteration [167]: 0.22011504303496454
Loss at iteration [168]: 0.21992200380882262
Loss at iteration [169]: 0.21985195567579244
Loss at iteration [170]: 0.2197815212894308
Loss at iteration [171]: 0.21969571004871968
Loss at iteration [172]: 0.21959599697923346
Loss at iteration [173]: 0.2194952111652068
Loss at iteration [174]: 0.2194952111652068
Loss at iteration [175]: 0.21944199535560105
Loss at iteration [176]: 0.21936274297457597
Loss at iteration [177]: 0.2193233146379931
Loss at iteration [178]: 0.21925719364743446
Loss at iteration [179]: 0.2190754213082034
Loss at iteration [180]: 0.21893654097919213
Loss at iteration [181]: 0.21863945381194744
Loss at iteration [182]: 0.21863945381194744
Loss at iteration [183]: 0.21857989915751475
Loss at iteration [184]: 0.21849724549260185
Loss at iteration [185]: 0.2184277498462105
Loss at iteration [186]: 0.21841266937618914
Loss at iteration [187]: 0.2183413197954884
Loss at iteration [188]: 0.21826775160792275
Loss at iteration [189]: 0.2182416984116467
Loss at iteration [190]: 0.21821994711598097
Loss at iteration [191]: 0.21821994711598097
Loss at iteration [192]: 0.21816934910417918
Loss at iteration [193]: 0.2181515023922855
Loss at iteration [194]: 0.21813045748189108
Loss at iteration [195]: 0.21811326622705865
Loss at iteration [196]: 0.21807025696020946
Loss at iteration [197]: 0.21802746190535072
Loss at iteration [198]: 0.21794927947042717
Loss at iteration [199]: 0.21788204704195874
Loss at iteration [200]: 0.21788204704195874
Loss at iteration [201]: 0.2178131588336671
Loss at iteration [202]: 0.21778092498800636
Loss at iteration [203]: 0.2177679827891184
Loss at iteration [204]: 0.2177372422976031
Loss at iteration [205]: 0.21770626623348646
Loss at iteration [206]: 0.21766904646300844
Loss at iteration [207]: 0.21766904646300844
Loss at iteration [208]: 0.21764722637339873
Loss at iteration [209]: 0.21763405347035128
Loss at iteration [210]: 0.2176276138303716
Loss at iteration [211]: 0.2176180229972889
Loss at iteration [212]: 0.21761137659132979
Loss at iteration [213]: 0.21760185553977432
Loss at iteration [214]: 0.2175853394849361
Loss at iteration [215]: 0.21756848728291472
Loss at iteration [216]: 0.21753696122806784
Loss at iteration [217]: 0.21734734824057342
Loss at iteration [218]: 0.21734734824057342
Loss at iteration [219]: 0.2172753391824729
Loss at iteration [220]: 0.21720926039632202
Loss at iteration [221]: 0.21716267809336126
Loss at iteration [222]: 0.21709206092704106
Loss at iteration [223]: 0.2170491105887108
Loss at iteration [224]: 0.2170248456418539
Loss at iteration [225]: 0.21700295746788165
Loss at iteration [226]: 0.21696092535149125
Loss at iteration [227]: 0.21696092535149125
Loss at iteration [228]: 0.21693981744623553
Loss at iteration [229]: 0.2169357596422916
Loss at iteration [230]: 0.21691670461832088
Loss at iteration [231]: 0.216910846015654
Loss at iteration [232]: 0.2168777087883666
Loss at iteration [233]: 0.21686138686784615
Loss at iteration [234]: 0.21683526178318144
Loss at iteration [235]: 0.2168069483392888
Loss at iteration [236]: 0.21679121524687797
Loss at iteration [237]: 0.21679121524687797
Loss at iteration [238]: 0.21678627233871728
Loss at iteration [239]: 0.21677208858307312
Loss at iteration [240]: 0.21675907134283467
Loss at iteration [241]: 0.21675101756139784
Loss at iteration [242]: 0.21672290790909116
Loss at iteration [243]: 0.21646117166491907
Loss at iteration [244]: 0.2159152200681884
Loss at iteration [245]: 0.20899668945791935
Loss at iteration [246]: 0.20899668945791935
Loss at iteration [247]: 0.20792783895631614
Loss at iteration [248]: 0.205342081274272
Loss at iteration [249]: 0.20513692139900747
Loss at iteration [250]: 0.20399221559542363
Loss at iteration [251]: 0.20380454563689193
Loss at iteration [252]: 0.20282844462609811
Loss at iteration [253]: 0.20282844462609811
Loss at iteration [254]: 0.20247674613602495
Loss at iteration [255]: 0.20184067854976456
Loss at iteration [256]: 0.20172870952877173
Loss at iteration [257]: 0.2011396437516569
Loss at iteration [258]: 0.2007260905688223
Loss at iteration [259]: 0.20056549671020457
Loss at iteration [260]: 0.19992499413729029
Loss at iteration [261]: 0.19992499413729029
Loss at iteration [262]: 0.19975208538297598
Loss at iteration [263]: 0.19891547557150954
Loss at iteration [264]: 0.19882909205005636
Loss at iteration [265]: 0.19838676578562045
Loss at iteration [266]: 0.19828971185734265
Loss at iteration [267]: 0.19780391316864576
Loss at iteration [268]: 0.19780391316864576
Loss at iteration [269]: 0.19762795536091862
Loss at iteration [270]: 0.19752147113283225
Loss at iteration [271]: 0.19731359332589782
Loss at iteration [272]: 0.19716006920654267
Loss at iteration [273]: 0.19715729382864322
Loss at iteration [274]: 0.19702343342413656
Loss at iteration [275]: 0.1969174052704473
Loss at iteration [276]: 0.19672974372876653
Loss at iteration [277]: 0.19672974372876653
Loss at iteration [278]: 0.19664433562913605
Loss at iteration [279]: 0.19637774883352788
Loss at iteration [280]: 0.196290157381164
Loss at iteration [281]: 0.19622390186411884
Loss at iteration [282]: 0.19616126523666738
Loss at iteration [283]: 0.19600761753410506
Loss at iteration [284]: 0.19590606867939728
Loss at iteration [285]: 0.19584928465296783
Loss at iteration [286]: 0.19584928465296783
Loss at iteration [287]: 0.19577748452523316
Loss at iteration [288]: 0.1956663382088933
Loss at iteration [289]: 0.195480398656534
Loss at iteration [290]: 0.19538338562233304
Loss at iteration [291]: 0.19531289061682727
Loss at iteration [292]: 0.1951503637832901
Loss at iteration [293]: 0.19510092757106381
Loss at iteration [294]: 0.19507697354139097
Loss at iteration [295]: 0.19507697354139097
Loss at iteration [296]: 0.19503070540013032
Loss at iteration [297]: 0.19500854963925093
Loss at iteration [298]: 0.19496980614895565
Loss at iteration [299]: 0.19487092406469994
Loss at iteration [300]: 0.1948567978335871
Loss at iteration [301]: 0.19475051167593035
Loss at iteration [302]: 0.19462393300375835
Loss at iteration [303]: 0.19449541040226376
Loss at iteration [304]: 0.19449541040226376
Loss at iteration [305]: 0.19440046909819783
Loss at iteration [306]: 0.1942876248593605
Loss at iteration [307]: 0.19426161695372976
Loss at iteration [308]: 0.19421368723867966
Loss at iteration [309]: 0.19417460731226477
Loss at iteration [310]: 0.19411091706506498
Loss at iteration [311]: 0.19408473428437256
Loss at iteration [312]: 0.19406023954797952
Loss at iteration [313]: 0.19406023954797952
Loss at iteration [314]: 0.1940184990024122
Loss at iteration [315]: 0.19400327642716894
Loss at iteration [316]: 0.19398965846068517
Loss at iteration [317]: 0.19397485318399812
Loss at iteration [318]: 0.19396273878192455
Loss at iteration [319]: 0.19393337135869987
Loss at iteration [320]: 0.19392328045710275
Loss at iteration [321]: 0.1939009978066379
Loss at iteration [322]: 0.1938868141203299
Loss at iteration [323]: 0.1938868141203299
Loss at iteration [324]: 0.19387541098208388
Loss at iteration [325]: 0.19387191691481878
Loss at iteration [326]: 0.19386652248228198
Loss at iteration [327]: 0.1938557763423349
Loss at iteration [328]: 0.1938415347943431
Loss at iteration [329]: 0.19380932462206427
Loss at iteration [330]: 0.1937126926739149
Loss at iteration [331]: 0.19352020702997308
Loss at iteration [332]: 0.19304789600346106
Loss at iteration [333]: 0.19304789600346106
Loss at iteration [334]: 0.19290701841563326
Loss at iteration [335]: 0.19286390952175236
Loss at iteration [336]: 0.1928077000137283
Loss at iteration [337]: 0.19278614064345964
Loss at iteration [338]: 0.19277623532389188
Loss at iteration [339]: 0.1927380566730912
Loss at iteration [340]: 0.19270501756914604
Loss at iteration [341]: 0.19261865154696836
Loss at iteration [342]: 0.19261865154696836
Loss at iteration [343]: 0.1925544068692285
Loss at iteration [344]: 0.19254277926057298
Loss at iteration [345]: 0.19251579724518322
Loss at iteration [346]: 0.19247857352295442
Loss at iteration [347]: 0.1924527723125715
Loss at iteration [348]: 0.1924331686325451
Loss at iteration [349]: 0.19239528355476515
Loss at iteration [350]: 0.19234171670363528
Loss at iteration [351]: 0.19234171670363528
Loss at iteration [352]: 0.19231999985220233
Loss at iteration [353]: 0.1922833854894252
Loss at iteration [354]: 0.1922717797040886
Loss at iteration [355]: 0.1922452526305126
Loss at iteration [356]: 0.19222399669719556
Loss at iteration [357]: 0.19217496083557797
Loss at iteration [358]: 0.1921604905295504
Loss at iteration [359]: 0.19215388562840335
Loss at iteration [360]: 0.19214008481016392
Loss at iteration [361]: 0.19214008481016392
Loss at iteration [362]: 0.19212983650914156
Loss at iteration [363]: 0.19212738598626186
Loss at iteration [364]: 0.19212483776187833
Loss at iteration [365]: 0.19212124656031784
Loss at iteration [366]: 0.19211245935649487
Loss at iteration [367]: 0.19210288058579197
Loss at iteration [368]: 0.1920999486567296
Loss at iteration [369]: 0.19209680876414945
Loss at iteration [370]: 0.1920910145331904
Loss at iteration [371]: 0.19208533868253758
Loss at iteration [372]: 0.19208050325184955
Loss at iteration [373]: 0.19207504821348473
Loss at iteration [374]: 0.19207212277397168
Loss at iteration [375]: 0.19206542794226952
Loss at iteration [376]: 0.19206542794226952
Loss at iteration [377]: 0.1920633263920516
Loss at iteration [378]: 0.19206313312023585
Loss at iteration [379]: 0.19206192558667928
Loss at iteration [380]: 0.19206045483216003
Loss at iteration [381]: 0.19205768438162443
Loss at iteration [382]: 0.19205746712611407
Loss at iteration [383]: 0.19196033790451478
Loss at iteration [384]: 0.1915216249437185
Loss at iteration [385]: 0.19105829660324822
Loss at iteration [386]: 0.18619438930311377
Loss at iteration [387]: 0.18619438930311377
Loss at iteration [388]: 0.18439872976016655
Loss at iteration [389]: 0.18155684326823496
Loss at iteration [390]: 0.18123136655823055
Loss at iteration [391]: 0.17971852334937838
Loss at iteration [392]: 0.17945169674595107
Loss at iteration [393]: 0.17713284743730037
Loss at iteration [394]: 0.17696438849092652
Loss at iteration [395]: 0.17696438849092652
Loss at iteration [396]: 0.17678090029833946
Loss at iteration [397]: 0.1756217810228092
Loss at iteration [398]: 0.17546160934304986
Loss at iteration [399]: 0.1747477809958706
Loss at iteration [400]: 0.1745803232453286
Loss at iteration [401]: 0.17399801929172434
Loss at iteration [402]: 0.17399801929172434
Loss at iteration [403]: 0.17385966900409466
Loss at iteration [404]: 0.17355745944342027
Loss at iteration [405]: 0.1734411042194502
Loss at iteration [406]: 0.1733301687803322
Loss at iteration [407]: 0.17319880494337683
Loss at iteration [408]: 0.1731579414340046
Loss at iteration [409]: 0.173115972317076
Loss at iteration [410]: 0.173115972317076
Loss at iteration [411]: 0.1730517767732826
Loss at iteration [412]: 0.17302986208638224
Loss at iteration [413]: 0.17295737947823214
Loss at iteration [414]: 0.17282416194778538
Loss at iteration [415]: 0.17278585143898503
Loss at iteration [416]: 0.17256990432921498
Loss at iteration [417]: 0.17253330555209567
Loss at iteration [418]: 0.17245819839841028
Loss at iteration [419]: 0.17245819839841028
Loss at iteration [420]: 0.1724047340489169
Loss at iteration [421]: 0.17239971017233663
Loss at iteration [422]: 0.17236932179774642
Loss at iteration [423]: 0.17235954508692583
Loss at iteration [424]: 0.17226334141479152
Loss at iteration [425]: 0.17221083678644153
Loss at iteration [426]: 0.1721091428644122
Loss at iteration [427]: 0.17205801226884382
Loss at iteration [428]: 0.1719663624770403
Loss at iteration [429]: 0.171890729940102
Loss at iteration [430]: 0.171890729940102
Loss at iteration [431]: 0.17181940981127825
Loss at iteration [432]: 0.17179445291466952
Loss at iteration [433]: 0.17174650818642428
Loss at iteration [434]: 0.1717432122716687
Loss at iteration [435]: 0.17173390080674225
Loss at iteration [436]: 0.17171492035675845
Loss at iteration [437]: 0.17169493881211167
Loss at iteration [438]: 0.17166322855379254
Loss at iteration [439]: 0.1715650196504518
Loss at iteration [440]: 0.1715169924562074
Loss at iteration [441]: 0.1715169924562074
Loss at iteration [442]: 0.17147431007057043
Loss at iteration [443]: 0.171421177667894
Loss at iteration [444]: 0.1714014769028126
Loss at iteration [445]: 0.17132755071304634
Loss at iteration [446]: 0.171260952720955
Loss at iteration [447]: 0.17117917896141696
Loss at iteration [448]: 0.17107536596078113
Loss at iteration [449]: 0.17107536596078113
Loss at iteration [450]: 0.17105850682893012
Loss at iteration [451]: 0.17102226875788915
Loss at iteration [452]: 0.17101618395940493
Loss at iteration [453]: 0.17099088323498507
Loss at iteration [454]: 0.1709720544441415
Loss at iteration [455]: 0.17094268784408279
Loss at iteration [456]: 0.17091586862981226
Loss at iteration [457]: 0.1708871465084486
Loss at iteration [458]: 0.17085895436823473
Loss at iteration [459]: 0.17085895436823473
Loss at iteration [460]: 0.17083378179572045
Loss at iteration [461]: 0.17082104983509358
Loss at iteration [462]: 0.17079190461672378
Loss at iteration [463]: 0.17076286383068784
Loss at iteration [464]: 0.17069165391655988
Loss at iteration [465]: 0.1704766904878442
Loss at iteration [466]: 0.1698251532454995
Loss at iteration [467]: 0.16948582173134139
Loss at iteration [468]: 0.16948582173134139
Loss at iteration [469]: 0.16917099634499166
Loss at iteration [470]: 0.16885585314020662
Loss at iteration [471]: 0.1686873138707626
Loss at iteration [472]: 0.16856568826249727
Loss at iteration [473]: 0.16850165809958934
Loss at iteration [474]: 0.1684380156791758
Loss at iteration [475]: 0.16828518203662016
Loss at iteration [476]: 0.1682418069840118
Loss at iteration [477]: 0.16820794521217822
Loss at iteration [478]: 0.16820794521217822
Loss at iteration [479]: 0.1681910765326767
Loss at iteration [480]: 0.16811770088526337
Loss at iteration [481]: 0.16810148321237672
Loss at iteration [482]: 0.1680426048142878
Loss at iteration [483]: 0.16802636500773377
Loss at iteration [484]: 0.16800780456329958
Loss at iteration [485]: 0.16800467824174872
Loss at iteration [486]: 0.1679767594462904
Loss at iteration [487]: 0.1679612902958211
Loss at iteration [488]: 0.16794393099066754
Loss at iteration [489]: 0.16794393099066754
Loss at iteration [490]: 0.16794210024826992
Loss at iteration [491]: 0.16793770594459123
Loss at iteration [492]: 0.16793336656792524
Loss at iteration [493]: 0.167923978110565
Loss at iteration [494]: 0.16788403185588072
Loss at iteration [495]: 0.1677396334417249
Loss at iteration [496]: 0.16724810068027815
Loss at iteration [497]: 0.16648340523651015
Loss at iteration [498]: 0.1653782263915835
Loss at iteration [499]: 0.1653782263915835
Loss at iteration [500]: 0.1650861062748287
Loss at iteration [501]: 0.16429257642772999
Loss at iteration [502]: 0.16406630025595562
Loss at iteration [503]: 0.16401598568934886
Loss at iteration [504]: 0.16378762706094888
Loss at iteration [505]: 0.16353925744027764
Loss at iteration [506]: 0.16337270313922
Loss at iteration [507]: 0.1632118716624748
Loss at iteration [508]: 0.1632118716624748
Loss at iteration [509]: 0.16298622150969716
Loss at iteration [510]: 0.16274702749190803
Loss at iteration [511]: 0.16263705693324246
Loss at iteration [512]: 0.16255941213300645
Loss at iteration [513]: 0.1625209625272734
Loss at iteration [514]: 0.1624857280395328
Loss at iteration [515]: 0.16242690777199043
Loss at iteration [516]: 0.16242690777199043
Loss at iteration [517]: 0.16237734865300482
Loss at iteration [518]: 0.16236002975620353
Loss at iteration [519]: 0.16235569853066384
Loss at iteration [520]: 0.1623161814638578
Loss at iteration [521]: 0.1622920519511805
Loss at iteration [522]: 0.16220391341245086
Loss at iteration [523]: 0.1621278930291022
Loss at iteration [524]: 0.1619997648328908
Loss at iteration [525]: 0.1618823026018887
Loss at iteration [526]: 0.1618823026018887
Loss at iteration [527]: 0.16181754032949308
Loss at iteration [528]: 0.16175141473784363
Loss at iteration [529]: 0.16174583034974152
Loss at iteration [530]: 0.16174180794211787
Loss at iteration [531]: 0.16170767331149163
Loss at iteration [532]: 0.16169036936567494
Loss at iteration [533]: 0.16157217419828554
Loss at iteration [534]: 0.1615441147447678
Loss at iteration [535]: 0.16148790608294397
Loss at iteration [536]: 0.16147749909686238
Loss at iteration [537]: 0.16147749909686238
Loss at iteration [538]: 0.1614436077351334
Loss at iteration [539]: 0.16143932840828382
Loss at iteration [540]: 0.16143594723024499
Loss at iteration [541]: 0.16142603732975122
Loss at iteration [542]: 0.16142104572816612
Loss at iteration [543]: 0.1613932683956525
Loss at iteration [544]: 0.161389790244774
Loss at iteration [545]: 0.16137395397500573
Loss at iteration [546]: 0.16135923003642125
Loss at iteration [547]: 0.16131072388090648
Loss at iteration [548]: 0.16129704681297924
Loss at iteration [549]: 0.16119242466507927
Loss at iteration [550]: 0.1606968873576324
Loss at iteration [551]: 0.1606968873576324
Loss at iteration [552]: 0.16035473726598967
Loss at iteration [553]: 0.1601719239490509
Loss at iteration [554]: 0.15989791012680413
Loss at iteration [555]: 0.15989133505061653
Loss at iteration [556]: 0.15982329738324502
Loss at iteration [557]: 0.15980730792479636
Loss at iteration [558]: 0.1597415175572927
Loss at iteration [559]: 0.15968885442360364
Loss at iteration [560]: 0.15968885442360364
Loss at iteration [561]: 0.15967476711727718
Loss at iteration [562]: 0.15961318497304983
Loss at iteration [563]: 0.15960749228461243
Loss at iteration [564]: 0.15960343277390723
Loss at iteration [565]: 0.15957075314613958
Loss at iteration [566]: 0.15954842726984364
Loss at iteration [567]: 0.15952861215802405
Loss at iteration [568]: 0.15950803044863604
Loss at iteration [569]: 0.15944370587431345
Loss at iteration [570]: 0.15944370587431345
Loss at iteration [571]: 0.15942008808757874
Loss at iteration [572]: 0.15936503980232472
Loss at iteration [573]: 0.15935923672360566
Loss at iteration [574]: 0.15934161663882582
Loss at iteration [575]: 0.15932790292404106
Loss at iteration [576]: 0.159325960882104
Loss at iteration [577]: 0.15931195300804
Loss at iteration [578]: 0.1593046863008828
Loss at iteration [579]: 0.159281212049584
Loss at iteration [580]: 0.15924658253375326
Loss at iteration [581]: 0.15924658253375326
Loss at iteration [582]: 0.15924061512812807
Loss at iteration [583]: 0.15923542463429768
Loss at iteration [584]: 0.15922613769877592
Loss at iteration [585]: 0.15921128004222745
Loss at iteration [586]: 0.15920688968707622
Loss at iteration [587]: 0.15918644872880305
Loss at iteration [588]: 0.15918212309849222
Loss at iteration [589]: 0.1591702149471135
Loss at iteration [590]: 0.1591494361151765
Loss at iteration [591]: 0.1591443224877605
Loss at iteration [592]: 0.15912382009742174
Loss at iteration [593]: 0.15912382009742174
Loss at iteration [594]: 0.15912270055754682
Loss at iteration [595]: 0.15912026749564434
Loss at iteration [596]: 0.15911674280145247
Loss at iteration [597]: 0.15911606331546835
Loss at iteration [598]: 0.15911545324074722
Loss at iteration [599]: 0.15911035447073507
Loss at iteration [600]: 0.15910713893056208
Loss at iteration [601]: 0.15910357397069227
Loss at iteration [602]: 0.15909829054386615
Loss at iteration [603]: 0.15908822634748285
Loss at iteration [604]: 0.15906891906146783
Loss at iteration [605]: 0.158497129744256
Loss at iteration [606]: 0.158054074955564
Loss at iteration [607]: 0.158054074955564
Loss at iteration [608]: 0.15770614923911083
Loss at iteration [609]: 0.15694395521730878
Loss at iteration [610]: 0.15688223093369902
Loss at iteration [611]: 0.15665263705458576
Loss at iteration [612]: 0.15660483673650716
Loss at iteration [613]: 0.1564929664018366
Loss at iteration [614]: 0.15642859325176536
Loss at iteration [615]: 0.15642859325176536
Loss at iteration [616]: 0.15635845965111758
Loss at iteration [617]: 0.15632908485899646
Loss at iteration [618]: 0.15627866888036282
Loss at iteration [619]: 0.15621385983834396
Loss at iteration [620]: 0.1561562187225633
Loss at iteration [621]: 0.15608526818463625
Loss at iteration [622]: 0.15603861722923157
Loss at iteration [623]: 0.1560245678390112
Loss at iteration [624]: 0.15600205512935486
Loss at iteration [625]: 0.15596663674006564
Loss at iteration [626]: 0.15596663674006564
Loss at iteration [627]: 0.15594461010760757
Loss at iteration [628]: 0.1559287290912938
Loss at iteration [629]: 0.15591385225675342
Loss at iteration [630]: 0.155912837587713
Loss at iteration [631]: 0.15590787776129722
Loss at iteration [632]: 0.15590194935380697
Loss at iteration [633]: 0.15589930373905692
Loss at iteration [634]: 0.15589417130752178
Loss at iteration [635]: 0.15589114182213407
Loss at iteration [636]: 0.15588686816178085
Loss at iteration [637]: 0.15588367279891632
Loss at iteration [638]: 0.15582818704055512
Loss at iteration [639]: 0.15577456027537356
Loss at iteration [640]: 0.15577456027537356
Loss at iteration [641]: 0.15566245228256764
Loss at iteration [642]: 0.15559056601836263
Loss at iteration [643]: 0.15553506979249415
Loss at iteration [644]: 0.15546644714827468
Loss at iteration [645]: 0.15543754190101924
Loss at iteration [646]: 0.15542117318192158
Loss at iteration [647]: 0.15540080312890067
Loss at iteration [648]: 0.15539019330532855
Loss at iteration [649]: 0.15533224594041165
Loss at iteration [650]: 0.15533224594041165
Loss at iteration [651]: 0.1553085654905092
Loss at iteration [652]: 0.15527953165049946
Loss at iteration [653]: 0.15526227175409252
Loss at iteration [654]: 0.15525342994880462
Loss at iteration [655]: 0.1552394283254274
Loss at iteration [656]: 0.1552373077832783
Loss at iteration [657]: 0.1552140988825614
Loss at iteration [658]: 0.15520148050515875
Loss at iteration [659]: 0.15517692497881483
Loss at iteration [660]: 0.15512258918632144
Loss at iteration [661]: 0.15504713306825163
Loss at iteration [662]: 0.15504713306825163
Loss at iteration [663]: 0.15502515006185863
Loss at iteration [664]: 0.15498350503632638
Loss at iteration [665]: 0.15496606749144115
Loss at iteration [666]: 0.15493474405858645
Loss at iteration [667]: 0.1549079810375241
Loss at iteration [668]: 0.15487033117823815
Loss at iteration [669]: 0.15486219617235528
Loss at iteration [670]: 0.15482345440056614
Loss at iteration [671]: 0.1548003335370136
Loss at iteration [672]: 0.1548003335370136
Loss at iteration [673]: 0.1547770669698396
Loss at iteration [674]: 0.15477647146822646
Loss at iteration [675]: 0.154773736773887
Loss at iteration [676]: 0.15475765379204084
Loss at iteration [677]: 0.1547405334246099
Loss at iteration [678]: 0.15473788475738684
Loss at iteration [679]: 0.15470671733777006
Loss at iteration [680]: 0.15470468789059003
Loss at iteration [681]: 0.1546841509963692
Loss at iteration [682]: 0.1546611740663567
Loss at iteration [683]: 0.15462455549051174
Loss at iteration [684]: 0.15460565340226315
Loss at iteration [685]: 0.15460565340226315
Loss at iteration [686]: 0.15457164661131506
Loss at iteration [687]: 0.15456016646378828
Loss at iteration [688]: 0.15454647042632255
Loss at iteration [689]: 0.15452466555507727
Loss at iteration [690]: 0.15452102117798874
Loss at iteration [691]: 0.15450301142564463
Loss at iteration [692]: 0.15449860259016812
Loss at iteration [693]: 0.1544962566509937
Loss at iteration [694]: 0.1544901259006394
Loss at iteration [695]: 0.15448824457245938
Loss at iteration [696]: 0.1544774866814733
Loss at iteration [697]: 0.1544774866814733
Loss at iteration [698]: 0.15447497822266834
Loss at iteration [699]: 0.15447345755172212
Loss at iteration [700]: 0.15447219252043365
Loss at iteration [701]: 0.15446979145759954
Loss at iteration [702]: 0.15446738831137197
Loss at iteration [703]: 0.15446708811004362
Loss at iteration [704]: 0.15446348980367486
Loss at iteration [705]: 0.15445998514905945
Loss at iteration [706]: 0.1544594555644374
Loss at iteration [707]: 0.15445643629432568
Loss at iteration [708]: 0.1544548304565919
Loss at iteration [709]: 0.1544536950601417
Loss at iteration [710]: 0.15444860325661958
Loss at iteration [711]: 0.15444115682028933
Loss at iteration [712]: 0.15443728639927515
Loss at iteration [713]: 0.15440520617589068
Loss at iteration [714]: 0.15440520617589068
Loss at iteration [715]: 0.15437648181936445
Loss at iteration [716]: 0.15436816479778395
Loss at iteration [717]: 0.1543620557135556
Loss at iteration [718]: 0.15435634159198344
Loss at iteration [719]: 0.15434535371782004
Loss at iteration [720]: 0.15433722625341806
Loss at iteration [721]: 0.15433273398465805
Loss at iteration [722]: 0.15432933602984894
Loss at iteration [723]: 0.15432492622225819
Loss at iteration [724]: 0.154321531628249
Loss at iteration [725]: 0.15432127219542258
Loss at iteration [726]: 0.15432022358952469
Loss at iteration [727]: 0.1543191008299043
Loss at iteration [728]: 0.15431736509553617
Loss at iteration [729]: 0.15431736509553617
Loss at iteration [730]: 0.15431234341902642
Loss at iteration [731]: 0.15431227846339135
Loss at iteration [732]: 0.15431075431393
Loss at iteration [733]: 0.15431044089221763
Loss at iteration [734]: 0.15430910046945245
Loss at iteration [735]: 0.15430842301261632
Loss at iteration [736]: 0.1543059517510775
Loss at iteration [737]: 0.15430039621294211
Loss at iteration [738]: 0.15429068546750754
Loss at iteration [739]: 0.15426490953135705
Loss at iteration [740]: 0.15288540600646433
Loss at iteration [741]: 0.152066701761003
Loss at iteration [742]: 0.14266614593821678
Loss at iteration [743]: 0.14266614593821678
Loss at iteration [744]: 0.14190333546168385
Loss at iteration [745]: 0.13868474982560874
Loss at iteration [746]: 0.1369937687137048
Loss at iteration [747]: 0.1369359594890997
Loss at iteration [748]: 0.13637222746824448
Loss at iteration [749]: 0.13565326395315339
Loss at iteration [750]: 0.13441546917681169
Loss at iteration [751]: 0.13424242049898602
Loss at iteration [752]: 0.13350439593323746
Loss at iteration [753]: 0.13350439593323746
Loss at iteration [754]: 0.13313270572579797
Loss at iteration [755]: 0.13290484146945006
Loss at iteration [756]: 0.13271448353773552
Loss at iteration [757]: 0.13256842861298623
Loss at iteration [758]: 0.1322918092630451
Loss at iteration [759]: 0.1320284061436519
Loss at iteration [760]: 0.131795165707717
Loss at iteration [761]: 0.131795165707717
Loss at iteration [762]: 0.13095698107133716
Loss at iteration [763]: 0.13076622719471687
Loss at iteration [764]: 0.130576857023507
Loss at iteration [765]: 0.13046296624172493
Loss at iteration [766]: 0.13024180399547736
Loss at iteration [767]: 0.13018797246858455
Loss at iteration [768]: 0.1299670278552561
Loss at iteration [769]: 0.1299670278552561
Loss at iteration [770]: 0.1299311427957836
Loss at iteration [771]: 0.12985735532666157
Loss at iteration [772]: 0.12982538436531196
Loss at iteration [773]: 0.12979309609643083
Loss at iteration [774]: 0.12972349198852626
Loss at iteration [775]: 0.12965200912766414
Loss at iteration [776]: 0.1295373297460112
Loss at iteration [777]: 0.1295373297460112
Loss at iteration [778]: 0.12945571109599485
Loss at iteration [779]: 0.12940731068549208
Loss at iteration [780]: 0.12938965171719183
Loss at iteration [781]: 0.12938375282705764
Loss at iteration [782]: 0.129378589125255
Loss at iteration [783]: 0.1293652123576737
Loss at iteration [784]: 0.12935964844589842
Loss at iteration [785]: 0.12934936892640062
Loss at iteration [786]: 0.12934644490026695
Loss at iteration [787]: 0.1293272498875828
Loss at iteration [788]: 0.12932395512485353
Loss at iteration [789]: 0.12930282119968287
Loss at iteration [790]: 0.1292950000361153
Loss at iteration [791]: 0.1292950000361153
Loss at iteration [792]: 0.12929195292032475
Loss at iteration [793]: 0.12928785563446382
Loss at iteration [794]: 0.12928400594791314
Loss at iteration [795]: 0.12928381570797937
Loss at iteration [796]: 0.12927995464503778
Loss at iteration [797]: 0.12927812152153345
Loss at iteration [798]: 0.12927060993330503
Loss at iteration [799]: 0.1292291061088497
Loss at iteration [800]: 0.1290996614250351
Loss at iteration [801]: 0.12890454510127547
Loss at iteration [802]: 0.128422241884188
Loss at iteration [803]: 0.128422241884188
Loss at iteration [804]: 0.12809943608049135
Loss at iteration [805]: 0.12799463366031008
Loss at iteration [806]: 0.12773627179499264
Loss at iteration [807]: 0.12764130638536278
Loss at iteration [808]: 0.12756143697403532
Loss at iteration [809]: 0.1275262844043125
Loss at iteration [810]: 0.12734494366027208
Loss at iteration [811]: 0.12713031092094362
Loss at iteration [812]: 0.12699798573856366
Loss at iteration [813]: 0.12699798573856366
Loss at iteration [814]: 0.1268377400641657
Loss at iteration [815]: 0.1268020427398705
Loss at iteration [816]: 0.12668455820518051
Loss at iteration [817]: 0.12656727057246236
Loss at iteration [818]: 0.1265176544979393
Loss at iteration [819]: 0.12649339063151083
Loss at iteration [820]: 0.12646230405565217
Loss at iteration [821]: 0.1264278366154989
Loss at iteration [822]: 0.1263791857763415
Loss at iteration [823]: 0.1263791857763415
Loss at iteration [824]: 0.1263450155796591
Loss at iteration [825]: 0.1263312945360166
Loss at iteration [826]: 0.12631805315891287
Loss at iteration [827]: 0.12630884404555456
Loss at iteration [828]: 0.1263018512470757
Loss at iteration [829]: 0.12628777018953413
Loss at iteration [830]: 0.1262839306698126
Loss at iteration [831]: 0.12625666014162806
Loss at iteration [832]: 0.12621706147432407
Loss at iteration [833]: 0.1262088388724551
Loss at iteration [834]: 0.126179781692988
Loss at iteration [835]: 0.12614489289074285
Loss at iteration [836]: 0.12611299491899508
Loss at iteration [837]: 0.12611299491899508
Loss at iteration [838]: 0.12611108049570766
Loss at iteration [839]: 0.12609240415114817
Loss at iteration [840]: 0.12608847894153014
Loss at iteration [841]: 0.1260844608947392
Loss at iteration [842]: 0.12607887212938398
Loss at iteration [843]: 0.12607651841906486
Loss at iteration [844]: 0.12607595389262255
Loss at iteration [845]: 0.126062546089006
Loss at iteration [846]: 0.12605824062553275
Loss at iteration [847]: 0.12604898781874466
Loss at iteration [848]: 0.12601659217009964
Loss at iteration [849]: 0.1259853882192868
Loss at iteration [850]: 0.12597575605646674
Loss at iteration [851]: 0.12596629384106006
Loss at iteration [852]: 0.12594103360150302
Loss at iteration [853]: 0.12594103360150302
Loss at iteration [854]: 0.1259254808086253
Loss at iteration [855]: 0.1259200442943118
Loss at iteration [856]: 0.12591613753802294
Loss at iteration [857]: 0.12591429546464025
Loss at iteration [858]: 0.12590780659556772
Loss at iteration [859]: 0.12590441188438325
Loss at iteration [860]: 0.12590294162539178
Loss at iteration [861]: 0.1258990687315643
Loss at iteration [862]: 0.12589293833129633
Loss at iteration [863]: 0.125892070186892
Loss at iteration [864]: 0.12588937029999195
Loss at iteration [865]: 0.12588529819120672
Loss at iteration [866]: 0.12588024010305957
Loss at iteration [867]: 0.12587472983789105
Loss at iteration [868]: 0.1258720846721631
Loss at iteration [869]: 0.12586709018595252
Loss at iteration [870]: 0.12586021049316778
Loss at iteration [871]: 0.12583533848582842
Loss at iteration [872]: 0.12565504746416145
Loss at iteration [873]: 0.12565504746416145
Loss at iteration [874]: 0.12556799126016935
Loss at iteration [875]: 0.1255398815132844
Loss at iteration [876]: 0.1255308029220595
Loss at iteration [877]: 0.1255071200352487
Loss at iteration [878]: 0.12548389165004165
Loss at iteration [879]: 0.1254753290347547
Loss at iteration [880]: 0.12546643432450108
Loss at iteration [881]: 0.1254179161548558
Loss at iteration [882]: 0.12541790486908297
Loss at iteration [883]: 0.12541790486908297
Loss at iteration [884]: 0.12541771861570153
Loss at iteration [885]: 0.1254115961680413
Loss at iteration [886]: 0.1254052868540948
Loss at iteration [887]: 0.12540509490580828
Loss at iteration [888]: 0.12540127889527553
Loss at iteration [889]: 0.12539781389242
Loss at iteration [890]: 0.12539633346733006
Loss at iteration [891]: 0.12539590487449664
Loss at iteration [892]: 0.12539163907299505
Loss at iteration [893]: 0.12538283945741846
Loss at iteration [894]: 0.12537384303044843
Loss at iteration [895]: 0.12535636392320088
Loss at iteration [896]: 0.12535202326048747
Loss at iteration [897]: 0.12533919986784187
Loss at iteration [898]: 0.12533919986784187
Loss at iteration [899]: 0.12533270319759485
Loss at iteration [900]: 0.1253326367892279
Loss at iteration [901]: 0.1253319402406242
Loss at iteration [902]: 0.12532477550612192
Loss at iteration [903]: 0.12532313596629238
Loss at iteration [904]: 0.12532024691285085
Loss at iteration [905]: 0.1253144112180228
Loss at iteration [906]: 0.12531172730478776
Loss at iteration [907]: 0.12530862006525031
Loss at iteration [908]: 0.12530052748708484
Loss at iteration [909]: 0.12528726009174607
Loss at iteration [910]: 0.1252815804357948
Loss at iteration [911]: 0.12525906010207186
Loss at iteration [912]: 0.1252428190634689
Loss at iteration [913]: 0.12523667023195476
Loss at iteration [914]: 0.12522989258563433
Loss at iteration [915]: 0.12522989258563433
Loss at iteration [916]: 0.12522266005506574
Loss at iteration [917]: 0.12521712083329598
Loss at iteration [918]: 0.12521299367267008
Loss at iteration [919]: 0.12521270877874008
Loss at iteration [920]: 0.12521247948903788
Loss at iteration [921]: 0.12521003522580185
Loss at iteration [922]: 0.1252088060658742
Loss at iteration [923]: 0.12520772488849616
Loss at iteration [924]: 0.12520450690162505
Loss at iteration [925]: 0.1251970326814778
Loss at iteration [926]: 0.12519243813640177
Loss at iteration [927]: 0.12519228361741874
Loss at iteration [928]: 0.12519046416019136
Loss at iteration [929]: 0.1251885937234398
Loss at iteration [930]: 0.12518485030449564
Loss at iteration [931]: 0.12518330501967023
Loss at iteration [932]: 0.12517839728749272
Loss at iteration [933]: 0.1251605945532112
Loss at iteration [934]: 0.1251605945532112
Loss at iteration [935]: 0.12515181421080562
Loss at iteration [936]: 0.1251499748733921
Loss at iteration [937]: 0.12514679787062946
Loss at iteration [938]: 0.12514536475097485
Loss at iteration [939]: 0.1251414175273782
Loss at iteration [940]: 0.12513599572124573
Loss at iteration [941]: 0.1251348160694728
Loss at iteration [942]: 0.12513464709221941
Loss at iteration [943]: 0.12513249243662802
Loss at iteration [944]: 0.12512964307013288
Loss at iteration [945]: 0.1251274394597729
Loss at iteration [946]: 0.12512094541050348
Loss at iteration [947]: 0.1251189254466998
Loss at iteration [948]: 0.1251189254466998
Loss at iteration [949]: 0.1251156179471343
Loss at iteration [950]: 0.1251151274805221
Loss at iteration [951]: 0.12511333026660754
Loss at iteration [952]: 0.1251131381815147
Loss at iteration [953]: 0.12511251944255464
Loss at iteration [954]: 0.12511181226099288
Loss at iteration [955]: 0.12511008369944704
Loss at iteration [956]: 0.1251092194028327
Loss at iteration [957]: 0.12510909050759117
Loss at iteration [958]: 0.12510600307962494
Loss at iteration [959]: 0.12509288007580038
Loss at iteration [960]: 0.12508481869553517
Loss at iteration [961]: 0.12491017710756672
Loss at iteration [962]: 0.12491017710756672
Loss at iteration [963]: 0.12484568080751399
Loss at iteration [964]: 0.12482003079323273
Loss at iteration [965]: 0.12479516406212367
Loss at iteration [966]: 0.12474934535255387
Loss at iteration [967]: 0.12474313052828
Loss at iteration [968]: 0.12473438624185099
Loss at iteration [969]: 0.1247281957954415
Loss at iteration [970]: 0.12472324594703424
Loss at iteration [971]: 0.12471946091740824
Loss at iteration [972]: 0.12471540404450467
Loss at iteration [973]: 0.12471076880194094
Loss at iteration [974]: 0.12470498676117721
Loss at iteration [975]: 0.12470427247122814
Loss at iteration [976]: 0.12470060093682327
Loss at iteration [977]: 0.12470060093682327
Loss at iteration [978]: 0.1246966684984534
Loss at iteration [979]: 0.12469352284230152
Loss at iteration [980]: 0.1246935181236649
Loss at iteration [981]: 0.12469195126337985
Loss at iteration [982]: 0.1246911866697049
Loss at iteration [983]: 0.12468755187650876
Loss at iteration [984]: 0.12468203928695001
Loss at iteration [985]: 0.12467814169878905
Loss at iteration [986]: 0.12467353292020313
Loss at iteration [987]: 0.12467353292020313
Loss at iteration [988]: 0.12466839648922524
Loss at iteration [989]: 0.12466757412278558
Loss at iteration [990]: 0.12466342867382203
Loss at iteration [991]: 0.12466287042231634
Loss at iteration [992]: 0.12466276612929908
Loss at iteration [993]: 0.12466083052187012
Loss at iteration [994]: 0.12466007667795145
Loss at iteration [995]: 0.12465941300563126
Loss at iteration [996]: 0.12465941300563126
Loss at iteration [997]: 0.12465603335315563
Loss at iteration [998]: 0.12465523721879603
Loss at iteration [999]: 0.12465519767788673
Loss at iteration [1000]: 0.12465430589064656
Loss at iteration [1001]: 0.12465407911672374
Loss at iteration [1002]: 0.12465300722286446
Loss at iteration [1003]: 0.12465289546463959
Loss at iteration [1004]: 0.12465258476973066
Loss at iteration [1005]: 0.124652429199516
Loss at iteration [1006]: 0.12465005484068273
Loss at iteration [1007]: 0.12464971169356596
Loss at iteration [1008]: 0.12464971169356596
Loss at iteration [1009]: 0.12464254458181166
Loss at iteration [1010]: 0.12464236180687482
Loss at iteration [1011]: 0.12464033256980546
Loss at iteration [1012]: 0.1246395258537411
Loss at iteration [1013]: 0.12463890911212619
Loss at iteration [1014]: 0.12463867877121472
Loss at iteration [1015]: 0.1246375403496352
Loss at iteration [1016]: 0.12463616813833457
Loss at iteration [1017]: 0.12463614172968253
Loss at iteration [1018]: 0.12463556664243315
Loss at iteration [1019]: 0.12463529960969183
Loss at iteration [1020]: 0.12463529960969183
Loss at iteration [1021]: 0.12463458901472213
Loss at iteration [1022]: 0.1246345721413757
Loss at iteration [1023]: 0.12463455458383206
Loss at iteration [1024]: 0.12463450958035434
Loss at iteration [1025]: 0.12463429856830681
Loss at iteration [1026]: 0.1246341582125046
Loss at iteration [1027]: 0.12463350457143793
Loss at iteration [1028]: 0.12463259065724638
Loss at iteration [1029]: 0.12463259065724638
Loss at iteration [1030]: 0.12463203988593378
Loss at iteration [1031]: 0.12463191954437723
Loss at iteration [1032]: 0.12463175915944547
Loss at iteration [1033]: 0.1246316558626867
Loss at iteration [1034]: 0.1246314991065057
Loss at iteration [1035]: 0.1246314253165494
Loss at iteration [1036]: 0.12463125320579997
