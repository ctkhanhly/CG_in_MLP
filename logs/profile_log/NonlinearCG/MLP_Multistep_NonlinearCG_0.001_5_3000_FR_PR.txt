Model name                            : MLP_Multistep
The number of input features          : 5
The number of output features         : 2
Optimizer name                        : NonlinearCG
Learning rate                         : 0.001
Beta type                             :FR_PR
Total number of function evaluations  : 2053
Total number of iterations            : 975
Max number of iterations              : 3000
Number of samples in training data    : 122
Number of samples in tests data       : 52
Total training time                   : 4.814851760864258
Total number of parameters            : 202302
Percentage of parameters < 1e-9       : 50.00444879437672%
Percentage of parameters < 1e-7       : 50.00444879437672%
Percentage of parameters < 1e-6       : 50.00593172583563%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.6541798674357021
Loss at iteration [2]: 0.6512545599798335
Loss at iteration [3]: 0.6352013363174193
Loss at iteration [4]: 0.6216328650567475
Loss at iteration [5]: 0.6048887551084192
Loss at iteration [6]: 0.596546886274899
Loss at iteration [7]: 0.5762853164605471
Loss at iteration [8]: 0.5672261824566782
Loss at iteration [9]: 0.5672261824566782
Loss at iteration [10]: 0.5657018500915525
Loss at iteration [11]: 0.5581817680070412
Loss at iteration [12]: 0.5571504371773618
Loss at iteration [13]: 0.5514326971442643
Loss at iteration [14]: 0.5489923401768643
Loss at iteration [15]: 0.5004259325019657
Loss at iteration [16]: 0.48607153494129324
Loss at iteration [17]: 0.48607153494129324
Loss at iteration [18]: 0.4723344062747068
Loss at iteration [19]: 0.4695006338879622
Loss at iteration [20]: 0.45875656439346907
Loss at iteration [21]: 0.45318660878690536
Loss at iteration [22]: 0.44829188388353075
Loss at iteration [23]: 0.4442620188804939
Loss at iteration [24]: 0.4175127133093539
Loss at iteration [25]: 0.4175127133093539
Loss at iteration [26]: 0.4084814972132599
Loss at iteration [27]: 0.40544669024117236
Loss at iteration [28]: 0.3974592463205445
Loss at iteration [29]: 0.39502255780044715
Loss at iteration [30]: 0.38492288805201713
Loss at iteration [31]: 0.3782509642849138
Loss at iteration [32]: 0.36591059658450104
Loss at iteration [33]: 0.36137443546420445
Loss at iteration [34]: 0.3546779751233018
Loss at iteration [35]: 0.3546779751233018
Loss at iteration [36]: 0.3534059357917445
Loss at iteration [37]: 0.3481615932560116
Loss at iteration [38]: 0.34228314078479416
Loss at iteration [39]: 0.3052679559400522
Loss at iteration [40]: 0.30407398858871953
Loss at iteration [41]: 0.2944763932282839
Loss at iteration [42]: 0.2915874514479751
Loss at iteration [43]: 0.2915874514479751
Loss at iteration [44]: 0.29123201049157516
Loss at iteration [45]: 0.28517357924785486
Loss at iteration [46]: 0.2848553428167547
Loss at iteration [47]: 0.27955879704132136
Loss at iteration [48]: 0.2790351456989281
Loss at iteration [49]: 0.27644106646308086
Loss at iteration [50]: 0.27342582183100345
Loss at iteration [51]: 0.2731981511496751
Loss at iteration [52]: 0.2711989263118692
Loss at iteration [53]: 0.2711989263118692
Loss at iteration [54]: 0.26962706227683686
Loss at iteration [55]: 0.2668795332251063
Loss at iteration [56]: 0.2666000474445008
Loss at iteration [57]: 0.2657445170501299
Loss at iteration [58]: 0.26554897778869757
Loss at iteration [59]: 0.26320975040649347
Loss at iteration [60]: 0.2615629709584181
Loss at iteration [61]: 0.26126160435610746
Loss at iteration [62]: 0.26126160435610746
Loss at iteration [63]: 0.26109529181302904
Loss at iteration [64]: 0.25894829769864625
Loss at iteration [65]: 0.25875650404032624
Loss at iteration [66]: 0.2575747697170244
Loss at iteration [67]: 0.25742398012667644
Loss at iteration [68]: 0.2563626454270734
Loss at iteration [69]: 0.2558695857387006
Loss at iteration [70]: 0.25493665332809035
Loss at iteration [71]: 0.25493665332809035
Loss at iteration [72]: 0.2543662091089709
Loss at iteration [73]: 0.25409552759306764
Loss at iteration [74]: 0.2530201672532948
Loss at iteration [75]: 0.2522487450039729
Loss at iteration [76]: 0.2517681860388333
Loss at iteration [77]: 0.2515304346761418
Loss at iteration [78]: 0.2514308128948725
Loss at iteration [79]: 0.2512289627289133
Loss at iteration [80]: 0.25066350902730067
Loss at iteration [81]: 0.25066350902730067
Loss at iteration [82]: 0.25055433071473315
Loss at iteration [83]: 0.25046941649211757
Loss at iteration [84]: 0.2503860564574128
Loss at iteration [85]: 0.2501162305110298
Loss at iteration [86]: 0.24993751910740036
Loss at iteration [87]: 0.24955414549599278
Loss at iteration [88]: 0.24924353609355857
Loss at iteration [89]: 0.2487890651155893
Loss at iteration [90]: 0.24843853151465844
Loss at iteration [91]: 0.24843853151465844
Loss at iteration [92]: 0.2481951815110987
Loss at iteration [93]: 0.24740956966847855
Loss at iteration [94]: 0.2470793277557187
Loss at iteration [95]: 0.24699247718364611
Loss at iteration [96]: 0.24654270959871818
Loss at iteration [97]: 0.2463951986260236
Loss at iteration [98]: 0.2462344915508669
Loss at iteration [99]: 0.24575428300198765
Loss at iteration [100]: 0.24563612509163069
Loss at iteration [101]: 0.24563612509163069
Loss at iteration [102]: 0.24554555392811617
Loss at iteration [103]: 0.2453385400183909
Loss at iteration [104]: 0.2452223251684015
Loss at iteration [105]: 0.24484852310270036
Loss at iteration [106]: 0.2447238372204002
Loss at iteration [107]: 0.24450676237605834
Loss at iteration [108]: 0.24440083928983503
Loss at iteration [109]: 0.2441712004933295
Loss at iteration [110]: 0.2440722311593759
Loss at iteration [111]: 0.24391073040240263
Loss at iteration [112]: 0.24367571373612745
Loss at iteration [113]: 0.24367571373612745
Loss at iteration [114]: 0.24355581751271116
Loss at iteration [115]: 0.24306391893350757
Loss at iteration [116]: 0.2429850428469842
Loss at iteration [117]: 0.2428581468304074
Loss at iteration [118]: 0.24275758643798967
Loss at iteration [119]: 0.24271108518679022
Loss at iteration [120]: 0.2426708815023474
Loss at iteration [121]: 0.24266061777776762
Loss at iteration [122]: 0.24261034313953952
Loss at iteration [123]: 0.24256680630690636
Loss at iteration [124]: 0.24256680630690636
Loss at iteration [125]: 0.2425213691917464
Loss at iteration [126]: 0.2424714990615426
Loss at iteration [127]: 0.24241823826332437
Loss at iteration [128]: 0.24212266874744584
Loss at iteration [129]: 0.24179288228947432
Loss at iteration [130]: 0.24147180200103824
Loss at iteration [131]: 0.2405992787881815
Loss at iteration [132]: 0.24030750926169175
Loss at iteration [133]: 0.23797495534427293
Loss at iteration [134]: 0.23534240788212674
Loss at iteration [135]: 0.23534240788212674
Loss at iteration [136]: 0.23499481352180113
Loss at iteration [137]: 0.23157972029328389
Loss at iteration [138]: 0.23147508175652212
Loss at iteration [139]: 0.22964340705150568
Loss at iteration [140]: 0.22939942029252564
Loss at iteration [141]: 0.2292205562763668
Loss at iteration [142]: 0.22871608741078758
Loss at iteration [143]: 0.2286345214357127
Loss at iteration [144]: 0.2279459843055784
Loss at iteration [145]: 0.2279459843055784
Loss at iteration [146]: 0.22777601574323722
Loss at iteration [147]: 0.22724036219572502
Loss at iteration [148]: 0.22713708852442285
Loss at iteration [149]: 0.22708486319977378
Loss at iteration [150]: 0.22647854885632016
Loss at iteration [151]: 0.22636319461007706
Loss at iteration [152]: 0.2261144870328819
Loss at iteration [153]: 0.22594331533904136
Loss at iteration [154]: 0.22594331533904136
Loss at iteration [155]: 0.22564650928749486
Loss at iteration [156]: 0.22553387888802848
Loss at iteration [157]: 0.22548116980361452
Loss at iteration [158]: 0.22546595212261628
Loss at iteration [159]: 0.225412015172976
Loss at iteration [160]: 0.2252712679980585
Loss at iteration [161]: 0.22511657248600514
Loss at iteration [162]: 0.224996495018721
Loss at iteration [163]: 0.22495300898533088
Loss at iteration [164]: 0.22466313760689074
Loss at iteration [165]: 0.2239502777925217
Loss at iteration [166]: 0.2239502777925217
Loss at iteration [167]: 0.22384190060198839
Loss at iteration [168]: 0.22355974228611977
Loss at iteration [169]: 0.22331544706844034
Loss at iteration [170]: 0.22318058733141657
Loss at iteration [171]: 0.22306836226043286
Loss at iteration [172]: 0.22295499993914508
Loss at iteration [173]: 0.22284887217793792
Loss at iteration [174]: 0.22272313723439496
Loss at iteration [175]: 0.22264955297631756
Loss at iteration [176]: 0.22243793029537015
Loss at iteration [177]: 0.22243793029537015
Loss at iteration [178]: 0.22238206845920963
Loss at iteration [179]: 0.2223515622933026
Loss at iteration [180]: 0.22232982290705852
Loss at iteration [181]: 0.22227422964857455
Loss at iteration [182]: 0.22224010678273717
Loss at iteration [183]: 0.22218951668016396
Loss at iteration [184]: 0.22216879155689476
Loss at iteration [185]: 0.22215538856489186
Loss at iteration [186]: 0.22212793336374456
Loss at iteration [187]: 0.2220863567205714
Loss at iteration [188]: 0.2220285848728635
Loss at iteration [189]: 0.22195567400831212
Loss at iteration [190]: 0.22184810959238627
Loss at iteration [191]: 0.22150125772046855
Loss at iteration [192]: 0.22150125772046855
Loss at iteration [193]: 0.2213577468179369
Loss at iteration [194]: 0.2212905209502787
Loss at iteration [195]: 0.22118680318861797
Loss at iteration [196]: 0.22103066767239696
Loss at iteration [197]: 0.2209973005863557
Loss at iteration [198]: 0.22098718579430232
Loss at iteration [199]: 0.22097864284638485
Loss at iteration [200]: 0.220937218899593
Loss at iteration [201]: 0.22087192527381538
Loss at iteration [202]: 0.22072155346507344
Loss at iteration [203]: 0.22069205121523672
Loss at iteration [204]: 0.22065828678112018
Loss at iteration [205]: 0.22062708992148938
Loss at iteration [206]: 0.22062708992148938
Loss at iteration [207]: 0.22055257721885946
Loss at iteration [208]: 0.22052180027776644
Loss at iteration [209]: 0.22050937362243142
Loss at iteration [210]: 0.22045780339063
Loss at iteration [211]: 0.22041462160647338
Loss at iteration [212]: 0.22037739957289695
Loss at iteration [213]: 0.22026333631081232
Loss at iteration [214]: 0.22018592564048636
Loss at iteration [215]: 0.22011804147854183
Loss at iteration [216]: 0.2199896464941999
Loss at iteration [217]: 0.21982822304090066
Loss at iteration [218]: 0.21982822304090066
Loss at iteration [219]: 0.21970321038752277
Loss at iteration [220]: 0.2196655406766874
Loss at iteration [221]: 0.21961627809702797
Loss at iteration [222]: 0.21948539903254113
Loss at iteration [223]: 0.2194391925975514
Loss at iteration [224]: 0.21938183719453636
Loss at iteration [225]: 0.2193254312286742
Loss at iteration [226]: 0.21925455269964234
Loss at iteration [227]: 0.219135279567303
Loss at iteration [228]: 0.219135279567303
Loss at iteration [229]: 0.219077178583934
Loss at iteration [230]: 0.21885082099200864
Loss at iteration [231]: 0.21882464607444432
Loss at iteration [232]: 0.21878679963105438
Loss at iteration [233]: 0.21876061768386057
Loss at iteration [234]: 0.2187152757282191
Loss at iteration [235]: 0.21870017696065475
Loss at iteration [236]: 0.21868685760490145
Loss at iteration [237]: 0.21864727235938497
Loss at iteration [238]: 0.2186439421810757
Loss at iteration [239]: 0.21853296301588032
Loss at iteration [240]: 0.2184851386912887
Loss at iteration [241]: 0.21838870960455786
Loss at iteration [242]: 0.21838870960455786
Loss at iteration [243]: 0.2183021349460411
Loss at iteration [244]: 0.21828914202589733
Loss at iteration [245]: 0.21821086147200305
Loss at iteration [246]: 0.21819300160729668
Loss at iteration [247]: 0.2181709406336723
Loss at iteration [248]: 0.2181212752462331
Loss at iteration [249]: 0.21808946686043587
Loss at iteration [250]: 0.21799891926559248
Loss at iteration [251]: 0.21786958714364152
Loss at iteration [252]: 0.21780508703335086
Loss at iteration [253]: 0.21776040608633052
Loss at iteration [254]: 0.21776040608633052
Loss at iteration [255]: 0.21769171908959722
Loss at iteration [256]: 0.2175941363786149
Loss at iteration [257]: 0.2175392700036328
Loss at iteration [258]: 0.21746409855197762
Loss at iteration [259]: 0.21740629627038818
Loss at iteration [260]: 0.21738708836927093
Loss at iteration [261]: 0.21730494146154417
Loss at iteration [262]: 0.21727206305198804
Loss at iteration [263]: 0.21723337420543073
Loss at iteration [264]: 0.21718912560069364
Loss at iteration [265]: 0.21714123809380093
Loss at iteration [266]: 0.21711302667412904
Loss at iteration [267]: 0.21686237681136764
Loss at iteration [268]: 0.21686237681136764
Loss at iteration [269]: 0.21662529447127685
Loss at iteration [270]: 0.21650597444349162
Loss at iteration [271]: 0.21634597291714128
Loss at iteration [272]: 0.21631169206107176
Loss at iteration [273]: 0.21627539747367214
Loss at iteration [274]: 0.21621523110287677
Loss at iteration [275]: 0.21617172383477382
Loss at iteration [276]: 0.2160271408822597
Loss at iteration [277]: 0.21598971216259216
Loss at iteration [278]: 0.21586981528964888
Loss at iteration [279]: 0.2158556326559989
Loss at iteration [280]: 0.2157952961672146
Loss at iteration [281]: 0.2157952961672146
Loss at iteration [282]: 0.21574169579430882
Loss at iteration [283]: 0.21570239204047784
Loss at iteration [284]: 0.21567410874469334
Loss at iteration [285]: 0.21563372790346969
Loss at iteration [286]: 0.21555325656820934
Loss at iteration [287]: 0.2154727559701475
Loss at iteration [288]: 0.21533035468128683
Loss at iteration [289]: 0.2152458344997517
Loss at iteration [290]: 0.21509979687493722
Loss at iteration [291]: 0.21491326603131508
Loss at iteration [292]: 0.21461468583711965
Loss at iteration [293]: 0.21461468583711965
Loss at iteration [294]: 0.2144119543917078
Loss at iteration [295]: 0.21435465359651174
Loss at iteration [296]: 0.2142492848244704
Loss at iteration [297]: 0.21420059483648793
Loss at iteration [298]: 0.21415518555532242
Loss at iteration [299]: 0.21410156211823772
Loss at iteration [300]: 0.21405400842732653
Loss at iteration [301]: 0.2140259053968026
Loss at iteration [302]: 0.21399334695737937
Loss at iteration [303]: 0.213957437293155
Loss at iteration [304]: 0.21394302736941748
Loss at iteration [305]: 0.21390412740064657
Loss at iteration [306]: 0.2138667671744497
Loss at iteration [307]: 0.2138667671744497
Loss at iteration [308]: 0.21384658550469596
Loss at iteration [309]: 0.21383223019726555
Loss at iteration [310]: 0.21382450716499807
Loss at iteration [311]: 0.21379519440264041
Loss at iteration [312]: 0.21373150481660566
Loss at iteration [313]: 0.2135447946597464
Loss at iteration [314]: 0.21351598976036257
Loss at iteration [315]: 0.21340587147502352
Loss at iteration [316]: 0.21315007767639804
Loss at iteration [317]: 0.21290967516020254
Loss at iteration [318]: 0.21265876079769724
Loss at iteration [319]: 0.21247365123520792
Loss at iteration [320]: 0.2124232401549405
Loss at iteration [321]: 0.2124232401549405
Loss at iteration [322]: 0.21238708712017396
Loss at iteration [323]: 0.2123646252157167
Loss at iteration [324]: 0.21234304273170937
Loss at iteration [325]: 0.2123143477046331
Loss at iteration [326]: 0.2122731654352484
Loss at iteration [327]: 0.21225041705535014
Loss at iteration [328]: 0.21220538651613702
Loss at iteration [329]: 0.21202386107137552
Loss at iteration [330]: 0.21190315478328153
Loss at iteration [331]: 0.21175002519044564
Loss at iteration [332]: 0.21156644592870247
Loss at iteration [333]: 0.21146484959782694
Loss at iteration [334]: 0.2113623830600394
Loss at iteration [335]: 0.2113623830600394
Loss at iteration [336]: 0.21123686952775075
Loss at iteration [337]: 0.21120972658103318
Loss at iteration [338]: 0.21115283226836737
Loss at iteration [339]: 0.21109720986710465
Loss at iteration [340]: 0.21105558002225577
Loss at iteration [341]: 0.21098930769633065
Loss at iteration [342]: 0.21092634933922902
Loss at iteration [343]: 0.21089823007915706
Loss at iteration [344]: 0.21086981061104673
Loss at iteration [345]: 0.21082992865234132
Loss at iteration [346]: 0.21081372027546175
Loss at iteration [347]: 0.21081372027546175
Loss at iteration [348]: 0.21079132190685393
Loss at iteration [349]: 0.21077867166328632
Loss at iteration [350]: 0.2107723611423969
Loss at iteration [351]: 0.21076691937277137
Loss at iteration [352]: 0.2107141562575229
Loss at iteration [353]: 0.21064361346782892
Loss at iteration [354]: 0.21057880039772434
Loss at iteration [355]: 0.21047172494931643
Loss at iteration [356]: 0.21025381985126093
Loss at iteration [357]: 0.21021098528822335
Loss at iteration [358]: 0.21011420554986876
Loss at iteration [359]: 0.21001031475887888
Loss at iteration [360]: 0.20997308415267157
Loss at iteration [361]: 0.20994636238658057
Loss at iteration [362]: 0.20992391638805985
Loss at iteration [363]: 0.20992391638805985
Loss at iteration [364]: 0.2098912954984053
Loss at iteration [365]: 0.2098844272180912
Loss at iteration [366]: 0.20986451218339217
Loss at iteration [367]: 0.2098414406188493
Loss at iteration [368]: 0.20982808550987667
Loss at iteration [369]: 0.20970499090740247
Loss at iteration [370]: 0.20962719799509744
Loss at iteration [371]: 0.20946673111578712
Loss at iteration [372]: 0.20933921314394702
Loss at iteration [373]: 0.209287885977122
Loss at iteration [374]: 0.20915728247535742
Loss at iteration [375]: 0.2091019154651588
Loss at iteration [376]: 0.20907529660332325
Loss at iteration [377]: 0.2090522982927776
Loss at iteration [378]: 0.2090522982927776
Loss at iteration [379]: 0.20904424764732613
Loss at iteration [380]: 0.20901378880161522
Loss at iteration [381]: 0.2089979598107008
Loss at iteration [382]: 0.20897042008863861
Loss at iteration [383]: 0.2089262565314892
Loss at iteration [384]: 0.2089110696261547
Loss at iteration [385]: 0.20889791744429873
Loss at iteration [386]: 0.20887403766428675
Loss at iteration [387]: 0.20883773460166336
Loss at iteration [388]: 0.20882124602177818
Loss at iteration [389]: 0.208788455716847
Loss at iteration [390]: 0.20874366205355174
Loss at iteration [391]: 0.20869506943956764
Loss at iteration [392]: 0.20851666753588402
Loss at iteration [393]: 0.20830317739816195
Loss at iteration [394]: 0.2082453533639996
Loss at iteration [395]: 0.20798156055006733
Loss at iteration [396]: 0.20798156055006733
Loss at iteration [397]: 0.20789204963283028
Loss at iteration [398]: 0.20779350163763732
Loss at iteration [399]: 0.2077314299319465
Loss at iteration [400]: 0.2076541752339977
Loss at iteration [401]: 0.2075932549441797
Loss at iteration [402]: 0.2075241601901817
Loss at iteration [403]: 0.2074147709984579
Loss at iteration [404]: 0.20730399820555498
Loss at iteration [405]: 0.2071964925193649
Loss at iteration [406]: 0.2071964925193649
Loss at iteration [407]: 0.20712898751099723
Loss at iteration [408]: 0.2071127684815773
Loss at iteration [409]: 0.20709259931384694
Loss at iteration [410]: 0.2070760037063101
Loss at iteration [411]: 0.2070347128172729
Loss at iteration [412]: 0.2069666746497185
Loss at iteration [413]: 0.20691622768735943
Loss at iteration [414]: 0.20688616762400755
Loss at iteration [415]: 0.20666290523857808
Loss at iteration [416]: 0.20659929657268825
Loss at iteration [417]: 0.20659671780762429
Loss at iteration [418]: 0.20655712512811333
Loss at iteration [419]: 0.20655712512811333
Loss at iteration [420]: 0.20652394189211193
Loss at iteration [421]: 0.20646723345572593
Loss at iteration [422]: 0.20646009708906027
Loss at iteration [423]: 0.20645017305400104
Loss at iteration [424]: 0.20641003063496358
Loss at iteration [425]: 0.20636799435057485
Loss at iteration [426]: 0.20633469431144688
Loss at iteration [427]: 0.20632046512902655
Loss at iteration [428]: 0.20630304381467393
Loss at iteration [429]: 0.20622533517936747
Loss at iteration [430]: 0.20620771755280054
Loss at iteration [431]: 0.20616832240829305
Loss at iteration [432]: 0.20616832240829305
Loss at iteration [433]: 0.206157822366549
Loss at iteration [434]: 0.20615423300245317
Loss at iteration [435]: 0.20614579935715632
Loss at iteration [436]: 0.20613777575762776
Loss at iteration [437]: 0.2061254293747325
Loss at iteration [438]: 0.20610066436598368
Loss at iteration [439]: 0.20608751430411187
Loss at iteration [440]: 0.2060458462027474
Loss at iteration [441]: 0.2060116164780592
Loss at iteration [442]: 0.20600127060430326
Loss at iteration [443]: 0.20598368883121598
Loss at iteration [444]: 0.20587666342491934
Loss at iteration [445]: 0.20566458246774422
Loss at iteration [446]: 0.2053588970355575
Loss at iteration [447]: 0.20468521273174248
Loss at iteration [448]: 0.20468521273174248
Loss at iteration [449]: 0.20454779207841828
Loss at iteration [450]: 0.2044560178355363
Loss at iteration [451]: 0.20431323545757082
Loss at iteration [452]: 0.2042458760880852
Loss at iteration [453]: 0.20412375953226586
Loss at iteration [454]: 0.20399439242909667
Loss at iteration [455]: 0.20394881083212343
Loss at iteration [456]: 0.2039257437626884
Loss at iteration [457]: 0.2037924721889268
Loss at iteration [458]: 0.20371435551842562
Loss at iteration [459]: 0.20364512162956658
Loss at iteration [460]: 0.20364512162956658
Loss at iteration [461]: 0.2035888970081708
Loss at iteration [462]: 0.20354416143637738
Loss at iteration [463]: 0.20352492125422952
Loss at iteration [464]: 0.20347563856374362
Loss at iteration [465]: 0.20342368905375988
Loss at iteration [466]: 0.20341509958143306
Loss at iteration [467]: 0.2033528589197575
Loss at iteration [468]: 0.20329810593824982
Loss at iteration [469]: 0.2032459110806943
Loss at iteration [470]: 0.20321908280456083
Loss at iteration [471]: 0.2031988722735266
Loss at iteration [472]: 0.20317377572834971
Loss at iteration [473]: 0.20315343161489152
Loss at iteration [474]: 0.2031257875399444
Loss at iteration [475]: 0.2031257875399444
Loss at iteration [476]: 0.20311257360844875
Loss at iteration [477]: 0.20310395849527552
Loss at iteration [478]: 0.20309104724820906
Loss at iteration [479]: 0.2030798644832988
Loss at iteration [480]: 0.20302950193019165
Loss at iteration [481]: 0.20296710065366771
Loss at iteration [482]: 0.2029148686480279
Loss at iteration [483]: 0.20282533582134013
Loss at iteration [484]: 0.2028059845312435
Loss at iteration [485]: 0.20278705630149244
Loss at iteration [486]: 0.20270505016432872
Loss at iteration [487]: 0.20264181549306085
Loss at iteration [488]: 0.20259124714432694
Loss at iteration [489]: 0.2025379985688065
Loss at iteration [490]: 0.20226317275382616
Loss at iteration [491]: 0.20226317275382616
Loss at iteration [492]: 0.2021032995875464
Loss at iteration [493]: 0.20203753687258044
Loss at iteration [494]: 0.2020074291865146
Loss at iteration [495]: 0.20191537430621
Loss at iteration [496]: 0.20188896725666924
Loss at iteration [497]: 0.20187408722734446
Loss at iteration [498]: 0.2018503521129769
Loss at iteration [499]: 0.20177791486956248
Loss at iteration [500]: 0.20176141642541204
Loss at iteration [501]: 0.201726726751097
Loss at iteration [502]: 0.20170326671981123
Loss at iteration [503]: 0.20168447954364108
Loss at iteration [504]: 0.2016564986367792
Loss at iteration [505]: 0.2016564986367792
Loss at iteration [506]: 0.20163233394725877
Loss at iteration [507]: 0.20161006838245135
Loss at iteration [508]: 0.20160312809249034
Loss at iteration [509]: 0.20159062800069638
Loss at iteration [510]: 0.20158213455039448
Loss at iteration [511]: 0.20156490579546404
Loss at iteration [512]: 0.20155248635245615
Loss at iteration [513]: 0.20144913243975615
Loss at iteration [514]: 0.20126554890527207
Loss at iteration [515]: 0.2007260325264086
Loss at iteration [516]: 0.20044469442877022
Loss at iteration [517]: 0.19921678984311222
Loss at iteration [518]: 0.19812961698633366
Loss at iteration [519]: 0.19812961698633366
Loss at iteration [520]: 0.19791886132425543
Loss at iteration [521]: 0.19783241146228767
Loss at iteration [522]: 0.19774618205473166
Loss at iteration [523]: 0.19759603881341506
Loss at iteration [524]: 0.19738628596876426
Loss at iteration [525]: 0.19727036509752752
Loss at iteration [526]: 0.197102381396864
Loss at iteration [527]: 0.1970721999445466
Loss at iteration [528]: 0.1970265055680307
Loss at iteration [529]: 0.19698555944348886
Loss at iteration [530]: 0.1968854815871861
Loss at iteration [531]: 0.1967811369398463
Loss at iteration [532]: 0.1966591599040016
Loss at iteration [533]: 0.1966591599040016
Loss at iteration [534]: 0.19651660258309678
Loss at iteration [535]: 0.19649390188044674
Loss at iteration [536]: 0.19645915440196807
Loss at iteration [537]: 0.19641070299612964
Loss at iteration [538]: 0.19638923858716942
Loss at iteration [539]: 0.19634159533598028
Loss at iteration [540]: 0.1962692290515892
Loss at iteration [541]: 0.19618036316030504
Loss at iteration [542]: 0.19597033691847074
Loss at iteration [543]: 0.19581124797818839
Loss at iteration [544]: 0.1955356985924438
Loss at iteration [545]: 0.19528175993715283
Loss at iteration [546]: 0.19528175993715283
Loss at iteration [547]: 0.1952034370826189
Loss at iteration [548]: 0.19505136735900128
Loss at iteration [549]: 0.19488709549774488
Loss at iteration [550]: 0.1948517070035843
Loss at iteration [551]: 0.1947712957834697
Loss at iteration [552]: 0.19474060669735674
Loss at iteration [553]: 0.19465150288255767
Loss at iteration [554]: 0.19461071909403077
Loss at iteration [555]: 0.1945697138532931
Loss at iteration [556]: 0.1945577694564207
Loss at iteration [557]: 0.19452946826095727
Loss at iteration [558]: 0.19447836615298214
Loss at iteration [559]: 0.19438060485798855
Loss at iteration [560]: 0.19438060485798855
Loss at iteration [561]: 0.1943705288266791
Loss at iteration [562]: 0.19435888190039646
Loss at iteration [563]: 0.19433349882309675
Loss at iteration [564]: 0.19430466503471222
Loss at iteration [565]: 0.19429838665163576
Loss at iteration [566]: 0.19428311625403577
Loss at iteration [567]: 0.1942448105221193
Loss at iteration [568]: 0.19421852110345236
Loss at iteration [569]: 0.19419870503241288
Loss at iteration [570]: 0.19414417129410858
Loss at iteration [571]: 0.19413231142178355
Loss at iteration [572]: 0.19409857913000392
Loss at iteration [573]: 0.1940670825941512
Loss at iteration [574]: 0.19396989362853773
Loss at iteration [575]: 0.1939319287969899
Loss at iteration [576]: 0.1939319287969899
Loss at iteration [577]: 0.19391054723146384
Loss at iteration [578]: 0.19389626933360182
Loss at iteration [579]: 0.19383973994817885
Loss at iteration [580]: 0.19382947033557527
Loss at iteration [581]: 0.1938143823356042
Loss at iteration [582]: 0.1937830547665101
Loss at iteration [583]: 0.19374365509226027
Loss at iteration [584]: 0.19371875290927354
Loss at iteration [585]: 0.19367091997699545
Loss at iteration [586]: 0.19362002958144406
Loss at iteration [587]: 0.1936045753055554
Loss at iteration [588]: 0.19357340982246815
Loss at iteration [589]: 0.19356971184552313
Loss at iteration [590]: 0.19355522745724346
Loss at iteration [591]: 0.19355426488632904
Loss at iteration [592]: 0.1934997778454217
Loss at iteration [593]: 0.1934997778454217
Loss at iteration [594]: 0.19344519319852324
Loss at iteration [595]: 0.19343225870813313
Loss at iteration [596]: 0.19341226797995936
Loss at iteration [597]: 0.1933890989423153
Loss at iteration [598]: 0.19338013978411372
Loss at iteration [599]: 0.19334566958520924
Loss at iteration [600]: 0.19330413031231589
Loss at iteration [601]: 0.1932935305342766
Loss at iteration [602]: 0.1932746078936387
Loss at iteration [603]: 0.19327170640894498
Loss at iteration [604]: 0.19325584936242798
Loss at iteration [605]: 0.19321761118706138
Loss at iteration [606]: 0.1931290554270918
Loss at iteration [607]: 0.19307091194775464
Loss at iteration [608]: 0.19303617356320338
Loss at iteration [609]: 0.1929779220562658
Loss at iteration [610]: 0.1929056518807427
Loss at iteration [611]: 0.1929056518807427
Loss at iteration [612]: 0.1928772682424251
Loss at iteration [613]: 0.1928635518159605
Loss at iteration [614]: 0.19284451896327995
Loss at iteration [615]: 0.1928264109515073
Loss at iteration [616]: 0.19281041451566874
Loss at iteration [617]: 0.19280137119784937
Loss at iteration [618]: 0.19274648588811744
Loss at iteration [619]: 0.1927225623020733
Loss at iteration [620]: 0.1927186411444456
Loss at iteration [621]: 0.19267720144139158
Loss at iteration [622]: 0.19266388864154918
Loss at iteration [623]: 0.19265643118169426
Loss at iteration [624]: 0.19264565075064183
Loss at iteration [625]: 0.19263633413166595
Loss at iteration [626]: 0.19262456798518937
Loss at iteration [627]: 0.19260709451567365
Loss at iteration [628]: 0.19260709451567365
Loss at iteration [629]: 0.19260484099536312
Loss at iteration [630]: 0.19256960271147944
Loss at iteration [631]: 0.19255675371026068
Loss at iteration [632]: 0.19254661421983046
Loss at iteration [633]: 0.19252854081191054
Loss at iteration [634]: 0.19251097740116896
Loss at iteration [635]: 0.19249632551893472
Loss at iteration [636]: 0.19247991397843484
Loss at iteration [637]: 0.19242715214632128
Loss at iteration [638]: 0.19241217163916274
Loss at iteration [639]: 0.19239248252619143
Loss at iteration [640]: 0.19233297415594558
Loss at iteration [641]: 0.1922465966753532
Loss at iteration [642]: 0.1921927781682571
Loss at iteration [643]: 0.19217816274605926
Loss at iteration [644]: 0.1921635278669049
Loss at iteration [645]: 0.19208511200731
Loss at iteration [646]: 0.1920463651848741
Loss at iteration [647]: 0.1920463651848741
Loss at iteration [648]: 0.19204070072687668
Loss at iteration [649]: 0.19200650243439601
Loss at iteration [650]: 0.1919958483134565
Loss at iteration [651]: 0.19197067208312063
Loss at iteration [652]: 0.1919476750952255
Loss at iteration [653]: 0.19190554493109835
Loss at iteration [654]: 0.19188980457881583
Loss at iteration [655]: 0.19183829532654087
Loss at iteration [656]: 0.19169449720235163
Loss at iteration [657]: 0.19164650617064327
Loss at iteration [658]: 0.19160192511894109
Loss at iteration [659]: 0.19158032449492837
Loss at iteration [660]: 0.1914748578718828
Loss at iteration [661]: 0.191287480287218
Loss at iteration [662]: 0.1912363073944664
Loss at iteration [663]: 0.19121143213073435
Loss at iteration [664]: 0.19121143213073435
Loss at iteration [665]: 0.19119804795447964
Loss at iteration [666]: 0.19110624012154118
Loss at iteration [667]: 0.19104417846806815
Loss at iteration [668]: 0.19103373945055885
Loss at iteration [669]: 0.1909821486455244
Loss at iteration [670]: 0.19093013157240263
Loss at iteration [671]: 0.19087661271229286
Loss at iteration [672]: 0.1908378452362763
Loss at iteration [673]: 0.19076022056338024
Loss at iteration [674]: 0.19070866284972576
Loss at iteration [675]: 0.19065946440161505
Loss at iteration [676]: 0.19064636083007758
Loss at iteration [677]: 0.19054050757262198
Loss at iteration [678]: 0.1905159749037808
Loss at iteration [679]: 0.19049675535322966
Loss at iteration [680]: 0.19047077826807868
Loss at iteration [681]: 0.19047077826807868
Loss at iteration [682]: 0.19044441823794156
Loss at iteration [683]: 0.19043232657162948
Loss at iteration [684]: 0.1904015574164017
Loss at iteration [685]: 0.1903929829171877
Loss at iteration [686]: 0.19037646473449696
Loss at iteration [687]: 0.19034498256773275
Loss at iteration [688]: 0.1902799135551796
Loss at iteration [689]: 0.1902753531258955
Loss at iteration [690]: 0.1902519185509786
Loss at iteration [691]: 0.1902329868579735
Loss at iteration [692]: 0.19018632329515459
Loss at iteration [693]: 0.1901759706652938
Loss at iteration [694]: 0.19016939471339606
Loss at iteration [695]: 0.19011897285443888
Loss at iteration [696]: 0.1900581422898544
Loss at iteration [697]: 0.1900581422898544
Loss at iteration [698]: 0.19001750590861916
Loss at iteration [699]: 0.18998841627365406
Loss at iteration [700]: 0.1899710872840649
Loss at iteration [701]: 0.1899439284653411
Loss at iteration [702]: 0.18993266831168396
Loss at iteration [703]: 0.18992442090093858
Loss at iteration [704]: 0.18988814197719997
Loss at iteration [705]: 0.18987259093519215
Loss at iteration [706]: 0.1898715877379598
Loss at iteration [707]: 0.18985021856441484
Loss at iteration [708]: 0.1897662074648936
Loss at iteration [709]: 0.18954477396322697
Loss at iteration [710]: 0.18900126342060602
Loss at iteration [711]: 0.18665606328303241
Loss at iteration [712]: 0.18665606328303241
Loss at iteration [713]: 0.18637604463444546
Loss at iteration [714]: 0.18474794460723445
Loss at iteration [715]: 0.1835852896521872
Loss at iteration [716]: 0.18323433534674452
Loss at iteration [717]: 0.1827399761401222
Loss at iteration [718]: 0.18240589521130007
Loss at iteration [719]: 0.18228601221902474
Loss at iteration [720]: 0.1821640218742343
Loss at iteration [721]: 0.18204935895683355
Loss at iteration [722]: 0.18175329752738925
Loss at iteration [723]: 0.18175329752738925
Loss at iteration [724]: 0.18169634023906098
Loss at iteration [725]: 0.18148436534723608
Loss at iteration [726]: 0.18145385013638385
Loss at iteration [727]: 0.18133939113073916
Loss at iteration [728]: 0.18123739532677574
Loss at iteration [729]: 0.18107856252799398
Loss at iteration [730]: 0.18097518146076666
Loss at iteration [731]: 0.18068531242624444
Loss at iteration [732]: 0.18053934853313766
Loss at iteration [733]: 0.18053934853313766
Loss at iteration [734]: 0.18039980442716638
Loss at iteration [735]: 0.18027465194609885
Loss at iteration [736]: 0.18023200174203222
Loss at iteration [737]: 0.1801655585195975
Loss at iteration [738]: 0.18014959496624033
Loss at iteration [739]: 0.18011629034312923
Loss at iteration [740]: 0.1800595504270049
Loss at iteration [741]: 0.18005377759919997
Loss at iteration [742]: 0.18001137101111472
Loss at iteration [743]: 0.17995638644903028
Loss at iteration [744]: 0.17994663756614174
Loss at iteration [745]: 0.1798959146066606
Loss at iteration [746]: 0.17989186079104993
Loss at iteration [747]: 0.17989186079104993
Loss at iteration [748]: 0.1798695751415565
Loss at iteration [749]: 0.17986601975543057
Loss at iteration [750]: 0.1798589198226579
Loss at iteration [751]: 0.1798295567009884
Loss at iteration [752]: 0.17982647436494953
Loss at iteration [753]: 0.1797935045431799
Loss at iteration [754]: 0.17977905990517998
Loss at iteration [755]: 0.179772597969975
Loss at iteration [756]: 0.17973865981415535
Loss at iteration [757]: 0.17970622819547882
Loss at iteration [758]: 0.17970329109744776
Loss at iteration [759]: 0.17958173030465374
Loss at iteration [760]: 0.17956906641956935
Loss at iteration [761]: 0.1795221026216438
Loss at iteration [762]: 0.1795221026216438
Loss at iteration [763]: 0.17946453469294743
Loss at iteration [764]: 0.17945938169654946
Loss at iteration [765]: 0.17944837673902259
Loss at iteration [766]: 0.17942192460162404
Loss at iteration [767]: 0.17939260020469333
Loss at iteration [768]: 0.1793876798584051
Loss at iteration [769]: 0.17937553614437937
Loss at iteration [770]: 0.17933636638113165
Loss at iteration [771]: 0.17923141925264952
Loss at iteration [772]: 0.17910233200534786
Loss at iteration [773]: 0.1788171616499879
Loss at iteration [774]: 0.17872627459454468
Loss at iteration [775]: 0.17853586154172893
Loss at iteration [776]: 0.17850103497420955
Loss at iteration [777]: 0.17841626755242146
Loss at iteration [778]: 0.17841626755242146
Loss at iteration [779]: 0.17834137010777434
Loss at iteration [780]: 0.17833646087701266
Loss at iteration [781]: 0.17831284458515542
Loss at iteration [782]: 0.17827264296436712
Loss at iteration [783]: 0.17817701317573909
Loss at iteration [784]: 0.17813504600298852
Loss at iteration [785]: 0.17808777104831505
Loss at iteration [786]: 0.1780128662582513
Loss at iteration [787]: 0.17797416750033063
Loss at iteration [788]: 0.17791578052799242
Loss at iteration [789]: 0.17783855805627316
Loss at iteration [790]: 0.1778213312848386
Loss at iteration [791]: 0.17775775245041084
Loss at iteration [792]: 0.17775775245041084
Loss at iteration [793]: 0.1777496546109395
Loss at iteration [794]: 0.17774365467406555
Loss at iteration [795]: 0.17771661120178486
Loss at iteration [796]: 0.17766309650089054
Loss at iteration [797]: 0.17762521860042896
Loss at iteration [798]: 0.1775995472866786
Loss at iteration [799]: 0.1775151363280424
Loss at iteration [800]: 0.17747958166299657
Loss at iteration [801]: 0.17746188073322686
Loss at iteration [802]: 0.17743086977008862
Loss at iteration [803]: 0.1772851500181159
Loss at iteration [804]: 0.1769330960287454
Loss at iteration [805]: 0.17635365533281636
Loss at iteration [806]: 0.17600966985924246
Loss at iteration [807]: 0.17600966985924246
Loss at iteration [808]: 0.17585245660176996
Loss at iteration [809]: 0.17555629184247976
Loss at iteration [810]: 0.17548000045845805
Loss at iteration [811]: 0.1753306525526995
Loss at iteration [812]: 0.17530691818714272
Loss at iteration [813]: 0.17528936133752718
Loss at iteration [814]: 0.17515632615661023
Loss at iteration [815]: 0.1750933851346594
Loss at iteration [816]: 0.1750630746456093
Loss at iteration [817]: 0.17496611146525684
Loss at iteration [818]: 0.17485120431746992
Loss at iteration [819]: 0.17485120431746992
Loss at iteration [820]: 0.17477793562869984
Loss at iteration [821]: 0.17476158678896442
Loss at iteration [822]: 0.1747014356718938
Loss at iteration [823]: 0.17465690046922153
Loss at iteration [824]: 0.17460121173717763
Loss at iteration [825]: 0.17459184006223016
Loss at iteration [826]: 0.17453497644159544
Loss at iteration [827]: 0.17453479758596616
Loss at iteration [828]: 0.17447811768181667
Loss at iteration [829]: 0.17445042390309112
Loss at iteration [830]: 0.1744375353513835
Loss at iteration [831]: 0.17440475349263468
Loss at iteration [832]: 0.17434213359962095
Loss at iteration [833]: 0.17434006052824627
Loss at iteration [834]: 0.17434006052824627
Loss at iteration [835]: 0.17432131597834377
Loss at iteration [836]: 0.1743191706596504
Loss at iteration [837]: 0.17431079736882527
Loss at iteration [838]: 0.17426208224193893
Loss at iteration [839]: 0.17426169464005822
Loss at iteration [840]: 0.17425524253835628
Loss at iteration [841]: 0.1741801773053669
Loss at iteration [842]: 0.1741492720293148
Loss at iteration [843]: 0.17407633642875495
Loss at iteration [844]: 0.17406271638296306
Loss at iteration [845]: 0.1740178709806968
Loss at iteration [846]: 0.1740046374428221
Loss at iteration [847]: 0.17398577634518367
Loss at iteration [848]: 0.17394462715728173
Loss at iteration [849]: 0.1738864613529603
Loss at iteration [850]: 0.17381985926429358
Loss at iteration [851]: 0.17381985926429358
Loss at iteration [852]: 0.17373614782133154
Loss at iteration [853]: 0.17371681835119807
Loss at iteration [854]: 0.1736975753859131
Loss at iteration [855]: 0.17367975354540044
Loss at iteration [856]: 0.17363385715953544
Loss at iteration [857]: 0.17361628875078977
Loss at iteration [858]: 0.17360100436292286
Loss at iteration [859]: 0.17358618418033875
Loss at iteration [860]: 0.17357285014984158
Loss at iteration [861]: 0.17354118441040314
Loss at iteration [862]: 0.17351510961112837
Loss at iteration [863]: 0.17348193408772006
Loss at iteration [864]: 0.17346268910674068
Loss at iteration [865]: 0.17344626428155807
Loss at iteration [866]: 0.17343363616913787
Loss at iteration [867]: 0.17342691753295003
Loss at iteration [868]: 0.17340625186559105
Loss at iteration [869]: 0.17336793192686045
Loss at iteration [870]: 0.17336793192686045
Loss at iteration [871]: 0.17336045565033822
Loss at iteration [872]: 0.1733181413687494
Loss at iteration [873]: 0.17330379069757632
Loss at iteration [874]: 0.1732947012215696
Loss at iteration [875]: 0.17326649578716874
Loss at iteration [876]: 0.17321211909825782
Loss at iteration [877]: 0.17318303309534963
Loss at iteration [878]: 0.1731575646822614
Loss at iteration [879]: 0.17313517637156298
Loss at iteration [880]: 0.1730482843243745
Loss at iteration [881]: 0.17302622054974892
Loss at iteration [882]: 0.1729882222320928
Loss at iteration [883]: 0.1729296672598079
Loss at iteration [884]: 0.17285451886764333
Loss at iteration [885]: 0.17285451886764333
Loss at iteration [886]: 0.1728270677733468
Loss at iteration [887]: 0.1727940162080275
Loss at iteration [888]: 0.1727805775720401
Loss at iteration [889]: 0.17271414071732172
Loss at iteration [890]: 0.1726676793397766
Loss at iteration [891]: 0.1726664086373443
Loss at iteration [892]: 0.17261968818243603
Loss at iteration [893]: 0.17257400763818123
Loss at iteration [894]: 0.17253936687839583
Loss at iteration [895]: 0.1725344893592648
Loss at iteration [896]: 0.17243090733759836
Loss at iteration [897]: 0.17237162115352742
Loss at iteration [898]: 0.17237162115352742
Loss at iteration [899]: 0.17234540244892455
Loss at iteration [900]: 0.17233881120652939
Loss at iteration [901]: 0.17229533955454004
Loss at iteration [902]: 0.1722787906639139
Loss at iteration [903]: 0.17227403733645327
Loss at iteration [904]: 0.17226581942758085
Loss at iteration [905]: 0.17221854657633548
Loss at iteration [906]: 0.17217218258514835
Loss at iteration [907]: 0.17214595707830055
Loss at iteration [908]: 0.17203677911878112
Loss at iteration [909]: 0.172007502388761
Loss at iteration [910]: 0.17191777364235233
Loss at iteration [911]: 0.17185988004734798
Loss at iteration [912]: 0.17185988004734798
Loss at iteration [913]: 0.1717185917897533
Loss at iteration [914]: 0.17166580721083521
Loss at iteration [915]: 0.17164889794368354
Loss at iteration [916]: 0.17161695957765122
Loss at iteration [917]: 0.17158181456444235
Loss at iteration [918]: 0.17155862599697597
Loss at iteration [919]: 0.1715367375798541
Loss at iteration [920]: 0.17150540707231246
Loss at iteration [921]: 0.17149917780452045
Loss at iteration [922]: 0.1714508136976879
Loss at iteration [923]: 0.17141647462505866
Loss at iteration [924]: 0.17137963661731329
Loss at iteration [925]: 0.1713032168743095
Loss at iteration [926]: 0.1712798872497863
Loss at iteration [927]: 0.17125953063921104
Loss at iteration [928]: 0.17125953063921104
Loss at iteration [929]: 0.17121891968806557
Loss at iteration [930]: 0.1712011516266021
Loss at iteration [931]: 0.1711900429571283
Loss at iteration [932]: 0.17117364519145314
Loss at iteration [933]: 0.17115424600142615
Loss at iteration [934]: 0.17113227835660677
Loss at iteration [935]: 0.17109668550146045
Loss at iteration [936]: 0.1710587236160494
Loss at iteration [937]: 0.17093614874945776
Loss at iteration [938]: 0.1708350449032927
Loss at iteration [939]: 0.17057529993088882
Loss at iteration [940]: 0.17029343953419873
Loss at iteration [941]: 0.1697360381759474
Loss at iteration [942]: 0.16885779354159047
Loss at iteration [943]: 0.16885779354159047
Loss at iteration [944]: 0.16843565565488713
Loss at iteration [945]: 0.1679268838898954
Loss at iteration [946]: 0.16788150228665874
Loss at iteration [947]: 0.16781783798199873
Loss at iteration [948]: 0.16777280795483268
Loss at iteration [949]: 0.1677224391994683
Loss at iteration [950]: 0.16770938485473066
Loss at iteration [951]: 0.16764917040582417
Loss at iteration [952]: 0.16757894626171962
Loss at iteration [953]: 0.16755040859821008
Loss at iteration [954]: 0.16748878675152037
Loss at iteration [955]: 0.16741450388365153
Loss at iteration [956]: 0.1673543307171351
Loss at iteration [957]: 0.1673001877070488
Loss at iteration [958]: 0.1673001877070488
Loss at iteration [959]: 0.1672963307382662
Loss at iteration [960]: 0.16727378781315094
Loss at iteration [961]: 0.1672514696939021
Loss at iteration [962]: 0.16720104309442554
Loss at iteration [963]: 0.16716132435469577
Loss at iteration [964]: 0.16713758809235132
Loss at iteration [965]: 0.16713339477638264
Loss at iteration [966]: 0.16707436037978085
Loss at iteration [967]: 0.16702755748513606
Loss at iteration [968]: 0.16701260026888204
Loss at iteration [969]: 0.1669875135658093
Loss at iteration [970]: 0.16683928131718634
Loss at iteration [971]: 0.16681370291230513
Loss at iteration [972]: 0.16666799034416693
Loss at iteration [973]: 0.16666799034416693
Loss at iteration [974]: 0.16660963288902106
Loss at iteration [975]: 0.166603999735362
Loss at iteration [976]: 0.1665926238306231
Loss at iteration [977]: 0.16657653040989184
Loss at iteration [978]: 0.16651111152456816
Loss at iteration [979]: 0.1664954225733001
Loss at iteration [980]: 0.1664074153809543
Loss at iteration [981]: 0.16637552100521016
Loss at iteration [982]: 0.1663515673179596
Loss at iteration [983]: 0.1663351658337833
Loss at iteration [984]: 0.1662807956219315
Loss at iteration [985]: 0.1662291200238817
Loss at iteration [986]: 0.16621034934367376
Loss at iteration [987]: 0.16614401336446524
Loss at iteration [988]: 0.1660924202612028
Loss at iteration [989]: 0.1660924202612028
Loss at iteration [990]: 0.16604666854665456
Loss at iteration [991]: 0.16603593046915852
Loss at iteration [992]: 0.16601694836994887
Loss at iteration [993]: 0.16598762336838632
Loss at iteration [994]: 0.16597940818146045
Loss at iteration [995]: 0.16594537125731984
Loss at iteration [996]: 0.1659178554429492
Loss at iteration [997]: 0.16590939951651035
Loss at iteration [998]: 0.16589166332125685
Loss at iteration [999]: 0.1658117146263748
Loss at iteration [1000]: 0.16578300608103314
Loss at iteration [1001]: 0.16575633425228006
Loss at iteration [1002]: 0.165694143479972
Loss at iteration [1003]: 0.16564792484693752
Loss at iteration [1004]: 0.16543922754751633
Loss at iteration [1005]: 0.16543922754751633
Loss at iteration [1006]: 0.16529428886856745
Loss at iteration [1007]: 0.16526778933567884
Loss at iteration [1008]: 0.1651484969899713
Loss at iteration [1009]: 0.16511521152704026
Loss at iteration [1010]: 0.16509625912030892
Loss at iteration [1011]: 0.1650635016765279
Loss at iteration [1012]: 0.16500239322130641
Loss at iteration [1013]: 0.1649839650405769
Loss at iteration [1014]: 0.16494786085747848
Loss at iteration [1015]: 0.16494137307303172
Loss at iteration [1016]: 0.16493071541398582
Loss at iteration [1017]: 0.16492375031255666
Loss at iteration [1018]: 0.16489985863433015
Loss at iteration [1019]: 0.16486274264165798
Loss at iteration [1020]: 0.16486274264165798
Loss at iteration [1021]: 0.1648191863691113
Loss at iteration [1022]: 0.16480297249703277
Loss at iteration [1023]: 0.16478167175526626
Loss at iteration [1024]: 0.16477549340987258
Loss at iteration [1025]: 0.16476883824975563
Loss at iteration [1026]: 0.16475938161936096
Loss at iteration [1027]: 0.16472124153291168
Loss at iteration [1028]: 0.16470398811482803
Loss at iteration [1029]: 0.1646652788521204
Loss at iteration [1030]: 0.16464627315709823
Loss at iteration [1031]: 0.16462069186982436
Loss at iteration [1032]: 0.16460242092595417
Loss at iteration [1033]: 0.16456026935755633
Loss at iteration [1034]: 0.16447676672078554
Loss at iteration [1035]: 0.16411303353737183
Loss at iteration [1036]: 0.16378445285526538
Loss at iteration [1037]: 0.16299180799318
Loss at iteration [1038]: 0.16299180799318
Loss at iteration [1039]: 0.16248648970594337
Loss at iteration [1040]: 0.16237138070361387
Loss at iteration [1041]: 0.1623354256632349
Loss at iteration [1042]: 0.16229463071520844
Loss at iteration [1043]: 0.16214993004759917
Loss at iteration [1044]: 0.1620609963955931
Loss at iteration [1045]: 0.16202656978504312
Loss at iteration [1046]: 0.16196548959934054
Loss at iteration [1047]: 0.161860292860023
Loss at iteration [1048]: 0.16181606536608054
