Model name                            : MLP
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : Adam
Learning rate                         : 0.0001
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 9.460623979568481
Total number of parameters            : 101001
Percentage of parameters < 1e-9       : 49.444064910248414%
Percentage of parameters < 1e-7       : 49.444064910248414%
Percentage of parameters < 1e-6       : 49.444064910248414%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.0157130643024872
Loss at iteration [2]: 0.9897846869623547
Loss at iteration [3]: 0.9648909272592662
Loss at iteration [4]: 0.9410009463867761
Loss at iteration [5]: 0.9174845687032208
Loss at iteration [6]: 0.8942908793323027
Loss at iteration [7]: 0.8715369654820807
Loss at iteration [8]: 0.8494348694736398
Loss at iteration [9]: 0.8278460105678677
Loss at iteration [10]: 0.8066586940959896
Loss at iteration [11]: 0.7858366129764304
Loss at iteration [12]: 0.7651819553295283
Loss at iteration [13]: 0.7447192163784292
Loss at iteration [14]: 0.7244729404745762
Loss at iteration [15]: 0.704482884897017
Loss at iteration [16]: 0.6847449048668653
Loss at iteration [17]: 0.6656655001907333
Loss at iteration [18]: 0.6470178203884747
Loss at iteration [19]: 0.628476135615063
Loss at iteration [20]: 0.610068217504404
Loss at iteration [21]: 0.5918481452493435
Loss at iteration [22]: 0.5738127002008558
Loss at iteration [23]: 0.5559187867459676
Loss at iteration [24]: 0.5381472784974229
Loss at iteration [25]: 0.5204874165531547
Loss at iteration [26]: 0.5029101750205728
Loss at iteration [27]: 0.48544009384530734
Loss at iteration [28]: 0.46813226350275206
Loss at iteration [29]: 0.45102371339755515
Loss at iteration [30]: 0.434078931455421
Loss at iteration [31]: 0.41731729906642034
Loss at iteration [32]: 0.4007347429026291
Loss at iteration [33]: 0.3843310421153369
Loss at iteration [34]: 0.3681357069111344
Loss at iteration [35]: 0.3521836215622442
Loss at iteration [36]: 0.33646741505662586
Loss at iteration [37]: 0.3209925319239638
Loss at iteration [38]: 0.3057649257830989
Loss at iteration [39]: 0.29081093499410504
Loss at iteration [40]: 0.2761495585784995
Loss at iteration [41]: 0.26178059994838054
Loss at iteration [42]: 0.24771141294216323
Loss at iteration [43]: 0.23395384672868727
Loss at iteration [44]: 0.22052109692304317
Loss at iteration [45]: 0.20744057759186718
Loss at iteration [46]: 0.19472811005658464
Loss at iteration [47]: 0.18240027988958446
Loss at iteration [48]: 0.1704668586406763
Loss at iteration [49]: 0.15894982084794634
Loss at iteration [50]: 0.14786541759131644
Loss at iteration [51]: 0.1372195645802555
Loss at iteration [52]: 0.12701822865917894
Loss at iteration [53]: 0.117274414389283
Loss at iteration [54]: 0.10799602316748615
Loss at iteration [55]: 0.0991887352320528
Loss at iteration [56]: 0.09085761908382513
Loss at iteration [57]: 0.08300540212112015
Loss at iteration [58]: 0.07563465314215777
Loss at iteration [59]: 0.06874473400256548
Loss at iteration [60]: 0.062333788662484825
Loss at iteration [61]: 0.05639707837766514
Loss at iteration [62]: 0.0509256725583955
Loss at iteration [63]: 0.045908883239741786
Loss at iteration [64]: 0.04133486560547306
Loss at iteration [65]: 0.0371886634187786
Loss at iteration [66]: 0.033452886720098905
Loss at iteration [67]: 0.03010910717391088
Loss at iteration [68]: 0.02713770587081886
Loss at iteration [69]: 0.024516194192739454
Loss at iteration [70]: 0.02221999337918894
Loss at iteration [71]: 0.02022501328141906
Loss at iteration [72]: 0.01850569062171591
Loss at iteration [73]: 0.017034022666273074
Loss at iteration [74]: 0.01578481590829748
Loss at iteration [75]: 0.014733451023643498
Loss at iteration [76]: 0.013854320909802976
Loss at iteration [77]: 0.013121765128201901
Loss at iteration [78]: 0.012511159606291252
Loss at iteration [79]: 0.012002384996137667
Loss at iteration [80]: 0.01157731362371067
Loss at iteration [81]: 0.011212376861874668
Loss at iteration [82]: 0.010891059690693873
Loss at iteration [83]: 0.010598828535682532
Loss at iteration [84]: 0.010325149081189155
Loss at iteration [85]: 0.010058780486141809
Loss at iteration [86]: 0.009793368169392924
Loss at iteration [87]: 0.009525891567604297
Loss at iteration [88]: 0.009262803730576138
Loss at iteration [89]: 0.009002715845360559
Loss at iteration [90]: 0.00873801949224511
Loss at iteration [91]: 0.00846908711868733
Loss at iteration [92]: 0.008199677678967189
Loss at iteration [93]: 0.007932137444594138
Loss at iteration [94]: 0.007668385731542952
Loss at iteration [95]: 0.007411126910876688
Loss at iteration [96]: 0.007166923988383615
Loss at iteration [97]: 0.006949998631364762
Loss at iteration [98]: 0.0067484348580703546
Loss at iteration [99]: 0.006565210444521496
Loss at iteration [100]: 0.0063969979948593795
Loss at iteration [101]: 0.00623929083342347
Loss at iteration [102]: 0.006097979346576022
Loss at iteration [103]: 0.005967952199933453
Loss at iteration [104]: 0.0058394802982842066
Loss at iteration [105]: 0.005713142394464108
Loss at iteration [106]: 0.005589675262127401
Loss at iteration [107]: 0.00546787598419177
Loss at iteration [108]: 0.005346112748404265
Loss at iteration [109]: 0.005224087481379151
Loss at iteration [110]: 0.005102040649867733
Loss at iteration [111]: 0.004981575580025601
Loss at iteration [112]: 0.004862919751416533
Loss at iteration [113]: 0.004748057667048408
Loss at iteration [114]: 0.004639655405215255
Loss at iteration [115]: 0.004538590523894987
Loss at iteration [116]: 0.004444153330758265
Loss at iteration [117]: 0.00435888424710555
Loss at iteration [118]: 0.004283041581125895
Loss at iteration [119]: 0.004213555335866593
Loss at iteration [120]: 0.004147742545932716
Loss at iteration [121]: 0.004085083176698424
Loss at iteration [122]: 0.004024746891544219
Loss at iteration [123]: 0.003969433224025547
Loss at iteration [124]: 0.003918608599426874
Loss at iteration [125]: 0.0038704434852067904
Loss at iteration [126]: 0.003824095813087856
Loss at iteration [127]: 0.0037788152693336297
Loss at iteration [128]: 0.0037350502214499107
Loss at iteration [129]: 0.003693379203254722
Loss at iteration [130]: 0.0036532506761241196
Loss at iteration [131]: 0.0036147903572904794
Loss at iteration [132]: 0.0035780076500966157
Loss at iteration [133]: 0.0035434165848307
Loss at iteration [134]: 0.003511223538866825
Loss at iteration [135]: 0.003480595781511405
Loss at iteration [136]: 0.003450752939716398
Loss at iteration [137]: 0.003421663477790381
Loss at iteration [138]: 0.0033933811722945176
Loss at iteration [139]: 0.0033660528237967205
Loss at iteration [140]: 0.0033397307344961145
Loss at iteration [141]: 0.003314490615190278
Loss at iteration [142]: 0.0032906424665079858
Loss at iteration [143]: 0.0032680349564406155
Loss at iteration [144]: 0.003246679955590707
Loss at iteration [145]: 0.003226403888757447
Loss at iteration [146]: 0.0032070183259275417
Loss at iteration [147]: 0.003188512827541035
Loss at iteration [148]: 0.0031708044670019316
Loss at iteration [149]: 0.0031538473101610605
Loss at iteration [150]: 0.003137662141267293
Loss at iteration [151]: 0.0031220533216115933
Loss at iteration [152]: 0.0031069124175229033
Loss at iteration [153]: 0.0030921715708317034
Loss at iteration [154]: 0.0030778412035432617
Loss at iteration [155]: 0.0030639586678613017
Loss at iteration [156]: 0.0030507319289380446
Loss at iteration [157]: 0.0030381659130615897
Loss at iteration [158]: 0.0030260627272892045
Loss at iteration [159]: 0.003014415597499696
Loss at iteration [160]: 0.003003245523532349
Loss at iteration [161]: 0.002992440038253563
Loss at iteration [162]: 0.002981994904210373
Loss at iteration [163]: 0.0029718369417572835
Loss at iteration [164]: 0.0029619813845144912
Loss at iteration [165]: 0.0029523725448588403
Loss at iteration [166]: 0.002943016549738269
Loss at iteration [167]: 0.0029339210605800283
Loss at iteration [168]: 0.0029250722354378375
Loss at iteration [169]: 0.002916471699851605
Loss at iteration [170]: 0.002908153422375607
Loss at iteration [171]: 0.002900141201646511
Loss at iteration [172]: 0.002892408313046874
Loss at iteration [173]: 0.0028849642790506184
Loss at iteration [174]: 0.002877763047895365
Loss at iteration [175]: 0.0028707366227243222
Loss at iteration [176]: 0.002863836014147481
Loss at iteration [177]: 0.0028571086705458486
Loss at iteration [178]: 0.002850559784000888
Loss at iteration [179]: 0.0028442182252924166
Loss at iteration [180]: 0.00283805154555065
Loss at iteration [181]: 0.002832070320312153
Loss at iteration [182]: 0.0028262344765018627
Loss at iteration [183]: 0.0028205471621038708
Loss at iteration [184]: 0.00281503041958889
Loss at iteration [185]: 0.0028096662411431386
Loss at iteration [186]: 0.0028044368436624307
Loss at iteration [187]: 0.0027993315841603156
Loss at iteration [188]: 0.0027943403684580087
Loss at iteration [189]: 0.0027894690266047134
Loss at iteration [190]: 0.0027847213574285798
Loss at iteration [191]: 0.0027801140594068577
Loss at iteration [192]: 0.0027755997953408363
Loss at iteration [193]: 0.002771167470392086
Loss at iteration [194]: 0.002766811730421718
Loss at iteration [195]: 0.0027625537064129976
Loss at iteration [196]: 0.002758383779527926
Loss at iteration [197]: 0.0027542933238304977
Loss at iteration [198]: 0.002750268616946307
Loss at iteration [199]: 0.0027463037103227688
Loss at iteration [200]: 0.0027424124343196107
Loss at iteration [201]: 0.0027385837329548706
Loss at iteration [202]: 0.002734800226714975
Loss at iteration [203]: 0.0027310871440904467
Loss at iteration [204]: 0.002727454045110981
Loss at iteration [205]: 0.002723903857106022
Loss at iteration [206]: 0.0027204164900602153
Loss at iteration [207]: 0.002716970677822628
Loss at iteration [208]: 0.002713555203408774
Loss at iteration [209]: 0.0027102096938718635
Loss at iteration [210]: 0.002706917009369576
Loss at iteration [211]: 0.0027036652568083255
Loss at iteration [212]: 0.0027005006511074472
Loss at iteration [213]: 0.0026974240931524115
Loss at iteration [214]: 0.00269440254879747
Loss at iteration [215]: 0.00269140687553892
Loss at iteration [216]: 0.002688473901528561
Loss at iteration [217]: 0.0026855807714781595
Loss at iteration [218]: 0.0026827260470333853
Loss at iteration [219]: 0.0026799494594235184
Loss at iteration [220]: 0.0026772179912347887
Loss at iteration [221]: 0.002674525527577976
Loss at iteration [222]: 0.0026718775923611584
Loss at iteration [223]: 0.0026692924006872726
Loss at iteration [224]: 0.0026667724504434542
Loss at iteration [225]: 0.002664291651605955
Loss at iteration [226]: 0.0026618875123513757
Loss at iteration [227]: 0.002659544848348264
Loss at iteration [228]: 0.0026572284355282265
Loss at iteration [229]: 0.002654942248412686
Loss at iteration [230]: 0.0026526883313384023
Loss at iteration [231]: 0.002650461777690727
Loss at iteration [232]: 0.002648262489076442
Loss at iteration [233]: 0.002646101773813961
Loss at iteration [234]: 0.0026439940724878215
Loss at iteration [235]: 0.0026419197178182722
Loss at iteration [236]: 0.002639880512545324
Loss at iteration [237]: 0.0026378570607313665
Loss at iteration [238]: 0.0026358795837844017
Loss at iteration [239]: 0.0026339690045494896
Loss at iteration [240]: 0.002632086189736672
Loss at iteration [241]: 0.0026302316310819495
Loss at iteration [242]: 0.0026283974287849426
Loss at iteration [243]: 0.0026265853933345826
Loss at iteration [244]: 0.0026248207736918544
Loss at iteration [245]: 0.00262309253541458
Loss at iteration [246]: 0.002621406598284714
Loss at iteration [247]: 0.002619747959998755
Loss at iteration [248]: 0.0026181267378826015
Loss at iteration [249]: 0.0026165515923566893
Loss at iteration [250]: 0.0026149997637567135
Loss at iteration [251]: 0.002613453886394057
Loss at iteration [252]: 0.0026119326439231604
Loss at iteration [253]: 0.0026104384411420037
Loss at iteration [254]: 0.0026089613712110054
Loss at iteration [255]: 0.0026075501248176043
Loss at iteration [256]: 0.0026061599001450755
Loss at iteration [257]: 0.002604786398498601
Loss at iteration [258]: 0.0026034484220845196
Loss at iteration [259]: 0.0026021490102266266
Loss at iteration [260]: 0.0026008642965070594
Loss at iteration [261]: 0.0025996044220107963
Loss at iteration [262]: 0.002598366854269684
Loss at iteration [263]: 0.0025971452538667552
Loss at iteration [264]: 0.0025959367913646406
Loss at iteration [265]: 0.002594733771015736
Loss at iteration [266]: 0.002593542123088105
Loss at iteration [267]: 0.0025923755340309168
Loss at iteration [268]: 0.002591214557547094
Loss at iteration [269]: 0.0025900719521935
Loss at iteration [270]: 0.0025889450345707
Loss at iteration [271]: 0.002587826743836726
Loss at iteration [272]: 0.0025867277801482173
Loss at iteration [273]: 0.0025856414123553552
Loss at iteration [274]: 0.0025845763670458355
Loss at iteration [275]: 0.0025835255042972157
Loss at iteration [276]: 0.0025824782511352836
Loss at iteration [277]: 0.002581465781697466
Loss at iteration [278]: 0.0025804670964285526
Loss at iteration [279]: 0.0025794774547842226
Loss at iteration [280]: 0.0025784990076958853
Loss at iteration [281]: 0.0025775244890383435
Loss at iteration [282]: 0.002576561628067625
Loss at iteration [283]: 0.0025756099432222993
Loss at iteration [284]: 0.0025746715750961055
Loss at iteration [285]: 0.002573745823026953
Loss at iteration [286]: 0.0025728360251171876
Loss at iteration [287]: 0.0025719365719896674
Loss at iteration [288]: 0.0025710479594628155
Loss at iteration [289]: 0.002570176968298228
Loss at iteration [290]: 0.002569325837838692
Loss at iteration [291]: 0.0025684899042299173
Loss at iteration [292]: 0.002567665425434624
Loss at iteration [293]: 0.0025652945231935936
Loss at iteration [294]: 0.002561925972596335
Loss at iteration [295]: 0.0025587659379637784
Loss at iteration [296]: 0.0025584714627511647
Loss at iteration [297]: 0.0025582779036910598
Loss at iteration [298]: 0.0025571810138954663
Loss at iteration [299]: 0.0025556017408372056
Loss at iteration [300]: 0.0025541099396992834
Loss at iteration [301]: 0.002553045964190182
Loss at iteration [302]: 0.0025524027292073213
Loss at iteration [303]: 0.0025516988374657944
Loss at iteration [304]: 0.0025506068111118174
Loss at iteration [305]: 0.0025494530583272113
Loss at iteration [306]: 0.0025483293955222987
Loss at iteration [307]: 0.002547314660683738
Loss at iteration [308]: 0.002546526707499176
Loss at iteration [309]: 0.0025457385989748884
Loss at iteration [310]: 0.00254485833738055
Loss at iteration [311]: 0.0025438445096434303
Loss at iteration [312]: 0.0025429581062316273
Loss at iteration [313]: 0.002542045174237233
Loss at iteration [314]: 0.0025411763479282878
Loss at iteration [315]: 0.002540462047283362
Loss at iteration [316]: 0.0025396541838473216
Loss at iteration [317]: 0.0025387232065173563
Loss at iteration [318]: 0.0025379563798957
Loss at iteration [319]: 0.0025372156006916078
Loss at iteration [320]: 0.0025364689769255856
Loss at iteration [321]: 0.002535707335182912
Loss at iteration [322]: 0.0025349264335831232
Loss at iteration [323]: 0.0025341534050718614
Loss at iteration [324]: 0.002533502105131237
Loss at iteration [325]: 0.0025328071581727602
Loss at iteration [326]: 0.0025320454285833855
Loss at iteration [327]: 0.002531405990302559
Loss at iteration [328]: 0.0025307764554072074
Loss at iteration [329]: 0.002530119833800151
Loss at iteration [330]: 0.0025294399615855413
Loss at iteration [331]: 0.0025288542906778105
Loss at iteration [332]: 0.0025282620725105625
Loss at iteration [333]: 0.0025276102396354755
Loss at iteration [334]: 0.0025269928587992848
Loss at iteration [335]: 0.0025264538201209626
Loss at iteration [336]: 0.0025258702652102226
Loss at iteration [337]: 0.002525243419356707
Loss at iteration [338]: 0.002524676381685575
Loss at iteration [339]: 0.0025241716977554385
Loss at iteration [340]: 0.002523618080824307
Loss at iteration [341]: 0.0025230273141671196
Loss at iteration [342]: 0.002522478814779498
Loss at iteration [343]: 0.002521969736916271
Loss at iteration [344]: 0.002521442134462022
Loss at iteration [345]: 0.00252091093720376
Loss at iteration [346]: 0.002520424754571908
Loss at iteration [347]: 0.0025199348649924277
Loss at iteration [348]: 0.0025194380447280465
Loss at iteration [349]: 0.002518953963693362
Loss at iteration [350]: 0.002518506320029435
Loss at iteration [351]: 0.0025180169809207644
Loss at iteration [352]: 0.0025175530264488774
Loss at iteration [353]: 0.0025171035391833517
Loss at iteration [354]: 0.0025166509604161217
Loss at iteration [355]: 0.002516208800426754
Loss at iteration [356]: 0.0025157689025053975
Loss at iteration [357]: 0.002515334099287395
Loss at iteration [358]: 0.002514905675698759
Loss at iteration [359]: 0.0025144890795830784
Loss at iteration [360]: 0.0025140717513821194
Loss at iteration [361]: 0.00251368306953952
Loss at iteration [362]: 0.0025132689552147956
Loss at iteration [363]: 0.002512871320043569
Loss at iteration [364]: 0.0025124711199206013
Loss at iteration [365]: 0.002512071189538898
Loss at iteration [366]: 0.0025116717641864386
Loss at iteration [367]: 0.002511274925600126
Loss at iteration [368]: 0.002510885158148348
Loss at iteration [369]: 0.0025104961442894576
Loss at iteration [370]: 0.002510110746040304
Loss at iteration [371]: 0.0025097453189299092
Loss at iteration [372]: 0.0025093644005491373
Loss at iteration [373]: 0.002508973633967612
Loss at iteration [374]: 0.002508613527512167
Loss at iteration [375]: 0.0025082518969836817
Loss at iteration [376]: 0.002507885961061216
Loss at iteration [377]: 0.0025075165887467957
Loss at iteration [378]: 0.00250714319023984
Loss at iteration [379]: 0.0025067722416418476
Loss at iteration [380]: 0.002506421931417126
Loss at iteration [381]: 0.0025060658439404423
Loss at iteration [382]: 0.0025057042433963917
Loss at iteration [383]: 0.002505362300549092
Loss at iteration [384]: 0.0025050180702193415
Loss at iteration [385]: 0.002504667266575597
Loss at iteration [386]: 0.002504309299383249
Loss at iteration [387]: 0.0025039854708233346
Loss at iteration [388]: 0.002503659713529872
Loss at iteration [389]: 0.002503321656908286
Loss at iteration [390]: 0.0025029787183603177
Loss at iteration [391]: 0.0025026512685599185
Loss at iteration [392]: 0.002502333341935967
Loss at iteration [393]: 0.0025020011373529986
Loss at iteration [394]: 0.0025016658525599147
Loss at iteration [395]: 0.0025013566007980356
Loss at iteration [396]: 0.002501044644368497
Loss at iteration [397]: 0.0025007237708611824
Loss at iteration [398]: 0.0025003984029392744
Loss at iteration [399]: 0.002500073284679883
Loss at iteration [400]: 0.002499769992252514
Loss at iteration [401]: 0.002499478031653672
Loss at iteration [402]: 0.0024991431007182706
Loss at iteration [403]: 0.0024988512106606437
Loss at iteration [404]: 0.0024985555710296814
Loss at iteration [405]: 0.0024982575302035406
Loss at iteration [406]: 0.0024979546565187098
Loss at iteration [407]: 0.002497652351158573
Loss at iteration [408]: 0.0024973731097346495
Loss at iteration [409]: 0.002497067440779677
Loss at iteration [410]: 0.002496781095237237
Loss at iteration [411]: 0.0024964959963085214
Loss at iteration [412]: 0.0024962092156379646
Loss at iteration [413]: 0.00249592103320831
Loss at iteration [414]: 0.002495650675307104
Loss at iteration [415]: 0.0024953591722909987
Loss at iteration [416]: 0.0024950775154360303
Loss at iteration [417]: 0.002494805793611042
Loss at iteration [418]: 0.0024945273876584273
Loss at iteration [419]: 0.0024942474654745346
Loss at iteration [420]: 0.0024939626637465223
Loss at iteration [421]: 0.0024936803671900872
Loss at iteration [422]: 0.0024934317275219714
Loss at iteration [423]: 0.0024931532949395777
Loss at iteration [424]: 0.0024928520321323773
Loss at iteration [425]: 0.0024925827675310705
Loss at iteration [426]: 0.0024923111173577096
Loss at iteration [427]: 0.002492036614036662
Loss at iteration [428]: 0.002491757831793724
Loss at iteration [429]: 0.0024915057349807223
Loss at iteration [430]: 0.0024912273509733454
Loss at iteration [431]: 0.0024909476465847097
Loss at iteration [432]: 0.00249068533650398
Loss at iteration [433]: 0.0024904139839093853
Loss at iteration [434]: 0.002490131999558092
Loss at iteration [435]: 0.0024898847188820888
Loss at iteration [436]: 0.0024896203353308153
Loss at iteration [437]: 0.0024893329702947
Loss at iteration [438]: 0.0024890786076508698
Loss at iteration [439]: 0.0024888224178320575
Loss at iteration [440]: 0.0024885574576941263
Loss at iteration [441]: 0.0024882831598529256
Loss at iteration [442]: 0.0024880255959678767
Loss at iteration [443]: 0.0024877742363823576
Loss at iteration [444]: 0.0024875065026456382
Loss at iteration [445]: 0.0024872540926514607
Loss at iteration [446]: 0.0024870098103149485
Loss at iteration [447]: 0.0024867556933713644
Loss at iteration [448]: 0.002486497695930484
Loss at iteration [449]: 0.002486254469308751
Loss at iteration [450]: 0.002486011205540367
Loss at iteration [451]: 0.0024857549832207485
Loss at iteration [452]: 0.002485515362264142
Loss at iteration [453]: 0.0024852730123662544
Loss at iteration [454]: 0.0024850386313098284
Loss at iteration [455]: 0.002484797581716984
Loss at iteration [456]: 0.0024845786287462186
Loss at iteration [457]: 0.002484352847084627
Loss at iteration [458]: 0.0024841182528501787
Loss at iteration [459]: 0.0024838776658524997
Loss at iteration [460]: 0.002483668973336024
Loss at iteration [461]: 0.0024834426354529166
Loss at iteration [462]: 0.0024831956601032356
Loss at iteration [463]: 0.002482988182139655
Loss at iteration [464]: 0.0024827765501983716
Loss at iteration [465]: 0.002482554927091321
Loss at iteration [466]: 0.0024823232414123274
Loss at iteration [467]: 0.00248208411577519
Loss at iteration [468]: 0.0024818471819919225
Loss at iteration [469]: 0.0024816569175518666
Loss at iteration [470]: 0.0024814393337629454
Loss at iteration [471]: 0.0024811943816528603
Loss at iteration [472]: 0.0024809675396316746
Loss at iteration [473]: 0.0024807667369902506
Loss at iteration [474]: 0.0024805521367860864
Loss at iteration [475]: 0.0024803303406032945
Loss at iteration [476]: 0.002480102718106337
Loss at iteration [477]: 0.0024798726257686796
Loss at iteration [478]: 0.002479686214560167
Loss at iteration [479]: 0.0024794723955273005
Loss at iteration [480]: 0.0024792274854357815
Loss at iteration [481]: 0.0024790392548940114
Loss at iteration [482]: 0.0024788580663523034
Loss at iteration [483]: 0.0024786318870103413
Loss at iteration [484]: 0.002478390230895719
Loss at iteration [485]: 0.0024782130129112154
Loss at iteration [486]: 0.002478028916788572
Loss at iteration [487]: 0.0024777988809595126
Loss at iteration [488]: 0.0024775682193353176
Loss at iteration [489]: 0.002477394624434476
Loss at iteration [490]: 0.002477186659651947
Loss at iteration [491]: 0.0024769523036032963
Loss at iteration [492]: 0.0024767916843457085
Loss at iteration [493]: 0.0024766003306810835
Loss at iteration [494]: 0.0024763713119170523
Loss at iteration [495]: 0.002476176156286591
Loss at iteration [496]: 0.0024759956558190552
Loss at iteration [497]: 0.002475770217403444
Loss at iteration [498]: 0.002475581733864337
Loss at iteration [499]: 0.0024754017837668916
Loss at iteration [500]: 0.0024751842046122556
Loss at iteration [501]: 0.0024749795765288025
Loss at iteration [502]: 0.0024747930735995057
Loss at iteration [503]: 0.0024745935666558314
Loss at iteration [504]: 0.002474408658386992
Loss at iteration [505]: 0.0024742160757602214
Loss at iteration [506]: 0.0024740219252243046
Loss at iteration [507]: 0.0024738281329849112
Loss at iteration [508]: 0.0024736345693114918
Loss at iteration [509]: 0.002473464546216365
Loss at iteration [510]: 0.0024732542314932116
Loss at iteration [511]: 0.0024730668170671044
Loss at iteration [512]: 0.002472879609122655
Loss at iteration [513]: 0.002472691254096777
Loss at iteration [514]: 0.002472502137898148
Loss at iteration [515]: 0.0024723153889398383
Loss at iteration [516]: 0.0024721321660490002
Loss at iteration [517]: 0.002471948932191838
Loss at iteration [518]: 0.0024717632534454206
Loss at iteration [519]: 0.0024715778021623903
Loss at iteration [520]: 0.002471389449692605
Loss at iteration [521]: 0.0024712078199842806
Loss at iteration [522]: 0.0024710218115794203
Loss at iteration [523]: 0.0024708434365185074
Loss at iteration [524]: 0.0024706639307413287
Loss at iteration [525]: 0.002470482616687565
Loss at iteration [526]: 0.0024702999376016
Loss at iteration [527]: 0.0024701479701320413
Loss at iteration [528]: 0.0024699498711852085
Loss at iteration [529]: 0.0024697853512380017
Loss at iteration [530]: 0.0024696147680588194
Loss at iteration [531]: 0.0024694367269314675
Loss at iteration [532]: 0.0024692548877095965
Loss at iteration [533]: 0.00246907272793311
Loss at iteration [534]: 0.0024689051017618047
Loss at iteration [535]: 0.0024687337577935556
Loss at iteration [536]: 0.002468546607461075
Loss at iteration [537]: 0.0024683807136982434
Loss at iteration [538]: 0.0024682148512828275
Loss at iteration [539]: 0.002468043526011841
Loss at iteration [540]: 0.0024678629109396773
Loss at iteration [541]: 0.0024676827718343552
Loss at iteration [542]: 0.0024675186978331525
Loss at iteration [543]: 0.0024673488708608256
Loss at iteration [544]: 0.002467165777583578
Loss at iteration [545]: 0.0024670031326457734
Loss at iteration [546]: 0.002466842720008864
Loss at iteration [547]: 0.0024666745295662948
Loss at iteration [548]: 0.0024664981332115647
Loss at iteration [549]: 0.002466323283763792
Loss at iteration [550]: 0.0024661694892483244
Loss at iteration [551]: 0.0024660030334888246
Loss at iteration [552]: 0.002465825389680213
Loss at iteration [553]: 0.0024656555289937435
Loss at iteration [554]: 0.002465499548502674
Loss at iteration [555]: 0.0024653321448161345
Loss at iteration [556]: 0.0024651588891666976
Loss at iteration [557]: 0.0024649880453532637
Loss at iteration [558]: 0.002464827123185257
Loss at iteration [559]: 0.0024646545814689023
Loss at iteration [560]: 0.0024644900991969494
Loss at iteration [561]: 0.0024643286202670612
Loss at iteration [562]: 0.0024641687521569067
Loss at iteration [563]: 0.002464004061618931
Loss at iteration [564]: 0.0024638442750620562
Loss at iteration [565]: 0.002463679662276268
Loss at iteration [566]: 0.0024635254601840517
Loss at iteration [567]: 0.0024633676160932135
Loss at iteration [568]: 0.0024632033194348594
Loss at iteration [569]: 0.0024630403160408945
Loss at iteration [570]: 0.0024628804849985923
Loss at iteration [571]: 0.0024627225334078098
Loss at iteration [572]: 0.0024625639965539996
Loss at iteration [573]: 0.0024624035186944808
Loss at iteration [574]: 0.002462245335537722
Loss at iteration [575]: 0.0024620909573500284
Loss at iteration [576]: 0.002461929709542098
Loss at iteration [577]: 0.00246177208790854
Loss at iteration [578]: 0.002461619037783562
Loss at iteration [579]: 0.002461456487242409
Loss at iteration [580]: 0.002461300023931247
Loss at iteration [581]: 0.0024611445709400797
Loss at iteration [582]: 0.00246098553812629
Loss at iteration [583]: 0.0024608263769310746
Loss at iteration [584]: 0.0024606688418570763
Loss at iteration [585]: 0.002460507177938209
Loss at iteration [586]: 0.002460347293532056
Loss at iteration [587]: 0.0024601928807636074
Loss at iteration [588]: 0.0024600305788565146
Loss at iteration [589]: 0.002459875411042689
Loss at iteration [590]: 0.0024597184593272395
Loss at iteration [591]: 0.0024595566066915784
Loss at iteration [592]: 0.002459409614868222
Loss at iteration [593]: 0.0024592440196222784
Loss at iteration [594]: 0.002459094332916073
Loss at iteration [595]: 0.0024589494394796725
Loss at iteration [596]: 0.0024587957280736376
Loss at iteration [597]: 0.0024586328777457677
Loss at iteration [598]: 0.0024584675625875375
Loss at iteration [599]: 0.0024583170333485464
Loss at iteration [600]: 0.0024581695388380762
Loss at iteration [601]: 0.0024580091612062104
Loss at iteration [602]: 0.0024578447842151584
Loss at iteration [603]: 0.002457693076299523
Loss at iteration [604]: 0.0024575357041432527
Loss at iteration [605]: 0.002457376821983256
Loss at iteration [606]: 0.002457224783663177
Loss at iteration [607]: 0.002457063929224106
Loss at iteration [608]: 0.00245691304562044
Loss at iteration [609]: 0.0024567628245530165
Loss at iteration [610]: 0.0024566075052130276
Loss at iteration [611]: 0.0024564490514857257
Loss at iteration [612]: 0.002456289102889872
Loss at iteration [613]: 0.002456148996298427
Loss at iteration [614]: 0.0024559930824654035
Loss at iteration [615]: 0.002455830745812549
Loss at iteration [616]: 0.002455683262367987
Loss at iteration [617]: 0.00245553137881272
Loss at iteration [618]: 0.002455374576022287
Loss at iteration [619]: 0.0024552211024252133
Loss at iteration [620]: 0.002455067860501004
Loss at iteration [621]: 0.002454915914584599
Loss at iteration [622]: 0.0024547706355527114
Loss at iteration [623]: 0.002454624866042785
Loss at iteration [624]: 0.002454466412824104
Loss at iteration [625]: 0.0024543279065368994
Loss at iteration [626]: 0.0024541743633130046
Loss at iteration [627]: 0.0024540202387248727
Loss at iteration [628]: 0.0024538858011
Loss at iteration [629]: 0.002453724402171365
Loss at iteration [630]: 0.0024535984972468635
Loss at iteration [631]: 0.0024534598809041255
Loss at iteration [632]: 0.0024532950587919625
Loss at iteration [633]: 0.002453155196964847
Loss at iteration [634]: 0.00245302037720653
Loss at iteration [635]: 0.002452857010257223
Loss at iteration [636]: 0.0024527246865739902
Loss at iteration [637]: 0.0024525907515878615
Loss at iteration [638]: 0.0024524284770270806
Loss at iteration [639]: 0.0024522883516532963
Loss at iteration [640]: 0.0024521518847842876
Loss at iteration [641]: 0.0024519990463760114
Loss at iteration [642]: 0.002451845724492721
Loss at iteration [643]: 0.0024517093252711237
Loss at iteration [644]: 0.002451555813816436
Loss at iteration [645]: 0.0024514150670002536
Loss at iteration [646]: 0.002451273872718845
Loss at iteration [647]: 0.0024511262620127154
Loss at iteration [648]: 0.002450981876283235
Loss at iteration [649]: 0.002450839277275685
Loss at iteration [650]: 0.0024506894278342817
Loss at iteration [651]: 0.0024505500031762927
Loss at iteration [652]: 0.002450405172648395
Loss at iteration [653]: 0.002450252302759813
Loss at iteration [654]: 0.0024501064096819165
Loss at iteration [655]: 0.002449971349183722
Loss at iteration [656]: 0.002449826916512699
Loss at iteration [657]: 0.002449681480807337
Loss at iteration [658]: 0.002449538285353333
Loss at iteration [659]: 0.0024493962017648157
Loss at iteration [660]: 0.002449255749164339
Loss at iteration [661]: 0.002449116941383792
Loss at iteration [662]: 0.00244897580819139
Loss at iteration [663]: 0.0024488326641571583
Loss at iteration [664]: 0.002448690776513818
Loss at iteration [665]: 0.0024485553286317154
Loss at iteration [666]: 0.002448415393883896
Loss at iteration [667]: 0.0024482738080204174
Loss at iteration [668]: 0.002448134216277713
Loss at iteration [669]: 0.0024479995491451696
Loss at iteration [670]: 0.002447861593972462
Loss at iteration [671]: 0.002447720936469681
Loss at iteration [672]: 0.00244758175043121
Loss at iteration [673]: 0.002447455161233089
Loss at iteration [674]: 0.0024473178830626847
Loss at iteration [675]: 0.0024471766980409594
Loss at iteration [676]: 0.0024470410453713283
Loss at iteration [677]: 0.0024469119582623228
Loss at iteration [678]: 0.002446777813008409
Loss at iteration [679]: 0.0024466411688030677
Loss at iteration [680]: 0.0024465066515035436
Loss at iteration [681]: 0.0024463766628847854
Loss at iteration [682]: 0.002446243698315423
Loss at iteration [683]: 0.0024461047162288607
Loss at iteration [684]: 0.0024459712879311125
Loss at iteration [685]: 0.0024458451895250652
Loss at iteration [686]: 0.0024457142502333586
Loss at iteration [687]: 0.0024455736881855523
Loss at iteration [688]: 0.0024454598331434545
Loss at iteration [689]: 0.0024453300060376455
Loss at iteration [690]: 0.0024451872060791595
Loss at iteration [691]: 0.00244506811005604
Loss at iteration [692]: 0.0024449476512443612
Loss at iteration [693]: 0.00244480923929687
Loss at iteration [694]: 0.0024446718017641944
Loss at iteration [695]: 0.00244454978170083
Loss at iteration [696]: 0.0024444136515058635
Loss at iteration [697]: 0.0024442950542565046
Loss at iteration [698]: 0.0024441717700198103
Loss at iteration [699]: 0.0024440363362405486
Loss at iteration [700]: 0.0024439046204371736
Loss at iteration [701]: 0.0024437802616839466
Loss at iteration [702]: 0.0024436425699977866
Loss at iteration [703]: 0.0024435146523421503
Loss at iteration [704]: 0.0024433932664644207
Loss at iteration [705]: 0.0024432623842020884
Loss at iteration [706]: 0.0024431402844052492
Loss at iteration [707]: 0.002443011186706992
Loss at iteration [708]: 0.0024428738233153945
Loss at iteration [709]: 0.0024427649801047942
Loss at iteration [710]: 0.0024426369732996147
Loss at iteration [711]: 0.0024424944914045914
Loss at iteration [712]: 0.0024423774574218885
Loss at iteration [713]: 0.002442258575869997
Loss at iteration [714]: 0.0024421198190680564
Loss at iteration [715]: 0.0024419772637568975
Loss at iteration [716]: 0.0024418549089492724
Loss at iteration [717]: 0.0024417212717231167
Loss at iteration [718]: 0.002441591804257275
Loss at iteration [719]: 0.0024414735577708477
Loss at iteration [720]: 0.002441339458122424
Loss at iteration [721]: 0.002441225159664791
Loss at iteration [722]: 0.00244110219759559
Loss at iteration [723]: 0.002440965748765138
Loss at iteration [724]: 0.0024408401131303364
Loss at iteration [725]: 0.002440717181698711
Loss at iteration [726]: 0.0024405781024720284
Loss at iteration [727]: 0.0024404542863895305
Loss at iteration [728]: 0.002440328792807475
Loss at iteration [729]: 0.0024401995913141726
Loss at iteration [730]: 0.002440072492574653
Loss at iteration [731]: 0.0024399580662305804
Loss at iteration [732]: 0.0024398229623066683
Loss at iteration [733]: 0.0024397040200585165
Loss at iteration [734]: 0.002439583259149647
Loss at iteration [735]: 0.002439449386996156
Loss at iteration [736]: 0.0024393218729206996
Loss at iteration [737]: 0.00243919612961074
Loss at iteration [738]: 0.0024390717927362353
Loss at iteration [739]: 0.00243895201134817
Loss at iteration [740]: 0.002438822760304908
Loss at iteration [741]: 0.0024386990873073054
Loss at iteration [742]: 0.002438575949117106
Loss at iteration [743]: 0.0024384565260704926
Loss at iteration [744]: 0.002438333570544218
Loss at iteration [745]: 0.0024382037085540916
Loss at iteration [746]: 0.0024380795739561045
Loss at iteration [747]: 0.0024379518460743255
Loss at iteration [748]: 0.002437830815282615
Loss at iteration [749]: 0.0024377096469611003
Loss at iteration [750]: 0.0024375781899518244
Loss at iteration [751]: 0.002437451940578111
Loss at iteration [752]: 0.002437320052843761
Loss at iteration [753]: 0.002437196492173641
Loss at iteration [754]: 0.0024370721286744537
Loss at iteration [755]: 0.002436938007748774
Loss at iteration [756]: 0.002436802915793091
Loss at iteration [757]: 0.002436699312664952
Loss at iteration [758]: 0.0024365697037340536
Loss at iteration [759]: 0.0024364243874785124
Loss at iteration [760]: 0.002436302522020452
Loss at iteration [761]: 0.0024361711859890813
Loss at iteration [762]: 0.0024360403009056923
Loss at iteration [763]: 0.0024359168089951116
Loss at iteration [764]: 0.0024357950254412313
Loss at iteration [765]: 0.0024356725787948925
Loss at iteration [766]: 0.0024355401138107936
Loss at iteration [767]: 0.002435402614690935
Loss at iteration [768]: 0.002435281709384735
Loss at iteration [769]: 0.0024351366769340293
Loss at iteration [770]: 0.0024350009024762804
Loss at iteration [771]: 0.0024348671308195295
Loss at iteration [772]: 0.0024347162347258342
Loss at iteration [773]: 0.002434570162648958
Loss at iteration [774]: 0.0024344266192048193
Loss at iteration [775]: 0.002434257627508709
Loss at iteration [776]: 0.002434106668890524
Loss at iteration [777]: 0.0024339574642074425
Loss at iteration [778]: 0.002433804064144892
Loss at iteration [779]: 0.0024336489712326113
Loss at iteration [780]: 0.0024334977691181582
Loss at iteration [781]: 0.002433337437726683
Loss at iteration [782]: 0.0024331822093478683
Loss at iteration [783]: 0.002433031057365439
Loss at iteration [784]: 0.0024328633536232227
Loss at iteration [785]: 0.0024326741308707852
Loss at iteration [786]: 0.0024324736426661613
Loss at iteration [787]: 0.0024322155931265897
Loss at iteration [788]: 0.00243206070663803
Loss at iteration [789]: 0.0024319629150910565
Loss at iteration [790]: 0.002431812979841027
Loss at iteration [791]: 0.0024316289155422942
Loss at iteration [792]: 0.0024314765110696724
Loss at iteration [793]: 0.002431362989653064
Loss at iteration [794]: 0.002431244564600255
Loss at iteration [795]: 0.0024311246011208976
Loss at iteration [796]: 0.002431001732726717
Loss at iteration [797]: 0.0024308886073078767
Loss at iteration [798]: 0.002430789990685918
Loss at iteration [799]: 0.002430677330579467
Loss at iteration [800]: 0.0024305463446255265
Loss at iteration [801]: 0.0024304226353634084
Loss at iteration [802]: 0.0024303166927070814
Loss at iteration [803]: 0.0024301991530000216
Loss at iteration [804]: 0.002430074787000332
Loss at iteration [805]: 0.0024299531101546834
Loss at iteration [806]: 0.002429846820283447
Loss at iteration [807]: 0.0024297245839409853
Loss at iteration [808]: 0.0024296040116404023
Loss at iteration [809]: 0.0024294830554686202
Loss at iteration [810]: 0.0024293684446778717
Loss at iteration [811]: 0.0024292516753232265
Loss at iteration [812]: 0.0024291321520263994
Loss at iteration [813]: 0.0024290137089202674
Loss at iteration [814]: 0.002428896148597581
Loss at iteration [815]: 0.0024287838197806374
Loss at iteration [816]: 0.002428668042959454
Loss at iteration [817]: 0.0024285486557821217
Loss at iteration [818]: 0.002428432898877039
Loss at iteration [819]: 0.0024283221957829026
Loss at iteration [820]: 0.0024282096756145437
Loss at iteration [821]: 0.0024280947539350377
Loss at iteration [822]: 0.0024279812606243954
Loss at iteration [823]: 0.002427867811741553
Loss at iteration [824]: 0.0024277580361976537
Loss at iteration [825]: 0.0024276448465534416
Loss at iteration [826]: 0.002427530475767961
Loss at iteration [827]: 0.0024274213545634696
Loss at iteration [828]: 0.0024273117682256577
Loss at iteration [829]: 0.0024271994097053245
Loss at iteration [830]: 0.002427085845321689
Loss at iteration [831]: 0.0024269748894966093
Loss at iteration [832]: 0.0024268710949396097
Loss at iteration [833]: 0.0024267613722009245
Loss at iteration [834]: 0.0024266498404836635
Loss at iteration [835]: 0.002426538860639
Loss at iteration [836]: 0.0024264299199872326
Loss at iteration [837]: 0.0024263177641382044
Loss at iteration [838]: 0.002426216825670791
Loss at iteration [839]: 0.0024261041704185284
Loss at iteration [840]: 0.0024259929666762712
Loss at iteration [841]: 0.002425888088978845
Loss at iteration [842]: 0.00242577704718372
Loss at iteration [843]: 0.002425666135843459
Loss at iteration [844]: 0.002425558698091586
Loss at iteration [845]: 0.0024254439786471974
Loss at iteration [846]: 0.0024253400417762953
Loss at iteration [847]: 0.0024252322815450063
Loss at iteration [848]: 0.0024251170117680987
Loss at iteration [849]: 0.0024250114021396735
Loss at iteration [850]: 0.0024249060570697267
Loss at iteration [851]: 0.002424792405903359
Loss at iteration [852]: 0.0024246878342558446
Loss at iteration [853]: 0.0024245840411070987
Loss at iteration [854]: 0.0024244693117075073
Loss at iteration [855]: 0.0024243657215884977
Loss at iteration [856]: 0.00242426402093748
Loss at iteration [857]: 0.002424153030517283
Loss at iteration [858]: 0.0024240382797685272
Loss at iteration [859]: 0.002423937664797884
Loss at iteration [860]: 0.0024238315327408514
Loss at iteration [861]: 0.002423715413837654
Loss at iteration [862]: 0.0024236202415674965
Loss at iteration [863]: 0.002423520592963131
Loss at iteration [864]: 0.0024234087267808817
Loss at iteration [865]: 0.002423296121592404
Loss at iteration [866]: 0.002423201217597205
Loss at iteration [867]: 0.0024230958838176164
Loss at iteration [868]: 0.002422978775926122
Loss at iteration [869]: 0.002422879444002119
Loss at iteration [870]: 0.0024227782010245165
Loss at iteration [871]: 0.002422667479058736
Loss at iteration [872]: 0.0024225552028545897
Loss at iteration [873]: 0.0024224601949888384
Loss at iteration [874]: 0.0024223525634069158
Loss at iteration [875]: 0.0024222442263745867
Loss at iteration [876]: 0.0024221419948933123
Loss at iteration [877]: 0.002422037623685026
Loss at iteration [878]: 0.0024219291041559466
Loss at iteration [879]: 0.0024218228960081745
Loss at iteration [880]: 0.0024217296917031224
Loss at iteration [881]: 0.002421616449437063
Loss at iteration [882]: 0.0024215133978547914
Loss at iteration [883]: 0.0024214166752459447
Loss at iteration [884]: 0.00242130793389843
Loss at iteration [885]: 0.0024211999935146978
Loss at iteration [886]: 0.002421095376397627
Loss at iteration [887]: 0.002421003136691045
Loss at iteration [888]: 0.0024208904864480452
Loss at iteration [889]: 0.0024207858156981457
Loss at iteration [890]: 0.002420688718113957
Loss at iteration [891]: 0.002420581338920068
Loss at iteration [892]: 0.002420468394290735
Loss at iteration [893]: 0.0024203528628098637
Loss at iteration [894]: 0.002420243624723739
Loss at iteration [895]: 0.002420140236128202
Loss at iteration [896]: 0.002420038049141394
Loss at iteration [897]: 0.0024199278425920344
Loss at iteration [898]: 0.0024198176319917297
Loss at iteration [899]: 0.0024197124016609125
Loss at iteration [900]: 0.002419609142275386
Loss at iteration [901]: 0.0024195024631131195
Loss at iteration [902]: 0.0024193938309382858
Loss at iteration [903]: 0.002419288908225848
Loss at iteration [904]: 0.002419181812477107
Loss at iteration [905]: 0.002419073821540396
Loss at iteration [906]: 0.002418966088702177
Loss at iteration [907]: 0.0024188596988414766
Loss at iteration [908]: 0.0024187505387659584
Loss at iteration [909]: 0.0024186440181043173
Loss at iteration [910]: 0.0024185354460442483
Loss at iteration [911]: 0.002418424877229152
Loss at iteration [912]: 0.0024183191611300467
Loss at iteration [913]: 0.002418212623674907
Loss at iteration [914]: 0.002418101047406743
Loss at iteration [915]: 0.0024179950824995793
Loss at iteration [916]: 0.0024178886336222965
Loss at iteration [917]: 0.0024177813422656676
Loss at iteration [918]: 0.002417673462241567
Loss at iteration [919]: 0.0024175647019832247
Loss at iteration [920]: 0.002417456864549989
Loss at iteration [921]: 0.0024173480405936384
Loss at iteration [922]: 0.0024172400199697175
Loss at iteration [923]: 0.0024171318186577517
Loss at iteration [924]: 0.002417027347134569
Loss at iteration [925]: 0.002416918427236933
Loss at iteration [926]: 0.002416808683370649
Loss at iteration [927]: 0.0024167009871183653
Loss at iteration [928]: 0.002416597754488863
Loss at iteration [929]: 0.0024164955594483777
Loss at iteration [930]: 0.002416391447095333
Loss at iteration [931]: 0.0024162861646354816
Loss at iteration [932]: 0.002416182304258552
Loss at iteration [933]: 0.0024160748189594947
Loss at iteration [934]: 0.0024159798589268883
Loss at iteration [935]: 0.002415863459611155
Loss at iteration [936]: 0.002415761545001846
Loss at iteration [937]: 0.002415652174566928
Loss at iteration [938]: 0.002415544224967748
Loss at iteration [939]: 0.002415434836908893
Loss at iteration [940]: 0.002415328833447266
Loss at iteration [941]: 0.002415222310637689
Loss at iteration [942]: 0.0024151146365017496
Loss at iteration [943]: 0.0024150082370766536
Loss at iteration [944]: 0.0024148993939642678
Loss at iteration [945]: 0.0024147891818514446
Loss at iteration [946]: 0.0024146791872967782
Loss at iteration [947]: 0.0024145693621970272
Loss at iteration [948]: 0.002414461786926277
Loss at iteration [949]: 0.0024143508224838592
Loss at iteration [950]: 0.002414239644412976
Loss at iteration [951]: 0.002414133418709622
Loss at iteration [952]: 0.0024140286757568293
Loss at iteration [953]: 0.0024139223057878423
Loss at iteration [954]: 0.0024138174066172958
Loss at iteration [955]: 0.002413714033562211
Loss at iteration [956]: 0.0024136109057260684
Loss at iteration [957]: 0.0024135097211983652
Loss at iteration [958]: 0.002413406962382961
Loss at iteration [959]: 0.0024133080035462075
Loss at iteration [960]: 0.0024132099130434194
Loss at iteration [961]: 0.0024131114662543345
Loss at iteration [962]: 0.0024130092905521325
Loss at iteration [963]: 0.0024129101492184105
Loss at iteration [964]: 0.002412812150372047
Loss at iteration [965]: 0.0024127205887798206
Loss at iteration [966]: 0.002412617252354882
Loss at iteration [967]: 0.0024125210765561745
Loss at iteration [968]: 0.0024124250245653174
Loss at iteration [969]: 0.0024123285417378044
Loss at iteration [970]: 0.002412233875445968
Loss at iteration [971]: 0.002412138185098357
Loss at iteration [972]: 0.002412043320058487
Loss at iteration [973]: 0.002411949144253351
Loss at iteration [974]: 0.002411853670457395
Loss at iteration [975]: 0.0024117587434364053
Loss at iteration [976]: 0.0024116642608066076
Loss at iteration [977]: 0.0024115692679235303
Loss at iteration [978]: 0.0024114761618165745
Loss at iteration [979]: 0.002411380982042385
Loss at iteration [980]: 0.002411286150506894
Loss at iteration [981]: 0.002411191558947323
Loss at iteration [982]: 0.0024110967410164337
Loss at iteration [983]: 0.0024110025857037544
Loss at iteration [984]: 0.0024109091626429973
Loss at iteration [985]: 0.002410815029693717
Loss at iteration [986]: 0.0024107216389601554
Loss at iteration [987]: 0.002410628279799738
Loss at iteration [988]: 0.002410534619998316
Loss at iteration [989]: 0.002410440456029172
Loss at iteration [990]: 0.0024103461720065764
Loss at iteration [991]: 0.0024102533323116172
Loss at iteration [992]: 0.002410164500029021
Loss at iteration [993]: 0.0024100680163558234
Loss at iteration [994]: 0.002409975296407772
Loss at iteration [995]: 0.0024098844096239187
Loss at iteration [996]: 0.002409793595429312
Loss at iteration [997]: 0.0024097022897239793
Loss at iteration [998]: 0.0024096106651077414
Loss at iteration [999]: 0.0024095197366186464
Loss at iteration [1000]: 0.002409429788609244
Loss at iteration [1001]: 0.0024093386805399413
Loss at iteration [1002]: 0.0024092483188803996
Loss at iteration [1003]: 0.002409158232809467
Loss at iteration [1004]: 0.002409068175610239
Loss at iteration [1005]: 0.0024089774229477195
Loss at iteration [1006]: 0.0024088859362598517
Loss at iteration [1007]: 0.002408793637640587
Loss at iteration [1008]: 0.0024087022886981058
Loss at iteration [1009]: 0.0024086118486630385
Loss at iteration [1010]: 0.0024085210051814523
Loss at iteration [1011]: 0.0024084305811581503
Loss at iteration [1012]: 0.002408340426049621
Loss at iteration [1013]: 0.0024082507145311125
Loss at iteration [1014]: 0.0024081605383634622
Loss at iteration [1015]: 0.002408070125229535
Loss at iteration [1016]: 0.0024079800713006447
Loss at iteration [1017]: 0.002407889865697848
Loss at iteration [1018]: 0.002407799438220759
Loss at iteration [1019]: 0.002407709401727735
Loss at iteration [1020]: 0.0024076192415243324
Loss at iteration [1021]: 0.0024075278991405355
Loss at iteration [1022]: 0.00240743650696452
Loss at iteration [1023]: 0.0024073430601567795
Loss at iteration [1024]: 0.002407251019957717
Loss at iteration [1025]: 0.0024071615696173057
Loss at iteration [1026]: 0.0024070715820833193
Loss at iteration [1027]: 0.002406999601664703
Loss at iteration [1028]: 0.002406892725179982
Loss at iteration [1029]: 0.002406805030827693
Loss at iteration [1030]: 0.0024067143059944714
Loss at iteration [1031]: 0.002406624883996255
Loss at iteration [1032]: 0.002406535077255026
Loss at iteration [1033]: 0.002406448020899254
Loss at iteration [1034]: 0.0024063596881507866
Loss at iteration [1035]: 0.0024062712156816836
Loss at iteration [1036]: 0.002406182045597622
Loss at iteration [1037]: 0.002406095369315235
Loss at iteration [1038]: 0.002406004839000448
Loss at iteration [1039]: 0.002405916419436975
Loss at iteration [1040]: 0.0024058282793833177
Loss at iteration [1041]: 0.002405742954066394
Loss at iteration [1042]: 0.0024056574109425828
Loss at iteration [1043]: 0.0024055717312562535
Loss at iteration [1044]: 0.0024054853679591507
Loss at iteration [1045]: 0.0024053998282205125
Loss at iteration [1046]: 0.0024053137439238362
Loss at iteration [1047]: 0.0024052299049571284
Loss at iteration [1048]: 0.002405145523178478
Loss at iteration [1049]: 0.002405060338908492
Loss at iteration [1050]: 0.0024049751442056736
Loss at iteration [1051]: 0.002404889917029825
Loss at iteration [1052]: 0.0024048055008695983
Loss at iteration [1053]: 0.00240472055510276
Loss at iteration [1054]: 0.002404635682264988
Loss at iteration [1055]: 0.0024045495452904796
Loss at iteration [1056]: 0.0024044641521087187
Loss at iteration [1057]: 0.0024043807675841722
Loss at iteration [1058]: 0.0024042958177757567
Loss at iteration [1059]: 0.002404211083323481
Loss at iteration [1060]: 0.0024041260306872773
Loss at iteration [1061]: 0.0024040419224880946
Loss at iteration [1062]: 0.0024039574248762696
Loss at iteration [1063]: 0.002403872604631457
Loss at iteration [1064]: 0.002403788694952001
Loss at iteration [1065]: 0.002403701556438872
Loss at iteration [1066]: 0.002403574296627064
Loss at iteration [1067]: 0.002403362845598841
Loss at iteration [1068]: 0.002403444658463008
***** Warning: Loss has increased *****
Loss at iteration [1069]: 0.0024032015193179083
Loss at iteration [1070]: 0.0024032120359353186
***** Warning: Loss has increased *****
Loss at iteration [1071]: 0.002403255459719881
***** Warning: Loss has increased *****
Loss at iteration [1072]: 0.0024031246914397544
Loss at iteration [1073]: 0.0024029031901604153
Loss at iteration [1074]: 0.0024027408996592082
Loss at iteration [1075]: 0.0024029481352468044
***** Warning: Loss has increased *****
Loss at iteration [1076]: 0.002402589809112827
Loss at iteration [1077]: 0.0024026037762791405
***** Warning: Loss has increased *****
Loss at iteration [1078]: 0.0024027174097550276
***** Warning: Loss has increased *****
Loss at iteration [1079]: 0.0024026243741973726
Loss at iteration [1080]: 0.0024023349439717405
Loss at iteration [1081]: 0.0024020929508390045
Loss at iteration [1082]: 0.0024022793178704307
***** Warning: Loss has increased *****
Loss at iteration [1083]: 0.0024022115258685475
Loss at iteration [1084]: 0.002402010308999979
Loss at iteration [1085]: 0.0024017550446788346
Loss at iteration [1086]: 0.0024017400545516833
Loss at iteration [1087]: 0.0024016880912820595
Loss at iteration [1088]: 0.0024014934122713366
Loss at iteration [1089]: 0.002401405219516926
Loss at iteration [1090]: 0.0024013640172789465
Loss at iteration [1091]: 0.002401237775318046
Loss at iteration [1092]: 0.0024012430656071256
***** Warning: Loss has increased *****
Loss at iteration [1093]: 0.0024011926215638506
Loss at iteration [1094]: 0.0024010218038759026
Loss at iteration [1095]: 0.002400941707637589
Loss at iteration [1096]: 0.00240085626495931
Loss at iteration [1097]: 0.002400761402965618
Loss at iteration [1098]: 0.0024006419572236795
Loss at iteration [1099]: 0.002400548367624844
Loss at iteration [1100]: 0.0024004448220759428
Loss at iteration [1101]: 0.0024003468109231375
Loss at iteration [1102]: 0.0024002299702542374
Loss at iteration [1103]: 0.0024001129851991864
Loss at iteration [1104]: 0.002400001965308548
Loss at iteration [1105]: 0.0023998790040792237
Loss at iteration [1106]: 0.0023998116089136014
Loss at iteration [1107]: 0.0023996844858067985
Loss at iteration [1108]: 0.00239958699942175
Loss at iteration [1109]: 0.002399437753568163
Loss at iteration [1110]: 0.0023992072726848486
Loss at iteration [1111]: 0.002398875371987107
Loss at iteration [1112]: 0.002398496363362794
Loss at iteration [1113]: 0.0023982878819990843
Loss at iteration [1114]: 0.002398296285132803
***** Warning: Loss has increased *****
Loss at iteration [1115]: 0.0023982728982782724
Loss at iteration [1116]: 0.002397951289879556
Loss at iteration [1117]: 0.0023976639482549264
Loss at iteration [1118]: 0.002397562328350881
Loss at iteration [1119]: 0.002397474339259399
Loss at iteration [1120]: 0.0023972981183114205
Loss at iteration [1121]: 0.00239704851336383
Loss at iteration [1122]: 0.002396860372356594
Loss at iteration [1123]: 0.0023966827813307
Loss at iteration [1124]: 0.002396673634616495
Loss at iteration [1125]: 0.002396504654314548
Loss at iteration [1126]: 0.0023962439310217013
Loss at iteration [1127]: 0.002395938165168968
Loss at iteration [1128]: 0.0023959012630447142
Loss at iteration [1129]: 0.0023958188819259477
Loss at iteration [1130]: 0.0023954974250481203
Loss at iteration [1131]: 0.0023953371741995506
Loss at iteration [1132]: 0.0023952866579492107
Loss at iteration [1133]: 0.002395080406843646
Loss at iteration [1134]: 0.0023948381432037725
Loss at iteration [1135]: 0.0023947535842803896
Loss at iteration [1136]: 0.0023945508086681768
Loss at iteration [1137]: 0.0023944201363295652
Loss at iteration [1138]: 0.002394319388439458
Loss at iteration [1139]: 0.002394154047983844
Loss at iteration [1140]: 0.002393962359873287
Loss at iteration [1141]: 0.002393836154253968
Loss at iteration [1142]: 0.002393798264504979
Loss at iteration [1143]: 0.0023936030422400533
Loss at iteration [1144]: 0.002393655263081926
***** Warning: Loss has increased *****
Loss at iteration [1145]: 0.0023935858229420398
Loss at iteration [1146]: 0.0023933368288564703
Loss at iteration [1147]: 0.002393214906154666
Loss at iteration [1148]: 0.0023931398998171985
Loss at iteration [1149]: 0.0023929371394483265
Loss at iteration [1150]: 0.0023929359313455286
Loss at iteration [1151]: 0.002392828650749336
Loss at iteration [1152]: 0.0023926120435163274
Loss at iteration [1153]: 0.00239252699198945
Loss at iteration [1154]: 0.002392474479064859
Loss at iteration [1155]: 0.0023922990872904705
Loss at iteration [1156]: 0.002392170635975741
Loss at iteration [1157]: 0.0023920516760928957
Loss at iteration [1158]: 0.002391962795613913
Loss at iteration [1159]: 0.002391847965741933
Loss at iteration [1160]: 0.0023917076582731303
Loss at iteration [1161]: 0.0023916065138987826
Loss at iteration [1162]: 0.0023915045077089214
Loss at iteration [1163]: 0.0023913922519036247
Loss at iteration [1164]: 0.0023912752465386823
Loss at iteration [1165]: 0.002391175912521038
Loss at iteration [1166]: 0.0023910576880078757
Loss at iteration [1167]: 0.0023909528202858375
Loss at iteration [1168]: 0.002390847550471039
Loss at iteration [1169]: 0.0023907429510228516
Loss at iteration [1170]: 0.002390641837162039
Loss at iteration [1171]: 0.002390539836215709
Loss at iteration [1172]: 0.002390437568198791
Loss at iteration [1173]: 0.002390335888487361
Loss at iteration [1174]: 0.0023902334948696356
Loss at iteration [1175]: 0.00239013468695149
Loss at iteration [1176]: 0.0023900358039369895
Loss at iteration [1177]: 0.002389935218589835
Loss at iteration [1178]: 0.0023898361483034357
Loss at iteration [1179]: 0.0023897382565948783
Loss at iteration [1180]: 0.002389641896787092
Loss at iteration [1181]: 0.002389575800107531
Loss at iteration [1182]: 0.002389486465679874
Loss at iteration [1183]: 0.002389347909910691
Loss at iteration [1184]: 0.0023893011326659363
Loss at iteration [1185]: 0.0023891504034022825
Loss at iteration [1186]: 0.002389056535111209
Loss at iteration [1187]: 0.0023889727384491673
Loss at iteration [1188]: 0.0023888580238062554
Loss at iteration [1189]: 0.002388767146954839
Loss at iteration [1190]: 0.0023886644053244268
Loss at iteration [1191]: 0.00238858985314385
Loss at iteration [1192]: 0.0023884792078330197
Loss at iteration [1193]: 0.0023883784206779565
Loss at iteration [1194]: 0.0023882747102138726
Loss at iteration [1195]: 0.0023881988734146707
Loss at iteration [1196]: 0.002388072877899962
Loss at iteration [1197]: 0.002387972377726265
Loss at iteration [1198]: 0.002387870133773663
Loss at iteration [1199]: 0.0023877662387544727
Loss at iteration [1200]: 0.002387657021601938
Loss at iteration [1201]: 0.0023875610263752434
Loss at iteration [1202]: 0.0023874604205007164
Loss at iteration [1203]: 0.0023873643277702605
Loss at iteration [1204]: 0.002387261397197889
Loss at iteration [1205]: 0.002387145980778983
Loss at iteration [1206]: 0.0023870379962905373
Loss at iteration [1207]: 0.0023869257651078545
Loss at iteration [1208]: 0.0023868088786475447
Loss at iteration [1209]: 0.0023866839716708004
Loss at iteration [1210]: 0.002386552946948264
Loss at iteration [1211]: 0.0023864166782810755
Loss at iteration [1212]: 0.0023862780204197127
Loss at iteration [1213]: 0.0023861822914469197
Loss at iteration [1214]: 0.0023860077198390147
Loss at iteration [1215]: 0.0023858808338383616
Loss at iteration [1216]: 0.0023857466160194917
Loss at iteration [1217]: 0.002385613741549019
Loss at iteration [1218]: 0.0023854877753672686
Loss at iteration [1219]: 0.002385360913785478
Loss at iteration [1220]: 0.0023852137675931563
Loss at iteration [1221]: 0.0023851425044815566
Loss at iteration [1222]: 0.0023850051870566687
Loss at iteration [1223]: 0.0023848446186894045
Loss at iteration [1224]: 0.0023847320015573806
Loss at iteration [1225]: 0.002384597080126947
Loss at iteration [1226]: 0.0023844685885915217
Loss at iteration [1227]: 0.0023843545835354283
Loss at iteration [1228]: 0.002384218072022722
Loss at iteration [1229]: 0.0023840821501692065
Loss at iteration [1230]: 0.002383944641419476
Loss at iteration [1231]: 0.002383802729224545
Loss at iteration [1232]: 0.002383647165245302
Loss at iteration [1233]: 0.002383493296066921
Loss at iteration [1234]: 0.002383423262497923
Loss at iteration [1235]: 0.0023832348541508444
Loss at iteration [1236]: 0.0023831626271433428
Loss at iteration [1237]: 0.002383082657435239
Loss at iteration [1238]: 0.0023829130225604474
Loss at iteration [1239]: 0.0023827337947763825
Loss at iteration [1240]: 0.0023826605454015637
Loss at iteration [1241]: 0.0023825066965678324
Loss at iteration [1242]: 0.0023823796214020314
Loss at iteration [1243]: 0.002382265725391278
Loss at iteration [1244]: 0.0023821575244348902
Loss at iteration [1245]: 0.002382060558744814
Loss at iteration [1246]: 0.0023819401884551134
Loss at iteration [1247]: 0.0023818003665563026
Loss at iteration [1248]: 0.002381720566350118
Loss at iteration [1249]: 0.00238157281818753
Loss at iteration [1250]: 0.0023814971742755144
Loss at iteration [1251]: 0.002381423377016578
Loss at iteration [1252]: 0.0023813084642258886
Loss at iteration [1253]: 0.0023811673312950058
Loss at iteration [1254]: 0.0023810214792756453
Loss at iteration [1255]: 0.002380916596547838
Loss at iteration [1256]: 0.0023808131379862824
Loss at iteration [1257]: 0.0023806834078168443
Loss at iteration [1258]: 0.002380538760454233
Loss at iteration [1259]: 0.002380471520755818
Loss at iteration [1260]: 0.0023803315790847817
Loss at iteration [1261]: 0.0023801729416536993
Loss at iteration [1262]: 0.002380072856320856
Loss at iteration [1263]: 0.002379937075841355
Loss at iteration [1264]: 0.0023797782120013383
Loss at iteration [1265]: 0.0023796504335407385
Loss at iteration [1266]: 0.00237953902123616
Loss at iteration [1267]: 0.0023794055757197976
Loss at iteration [1268]: 0.0023792762236596846
Loss at iteration [1269]: 0.002379177252258602
Loss at iteration [1270]: 0.002379027470872004
Loss at iteration [1271]: 0.0023787524538074994
Loss at iteration [1272]: 0.002378400986772594
Loss at iteration [1273]: 0.002377996003156891
Loss at iteration [1274]: 0.0023775571037733733
Loss at iteration [1275]: 0.0023770958584991312
Loss at iteration [1276]: 0.0023766289110973724
Loss at iteration [1277]: 0.0023761413435943145
Loss at iteration [1278]: 0.0023756222331513164
Loss at iteration [1279]: 0.0023751203645139677
Loss at iteration [1280]: 0.0023746120662668318
Loss at iteration [1281]: 0.0023741041990498835
Loss at iteration [1282]: 0.0023735709202528103
Loss at iteration [1283]: 0.002373034073572291
Loss at iteration [1284]: 0.002372511376930991
Loss at iteration [1285]: 0.0023719964914071805
Loss at iteration [1286]: 0.00237147609743775
Loss at iteration [1287]: 0.0023709571846438175
Loss at iteration [1288]: 0.002370448695778384
Loss at iteration [1289]: 0.002369941763150174
Loss at iteration [1290]: 0.0023694466240496556
Loss at iteration [1291]: 0.0023689415944612552
Loss at iteration [1292]: 0.0023684548366835908
Loss at iteration [1293]: 0.0023678856823749605
Loss at iteration [1294]: 0.002367255060180816
Loss at iteration [1295]: 0.002366607147640297
Loss at iteration [1296]: 0.002365961602643403
Loss at iteration [1297]: 0.0023653091604191575
Loss at iteration [1298]: 0.002364643823693211
Loss at iteration [1299]: 0.0023640073831234488
Loss at iteration [1300]: 0.0023633594612178024
Loss at iteration [1301]: 0.0023626936162363596
Loss at iteration [1302]: 0.0023620572090640177
Loss at iteration [1303]: 0.0023614268907850913
Loss at iteration [1304]: 0.0023607907018650663
Loss at iteration [1305]: 0.0023601570398274273
Loss at iteration [1306]: 0.002359530581687585
Loss at iteration [1307]: 0.0023588150539646355
Loss at iteration [1308]: 0.0023581529514800827
Loss at iteration [1309]: 0.0023575223147552955
Loss at iteration [1310]: 0.0023569892209557943
Loss at iteration [1311]: 0.0023564415628286473
Loss at iteration [1312]: 0.0023558900762715752
Loss at iteration [1313]: 0.0023554625670224173
Loss at iteration [1314]: 0.002355030713747468
Loss at iteration [1315]: 0.0023546470859091687
Loss at iteration [1316]: 0.0023542670101494028
Loss at iteration [1317]: 0.0023538658298689155
Loss at iteration [1318]: 0.0023533718384136765
Loss at iteration [1319]: 0.002352838538529264
Loss at iteration [1320]: 0.00235231954816417
Loss at iteration [1321]: 0.0023521496850685292
Loss at iteration [1322]: 0.0023519963542650985
Loss at iteration [1323]: 0.0023514206605739483
Loss at iteration [1324]: 0.002350549751949998
Loss at iteration [1325]: 0.002350802607282274
***** Warning: Loss has increased *****
Loss at iteration [1326]: 0.0023505762234245033
Loss at iteration [1327]: 0.0023497549397864664
Loss at iteration [1328]: 0.0023490369134644305
Loss at iteration [1329]: 0.002348961321089651
Loss at iteration [1330]: 0.0023485749701735543
Loss at iteration [1331]: 0.0023480076529203892
Loss at iteration [1332]: 0.002347965306912403
Loss at iteration [1333]: 0.002347836786397578
Loss at iteration [1334]: 0.0023474515197551772
Loss at iteration [1335]: 0.0023472781072611205
Loss at iteration [1336]: 0.00234721241026716
Loss at iteration [1337]: 0.0023470126534701546
Loss at iteration [1338]: 0.0023466961810073134
Loss at iteration [1339]: 0.002346440526549528
Loss at iteration [1340]: 0.0023463502136256706
Loss at iteration [1341]: 0.0023461844877374093
Loss at iteration [1342]: 0.0023458775524155505
Loss at iteration [1343]: 0.002345577865277152
Loss at iteration [1344]: 0.0023453783851772277
Loss at iteration [1345]: 0.0023452331495750476
Loss at iteration [1346]: 0.0023449960766352257
Loss at iteration [1347]: 0.0023446965536608635
Loss at iteration [1348]: 0.0023444361056111584
Loss at iteration [1349]: 0.0023442897263530192
Loss at iteration [1350]: 0.002344077593191745
Loss at iteration [1351]: 0.002343751471082736
Loss at iteration [1352]: 0.0023435351919547345
Loss at iteration [1353]: 0.00234333543773003
Loss at iteration [1354]: 0.0023431245183970738
Loss at iteration [1355]: 0.002342971099744278
Loss at iteration [1356]: 0.002342783466770843
Loss at iteration [1357]: 0.0023425969708244366
Loss at iteration [1358]: 0.002342412636429867
Loss at iteration [1359]: 0.002342247402609095
Loss at iteration [1360]: 0.0023420945443262163
Loss at iteration [1361]: 0.0023419259577587646
Loss at iteration [1362]: 0.002341738201123528
Loss at iteration [1363]: 0.002341536068576908
Loss at iteration [1364]: 0.002341407388998078
Loss at iteration [1365]: 0.002341174361334531
Loss at iteration [1366]: 0.002340998943154162
Loss at iteration [1367]: 0.0023408067736402503
Loss at iteration [1368]: 0.002340624049232985
Loss at iteration [1369]: 0.0023404316699717114
Loss at iteration [1370]: 0.002340258314458041
Loss at iteration [1371]: 0.0023401198849652763
Loss at iteration [1372]: 0.002339924673436639
Loss at iteration [1373]: 0.002339769013333019
Loss at iteration [1374]: 0.002339608999295921
Loss at iteration [1375]: 0.002339447509740524
Loss at iteration [1376]: 0.0023392781373092024
Loss at iteration [1377]: 0.002339105643173724
Loss at iteration [1378]: 0.0023389333973933067
Loss at iteration [1379]: 0.0023387935837154965
Loss at iteration [1380]: 0.002338619062716117
Loss at iteration [1381]: 0.00233846886592622
Loss at iteration [1382]: 0.002338287724583242
Loss at iteration [1383]: 0.0023381371652500533
Loss at iteration [1384]: 0.0023379793540667373
Loss at iteration [1385]: 0.0023378123899237915
Loss at iteration [1386]: 0.0023376526274528713
Loss at iteration [1387]: 0.0023375147167607416
Loss at iteration [1388]: 0.002337345651422888
Loss at iteration [1389]: 0.0023372126882075634
Loss at iteration [1390]: 0.002337033113465304
Loss at iteration [1391]: 0.0023368844731368192
Loss at iteration [1392]: 0.002336722900777255
Loss at iteration [1393]: 0.0023365846925977366
Loss at iteration [1394]: 0.002336447169864921
Loss at iteration [1395]: 0.002336255266941526
Loss at iteration [1396]: 0.0023361425129341472
Loss at iteration [1397]: 0.002336027479032424
Loss at iteration [1398]: 0.0023357952726798877
Loss at iteration [1399]: 0.002335700160075976
Loss at iteration [1400]: 0.0023355404640518712
Loss at iteration [1401]: 0.0023353352507471596
Loss at iteration [1402]: 0.002335229828543107
Loss at iteration [1403]: 0.0023350242768949265
Loss at iteration [1404]: 0.0023349270778067117
Loss at iteration [1405]: 0.0023347470794333725
Loss at iteration [1406]: 0.002334633524467249
Loss at iteration [1407]: 0.002334506716348023
Loss at iteration [1408]: 0.002334269440830606
Loss at iteration [1409]: 0.0023342334527422614
Loss at iteration [1410]: 0.0023340665282279545
Loss at iteration [1411]: 0.002333837089658876
Loss at iteration [1412]: 0.0023337147608723597
Loss at iteration [1413]: 0.0023335477754946924
Loss at iteration [1414]: 0.0023333778617803647
Loss at iteration [1415]: 0.002333300856198252
Loss at iteration [1416]: 0.002333105965376175
Loss at iteration [1417]: 0.0023329915228988618
Loss at iteration [1418]: 0.0023327925915950926
Loss at iteration [1419]: 0.0023326498162431902
Loss at iteration [1420]: 0.002332504735053523
Loss at iteration [1421]: 0.0023323839662921083
Loss at iteration [1422]: 0.002332243808312217
Loss at iteration [1423]: 0.0023321064367993675
Loss at iteration [1424]: 0.00233197925115248
Loss at iteration [1425]: 0.002331811477453758
Loss at iteration [1426]: 0.0023316795053796593
Loss at iteration [1427]: 0.0023315561692681753
Loss at iteration [1428]: 0.0023314495980834783
Loss at iteration [1429]: 0.002331264172435217
Loss at iteration [1430]: 0.0023311416021874446
Loss at iteration [1431]: 0.0023310050189778463
Loss at iteration [1432]: 0.0023308694737342044
Loss at iteration [1433]: 0.0023307240525925594
Loss at iteration [1434]: 0.002330598603185732
Loss at iteration [1435]: 0.002330511531791206
Loss at iteration [1436]: 0.002330372645003756
Loss at iteration [1437]: 0.0023301991432615214
Loss at iteration [1438]: 0.0023301406189760484
Loss at iteration [1439]: 0.002329968517418268
Loss at iteration [1440]: 0.0023299002965109948
Loss at iteration [1441]: 0.0023297364387107537
Loss at iteration [1442]: 0.0023295675317058697
Loss at iteration [1443]: 0.002329491759753528
Loss at iteration [1444]: 0.0023293220869671978
Loss at iteration [1445]: 0.0023292229455519472
Loss at iteration [1446]: 0.0023291332719032115
Loss at iteration [1447]: 0.0023289416712730148
Loss at iteration [1448]: 0.002328847325995121
Loss at iteration [1449]: 0.0023287051015600585
Loss at iteration [1450]: 0.002328554129479207
Loss at iteration [1451]: 0.0023284349047478377
Loss at iteration [1452]: 0.00232831915148893
Loss at iteration [1453]: 0.002328199008131802
Loss at iteration [1454]: 0.0023280822419907195
Loss at iteration [1455]: 0.002327940220398585
Loss at iteration [1456]: 0.0023278453249367726
Loss at iteration [1457]: 0.0023277062355963967
Loss at iteration [1458]: 0.002327571201646656
Loss at iteration [1459]: 0.002327487929541223
Loss at iteration [1460]: 0.0023273330799191204
Loss at iteration [1461]: 0.002327200428842061
Loss at iteration [1462]: 0.0023270938770038494
Loss at iteration [1463]: 0.0023269472452696815
Loss at iteration [1464]: 0.002326841594010433
Loss at iteration [1465]: 0.0023267439494513297
Loss at iteration [1466]: 0.0023265826806650805
Loss at iteration [1467]: 0.0023264720062142227
Loss at iteration [1468]: 0.0023263423758809565
Loss at iteration [1469]: 0.0023262181814594513
Loss at iteration [1470]: 0.0023260909081672257
Loss at iteration [1471]: 0.002325969573988946
Loss at iteration [1472]: 0.002325857348234621
Loss at iteration [1473]: 0.0023257633859332565
Loss at iteration [1474]: 0.0023256293715205978
Loss at iteration [1475]: 0.0023255396400778034
Loss at iteration [1476]: 0.002325408250743678
Loss at iteration [1477]: 0.002325294800656999
Loss at iteration [1478]: 0.002325189370231575
Loss at iteration [1479]: 0.0023250187576037565
Loss at iteration [1480]: 0.0023249286858413962
Loss at iteration [1481]: 0.0023247850265312375
Loss at iteration [1482]: 0.0023246711144375314
Loss at iteration [1483]: 0.002324555161054131
Loss at iteration [1484]: 0.0023244471494484427
Loss at iteration [1485]: 0.0023243533345591308
Loss at iteration [1486]: 0.002324236182924419
Loss at iteration [1487]: 0.002324101343519274
Loss at iteration [1488]: 0.002324033600674057
Loss at iteration [1489]: 0.002323870741419746
Loss at iteration [1490]: 0.0023237523533064528
Loss at iteration [1491]: 0.0023236581485426584
Loss at iteration [1492]: 0.0023235238282111608
Loss at iteration [1493]: 0.0023234083897451224
Loss at iteration [1494]: 0.002323316231033484
Loss at iteration [1495]: 0.0023231977798884775
Loss at iteration [1496]: 0.002323107180605845
Loss at iteration [1497]: 0.0023229593432828087
Loss at iteration [1498]: 0.0023229159099305762
Loss at iteration [1499]: 0.0023228354875066107
Loss at iteration [1500]: 0.0023226870655151857
Loss at iteration [1501]: 0.002322523124278221
Loss at iteration [1502]: 0.0023225036060583342
Loss at iteration [1503]: 0.002322361753319541
Loss at iteration [1504]: 0.002322203477035966
Loss at iteration [1505]: 0.0023221239717084938
Loss at iteration [1506]: 0.002321994003310688
Loss at iteration [1507]: 0.002321884061757014
Loss at iteration [1508]: 0.002321801666812987
Loss at iteration [1509]: 0.0023216694210641342
Loss at iteration [1510]: 0.002321556635753872
Loss at iteration [1511]: 0.002321441282653379
Loss at iteration [1512]: 0.002321359386389122
Loss at iteration [1513]: 0.0023212359514207088
Loss at iteration [1514]: 0.002321115497294041
Loss at iteration [1515]: 0.002321020651304499
Loss at iteration [1516]: 0.002320897565486238
Loss at iteration [1517]: 0.0023207903623705933
Loss at iteration [1518]: 0.0023207173345238946
Loss at iteration [1519]: 0.0023205936457324277
Loss at iteration [1520]: 0.002320460617800305
Loss at iteration [1521]: 0.0023204031555336788
Loss at iteration [1522]: 0.0023202455953881835
Loss at iteration [1523]: 0.0023201547170356345
Loss at iteration [1524]: 0.0023200488820973014
Loss at iteration [1525]: 0.0023199230280520618
Loss at iteration [1526]: 0.00231986696757035
Loss at iteration [1527]: 0.002319711992478854
Loss at iteration [1528]: 0.002319612609930952
Loss at iteration [1529]: 0.0023195117914418537
Loss at iteration [1530]: 0.002319416011064455
Loss at iteration [1531]: 0.002319314127348908
Loss at iteration [1532]: 0.0023192025463948662
Loss at iteration [1533]: 0.0023191087690431424
Loss at iteration [1534]: 0.002318999720705258
Loss at iteration [1535]: 0.0023189083835160706
Loss at iteration [1536]: 0.0023188026207787496
Loss at iteration [1537]: 0.00231869633801102
Loss at iteration [1538]: 0.0023185932536382604
Loss at iteration [1539]: 0.0023184884999056196
Loss at iteration [1540]: 0.0023183915076152536
Loss at iteration [1541]: 0.0023182739038374073
Loss at iteration [1542]: 0.002318176234188143
Loss at iteration [1543]: 0.0023180673173822776
Loss at iteration [1544]: 0.0023179858089854804
Loss at iteration [1545]: 0.0023178886697532665
Loss at iteration [1546]: 0.0023177665403211847
Loss at iteration [1547]: 0.0023176699468138206
Loss at iteration [1548]: 0.002317562966406831
Loss at iteration [1549]: 0.0023174652323576087
Loss at iteration [1550]: 0.002317375710132412
Loss at iteration [1551]: 0.0023172630683773354
Loss at iteration [1552]: 0.002317219822472396
Loss at iteration [1553]: 0.0023170561716459354
Loss at iteration [1554]: 0.0023170124594664877
Loss at iteration [1555]: 0.002316932991310109
Loss at iteration [1556]: 0.0023168108917252976
Loss at iteration [1557]: 0.00231666544540726
Loss at iteration [1558]: 0.0023166328037388536
Loss at iteration [1559]: 0.002316494472601616
Loss at iteration [1560]: 0.0023163940209637206
Loss at iteration [1561]: 0.0023163433196064084
Loss at iteration [1562]: 0.002316245108400041
Loss at iteration [1563]: 0.002316114537705776
Loss at iteration [1564]: 0.002316006011713244
Loss at iteration [1565]: 0.00231592916805441
Loss at iteration [1566]: 0.0023158312689800613
Loss at iteration [1567]: 0.0023157241303369356
Loss at iteration [1568]: 0.002315612874817314
Loss at iteration [1569]: 0.00231549173324696
Loss at iteration [1570]: 0.0023154349262774127
Loss at iteration [1571]: 0.002315350503910385
Loss at iteration [1572]: 0.0023152326465479653
Loss at iteration [1573]: 0.0023151003129609493
Loss at iteration [1574]: 0.00231501059026251
Loss at iteration [1575]: 0.0023149184158217134
Loss at iteration [1576]: 0.002314811766646379
Loss at iteration [1577]: 0.002314705505581035
Loss at iteration [1578]: 0.0023146118489710344
Loss at iteration [1579]: 0.002314517915609593
Loss at iteration [1580]: 0.00231443501901195
Loss at iteration [1581]: 0.002314358352539956
Loss at iteration [1582]: 0.0023142931111123388
Loss at iteration [1583]: 0.0023142016151147127
Loss at iteration [1584]: 0.002314086151317522
Loss at iteration [1585]: 0.0023139500448484214
Loss at iteration [1586]: 0.0023139489868742352
Loss at iteration [1587]: 0.0023138056109504646
Loss at iteration [1588]: 0.002313700609401053
Loss at iteration [1589]: 0.0023136501349947537
Loss at iteration [1590]: 0.002313576571310438
Loss at iteration [1591]: 0.0023134709553467364
Loss at iteration [1592]: 0.002313343647179824
Loss at iteration [1593]: 0.0023132256853451226
Loss at iteration [1594]: 0.002313144760594749
Loss at iteration [1595]: 0.0023130640584507066
Loss at iteration [1596]: 0.002312972889885336
Loss at iteration [1597]: 0.002312859489992756
Loss at iteration [1598]: 0.0023127463286879892
Loss at iteration [1599]: 0.0023126621669368763
Loss at iteration [1600]: 0.0023125654316925384
Loss at iteration [1601]: 0.0023124737400951846
Loss at iteration [1602]: 0.0023123825114180633
Loss at iteration [1603]: 0.002312272709083637
Loss at iteration [1604]: 0.0023121966878350913
Loss at iteration [1605]: 0.002312115063161187
Loss at iteration [1606]: 0.002312007200785652
Loss at iteration [1607]: 0.0023119313963589827
Loss at iteration [1608]: 0.0023118438864979263
Loss at iteration [1609]: 0.0023117445969144763
Loss at iteration [1610]: 0.002311625613796573
Loss at iteration [1611]: 0.00231156777041722
Loss at iteration [1612]: 0.002311501076936533
Loss at iteration [1613]: 0.002311407591827437
Loss at iteration [1614]: 0.002311291762860929
Loss at iteration [1615]: 0.0023111664556484932
Loss at iteration [1616]: 0.00231119589427168
***** Warning: Loss has increased *****
Loss at iteration [1617]: 0.002311016808690301
Loss at iteration [1618]: 0.0023109482684535083
Loss at iteration [1619]: 0.002310914192539201
Loss at iteration [1620]: 0.0023108588721346187
Loss at iteration [1621]: 0.00231076920924779
Loss at iteration [1622]: 0.0023106521933930757
Loss at iteration [1623]: 0.00231051536165686
Loss at iteration [1624]: 0.0023103666927993074
Loss at iteration [1625]: 0.002310317817173453
Loss at iteration [1626]: 0.0023102469850416595
Loss at iteration [1627]: 0.002310151871392655
Loss at iteration [1628]: 0.002310031863734319
Loss at iteration [1629]: 0.002309943247288594
Loss at iteration [1630]: 0.002309881327730078
Loss at iteration [1631]: 0.002309801639483559
Loss at iteration [1632]: 0.002309696597864596
Loss at iteration [1633]: 0.0023095881309315057
Loss at iteration [1634]: 0.002309500060459346
Loss at iteration [1635]: 0.0023093909133227106
Loss at iteration [1636]: 0.0023093198113373526
Loss at iteration [1637]: 0.002309245705894171
Loss at iteration [1638]: 0.002309146461784487
Loss at iteration [1639]: 0.002309035206545568
Loss at iteration [1640]: 0.0023089474698623877
Loss at iteration [1641]: 0.002308862449593992
Loss at iteration [1642]: 0.0023087707549270986
Loss at iteration [1643]: 0.0023086717637718595
Loss at iteration [1644]: 0.0023086081136938215
Loss at iteration [1645]: 0.002308522239844701
Loss at iteration [1646]: 0.002308412323977724
Loss at iteration [1647]: 0.0023083491943354864
Loss at iteration [1648]: 0.002308274882535505
Loss at iteration [1649]: 0.0023081893915542612
Loss at iteration [1650]: 0.0023080892600912247
Loss at iteration [1651]: 0.0023079789546930785
Loss at iteration [1652]: 0.002307919094358935
Loss at iteration [1653]: 0.002307847894904435
Loss at iteration [1654]: 0.002307739995790279
Loss at iteration [1655]: 0.0023076305020258395
Loss at iteration [1656]: 0.00230755856829711
Loss at iteration [1657]: 0.002307471634668584
Loss at iteration [1658]: 0.002307376559726519
Loss at iteration [1659]: 0.0023072802528766143
Loss at iteration [1660]: 0.002307194025730836
Loss at iteration [1661]: 0.002307113947652494
Loss at iteration [1662]: 0.0023070343674748894
Loss at iteration [1663]: 0.0023069421068878824
Loss at iteration [1664]: 0.0023068520482998644
Loss at iteration [1665]: 0.002306762003179999
Loss at iteration [1666]: 0.002306677768946494
Loss at iteration [1667]: 0.0023065978525011466
Loss at iteration [1668]: 0.0023065144675393176
Loss at iteration [1669]: 0.0023064185008394057
Loss at iteration [1670]: 0.002306337498995895
Loss at iteration [1671]: 0.0023062535095942915
Loss at iteration [1672]: 0.0023061703249060692
Loss at iteration [1673]: 0.002306075829853999
Loss at iteration [1674]: 0.0023059980457172126
Loss at iteration [1675]: 0.0023059343619591436
Loss at iteration [1676]: 0.002305838874372267
Loss at iteration [1677]: 0.0023057536390546983
Loss at iteration [1678]: 0.0023056815802591788
Loss at iteration [1679]: 0.0023056034813976395
Loss at iteration [1680]: 0.0023055086041880992
Loss at iteration [1681]: 0.002305419207539639
Loss at iteration [1682]: 0.0023053296337876947
Loss at iteration [1683]: 0.0023052433264543143
Loss at iteration [1684]: 0.002305167031667524
Loss at iteration [1685]: 0.0023050757688535435
Loss at iteration [1686]: 0.002304992901485655
Loss at iteration [1687]: 0.00230490645486338
Loss at iteration [1688]: 0.002304832687888827
Loss at iteration [1689]: 0.0023047582712206506
Loss at iteration [1690]: 0.0023046699171107208
Loss at iteration [1691]: 0.0023045686943393468
Loss at iteration [1692]: 0.0023045043939954107
Loss at iteration [1693]: 0.0023044277502391845
Loss at iteration [1694]: 0.0023043234975114644
Loss at iteration [1695]: 0.0023042400800105385
Loss at iteration [1696]: 0.0023041544893520195
Loss at iteration [1697]: 0.0023040760019762763
Loss at iteration [1698]: 0.002303986834845172
Loss at iteration [1699]: 0.0023038991109653687
Loss at iteration [1700]: 0.0023038269043648947
Loss at iteration [1701]: 0.002303748134019821
Loss at iteration [1702]: 0.0023036544996522775
Loss at iteration [1703]: 0.002303572526484384
Loss at iteration [1704]: 0.00230348707751004
Loss at iteration [1705]: 0.002303404669071895
Loss at iteration [1706]: 0.002303320222206612
Loss at iteration [1707]: 0.002303247413419936
Loss at iteration [1708]: 0.0023031586124871257
Loss at iteration [1709]: 0.0023030792715675636
Loss at iteration [1710]: 0.0023029938102859747
Loss at iteration [1711]: 0.002302917877340178
Loss at iteration [1712]: 0.0023028466755290315
Loss at iteration [1713]: 0.002302763949042019
Loss at iteration [1714]: 0.002302670083386916
Loss at iteration [1715]: 0.0023025817615438464
Loss at iteration [1716]: 0.002302496980296017
Loss at iteration [1717]: 0.0023024223052313776
Loss at iteration [1718]: 0.0023023431549212114
Loss at iteration [1719]: 0.002302258876202946
Loss at iteration [1720]: 0.0023021691716983606
Loss at iteration [1721]: 0.002302098224413915
Loss at iteration [1722]: 0.0023020179552648914
Loss at iteration [1723]: 0.002301926559779118
Loss at iteration [1724]: 0.002301850708764697
Loss at iteration [1725]: 0.002301769135704753
Loss at iteration [1726]: 0.0023016767603772983
Loss at iteration [1727]: 0.0023016110805899395
Loss at iteration [1728]: 0.002301519708859089
Loss at iteration [1729]: 0.0023014367290774018
Loss at iteration [1730]: 0.002301365108493767
Loss at iteration [1731]: 0.0023012773316160406
Loss at iteration [1732]: 0.002301186105899763
Loss at iteration [1733]: 0.002301119843625043
Loss at iteration [1734]: 0.002301026785999767
Loss at iteration [1735]: 0.0023009493926020863
Loss at iteration [1736]: 0.0023008784961471218
Loss at iteration [1737]: 0.0023007959602381204
Loss at iteration [1738]: 0.0023007068916057766
Loss at iteration [1739]: 0.0023006252179907046
Loss at iteration [1740]: 0.0023005394917099643
Loss at iteration [1741]: 0.0023004619316743225
Loss at iteration [1742]: 0.0023003901121236344
Loss at iteration [1743]: 0.00230030961546818
Loss at iteration [1744]: 0.0023002186428839532
Loss at iteration [1745]: 0.0023001371801965684
Loss at iteration [1746]: 0.0023000581708379608
Loss at iteration [1747]: 0.002299983687936822
Loss at iteration [1748]: 0.002299907886491038
Loss at iteration [1749]: 0.002299828096174966
Loss at iteration [1750]: 0.0022997377217958245
Loss at iteration [1751]: 0.0022996571282733413
Loss at iteration [1752]: 0.002299567948815556
Loss at iteration [1753]: 0.0022995049081322456
Loss at iteration [1754]: 0.0022994281705338068
Loss at iteration [1755]: 0.002299350073864867
Loss at iteration [1756]: 0.0022992606916917148
Loss at iteration [1757]: 0.0022991735909307447
Loss at iteration [1758]: 0.0022990888361347586
Loss at iteration [1759]: 0.0022990237805017434
Loss at iteration [1760]: 0.002298950645288773
Loss at iteration [1761]: 0.002298873960853781
Loss at iteration [1762]: 0.0022987885350265794
Loss at iteration [1763]: 0.0022986955057028467
Loss at iteration [1764]: 0.002298610511649684
Loss at iteration [1765]: 0.0022985366710945965
Loss at iteration [1766]: 0.0022984615571561163
Loss at iteration [1767]: 0.002298387811572061
Loss at iteration [1768]: 0.0022983077001065416
Loss at iteration [1769]: 0.0022982217536944684
Loss at iteration [1770]: 0.002298145165411487
Loss at iteration [1771]: 0.0022980657352641687
Loss at iteration [1772]: 0.0022979890172948685
Loss at iteration [1773]: 0.002297907458027683
Loss at iteration [1774]: 0.0022978291462384813
Loss at iteration [1775]: 0.0022977400644770447
Loss at iteration [1776]: 0.002297681648479612
Loss at iteration [1777]: 0.002297594339187574
Loss at iteration [1778]: 0.0022975189828430874
Loss at iteration [1779]: 0.0022974443438273915
Loss at iteration [1780]: 0.002297374783322309
Loss at iteration [1781]: 0.0022972947979566474
Loss at iteration [1782]: 0.0022971963826806416
Loss at iteration [1783]: 0.002297156340427458
Loss at iteration [1784]: 0.0022970825002105837
Loss at iteration [1785]: 0.0022969687334204562
Loss at iteration [1786]: 0.0022969121327099822
Loss at iteration [1787]: 0.002296866825964702
Loss at iteration [1788]: 0.0022967941922782524
Loss at iteration [1789]: 0.00229670115270053
Loss at iteration [1790]: 0.002296598199709695
Loss at iteration [1791]: 0.002296504848475026
Loss at iteration [1792]: 0.002296460575319352
Loss at iteration [1793]: 0.0022963896000460097
Loss at iteration [1794]: 0.002296280061493192
Loss at iteration [1795]: 0.0022962064394302564
Loss at iteration [1796]: 0.002296150512386128
Loss at iteration [1797]: 0.0022960791121417056
Loss at iteration [1798]: 0.0022959956478469526
Loss at iteration [1799]: 0.002295903924391878
Loss at iteration [1800]: 0.0022958137974178187
Loss at iteration [1801]: 0.0022957636078873964
Loss at iteration [1802]: 0.002295690224496311
Loss at iteration [1803]: 0.0022955812516830603
Loss at iteration [1804]: 0.0022955311437298192
Loss at iteration [1805]: 0.0022954724967533843
Loss at iteration [1806]: 0.002295407322990008
Loss at iteration [1807]: 0.002295322243258931
Loss at iteration [1808]: 0.002295228295692698
Loss at iteration [1809]: 0.002295132168231012
Loss at iteration [1810]: 0.0022950574193500903
Loss at iteration [1811]: 0.002294987251626331
Loss at iteration [1812]: 0.0022948937953997032
Loss at iteration [1813]: 0.0022948250966424734
Loss at iteration [1814]: 0.0022947483798435083
Loss at iteration [1815]: 0.0022946694728008562
Loss at iteration [1816]: 0.00229461259508345
Loss at iteration [1817]: 0.002294514407999599
Loss at iteration [1818]: 0.0022944599673197417
Loss at iteration [1819]: 0.0022943954397326807
Loss at iteration [1820]: 0.0022943176269736246
Loss at iteration [1821]: 0.002294239487935229
Loss at iteration [1822]: 0.0022941572947127787
Loss at iteration [1823]: 0.0022940660250690935
Loss at iteration [1824]: 0.0022940242290945085
Loss at iteration [1825]: 0.0022939569661205284
Loss at iteration [1826]: 0.00229384756230694
Loss at iteration [1827]: 0.002293784005693219
Loss at iteration [1828]: 0.0022937344844439693
Loss at iteration [1829]: 0.002293679114836423
Loss at iteration [1830]: 0.0022936002648927846
Loss at iteration [1831]: 0.0022934977604298396
Loss at iteration [1832]: 0.002293406208807665
Loss at iteration [1833]: 0.0022933184105203433
Loss at iteration [1834]: 0.002293303069396684
Loss at iteration [1835]: 0.0022932377496842895
Loss at iteration [1836]: 0.0022931283520779147
Loss at iteration [1837]: 0.0022930201727506083
Loss at iteration [1838]: 0.002292966285051153
Loss at iteration [1839]: 0.002292901577607961
Loss at iteration [1840]: 0.0022928252169707613
Loss at iteration [1841]: 0.002292745520831798
Loss at iteration [1842]: 0.0022926527574506305
Loss at iteration [1843]: 0.002292563244602484
Loss at iteration [1844]: 0.0022925413826765653
Loss at iteration [1845]: 0.002292471878987576
Loss at iteration [1846]: 0.002292356373934504
Loss at iteration [1847]: 0.0022922876983907403
Loss at iteration [1848]: 0.002292230248534296
Loss at iteration [1849]: 0.0022921659791732417
Loss at iteration [1850]: 0.0022920924778612193
Loss at iteration [1851]: 0.0022920060655294413
Loss at iteration [1852]: 0.002291919410497636
Loss at iteration [1853]: 0.0022918332380596116
Loss at iteration [1854]: 0.002291813530967306
Loss at iteration [1855]: 0.002291739065317042
Loss at iteration [1856]: 0.002291627910131515
Loss at iteration [1857]: 0.0022915605255085084
Loss at iteration [1858]: 0.002291502459803752
Loss at iteration [1859]: 0.002291438267168602
Loss at iteration [1860]: 0.0022913632203877383
Loss at iteration [1861]: 0.002291276575909644
Loss at iteration [1862]: 0.002291177714103486
Loss at iteration [1863]: 0.002291087655147937
Loss at iteration [1864]: 0.0022910740620258534
Loss at iteration [1865]: 0.002291008247262876
Loss at iteration [1866]: 0.0022908900372492873
Loss at iteration [1867]: 0.0022908089720737423
Loss at iteration [1868]: 0.0022907687296762035
Loss at iteration [1869]: 0.002290703484642282
Loss at iteration [1870]: 0.002290619284918759
Loss at iteration [1871]: 0.0022905412926867838
Loss at iteration [1872]: 0.002290455893622128
Loss at iteration [1873]: 0.002290356894100466
Loss at iteration [1874]: 0.002290314933622049
Loss at iteration [1875]: 0.002290254021002112
Loss at iteration [1876]: 0.002290147249564377
Loss at iteration [1877]: 0.002290094023559089
Loss at iteration [1878]: 0.0022900357216131886
Loss at iteration [1879]: 0.002289972764502618
Loss at iteration [1880]: 0.0022899012393392372
Loss at iteration [1881]: 0.002289826900417248
Loss at iteration [1882]: 0.002289735425201203
Loss at iteration [1883]: 0.002289635814093319
Loss at iteration [1884]: 0.002289584683069129
Loss at iteration [1885]: 0.002289521473184421
Loss at iteration [1886]: 0.002289421731244099
Loss at iteration [1887]: 0.002289376777850488
Loss at iteration [1888]: 0.0022893205887805595
Loss at iteration [1889]: 0.0022892445233960103
Loss at iteration [1890]: 0.0022891613656474533
Loss at iteration [1891]: 0.002289085513714725
Loss at iteration [1892]: 0.0022890047892046993
Loss at iteration [1893]: 0.0022889144551789006
Loss at iteration [1894]: 0.002288871184323575
Loss at iteration [1895]: 0.002288796268475319
Loss at iteration [1896]: 0.0022886936360650826
Loss at iteration [1897]: 0.0022886431025845523
Loss at iteration [1898]: 0.0022885735930888882
Loss at iteration [1899]: 0.0022884871570407117
Loss at iteration [1900]: 0.002288403254080447
Loss at iteration [1901]: 0.002288363579854101
Loss at iteration [1902]: 0.0022882740686916737
Loss at iteration [1903]: 0.0022881945052968637
Loss at iteration [1904]: 0.0022881335713484303
Loss at iteration [1905]: 0.002288068739161031
Loss at iteration [1906]: 0.0022879927436572156
Loss at iteration [1907]: 0.0022879132724469998
Loss at iteration [1908]: 0.0022878333005877743
Loss at iteration [1909]: 0.0022877736341686146
Loss at iteration [1910]: 0.0022876953515049386
Loss at iteration [1911]: 0.00228761232432501
Loss at iteration [1912]: 0.0022875486770398664
Loss at iteration [1913]: 0.002287470871331447
Loss at iteration [1914]: 0.0022873956086642672
Loss at iteration [1915]: 0.002287311230901229
Loss at iteration [1916]: 0.0022872606483374785
Loss at iteration [1917]: 0.0022871768067050944
Loss at iteration [1918]: 0.0022871139740944647
Loss at iteration [1919]: 0.002287057508767149
Loss at iteration [1920]: 0.0022869782324415654
Loss at iteration [1921]: 0.0022868928198524923
Loss at iteration [1922]: 0.002286812765802144
Loss at iteration [1923]: 0.002286739357998342
Loss at iteration [1924]: 0.0022866580926926595
Loss at iteration [1925]: 0.0022866033292669803
Loss at iteration [1926]: 0.0022865392433811097
Loss at iteration [1927]: 0.0022864644395794126
Loss at iteration [1928]: 0.0022863849083693613
Loss at iteration [1929]: 0.0022863032667028733
Loss at iteration [1930]: 0.0022862503635007973
Loss at iteration [1931]: 0.0022861688068197433
Loss at iteration [1932]: 0.0022860986222704672
Loss at iteration [1933]: 0.0022860359831007116
Loss at iteration [1934]: 0.0022859731031380894
Loss at iteration [1935]: 0.0022858971614192086
Loss at iteration [1936]: 0.0022858149875783513
Loss at iteration [1937]: 0.002285749380352759
Loss at iteration [1938]: 0.002285661390880227
Loss at iteration [1939]: 0.002285608042050969
Loss at iteration [1940]: 0.0022855552494376445
Loss at iteration [1941]: 0.0022854811488903838
Loss at iteration [1942]: 0.002285393730110118
Loss at iteration [1943]: 0.002285305936383197
Loss at iteration [1944]: 0.0022852499871841812
Loss at iteration [1945]: 0.002285174040268807
Loss at iteration [1946]: 0.0022851042030835656
Loss at iteration [1947]: 0.002285041181290711
Loss at iteration [1948]: 0.0022849779769201005
Loss at iteration [1949]: 0.0022849080955542867
Loss at iteration [1950]: 0.002284822749392534
Loss at iteration [1951]: 0.0022847444474051303
Loss at iteration [1952]: 0.0022846695426069165
Loss at iteration [1953]: 0.002284626642055355
Loss at iteration [1954]: 0.002284569273957762
Loss at iteration [1955]: 0.002284490681737298
Loss at iteration [1956]: 0.002284404159493312
Loss at iteration [1957]: 0.002284325336607333
Loss at iteration [1958]: 0.002284261397103195
Loss at iteration [1959]: 0.0022841753749824095
Loss at iteration [1960]: 0.002284109889155011
Loss at iteration [1961]: 0.0022840651570468253
Loss at iteration [1962]: 0.0022840000066112216
Loss at iteration [1963]: 0.002283922517887922
Loss at iteration [1964]: 0.002283839684581873
Loss at iteration [1965]: 0.0022837510469721086
Loss at iteration [1966]: 0.002283724894917809
Loss at iteration [1967]: 0.002283654567222078
Loss at iteration [1968]: 0.002283552532362306
Loss at iteration [1969]: 0.002283486623046471
Loss at iteration [1970]: 0.0022834236104459487
Loss at iteration [1971]: 0.0022833600103465707
Loss at iteration [1972]: 0.0022832860399279197
Loss at iteration [1973]: 0.0022831972905205476
Loss at iteration [1974]: 0.002283126095163848
Loss at iteration [1975]: 0.0022830677958240396
Loss at iteration [1976]: 0.0022829915609190315
Loss at iteration [1977]: 0.0022829314170745405
Loss at iteration [1978]: 0.0022828687891400714
Loss at iteration [1979]: 0.0022828004511832047
Loss at iteration [1980]: 0.0022827201195634176
Loss at iteration [1981]: 0.0022826500551923518
Loss at iteration [1982]: 0.002282579923703341
Loss at iteration [1983]: 0.002282516670683408
Loss at iteration [1984]: 0.0022824399753438324
Loss at iteration [1985]: 0.002282380890825524
Loss at iteration [1986]: 0.0022823013913784457
Loss at iteration [1987]: 0.002282232289931448
Loss at iteration [1988]: 0.0022821654521745843
Loss at iteration [1989]: 0.002282108054548728
Loss at iteration [1990]: 0.002282026947507247
Loss at iteration [1991]: 0.0022819634561389197
Loss at iteration [1992]: 0.002281894853110721
Loss at iteration [1993]: 0.002281819999325103
Loss at iteration [1994]: 0.0022817802949815164
Loss at iteration [1995]: 0.0022816930729390103
Loss at iteration [1996]: 0.002281629280574527
Loss at iteration [1997]: 0.0022815771173992773
Loss at iteration [1998]: 0.0022815142129841578
Loss at iteration [1999]: 0.002281441059352945
Loss at iteration [2000]: 0.0022813631741607898
Loss at iteration [2001]: 0.00228128079748396
Loss at iteration [2002]: 0.002281257715027116
Loss at iteration [2003]: 0.0022811838941128064
Loss at iteration [2004]: 0.0022810898074435465
Loss at iteration [2005]: 0.0022810314339735192
Loss at iteration [2006]: 0.002280978194661401
Loss at iteration [2007]: 0.002280910164760388
Loss at iteration [2008]: 0.0022808285811745047
Loss at iteration [2009]: 0.002280778432616764
Loss at iteration [2010]: 0.0022806928047514677
Loss at iteration [2011]: 0.002280623967427321
Loss at iteration [2012]: 0.00228058458693997
Loss at iteration [2013]: 0.002280525303651617
Loss at iteration [2014]: 0.002280440955376177
Loss at iteration [2015]: 0.0022803652062808634
Loss at iteration [2016]: 0.0022802899211340566
Loss at iteration [2017]: 0.002280254270621482
Loss at iteration [2018]: 0.002280175475160161
Loss at iteration [2019]: 0.002280087489310057
Loss at iteration [2020]: 0.002280026118720019
Loss at iteration [2021]: 0.002279967838300742
Loss at iteration [2022]: 0.002279898279000973
Loss at iteration [2023]: 0.002279820613428839
Loss at iteration [2024]: 0.0022797471009716962
Loss at iteration [2025]: 0.0022796761085036713
Loss at iteration [2026]: 0.0022796103394656453
Loss at iteration [2027]: 0.0022795457115535166
Loss at iteration [2028]: 0.0022794890015810135
Loss at iteration [2029]: 0.0022794247222190666
Loss at iteration [2030]: 0.0022793541350361757
Loss at iteration [2031]: 0.0022792902855316988
Loss at iteration [2032]: 0.0022792223220728714
Loss at iteration [2033]: 0.002279143911118751
Loss at iteration [2034]: 0.002279073887099564
Loss at iteration [2035]: 0.002278997857032687
Loss at iteration [2036]: 0.002278940017008865
Loss at iteration [2037]: 0.002278860494900167
Loss at iteration [2038]: 0.002278811502717177
Loss at iteration [2039]: 0.002278768192741545
Loss at iteration [2040]: 0.0022786644799740203
Loss at iteration [2041]: 0.0022785893253071884
Loss at iteration [2042]: 0.0022785350744218814
Loss at iteration [2043]: 0.002278469361686001
Loss at iteration [2044]: 0.0022784105242916065
Loss at iteration [2045]: 0.0022783394901654355
Loss at iteration [2046]: 0.0022782633046258896
Loss at iteration [2047]: 0.002278198453308408
Loss at iteration [2048]: 0.00227811982010548
Loss at iteration [2049]: 0.0022780571264020446
Loss at iteration [2050]: 0.0022779945038554337
Loss at iteration [2051]: 0.0022779330388540703
Loss at iteration [2052]: 0.0022778672004014253
Loss at iteration [2053]: 0.002277796404164443
Loss at iteration [2054]: 0.002277724113158804
Loss at iteration [2055]: 0.002277683148236185
Loss at iteration [2056]: 0.002277595043708857
Loss at iteration [2057]: 0.00227758839234303
Loss at iteration [2058]: 0.002277479509109678
Loss at iteration [2059]: 0.002277470693681324
Loss at iteration [2060]: 0.0022774423014086842
Loss at iteration [2061]: 0.0022773390718626666
Loss at iteration [2062]: 0.0022772042628642257
Loss at iteration [2063]: 0.002277183895959596
Loss at iteration [2064]: 0.0022770829313731285
Loss at iteration [2065]: 0.0022770426191184973
Loss at iteration [2066]: 0.002276972900257353
Loss at iteration [2067]: 0.002276891157116387
Loss at iteration [2068]: 0.002276842531619289
Loss at iteration [2069]: 0.0022767854241237595
Loss at iteration [2070]: 0.002276722248424354
Loss at iteration [2071]: 0.0022766229638390817
Loss at iteration [2072]: 0.002276654265118102
***** Warning: Loss has increased *****
Loss at iteration [2073]: 0.0022765515251859177
Loss at iteration [2074]: 0.0022764695945362958
Loss at iteration [2075]: 0.0022764584016096694
Loss at iteration [2076]: 0.0022763870486020013
Loss at iteration [2077]: 0.002276276655522149
Loss at iteration [2078]: 0.0022762419086964102
Loss at iteration [2079]: 0.0022761610982210234
Loss at iteration [2080]: 0.0022760804362983193
Loss at iteration [2081]: 0.0022760506156411214
Loss at iteration [2082]: 0.0022759734056101984
Loss at iteration [2083]: 0.002275883392800249
Loss at iteration [2084]: 0.002275829058509866
Loss at iteration [2085]: 0.002275760141141394
Loss at iteration [2086]: 0.002275691772852538
Loss at iteration [2087]: 0.0022756497216608997
Loss at iteration [2088]: 0.002275576864382794
Loss at iteration [2089]: 0.002275511279669213
Loss at iteration [2090]: 0.0022754634228826327
Loss at iteration [2091]: 0.0022753682476652974
Loss at iteration [2092]: 0.002275319549464717
Loss at iteration [2093]: 0.0022752389464786374
Loss at iteration [2094]: 0.0022751778657436068
Loss at iteration [2095]: 0.0022751165046813993
Loss at iteration [2096]: 0.0022750644291423465
Loss at iteration [2097]: 0.002274983023443787
Loss at iteration [2098]: 0.0022749214744893337
Loss at iteration [2099]: 0.002274909456552432
Loss at iteration [2100]: 0.0022748696445692982
Loss at iteration [2101]: 0.0022747648381342897
Loss at iteration [2102]: 0.0022747470637704704
Loss at iteration [2103]: 0.0022746573205151446
Loss at iteration [2104]: 0.002274593832724521
Loss at iteration [2105]: 0.002274555882202182
Loss at iteration [2106]: 0.002274469663690556
Loss at iteration [2107]: 0.0022743896443987665
Loss at iteration [2108]: 0.002274307515499724
Loss at iteration [2109]: 0.002274258189496735
Loss at iteration [2110]: 0.002274181023227577
Loss at iteration [2111]: 0.0022741772750698606
Loss at iteration [2112]: 0.002274054026670791
Loss at iteration [2113]: 0.0022740092773930066
Loss at iteration [2114]: 0.00227395086564326
Loss at iteration [2115]: 0.002273879060832721
Loss at iteration [2116]: 0.0022738093238187543
Loss at iteration [2117]: 0.0022737409283172623
Loss at iteration [2118]: 0.002273747535741923
***** Warning: Loss has increased *****
Loss at iteration [2119]: 0.002273622176193701
Loss at iteration [2120]: 0.0022735819116614406
Loss at iteration [2121]: 0.002273526778855764
Loss at iteration [2122]: 0.0022734356117956062
Loss at iteration [2123]: 0.0022733914795814354
Loss at iteration [2124]: 0.0022733318755190743
Loss at iteration [2125]: 0.002273280940481173
Loss at iteration [2126]: 0.002273183911700815
Loss at iteration [2127]: 0.002273237789602755
***** Warning: Loss has increased *****
Loss at iteration [2128]: 0.0022731488883551243
Loss at iteration [2129]: 0.002273045334105821
Loss at iteration [2130]: 0.002273010119986888
Loss at iteration [2131]: 0.0022729391320767934
Loss at iteration [2132]: 0.0022728330668174827
Loss at iteration [2133]: 0.0022728096114050245
Loss at iteration [2134]: 0.0022727057941717174
Loss at iteration [2135]: 0.0022726602381183073
Loss at iteration [2136]: 0.002272608836306785
Loss at iteration [2137]: 0.002272530104138083
Loss at iteration [2138]: 0.002272447916236295
Loss at iteration [2139]: 0.0022724487693700185
***** Warning: Loss has increased *****
