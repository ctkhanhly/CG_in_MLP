Model name                            : MLP_Multistep
The number of input features          : 10
The number of output features         : 2
Optimizer name                        : Adam
Learning rate                         : 0.0001
Max number of iterations              : 3000
Number of samples in training data    : 71
Number of samples in tests data       : 30
Total training time                   : 2.2493300437927246
Total number of parameters            : 203302
Percentage of parameters < 1e-9       : 49.39203746151046%
Percentage of parameters < 1e-7       : 49.39203746151046%
Percentage of parameters < 1e-6       : 49.3935130987398%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.5737996929020153
Loss at iteration [2]: 1.5569719984751567
Loss at iteration [3]: 1.5405811202439785
Loss at iteration [4]: 1.5242268993869608
Loss at iteration [5]: 1.5081932217708656
Loss at iteration [6]: 1.4929388342410235
Loss at iteration [7]: 1.4778996980056331
Loss at iteration [8]: 1.4631103566773893
Loss at iteration [9]: 1.4484294781401006
Loss at iteration [10]: 1.4339297922567718
Loss at iteration [11]: 1.4194776244621472
Loss at iteration [12]: 1.4050384561633937
Loss at iteration [13]: 1.3904986401262702
Loss at iteration [14]: 1.3759005118699248
Loss at iteration [15]: 1.3615635951663552
Loss at iteration [16]: 1.3473748565028592
Loss at iteration [17]: 1.3332277942925805
Loss at iteration [18]: 1.3189748176550025
Loss at iteration [19]: 1.3047300425802895
Loss at iteration [20]: 1.2904638479190096
Loss at iteration [21]: 1.2761650633685793
Loss at iteration [22]: 1.2617394052941593
Loss at iteration [23]: 1.247279910734213
Loss at iteration [24]: 1.2325886451435466
Loss at iteration [25]: 1.2176967016342723
Loss at iteration [26]: 1.2026523045459019
Loss at iteration [27]: 1.1874392088326062
Loss at iteration [28]: 1.1721674138128333
Loss at iteration [29]: 1.1568073021119551
Loss at iteration [30]: 1.141343458685247
Loss at iteration [31]: 1.1258805917151995
Loss at iteration [32]: 1.110424100410688
Loss at iteration [33]: 1.0949715943314478
Loss at iteration [34]: 1.0795196431515048
Loss at iteration [35]: 1.0641086673852778
Loss at iteration [36]: 1.0487937257768334
Loss at iteration [37]: 1.0335802217234331
Loss at iteration [38]: 1.0184634927065253
Loss at iteration [39]: 1.003458787770008
Loss at iteration [40]: 0.9886317199086082
Loss at iteration [41]: 0.9740585372292456
Loss at iteration [42]: 0.95976251480674
Loss at iteration [43]: 0.9457797673266827
Loss at iteration [44]: 0.9321770026294687
Loss at iteration [45]: 0.918987392182656
Loss at iteration [46]: 0.9062561825153168
Loss at iteration [47]: 0.8939585082627135
Loss at iteration [48]: 0.8820983899831543
Loss at iteration [49]: 0.8707124886022595
Loss at iteration [50]: 0.8598204591931483
Loss at iteration [51]: 0.8494373762832257
Loss at iteration [52]: 0.8395004997844937
Loss at iteration [53]: 0.8300605354937641
Loss at iteration [54]: 0.8212422864774566
Loss at iteration [55]: 0.8129500150675917
Loss at iteration [56]: 0.8051894407657216
Loss at iteration [57]: 0.7977946539035374
Loss at iteration [58]: 0.7907793815328632
Loss at iteration [59]: 0.7841774578950131
Loss at iteration [60]: 0.7779345728821422
Loss at iteration [61]: 0.7719794990589672
Loss at iteration [62]: 0.766237932006866
Loss at iteration [63]: 0.7608208238652766
Loss at iteration [64]: 0.7556678418827173
Loss at iteration [65]: 0.7507056332536887
Loss at iteration [66]: 0.7458582712891741
Loss at iteration [67]: 0.7410670224921595
Loss at iteration [68]: 0.7363252985915835
Loss at iteration [69]: 0.7317213405337448
Loss at iteration [70]: 0.7270655601499605
Loss at iteration [71]: 0.722434790578618
Loss at iteration [72]: 0.7178274232467254
Loss at iteration [73]: 0.7132146910870969
Loss at iteration [74]: 0.7086686987655305
Loss at iteration [75]: 0.7043480069231631
Loss at iteration [76]: 0.7001175896384793
Loss at iteration [77]: 0.695929234200447
Loss at iteration [78]: 0.6917167575943628
Loss at iteration [79]: 0.6874210163185057
Loss at iteration [80]: 0.683159001312845
Loss at iteration [81]: 0.6788961221066923
Loss at iteration [82]: 0.6746401120178407
Loss at iteration [83]: 0.6703502677982524
Loss at iteration [84]: 0.6659855704521733
Loss at iteration [85]: 0.6615387994722898
Loss at iteration [86]: 0.6570655323932284
Loss at iteration [87]: 0.6525513955181143
Loss at iteration [88]: 0.6480270782000084
Loss at iteration [89]: 0.6434615208832343
Loss at iteration [90]: 0.6388801061701984
Loss at iteration [91]: 0.63428163772856
Loss at iteration [92]: 0.6296371309276546
Loss at iteration [93]: 0.6249590248457748
Loss at iteration [94]: 0.6202604024849323
Loss at iteration [95]: 0.6156124089863553
Loss at iteration [96]: 0.6109727202397635
Loss at iteration [97]: 0.6062993188941879
Loss at iteration [98]: 0.6016127107860597
Loss at iteration [99]: 0.596928473632689
Loss at iteration [100]: 0.5922084712592209
Loss at iteration [101]: 0.5874681434718415
Loss at iteration [102]: 0.5827240839530223
Loss at iteration [103]: 0.5780261619019542
Loss at iteration [104]: 0.5733570198005318
Loss at iteration [105]: 0.5686794491369666
Loss at iteration [106]: 0.5639372949937053
Loss at iteration [107]: 0.5592130410628366
Loss at iteration [108]: 0.5545327081279088
Loss at iteration [109]: 0.5499060328208765
Loss at iteration [110]: 0.5452872936391384
Loss at iteration [111]: 0.5407041862161163
Loss at iteration [112]: 0.5361254642041836
Loss at iteration [113]: 0.5315770341041417
Loss at iteration [114]: 0.5270802425789933
Loss at iteration [115]: 0.5226651259219054
Loss at iteration [116]: 0.5183168434938124
Loss at iteration [117]: 0.5140319300682047
Loss at iteration [118]: 0.5098018411113
Loss at iteration [119]: 0.5056159776776231
Loss at iteration [120]: 0.5014788405661216
Loss at iteration [121]: 0.49741621550626774
Loss at iteration [122]: 0.4934742378864216
Loss at iteration [123]: 0.48960374185762223
Loss at iteration [124]: 0.48580439634805106
Loss at iteration [125]: 0.4821047593677635
Loss at iteration [126]: 0.4785117563661005
Loss at iteration [127]: 0.4750530526386174
Loss at iteration [128]: 0.47170564466296677
Loss at iteration [129]: 0.46844736038355017
Loss at iteration [130]: 0.46527987359487644
Loss at iteration [131]: 0.462189519406118
Loss at iteration [132]: 0.45918617211903556
Loss at iteration [133]: 0.45626198331932877
Loss at iteration [134]: 0.45343883655082473
Loss at iteration [135]: 0.45068853782812845
Loss at iteration [136]: 0.4480067310032891
Loss at iteration [137]: 0.445370108436681
Loss at iteration [138]: 0.44279790539577935
Loss at iteration [139]: 0.44026724199115075
Loss at iteration [140]: 0.43778844200332445
Loss at iteration [141]: 0.4353394308175868
Loss at iteration [142]: 0.43292105506157696
Loss at iteration [143]: 0.4305148893535797
Loss at iteration [144]: 0.42814593990228816
Loss at iteration [145]: 0.4258125748839446
Loss at iteration [146]: 0.42348145617821636
Loss at iteration [147]: 0.4211529919338349
Loss at iteration [148]: 0.4188254325851458
Loss at iteration [149]: 0.4164939444785411
Loss at iteration [150]: 0.41415220388932694
Loss at iteration [151]: 0.41180173723113017
Loss at iteration [152]: 0.40943685066772817
Loss at iteration [153]: 0.407066843957289
Loss at iteration [154]: 0.40472233785350387
Loss at iteration [155]: 0.4023291219951897
Loss at iteration [156]: 0.39991011476415506
Loss at iteration [157]: 0.3974896398654912
Loss at iteration [158]: 0.39507537906232393
Loss at iteration [159]: 0.39264869877572545
Loss at iteration [160]: 0.3902216428882706
Loss at iteration [161]: 0.38781394422423093
Loss at iteration [162]: 0.38539991773994825
Loss at iteration [163]: 0.38297566002313044
Loss at iteration [164]: 0.38061822483408925
Loss at iteration [165]: 0.3782591974134088
Loss at iteration [166]: 0.37589274952836765
Loss at iteration [167]: 0.37351246178072345
Loss at iteration [168]: 0.3711788017622964
Loss at iteration [169]: 0.3689131051638035
Loss at iteration [170]: 0.36661893204101303
Loss at iteration [171]: 0.36429792262527855
Loss at iteration [172]: 0.36195959487157736
Loss at iteration [173]: 0.35963828298101247
Loss at iteration [174]: 0.35740042938373073
Loss at iteration [175]: 0.35512972996472836
Loss at iteration [176]: 0.3528834834427785
Loss at iteration [177]: 0.3506838294056553
Loss at iteration [178]: 0.3485068185549457
Loss at iteration [179]: 0.3463817719238648
Loss at iteration [180]: 0.34426221651414207
Loss at iteration [181]: 0.34217579452137853
Loss at iteration [182]: 0.3401000592186545
Loss at iteration [183]: 0.33799937543174
Loss at iteration [184]: 0.33589652845079515
Loss at iteration [185]: 0.33385126358731804
Loss at iteration [186]: 0.33179374679769574
Loss at iteration [187]: 0.32970692097492277
Loss at iteration [188]: 0.3276041958601277
Loss at iteration [189]: 0.3255633373993517
Loss at iteration [190]: 0.3235632699710093
Loss at iteration [191]: 0.3215882405946785
Loss at iteration [192]: 0.3196464965036756
Loss at iteration [193]: 0.317718069083328
Loss at iteration [194]: 0.3157724756151435
Loss at iteration [195]: 0.313854294792162
Loss at iteration [196]: 0.31200296023786345
Loss at iteration [197]: 0.3101613041434005
Loss at iteration [198]: 0.3083537505191473
Loss at iteration [199]: 0.3065562535028044
Loss at iteration [200]: 0.30477791067829374
Loss at iteration [201]: 0.3030441566415743
Loss at iteration [202]: 0.30135708683670437
Loss at iteration [203]: 0.2996535806666333
Loss at iteration [204]: 0.29798517760204873
Loss at iteration [205]: 0.29633664595013437
Loss at iteration [206]: 0.2946771317329745
Loss at iteration [207]: 0.29302783192904447
Loss at iteration [208]: 0.29141850115098517
Loss at iteration [209]: 0.28985354427232135
Loss at iteration [210]: 0.2883140816551653
Loss at iteration [211]: 0.2868404774461544
Loss at iteration [212]: 0.28538670233821023
Loss at iteration [213]: 0.283914746100951
Loss at iteration [214]: 0.28245244343465437
Loss at iteration [215]: 0.2810457136047646
Loss at iteration [216]: 0.2796519420538899
Loss at iteration [217]: 0.27825932006312787
Loss at iteration [218]: 0.27688622751181347
Loss at iteration [219]: 0.2755317382800867
Loss at iteration [220]: 0.2742226458837417
Loss at iteration [221]: 0.2729090619302977
Loss at iteration [222]: 0.27160052902653026
Loss at iteration [223]: 0.27031788882540114
Loss at iteration [224]: 0.26903998557880243
Loss at iteration [225]: 0.2677907767718578
Loss at iteration [226]: 0.2665618265125334
Loss at iteration [227]: 0.26534905253929175
Loss at iteration [228]: 0.2641392542984689
Loss at iteration [229]: 0.2629404291728204
Loss at iteration [230]: 0.26175774619423536
Loss at iteration [231]: 0.2605731544261996
Loss at iteration [232]: 0.2594221172798469
Loss at iteration [233]: 0.25829671951028216
Loss at iteration [234]: 0.25717690561248313
Loss at iteration [235]: 0.25605283834761694
Loss at iteration [236]: 0.25494702980004036
Loss at iteration [237]: 0.2538529161111561
Loss at iteration [238]: 0.25277866739402893
Loss at iteration [239]: 0.2517278602114837
Loss at iteration [240]: 0.25068764489092366
Loss at iteration [241]: 0.24965758536871813
Loss at iteration [242]: 0.24864492636308344
Loss at iteration [243]: 0.24764137285107443
Loss at iteration [244]: 0.24665391991904242
Loss at iteration [245]: 0.24569600309390208
Loss at iteration [246]: 0.2447598722393356
Loss at iteration [247]: 0.24383064580466646
Loss at iteration [248]: 0.24291992278417446
Loss at iteration [249]: 0.2420101584228603
Loss at iteration [250]: 0.2411291427113456
Loss at iteration [251]: 0.24026547229405537
Loss at iteration [252]: 0.2394240347983509
Loss at iteration [253]: 0.2385896462974357
Loss at iteration [254]: 0.2377661038094624
Loss at iteration [255]: 0.2369618154517797
Loss at iteration [256]: 0.23617413131061646
Loss at iteration [257]: 0.2353964493646631
Loss at iteration [258]: 0.23464964833585766
Loss at iteration [259]: 0.23391996570515966
Loss at iteration [260]: 0.23321035657892403
Loss at iteration [261]: 0.23251743252209037
Loss at iteration [262]: 0.23183143269713588
Loss at iteration [263]: 0.23116466633658006
Loss at iteration [264]: 0.23052504840934038
Loss at iteration [265]: 0.2299005890608829
Loss at iteration [266]: 0.22928942868948468
Loss at iteration [267]: 0.22869249377375628
Loss at iteration [268]: 0.22811170858764454
Loss at iteration [269]: 0.22755000285562924
Loss at iteration [270]: 0.2270071923010779
Loss at iteration [271]: 0.22648000175207322
Loss at iteration [272]: 0.22596714513289193
Loss at iteration [273]: 0.2254707992455409
Loss at iteration [274]: 0.22498790707757532
Loss at iteration [275]: 0.22451869682957412
Loss at iteration [276]: 0.2240707930264801
Loss at iteration [277]: 0.2236365335724496
Loss at iteration [278]: 0.2232138753356701
Loss at iteration [279]: 0.22280876980122327
Loss at iteration [280]: 0.2224172056686064
Loss at iteration [281]: 0.22204421268524843
Loss at iteration [282]: 0.22167844046719803
Loss at iteration [283]: 0.22132286804392554
Loss at iteration [284]: 0.22097949367871894
Loss at iteration [285]: 0.22065909328109615
Loss at iteration [286]: 0.2203462039592955
Loss at iteration [287]: 0.22004247583341507
Loss at iteration [288]: 0.219754578361043
Loss at iteration [289]: 0.21948445204376044
Loss at iteration [290]: 0.21922103187683797
Loss at iteration [291]: 0.21896835173093557
Loss at iteration [292]: 0.21872735437889765
Loss at iteration [293]: 0.21849870012849065
Loss at iteration [294]: 0.21827995091709396
Loss at iteration [295]: 0.21806846545810898
Loss at iteration [296]: 0.2178685245189291
Loss at iteration [297]: 0.2176687045298179
Loss at iteration [298]: 0.2174852460454067
Loss at iteration [299]: 0.21731512571915002
Loss at iteration [300]: 0.21715027960505112
Loss at iteration [301]: 0.21699505897985172
Loss at iteration [302]: 0.21684789464522636
Loss at iteration [303]: 0.21670885236421064
Loss at iteration [304]: 0.21657657503498784
Loss at iteration [305]: 0.21645186143516656
Loss at iteration [306]: 0.21633131935702354
Loss at iteration [307]: 0.21622170104487767
Loss at iteration [308]: 0.2161175860124573
Loss at iteration [309]: 0.21601605543146193
Loss at iteration [310]: 0.21592032703613734
Loss at iteration [311]: 0.21583236521282453
Loss at iteration [312]: 0.21574873413356466
Loss at iteration [313]: 0.2156702664276215
Loss at iteration [314]: 0.21559668170086274
Loss at iteration [315]: 0.21552778662640312
Loss at iteration [316]: 0.21546286398746112
Loss at iteration [317]: 0.2154015908217104
Loss at iteration [318]: 0.21534615534966267
Loss at iteration [319]: 0.21529369715241575
Loss at iteration [320]: 0.21524412371142132
Loss at iteration [321]: 0.21519707723150308
Loss at iteration [322]: 0.2151543352869307
Loss at iteration [323]: 0.21511402585804756
Loss at iteration [324]: 0.215076836906757
Loss at iteration [325]: 0.21504134656920865
Loss at iteration [326]: 0.21500958843686493
Loss at iteration [327]: 0.21497975695809704
Loss at iteration [328]: 0.21495139491143378
Loss at iteration [329]: 0.21492547745906512
Loss at iteration [330]: 0.21490187008177422
Loss at iteration [331]: 0.21487977338700073
Loss at iteration [332]: 0.21485910305921282
Loss at iteration [333]: 0.2148402839213863
Loss at iteration [334]: 0.21482297198241035
Loss at iteration [335]: 0.21480677567172626
Loss at iteration [336]: 0.21479198125867466
Loss at iteration [337]: 0.21477860334948093
Loss at iteration [338]: 0.214766183131548
Loss at iteration [339]: 0.21475483631587086
Loss at iteration [340]: 0.21474422394186168
Loss at iteration [341]: 0.21473433788933635
Loss at iteration [342]: 0.21472540157763986
Loss at iteration [343]: 0.2147172248324543
Loss at iteration [344]: 0.2147096184264679
Loss at iteration [345]: 0.21470262480408697
Loss at iteration [346]: 0.21469639464111706
Loss at iteration [347]: 0.21469069300997662
Loss at iteration [348]: 0.21468540648076243
Loss at iteration [349]: 0.21468051809138863
Loss at iteration [350]: 0.2146760130834108
Loss at iteration [351]: 0.2146719463337915
Loss at iteration [352]: 0.2146682263146959
Loss at iteration [353]: 0.21466478652530527
Loss at iteration [354]: 0.2146616338627172
Loss at iteration [355]: 0.2146586468978469
Loss at iteration [356]: 0.21465603128902622
Loss at iteration [357]: 0.2146536089079083
Loss at iteration [358]: 0.21465132824915786
Loss at iteration [359]: 0.21464921200788278
Loss at iteration [360]: 0.214647205887783
Loss at iteration [361]: 0.21464533375048372
Loss at iteration [362]: 0.2146436395266203
Loss at iteration [363]: 0.21464210424318111
Loss at iteration [364]: 0.21464065078189856
Loss at iteration [365]: 0.21463924762683068
Loss at iteration [366]: 0.2146379278522504
Loss at iteration [367]: 0.21463666407344006
Loss at iteration [368]: 0.21463546583644139
Loss at iteration [369]: 0.21463438092772266
Loss at iteration [370]: 0.2146333230453316
Loss at iteration [371]: 0.21463230365389335
Loss at iteration [372]: 0.21463134866239192
Loss at iteration [373]: 0.21463042039952498
Loss at iteration [374]: 0.21462950418756127
Loss at iteration [375]: 0.2146286350222196
Loss at iteration [376]: 0.21462778498534293
Loss at iteration [377]: 0.21462696084628463
Loss at iteration [378]: 0.21462615494896817
Loss at iteration [379]: 0.2146253685543818
Loss at iteration [380]: 0.2146246144308719
Loss at iteration [381]: 0.214623854575543
Loss at iteration [382]: 0.21462310035229
Loss at iteration [383]: 0.21462237727295802
Loss at iteration [384]: 0.214621661156537
Loss at iteration [385]: 0.21462095511410617
Loss at iteration [386]: 0.21462026269188747
Loss at iteration [387]: 0.21461958168054407
Loss at iteration [388]: 0.21461891396344185
Loss at iteration [389]: 0.2146182523197163
Loss at iteration [390]: 0.21461759451539247
Loss at iteration [391]: 0.21461694196743092
Loss at iteration [392]: 0.21461630893803704
Loss at iteration [393]: 0.2146156773870872
Loss at iteration [394]: 0.21461505360539554
Loss at iteration [395]: 0.21461444182036513
Loss at iteration [396]: 0.21461383613180754
Loss at iteration [397]: 0.21461323674147004
Loss at iteration [398]: 0.21461265091022289
Loss at iteration [399]: 0.21461206833914584
Loss at iteration [400]: 0.21461148808482797
Loss at iteration [401]: 0.214610923933251
Loss at iteration [402]: 0.21461036172008988
Loss at iteration [403]: 0.21460980764971746
Loss at iteration [404]: 0.2146092614786958
Loss at iteration [405]: 0.21460872765595804
Loss at iteration [406]: 0.21460819549731466
Loss at iteration [407]: 0.21460767100372677
Loss at iteration [408]: 0.2146071592125401
Loss at iteration [409]: 0.2146066510564647
Loss at iteration [410]: 0.2146061455559236
Loss at iteration [411]: 0.21460564595177856
Loss at iteration [412]: 0.21460516001568722
Loss at iteration [413]: 0.21460467567167774
Loss at iteration [414]: 0.21460419438017236
Loss at iteration [415]: 0.21460372472010025
Loss at iteration [416]: 0.21460325715442494
Loss at iteration [417]: 0.2146027947653619
Loss at iteration [418]: 0.21460235059748387
Loss at iteration [419]: 0.2146019167265955
Loss at iteration [420]: 0.21460149527949568
Loss at iteration [421]: 0.21460107011710303
Loss at iteration [422]: 0.2146006516336732
Loss at iteration [423]: 0.21460024538721859
Loss at iteration [424]: 0.21459984498238993
Loss at iteration [425]: 0.21459944725301863
Loss at iteration [426]: 0.2145990512517856
Loss at iteration [427]: 0.21459866125480395
Loss at iteration [428]: 0.21459827947099402
Loss at iteration [429]: 0.21459789885149938
Loss at iteration [430]: 0.21459751788704196
Loss at iteration [431]: 0.21459714515894124
Loss at iteration [432]: 0.2145967762947808
Loss at iteration [433]: 0.21459641015383019
Loss at iteration [434]: 0.21459604706192068
Loss at iteration [435]: 0.21459568809011778
Loss at iteration [436]: 0.21459533260403693
Loss at iteration [437]: 0.2145949804415587
Loss at iteration [438]: 0.2145946314670531
Loss at iteration [439]: 0.21459428757924628
Loss at iteration [440]: 0.21459394511384045
Loss at iteration [441]: 0.2145936054010984
Loss at iteration [442]: 0.21459327054714017
Loss at iteration [443]: 0.21459293880302496
Loss at iteration [444]: 0.21459261019483106
Loss at iteration [445]: 0.2145922824895136
Loss at iteration [446]: 0.21459195987158736
Loss at iteration [447]: 0.2145916372235535
Loss at iteration [448]: 0.21459132154248522
Loss at iteration [449]: 0.21459100838994669
Loss at iteration [450]: 0.21459069573649195
Loss at iteration [451]: 0.21459038444368547
Loss at iteration [452]: 0.21459007501195046
Loss at iteration [453]: 0.21458976893430287
Loss at iteration [454]: 0.21458942868019612
Loss at iteration [455]: 0.21458907859624946
Loss at iteration [456]: 0.21458872666249026
Loss at iteration [457]: 0.2145883707393873
Loss at iteration [458]: 0.21458801660127114
Loss at iteration [459]: 0.21458773552059104
Loss at iteration [460]: 0.21458745460936396
Loss at iteration [461]: 0.2145871724149461
Loss at iteration [462]: 0.21458688889877098
Loss at iteration [463]: 0.21458660949893554
Loss at iteration [464]: 0.21458633308413502
Loss at iteration [465]: 0.21458606454129114
Loss at iteration [466]: 0.21458579768663416
Loss at iteration [467]: 0.21458553102663602
Loss at iteration [468]: 0.21458526393372934
Loss at iteration [469]: 0.2145849964332397
Loss at iteration [470]: 0.2145847296541129
Loss at iteration [471]: 0.21458446915887558
Loss at iteration [472]: 0.21458420890152752
Loss at iteration [473]: 0.2145839484724887
Loss at iteration [474]: 0.2145836947507294
Loss at iteration [475]: 0.2145834423620568
Loss at iteration [476]: 0.21458319110078986
Loss at iteration [477]: 0.21458294021495475
Loss at iteration [478]: 0.2145826912973035
Loss at iteration [479]: 0.21458244497931167
Loss at iteration [480]: 0.21458220098815353
Loss at iteration [481]: 0.21458195939297997
Loss at iteration [482]: 0.214581719991258
Loss at iteration [483]: 0.21458148350865763
Loss at iteration [484]: 0.21458124879526322
Loss at iteration [485]: 0.21458101537703664
Loss at iteration [486]: 0.21458078305577338
Loss at iteration [487]: 0.21458055198062542
Loss at iteration [488]: 0.21458032313888595
Loss at iteration [489]: 0.21458009708192416
Loss at iteration [490]: 0.21457987277741092
Loss at iteration [491]: 0.21457965012410293
Loss at iteration [492]: 0.2145794287999346
Loss at iteration [493]: 0.2145792095259564
Loss at iteration [494]: 0.2145789915544202
Loss at iteration [495]: 0.21457877555477498
Loss at iteration [496]: 0.21457856094524635
Loss at iteration [497]: 0.21457837551331954
Loss at iteration [498]: 0.21457821263201246
Loss at iteration [499]: 0.2145780452166986
Loss at iteration [500]: 0.21457787570873807
Loss at iteration [501]: 0.2145777029603668
Loss at iteration [502]: 0.21457752878643663
Loss at iteration [503]: 0.21457735258856148
Loss at iteration [504]: 0.21457717468832907
Loss at iteration [505]: 0.21457699690478327
Loss at iteration [506]: 0.21457683169392663
Loss at iteration [507]: 0.2145766525039518
Loss at iteration [508]: 0.2145764694596409
Loss at iteration [509]: 0.21457629596498287
Loss at iteration [510]: 0.21457612000319462
Loss at iteration [511]: 0.21457594905325575
Loss at iteration [512]: 0.21457579463460486
Loss at iteration [513]: 0.21457563749262892
Loss at iteration [514]: 0.21457548019806646
Loss at iteration [515]: 0.21457532186626269
Loss at iteration [516]: 0.21457516366656643
Loss at iteration [517]: 0.21457500548619457
Loss at iteration [518]: 0.21457485455698597
Loss at iteration [519]: 0.2145746982594097
Loss at iteration [520]: 0.21457453947438282
Loss at iteration [521]: 0.21457439270531573
Loss at iteration [522]: 0.21457424659756427
Loss at iteration [523]: 0.21457409749610873
Loss at iteration [524]: 0.21457394529167095
Loss at iteration [525]: 0.21457380581485005
Loss at iteration [526]: 0.214573664577776
Loss at iteration [527]: 0.21457352408438354
Loss at iteration [528]: 0.21457338123244496
Loss at iteration [529]: 0.214573237463839
Loss at iteration [530]: 0.21457309272947825
Loss at iteration [531]: 0.2145729465858657
Loss at iteration [532]: 0.21457280976096893
Loss at iteration [533]: 0.2145726745996039
Loss at iteration [534]: 0.21457253697234394
Loss at iteration [535]: 0.21457239678129134
Loss at iteration [536]: 0.21457226241879132
Loss at iteration [537]: 0.2145721258592827
Loss at iteration [538]: 0.21457199106396935
Loss at iteration [539]: 0.21457185567354142
Loss at iteration [540]: 0.21457172625385862
Loss at iteration [541]: 0.21457159609150228
Loss at iteration [542]: 0.21457146132487456
Loss at iteration [543]: 0.2145713322054153
Loss at iteration [544]: 0.21457120031757954
Loss at iteration [545]: 0.21457107130089753
Loss at iteration [546]: 0.21457094284679076
Loss at iteration [547]: 0.21457081286455654
Loss at iteration [548]: 0.21457068591167786
Loss at iteration [549]: 0.21457055747149298
Loss at iteration [550]: 0.21457043130093958
Loss at iteration [551]: 0.21457030374159317
Loss at iteration [552]: 0.2145701804826869
Loss at iteration [553]: 0.21457005419323014
Loss at iteration [554]: 0.21456992826643778
Loss at iteration [555]: 0.2145698042727439
Loss at iteration [556]: 0.21456967870968877
Loss at iteration [557]: 0.2145695606631018
Loss at iteration [558]: 0.21456943619002275
Loss at iteration [559]: 0.2145693143457386
Loss at iteration [560]: 0.21456919276713998
Loss at iteration [561]: 0.21456907065281483
Loss at iteration [562]: 0.21456895549668767
Loss at iteration [563]: 0.21456883322420425
Loss at iteration [564]: 0.2145687132916607
Loss at iteration [565]: 0.21456859648861532
Loss at iteration [566]: 0.2145684753454615
Loss at iteration [567]: 0.21456835577155126
Loss at iteration [568]: 0.21456824025320523
Loss at iteration [569]: 0.21456812146938245
Loss at iteration [570]: 0.21456800278077015
Loss at iteration [571]: 0.21456788941559582
Loss at iteration [572]: 0.21456777334262242
Loss at iteration [573]: 0.21456765690453838
Loss at iteration [574]: 0.21456753828284292
Loss at iteration [575]: 0.2145674207275231
Loss at iteration [576]: 0.21456730712137873
Loss at iteration [577]: 0.21456719084297965
Loss at iteration [578]: 0.21456707379366144
Loss at iteration [579]: 0.2145669607998732
Loss at iteration [580]: 0.21456684519282085
Loss at iteration [581]: 0.21456673080401675
Loss at iteration [582]: 0.21456661761301238
Loss at iteration [583]: 0.21456650247947293
Loss at iteration [584]: 0.21456639212500758
Loss at iteration [585]: 0.214566280603044
Loss at iteration [586]: 0.21456617212993023
Loss at iteration [587]: 0.2145660529664722
Loss at iteration [588]: 0.2145659474956616
Loss at iteration [589]: 0.21456583954881223
Loss at iteration [590]: 0.21456572578266594
Loss at iteration [591]: 0.2145656133849099
Loss at iteration [592]: 0.21456550480176667
Loss at iteration [593]: 0.2145653954733442
Loss at iteration [594]: 0.2145652842662458
Loss at iteration [595]: 0.21456517322133753
Loss at iteration [596]: 0.21456506162493658
Loss at iteration [597]: 0.21456495413281795
Loss at iteration [598]: 0.21456484393516026
Loss at iteration [599]: 0.2145647351127999
Loss at iteration [600]: 0.21456462745359783
Loss at iteration [601]: 0.21456451947871447
Loss at iteration [602]: 0.2145644116975367
Loss at iteration [603]: 0.2145643035438536
Loss at iteration [604]: 0.21456419560643702
Loss at iteration [605]: 0.2145640908875699
Loss at iteration [606]: 0.214563985023068
Loss at iteration [607]: 0.2145638780167198
Loss at iteration [608]: 0.21456377605423593
Loss at iteration [609]: 0.21456366955986264
Loss at iteration [610]: 0.21456356020716313
Loss at iteration [611]: 0.21456345587745157
Loss at iteration [612]: 0.21456335159117146
Loss at iteration [613]: 0.21456324788529987
Loss at iteration [614]: 0.2145631434882034
Loss at iteration [615]: 0.21456304101934814
Loss at iteration [616]: 0.21456293651898917
Loss at iteration [617]: 0.21456283238697005
Loss at iteration [618]: 0.21456272985100194
Loss at iteration [619]: 0.21456262635123477
Loss at iteration [620]: 0.2145625229806441
Loss at iteration [621]: 0.2145624203186618
Loss at iteration [622]: 0.21456231879881177
Loss at iteration [623]: 0.21456221614719911
Loss at iteration [624]: 0.21456211430201555
Loss at iteration [625]: 0.21456201436570752
Loss at iteration [626]: 0.21456191160013968
Loss at iteration [627]: 0.21456181327616194
Loss at iteration [628]: 0.21456171491457932
Loss at iteration [629]: 0.21456161252018852
Loss at iteration [630]: 0.21456151217615102
Loss at iteration [631]: 0.2145614155873926
Loss at iteration [632]: 0.2145613158269542
Loss at iteration [633]: 0.214561213546721
Loss at iteration [634]: 0.21456111359869054
Loss at iteration [635]: 0.2145610128967293
Loss at iteration [636]: 0.21456091429496385
Loss at iteration [637]: 0.21456081400775226
Loss at iteration [638]: 0.2145607185890536
Loss at iteration [639]: 0.2145606213651786
Loss at iteration [640]: 0.21456052071073387
Loss at iteration [641]: 0.21456042085883978
Loss at iteration [642]: 0.2145603223486533
Loss at iteration [643]: 0.2145602245869466
Loss at iteration [644]: 0.21456012676412956
Loss at iteration [645]: 0.214560028883849
Loss at iteration [646]: 0.2145599339400609
Loss at iteration [647]: 0.21455983587325678
Loss at iteration [648]: 0.214559737456229
Loss at iteration [649]: 0.21455964110569692
Loss at iteration [650]: 0.2145595434456756
Loss at iteration [651]: 0.21455944846314046
Loss at iteration [652]: 0.21455935107531518
Loss at iteration [653]: 0.21455925655063188
Loss at iteration [654]: 0.2145591608417894
Loss at iteration [655]: 0.214559063495801
Loss at iteration [656]: 0.2145589678423917
Loss at iteration [657]: 0.21455887133326476
Loss at iteration [658]: 0.21455877784706376
Loss at iteration [659]: 0.21455868340096718
Loss at iteration [660]: 0.21455858713403797
Loss at iteration [661]: 0.21455849229965662
Loss at iteration [662]: 0.21455839658141718
Loss at iteration [663]: 0.2145583034108099
Loss at iteration [664]: 0.21455820864649153
Loss at iteration [665]: 0.21455811429651764
Loss at iteration [666]: 0.21455802267996374
Loss at iteration [667]: 0.21455792747608216
Loss at iteration [668]: 0.21455783604519899
Loss at iteration [669]: 0.21455774292390226
Loss at iteration [670]: 0.21455764922422166
Loss at iteration [671]: 0.21455755481012098
Loss at iteration [672]: 0.21455746455247113
Loss at iteration [673]: 0.21455737373009526
Loss at iteration [674]: 0.21455727822183035
Loss at iteration [675]: 0.214557185576474
Loss at iteration [676]: 0.21455709562603031
Loss at iteration [677]: 0.21455700379249937
Loss at iteration [678]: 0.21455691074688954
Loss at iteration [679]: 0.21455681738035826
Loss at iteration [680]: 0.2145567270615434
Loss at iteration [681]: 0.21455663711022893
Loss at iteration [682]: 0.21455654384357312
Loss at iteration [683]: 0.21455645193819672
Loss at iteration [684]: 0.2145563624024037
Loss at iteration [685]: 0.21455627178072603
Loss at iteration [686]: 0.21455618001769253
Loss at iteration [687]: 0.2145560882197791
Loss at iteration [688]: 0.2145559980202524
Loss at iteration [689]: 0.2145559091465979
Loss at iteration [690]: 0.2145558187081518
Loss at iteration [691]: 0.2145557286274184
Loss at iteration [692]: 0.21455564002617816
Loss at iteration [693]: 0.21455554972871851
Loss at iteration [694]: 0.2145554610778742
Loss at iteration [695]: 0.21455537138361652
Loss at iteration [696]: 0.21455528210265254
Loss at iteration [697]: 0.21455519373664605
Loss at iteration [698]: 0.21455510402248207
Loss at iteration [699]: 0.21455501842086092
Loss at iteration [700]: 0.21455492991958267
Loss at iteration [701]: 0.2145548418939484
Loss at iteration [702]: 0.21455475252368514
Loss at iteration [703]: 0.21455466685399266
Loss at iteration [704]: 0.2145545804005686
Loss at iteration [705]: 0.2145544904501175
Loss at iteration [706]: 0.21455440437626655
Loss at iteration [707]: 0.21455431901547029
Loss at iteration [708]: 0.21455423221458442
Loss at iteration [709]: 0.21455414455725888
Loss at iteration [710]: 0.21455405646171136
Loss at iteration [711]: 0.21455397137983162
Loss at iteration [712]: 0.2145538860996859
Loss at iteration [713]: 0.21455379783796757
Loss at iteration [714]: 0.2145537120508791
Loss at iteration [715]: 0.21455362762795682
Loss at iteration [716]: 0.2145535422088097
Loss at iteration [717]: 0.21455345580657575
Loss at iteration [718]: 0.21455336845841688
Loss at iteration [719]: 0.21455328642522942
Loss at iteration [720]: 0.21455320258795504
Loss at iteration [721]: 0.2145531157629424
Loss at iteration [722]: 0.21455302875110202
Loss at iteration [723]: 0.2145529457639808
Loss at iteration [724]: 0.2145528617253431
Loss at iteration [725]: 0.21455277649046303
Loss at iteration [726]: 0.21455269210346084
Loss at iteration [727]: 0.21455260831590137
Loss at iteration [728]: 0.21455252535477412
Loss at iteration [729]: 0.2145524428252081
Loss at iteration [730]: 0.21455236078303172
Loss at iteration [731]: 0.21455228002480992
Loss at iteration [732]: 0.2145521954914788
Loss at iteration [733]: 0.21455211128590404
Loss at iteration [734]: 0.2145520282781925
Loss at iteration [735]: 0.21455194442654085
Loss at iteration [736]: 0.21455186232563753
Loss at iteration [737]: 0.21455178292623056
Loss at iteration [738]: 0.21455170055966258
Loss at iteration [739]: 0.21455161806511636
Loss at iteration [740]: 0.2145515358319095
Loss at iteration [741]: 0.21455145231145162
Loss at iteration [742]: 0.21455137393676826
Loss at iteration [743]: 0.2145512925720563
Loss at iteration [744]: 0.21455120895332552
Loss at iteration [745]: 0.21455113130669146
Loss at iteration [746]: 0.21455105175457845
Loss at iteration [747]: 0.2145509724667886
Loss at iteration [748]: 0.21455089144885
Loss at iteration [749]: 0.21455081001635398
Loss at iteration [750]: 0.21455072911413672
Loss at iteration [751]: 0.2145506475607223
Loss at iteration [752]: 0.2145505698764734
Loss at iteration [753]: 0.2145504891002789
Loss at iteration [754]: 0.2145504109175379
Loss at iteration [755]: 0.21455033240143898
Loss at iteration [756]: 0.2145502527788181
Loss at iteration [757]: 0.21455017325121764
Loss at iteration [758]: 0.21455009484508095
Loss at iteration [759]: 0.21455001649078329
Loss at iteration [760]: 0.21454993799141528
Loss at iteration [761]: 0.214549860071248
Loss at iteration [762]: 0.21454978198290595
Loss at iteration [763]: 0.21454970589253738
Loss at iteration [764]: 0.21454962795744129
Loss at iteration [765]: 0.214549550197937
Loss at iteration [766]: 0.21454947258338133
Loss at iteration [767]: 0.21454939470440632
Loss at iteration [768]: 0.21454931691923435
Loss at iteration [769]: 0.2145492387606972
Loss at iteration [770]: 0.21454916402676902
Loss at iteration [771]: 0.21454908686004193
Loss at iteration [772]: 0.2145490099320128
Loss at iteration [773]: 0.21454893235209999
Loss at iteration [774]: 0.21454885619443267
Loss at iteration [775]: 0.2145487800287276
Loss at iteration [776]: 0.21454870208639856
Loss at iteration [777]: 0.2145486259290027
Loss at iteration [778]: 0.2145485498874661
Loss at iteration [779]: 0.2145484757798879
Loss at iteration [780]: 0.21454839964340064
Loss at iteration [781]: 0.21454832326832934
Loss at iteration [782]: 0.21454824761047533
Loss at iteration [783]: 0.21454817214033117
Loss at iteration [784]: 0.21454809896010624
Loss at iteration [785]: 0.21454802279996085
Loss at iteration [786]: 0.21454794902508958
Loss at iteration [787]: 0.21454787435915776
Loss at iteration [788]: 0.21454779961822848
Loss at iteration [789]: 0.21454772475032283
Loss at iteration [790]: 0.21454765149205288
Loss at iteration [791]: 0.21454757778305
Loss at iteration [792]: 0.2145475018934704
Loss at iteration [793]: 0.21454742807659
Loss at iteration [794]: 0.21454735620300283
Loss at iteration [795]: 0.21454728141032536
Loss at iteration [796]: 0.21454720837871533
Loss at iteration [797]: 0.21454713626729666
Loss at iteration [798]: 0.21454706242441546
Loss at iteration [799]: 0.2145469905863343
Loss at iteration [800]: 0.21454691874301962
Loss at iteration [801]: 0.21454684614325578
Loss at iteration [802]: 0.21454677310438378
Loss at iteration [803]: 0.21454670006224272
Loss at iteration [804]: 0.21454662803146402
Loss at iteration [805]: 0.21454655684632334
Loss at iteration [806]: 0.21454648577985302
Loss at iteration [807]: 0.21454641388568785
Loss at iteration [808]: 0.21454634215628002
Loss at iteration [809]: 0.21454627043471206
Loss at iteration [810]: 0.21454620109443803
Loss at iteration [811]: 0.21454613043882897
Loss at iteration [812]: 0.21454605968883814
Loss at iteration [813]: 0.21454598830484267
Loss at iteration [814]: 0.21454591953237387
Loss at iteration [815]: 0.21454584980806088
Loss at iteration [816]: 0.21454578107733732
Loss at iteration [817]: 0.21454571658500293
Loss at iteration [818]: 0.21454565225137273
Loss at iteration [819]: 0.21454558639153942
Loss at iteration [820]: 0.21454551961809093
Loss at iteration [821]: 0.21454545235356814
Loss at iteration [822]: 0.2145453840974063
Loss at iteration [823]: 0.21454532171088164
Loss at iteration [824]: 0.21454525618825077
Loss at iteration [825]: 0.21454518808919606
Loss at iteration [826]: 0.21454511838386475
Loss at iteration [827]: 0.21454505475469407
Loss at iteration [828]: 0.21454499188096451
Loss at iteration [829]: 0.21454492436212577
Loss at iteration [830]: 0.21454486005179754
Loss at iteration [831]: 0.2145447959168268
Loss at iteration [832]: 0.21454473071003832
Loss at iteration [833]: 0.21454466218736648
Loss at iteration [834]: 0.21454459279342897
Loss at iteration [835]: 0.2145445276196635
Loss at iteration [836]: 0.21454446337276298
Loss at iteration [837]: 0.2145443987159199
Loss at iteration [838]: 0.21454433375587503
Loss at iteration [839]: 0.21454426891344744
Loss at iteration [840]: 0.21454420173550467
Loss at iteration [841]: 0.2145441373013503
Loss at iteration [842]: 0.21454407428740593
Loss at iteration [843]: 0.21454401078127439
Loss at iteration [844]: 0.21454394754954625
Loss at iteration [845]: 0.21454388391003806
Loss at iteration [846]: 0.21454381897232652
Loss at iteration [847]: 0.21454375555231053
Loss at iteration [848]: 0.21454369210262364
Loss at iteration [849]: 0.214543629873252
Loss at iteration [850]: 0.214543567813273
Loss at iteration [851]: 0.21454350493266222
Loss at iteration [852]: 0.21454344163251787
Loss at iteration [853]: 0.2145433794821479
Loss at iteration [854]: 0.21454331790646838
Loss at iteration [855]: 0.21454325578305555
Loss at iteration [856]: 0.21454319422352397
Loss at iteration [857]: 0.2145431317645469
Loss at iteration [858]: 0.2145430716315469
Loss at iteration [859]: 0.21454301394221667
Loss at iteration [860]: 0.21454295489725114
Loss at iteration [861]: 0.2145428978299306
Loss at iteration [862]: 0.21454284013720035
Loss at iteration [863]: 0.21454278289800469
Loss at iteration [864]: 0.21454272505948105
Loss at iteration [865]: 0.21454266681270068
Loss at iteration [866]: 0.21454260881320353
Loss at iteration [867]: 0.21454255158668703
Loss at iteration [868]: 0.21454249269937664
Loss at iteration [869]: 0.21454243606068316
Loss at iteration [870]: 0.2145423781411711
Loss at iteration [871]: 0.21454231963061038
Loss at iteration [872]: 0.21454226313042976
Loss at iteration [873]: 0.21454220535424381
Loss at iteration [874]: 0.21454214732741622
Loss at iteration [875]: 0.21454209214288514
Loss at iteration [876]: 0.21454203518695328
Loss at iteration [877]: 0.21454197636725075
Loss at iteration [878]: 0.21454192069876135
Loss at iteration [879]: 0.2145418652048741
Loss at iteration [880]: 0.21454181068916123
Loss at iteration [881]: 0.21454175543164705
Loss at iteration [882]: 0.21454170000968328
Loss at iteration [883]: 0.2145416439421143
Loss at iteration [884]: 0.21454158743165827
Loss at iteration [885]: 0.21454153476730894
Loss at iteration [886]: 0.2145414800490748
Loss at iteration [887]: 0.21454142430382206
Loss at iteration [888]: 0.21454136763234447
Loss at iteration [889]: 0.21454131527972184
Loss at iteration [890]: 0.21454126279591257
Loss at iteration [891]: 0.21454120927161974
Loss at iteration [892]: 0.21454115907398313
Loss at iteration [893]: 0.21454110819822536
Loss at iteration [894]: 0.21454105729574524
Loss at iteration [895]: 0.21454100702990864
Loss at iteration [896]: 0.2145409563490565
Loss at iteration [897]: 0.2145409050902197
Loss at iteration [898]: 0.21454085362460443
Loss at iteration [899]: 0.21454080479900062
Loss at iteration [900]: 0.21454075483496132
Loss at iteration [901]: 0.21454070305227244
Loss at iteration [902]: 0.2145406537720862
Loss at iteration [903]: 0.2145406041890299
Loss at iteration [904]: 0.21454055620658588
Loss at iteration [905]: 0.2145405042127771
Loss at iteration [906]: 0.21454045386160775
Loss at iteration [907]: 0.2145404037309392
Loss at iteration [908]: 0.21454035401186963
Loss at iteration [909]: 0.21454030470782554
Loss at iteration [910]: 0.21454025498495422
Loss at iteration [911]: 0.21454020559576503
Loss at iteration [912]: 0.21454015576739685
Loss at iteration [913]: 0.2145401067532156
Loss at iteration [914]: 0.21454005752749264
Loss at iteration [915]: 0.21454000825711536
Loss at iteration [916]: 0.21453996003324585
Loss at iteration [917]: 0.2145399109351763
Loss at iteration [918]: 0.21453986337531045
Loss at iteration [919]: 0.2145398159052473
Loss at iteration [920]: 0.21453976838580135
Loss at iteration [921]: 0.2145397204150649
Loss at iteration [922]: 0.21453967268369517
Loss at iteration [923]: 0.214539624464385
Loss at iteration [924]: 0.21453957748039157
Loss at iteration [925]: 0.21453953088330063
Loss at iteration [926]: 0.21453948351981864
Loss at iteration [927]: 0.21453943630752795
Loss at iteration [928]: 0.2145393898404443
Loss at iteration [929]: 0.21453934293859295
Loss at iteration [930]: 0.21453929625517015
Loss at iteration [931]: 0.2145392509556734
Loss at iteration [932]: 0.21453920425693623
Loss at iteration [933]: 0.21453915873885487
Loss at iteration [934]: 0.2145391130886184
Loss at iteration [935]: 0.21453906727026545
Loss at iteration [936]: 0.21453902134437652
Loss at iteration [937]: 0.21453897509525077
Loss at iteration [938]: 0.21453893215818762
Loss at iteration [939]: 0.21453888718130493
Loss at iteration [940]: 0.21453884046046703
Loss at iteration [941]: 0.2145387954587882
Loss at iteration [942]: 0.21453875181189005
Loss at iteration [943]: 0.21453870800855004
Loss at iteration [944]: 0.2145386631132767
Loss at iteration [945]: 0.2145386182003931
Loss at iteration [946]: 0.21453857295312
Loss at iteration [947]: 0.21453853143068935
Loss at iteration [948]: 0.21453848774218587
Loss at iteration [949]: 0.21453844288274543
Loss at iteration [950]: 0.21453839838826863
Loss at iteration [951]: 0.2145383557935244
Loss at iteration [952]: 0.21453831239077578
Loss at iteration [953]: 0.21453826810046156
Loss at iteration [954]: 0.2145382240408671
Loss at iteration [955]: 0.21453818064329275
Loss at iteration [956]: 0.21453813768984556
Loss at iteration [957]: 0.21453809352997896
Loss at iteration [958]: 0.21453805050851912
Loss at iteration [959]: 0.21453800733643086
Loss at iteration [960]: 0.21453796406293194
Loss at iteration [961]: 0.2145379217727289
Loss at iteration [962]: 0.21453787913572311
Loss at iteration [963]: 0.21453783700687978
Loss at iteration [964]: 0.21453779406165707
Loss at iteration [965]: 0.21453775248787885
Loss at iteration [966]: 0.2145377109130036
Loss at iteration [967]: 0.21453766917562564
Loss at iteration [968]: 0.21453762710184834
Loss at iteration [969]: 0.2145375847941923
Loss at iteration [970]: 0.21453754328085203
Loss at iteration [971]: 0.21453750175190248
Loss at iteration [972]: 0.21453746027094778
Loss at iteration [973]: 0.21453741951366564
Loss at iteration [974]: 0.2145373782219468
Loss at iteration [975]: 0.2145373369885227
Loss at iteration [976]: 0.21453729787414977
Loss at iteration [977]: 0.21453725748269564
Loss at iteration [978]: 0.2145372174893562
Loss at iteration [979]: 0.21453717972761419
Loss at iteration [980]: 0.21453714026442564
Loss at iteration [981]: 0.2145371001055327
Loss at iteration [982]: 0.21453705963622907
Loss at iteration [983]: 0.21453702022823418
Loss at iteration [984]: 0.21453698087688097
Loss at iteration [985]: 0.21453694066483223
Loss at iteration [986]: 0.21453689994152003
Loss at iteration [987]: 0.21453685935305
Loss at iteration [988]: 0.2145368215106054
Loss at iteration [989]: 0.21453678280730917
Loss at iteration [990]: 0.21453674273048726
Loss at iteration [991]: 0.21453670442054737
Loss at iteration [992]: 0.21453666602416857
Loss at iteration [993]: 0.2145366275530055
Loss at iteration [994]: 0.2145365894001604
Loss at iteration [995]: 0.21453655108822806
Loss at iteration [996]: 0.21453651350994876
Loss at iteration [997]: 0.21453647585005525
Loss at iteration [998]: 0.21453643775546397
Loss at iteration [999]: 0.214536400199728
Loss at iteration [1000]: 0.21453636315942104
Loss at iteration [1001]: 0.21453632570221803
Loss at iteration [1002]: 0.21453628860792065
Loss at iteration [1003]: 0.2145362518653168
Loss at iteration [1004]: 0.21453621505134884
Loss at iteration [1005]: 0.21453617808555622
Loss at iteration [1006]: 0.21453614161261916
Loss at iteration [1007]: 0.2145361050770262
Loss at iteration [1008]: 0.21453606867762065
Loss at iteration [1009]: 0.2145360327519684
Loss at iteration [1010]: 0.21453599693352723
Loss at iteration [1011]: 0.21453596085443263
Loss at iteration [1012]: 0.21453592514010866
Loss at iteration [1013]: 0.21453588917355104
Loss at iteration [1014]: 0.214535854041201
Loss at iteration [1015]: 0.2145358190874849
Loss at iteration [1016]: 0.21453578385306857
Loss at iteration [1017]: 0.21453574846400914
Loss at iteration [1018]: 0.21453571319626227
Loss at iteration [1019]: 0.2145356782820696
Loss at iteration [1020]: 0.2145356441149376
Loss at iteration [1021]: 0.21453560972211497
Loss at iteration [1022]: 0.21453557550732233
Loss at iteration [1023]: 0.21453554096587563
Loss at iteration [1024]: 0.21453550632531185
Loss at iteration [1025]: 0.21453547400047507
Loss at iteration [1026]: 0.21453544078937034
Loss at iteration [1027]: 0.2145354084314211
Loss at iteration [1028]: 0.21453537805220854
Loss at iteration [1029]: 0.21453534723891912
Loss at iteration [1030]: 0.2145353165846087
Loss at iteration [1031]: 0.21453528589217896
Loss at iteration [1032]: 0.21453525474097568
Loss at iteration [1033]: 0.21453522456628152
Loss at iteration [1034]: 0.21453519534930188
Loss at iteration [1035]: 0.21453516794315458
Loss at iteration [1036]: 0.21453513676283073
Loss at iteration [1037]: 0.21453510446893867
Loss at iteration [1038]: 0.2145350745189474
Loss at iteration [1039]: 0.21453504588880104
Loss at iteration [1040]: 0.2145350169295376
Loss at iteration [1041]: 0.2145349866273347
Loss at iteration [1042]: 0.21453495667013406
Loss at iteration [1043]: 0.21453492749009342
Loss at iteration [1044]: 0.21453489770297532
Loss at iteration [1045]: 0.2145348687337842
Loss at iteration [1046]: 0.21453484045590057
Loss at iteration [1047]: 0.2145348120240497
Loss at iteration [1048]: 0.21453478336245146
Loss at iteration [1049]: 0.21453475456270166
Loss at iteration [1050]: 0.2145347256904519
Loss at iteration [1051]: 0.21453469671161104
Loss at iteration [1052]: 0.21453466939397092
Loss at iteration [1053]: 0.21453464176965065
Loss at iteration [1054]: 0.21453461332722115
Loss at iteration [1055]: 0.21453458481389362
Loss at iteration [1056]: 0.214534557385517
Loss at iteration [1057]: 0.2145345290521353
Loss at iteration [1058]: 0.214534500750975
Loss at iteration [1059]: 0.21453447246559687
Loss at iteration [1060]: 0.21453444427140275
Loss at iteration [1061]: 0.21453441610267848
Loss at iteration [1062]: 0.21453438794493412
Loss at iteration [1063]: 0.21453436058989364
Loss at iteration [1064]: 0.2145343326087194
Loss at iteration [1065]: 0.21453430499419895
Loss at iteration [1066]: 0.2145342784371327
Loss at iteration [1067]: 0.21453425160712963
Loss at iteration [1068]: 0.21453422513883746
Loss at iteration [1069]: 0.2145341992776337
Loss at iteration [1070]: 0.21453417310265277
Loss at iteration [1071]: 0.21453414710529542
Loss at iteration [1072]: 0.21453412108333667
Loss at iteration [1073]: 0.21453409507384424
Loss at iteration [1074]: 0.21453406998075458
Loss at iteration [1075]: 0.21453404537014098
Loss at iteration [1076]: 0.21453401990849447
Loss at iteration [1077]: 0.2145339958859539
Loss at iteration [1078]: 0.21453397117223272
Loss at iteration [1079]: 0.21453394518271984
Loss at iteration [1080]: 0.21453391988838744
Loss at iteration [1081]: 0.21453389503940332
Loss at iteration [1082]: 0.2145338703810646
Loss at iteration [1083]: 0.2145338452444383
Loss at iteration [1084]: 0.21453381986313394
Loss at iteration [1085]: 0.2145337956654121
Loss at iteration [1086]: 0.21453377076910016
Loss at iteration [1087]: 0.2145337468210082
Loss at iteration [1088]: 0.21453372288414269
Loss at iteration [1089]: 0.21453369911182404
Loss at iteration [1090]: 0.2145336752169938
Loss at iteration [1091]: 0.21453365118213744
Loss at iteration [1092]: 0.21453362709632362
Loss at iteration [1093]: 0.21453360294690427
Loss at iteration [1094]: 0.21453357892902966
Loss at iteration [1095]: 0.21453355489960657
Loss at iteration [1096]: 0.21453353409124762
Loss at iteration [1097]: 0.21453351310826135
Loss at iteration [1098]: 0.21453349108476838
Loss at iteration [1099]: 0.2145334689873057
Loss at iteration [1100]: 0.21453344813232808
Loss at iteration [1101]: 0.2145334268897415
Loss at iteration [1102]: 0.21453340559242062
Loss at iteration [1103]: 0.21453338448394163
Loss at iteration [1104]: 0.21453336333802134
Loss at iteration [1105]: 0.2145333425374089
Loss at iteration [1106]: 0.2145333212740699
Loss at iteration [1107]: 0.21453330058478232
Loss at iteration [1108]: 0.21453328025145788
Loss at iteration [1109]: 0.2145332597519543
Loss at iteration [1110]: 0.21453323889960396
Loss at iteration [1111]: 0.21453321803096975
Loss at iteration [1112]: 0.21453319817256808
Loss at iteration [1113]: 0.21453317744372236
Loss at iteration [1114]: 0.21453315739902593
Loss at iteration [1115]: 0.2145331374739989
Loss at iteration [1116]: 0.21453311758602508
Loss at iteration [1117]: 0.21453309751714275
Loss at iteration [1118]: 0.21453307745850625
Loss at iteration [1119]: 0.21453305744577178
Loss at iteration [1120]: 0.2145330379356299
Loss at iteration [1121]: 0.21453301826136656
Loss at iteration [1122]: 0.21453299850915475
Loss at iteration [1123]: 0.2145329801033294
Loss at iteration [1124]: 0.21453296194797788
Loss at iteration [1125]: 0.21453294281667298
Loss at iteration [1126]: 0.21453292259226633
Loss at iteration [1127]: 0.21453290303616582
Loss at iteration [1128]: 0.21453288442753704
Loss at iteration [1129]: 0.21453286606295643
Loss at iteration [1130]: 0.2145328471243269
Loss at iteration [1131]: 0.21453282786135144
Loss at iteration [1132]: 0.21453280890889068
Loss at iteration [1133]: 0.21453279077402887
Loss at iteration [1134]: 0.2145327720614218
Loss at iteration [1135]: 0.21453275341790487
Loss at iteration [1136]: 0.21453273508814164
Loss at iteration [1137]: 0.21453271688369419
Loss at iteration [1138]: 0.21453269893598892
Loss at iteration [1139]: 0.2145326805627586
Loss at iteration [1140]: 0.2145326624158513
Loss at iteration [1141]: 0.2145326441220634
Loss at iteration [1142]: 0.2145326265958914
Loss at iteration [1143]: 0.21453260897300672
Loss at iteration [1144]: 0.2145325912843516
Loss at iteration [1145]: 0.21453257342458457
Loss at iteration [1146]: 0.21453255567858537
Loss at iteration [1147]: 0.2145325379447109
Loss at iteration [1148]: 0.21453252141936116
Loss at iteration [1149]: 0.2145325041690033
Loss at iteration [1150]: 0.21453248640874728
Loss at iteration [1151]: 0.21453246945422652
Loss at iteration [1152]: 0.21453245393833711
Loss at iteration [1153]: 0.21453243822269571
Loss at iteration [1154]: 0.21453242231239336
Loss at iteration [1155]: 0.21453240641613797
Loss at iteration [1156]: 0.2145323903254205
Loss at iteration [1157]: 0.21453237439520342
Loss at iteration [1158]: 0.21453235861972686
Loss at iteration [1159]: 0.21453234313702005
Loss at iteration [1160]: 0.2145323273251045
Loss at iteration [1161]: 0.21453231190386185
Loss at iteration [1162]: 0.21453229646088778
Loss at iteration [1163]: 0.21453228068339386
Loss at iteration [1164]: 0.21453226529430294
Loss at iteration [1165]: 0.214532249681934
Loss at iteration [1166]: 0.21453223452365658
Loss at iteration [1167]: 0.21453221929946262
Loss at iteration [1168]: 0.21453220581102936
Loss at iteration [1169]: 0.21453219003266674
Loss at iteration [1170]: 0.21453217592806814
Loss at iteration [1171]: 0.21453216100882852
Loss at iteration [1172]: 0.2145321454766229
Loss at iteration [1173]: 0.2145321309521338
Loss at iteration [1174]: 0.21453211726251145
Loss at iteration [1175]: 0.21453210337095677
Loss at iteration [1176]: 0.21453208942911453
Loss at iteration [1177]: 0.21453207514115058
Loss at iteration [1178]: 0.21453206096802846
Loss at iteration [1179]: 0.21453204752555993
Loss at iteration [1180]: 0.2145320340377761
Loss at iteration [1181]: 0.21453202033247912
Loss at iteration [1182]: 0.2145320064763787
Loss at iteration [1183]: 0.21453199291399416
Loss at iteration [1184]: 0.2145319793230059
Loss at iteration [1185]: 0.21453196572646213
Loss at iteration [1186]: 0.21453195211942033
Loss at iteration [1187]: 0.21453193873479606
Loss at iteration [1188]: 0.21453192556762002
Loss at iteration [1189]: 0.2145319124912548
Loss at iteration [1190]: 0.21453189928951438
Loss at iteration [1191]: 0.2145318861786305
Loss at iteration [1192]: 0.21453187298484805
Loss at iteration [1193]: 0.2145318601044543
Loss at iteration [1194]: 0.21453184705571457
Loss at iteration [1195]: 0.21453183436184745
Loss at iteration [1196]: 0.21453182148528302
Loss at iteration [1197]: 0.2145318086577795
Loss at iteration [1198]: 0.2145317959202248
Loss at iteration [1199]: 0.21453178325244243
Loss at iteration [1200]: 0.21453177046030583
Loss at iteration [1201]: 0.2145317583394549
Loss at iteration [1202]: 0.21453174563692295
Loss at iteration [1203]: 0.21453173313168222
Loss at iteration [1204]: 0.21453172089384953
Loss at iteration [1205]: 0.21453170850318193
Loss at iteration [1206]: 0.21453169606415537
Loss at iteration [1207]: 0.2145316837770017
Loss at iteration [1208]: 0.21453167184101765
Loss at iteration [1209]: 0.21453165955821235
Loss at iteration [1210]: 0.2145316476372474
Loss at iteration [1211]: 0.21453163570709669
Loss at iteration [1212]: 0.2145316237597256
Loss at iteration [1213]: 0.21453161174923827
Loss at iteration [1214]: 0.21453159994956955
Loss at iteration [1215]: 0.21453158854817428
Loss at iteration [1216]: 0.21453157738960993
Loss at iteration [1217]: 0.21453156785886018
Loss at iteration [1218]: 0.2145315576533147
Loss at iteration [1219]: 0.21453154594157833
Loss at iteration [1220]: 0.21453153474093586
Loss at iteration [1221]: 0.2145315243551797
Loss at iteration [1222]: 0.21453151409177726
Loss at iteration [1223]: 0.21453150305989166
Loss at iteration [1224]: 0.21453149193371196
Loss at iteration [1225]: 0.21453148117707663
Loss at iteration [1226]: 0.21453147074828974
Loss at iteration [1227]: 0.21453146048471897
Loss at iteration [1228]: 0.21453144957207101
Loss at iteration [1229]: 0.21453143865785587
Loss at iteration [1230]: 0.2145314287167992
Loss at iteration [1231]: 0.21453141828723374
Loss at iteration [1232]: 0.21453140765539
Loss at iteration [1233]: 0.21453139769847077
Loss at iteration [1234]: 0.21453138732221538
Loss at iteration [1235]: 0.21453137700571176
Loss at iteration [1236]: 0.2145313669135004
Loss at iteration [1237]: 0.2145313569424279
Loss at iteration [1238]: 0.21453134675847982
Loss at iteration [1239]: 0.21453133679470046
Loss at iteration [1240]: 0.21453132667857325
Loss at iteration [1241]: 0.21453131655334365
Loss at iteration [1242]: 0.21453130638287302
Loss at iteration [1243]: 0.2145312969444446
Loss at iteration [1244]: 0.21453128716627368
Loss at iteration [1245]: 0.21453127694240046
Loss at iteration [1246]: 0.21453126732768155
Loss at iteration [1247]: 0.21453125757945898
Loss at iteration [1248]: 0.21453124791860728
Loss at iteration [1249]: 0.2145312381461092
Loss at iteration [1250]: 0.2145312290190099
Loss at iteration [1251]: 0.21453121930565133
Loss at iteration [1252]: 0.2145312097890151
Loss at iteration [1253]: 0.21453120041544899
Loss at iteration [1254]: 0.21453119112872066
Loss at iteration [1255]: 0.2145311816147869
Loss at iteration [1256]: 0.21453117231878482
Loss at iteration [1257]: 0.21453116335804637
Loss at iteration [1258]: 0.214531154721892
Loss at iteration [1259]: 0.2145311461436774
Loss at iteration [1260]: 0.21453113663085893
Loss at iteration [1261]: 0.21453112677718453
Loss at iteration [1262]: 0.2145311180979413
Loss at iteration [1263]: 0.21453110946802606
Loss at iteration [1264]: 0.2145311001697554
Loss at iteration [1265]: 0.21453109133618453
Loss at iteration [1266]: 0.2145310826252114
Loss at iteration [1267]: 0.2145310734870077
Loss at iteration [1268]: 0.21453106458577467
Loss at iteration [1269]: 0.21453105590742488
Loss at iteration [1270]: 0.21453104734829995
Loss at iteration [1271]: 0.2145310388683686
Loss at iteration [1272]: 0.2145310302071686
Loss at iteration [1273]: 0.21453102146602315
Loss at iteration [1274]: 0.21453101273989703
Loss at iteration [1275]: 0.2145310040497533
Loss at iteration [1276]: 0.21453099537705542
Loss at iteration [1277]: 0.21453098673748217
Loss at iteration [1278]: 0.21453097806465007
Loss at iteration [1279]: 0.2145309697216617
Loss at iteration [1280]: 0.21453096144061695
Loss at iteration [1281]: 0.2145309531363253
Loss at iteration [1282]: 0.21453094459303262
Loss at iteration [1283]: 0.21453093630675713
Loss at iteration [1284]: 0.21453092834918702
Loss at iteration [1285]: 0.21453091995439877
Loss at iteration [1286]: 0.214530911857299
Loss at iteration [1287]: 0.2145309039831909
Loss at iteration [1288]: 0.2145308959786626
Loss at iteration [1289]: 0.21453088797030767
Loss at iteration [1290]: 0.21453087983234592
Loss at iteration [1291]: 0.2145308718747375
Loss at iteration [1292]: 0.21453086395625184
Loss at iteration [1293]: 0.21453085582093465
Loss at iteration [1294]: 0.21453084862851987
Loss at iteration [1295]: 0.21453084079194046
Loss at iteration [1296]: 0.21453083325591638
Loss at iteration [1297]: 0.21453082549948138
Loss at iteration [1298]: 0.2145308174961117
Loss at iteration [1299]: 0.21453081029057877
Loss at iteration [1300]: 0.21453080280302964
Loss at iteration [1301]: 0.21453079496010405
Loss at iteration [1302]: 0.21453078723773533
Loss at iteration [1303]: 0.21453077993453212
Loss at iteration [1304]: 0.21453077252134461
Loss at iteration [1305]: 0.21453076499721166
Loss at iteration [1306]: 0.21453075769581792
Loss at iteration [1307]: 0.21453075031942362
Loss at iteration [1308]: 0.2145307430738403
Loss at iteration [1309]: 0.21453073565955164
Loss at iteration [1310]: 0.21453072831347375
Loss at iteration [1311]: 0.21453072097861112
Loss at iteration [1312]: 0.21453071400800608
Loss at iteration [1313]: 0.2145307068666555
Loss at iteration [1314]: 0.21453069949103581
Loss at iteration [1315]: 0.21453069254784818
Loss at iteration [1316]: 0.21453068545374077
Loss at iteration [1317]: 0.2145306783851464
Loss at iteration [1318]: 0.2145306713625929
Loss at iteration [1319]: 0.2145306645977928
Loss at iteration [1320]: 0.214530657461694
Loss at iteration [1321]: 0.2145306505974978
Loss at iteration [1322]: 0.2145306439250319
Loss at iteration [1323]: 0.21453063708679943
Loss at iteration [1324]: 0.21453063022551153
Loss at iteration [1325]: 0.21453062347500892
Loss at iteration [1326]: 0.21453061670968548
Loss at iteration [1327]: 0.21453060991682693
Loss at iteration [1328]: 0.2145306031529679
Loss at iteration [1329]: 0.21453059710826375
Loss at iteration [1330]: 0.21453059084113327
Loss at iteration [1331]: 0.21453058427383753
Loss at iteration [1332]: 0.21453057767750253
Loss at iteration [1333]: 0.21453057094334585
Loss at iteration [1334]: 0.21453056474365592
Loss at iteration [1335]: 0.21453055852207303
Loss at iteration [1336]: 0.2145305522255689
Loss at iteration [1337]: 0.21453054553151205
Loss at iteration [1338]: 0.21453053911371195
Loss at iteration [1339]: 0.2145305331733224
Loss at iteration [1340]: 0.21453052694934507
Loss at iteration [1341]: 0.21453052027750363
Loss at iteration [1342]: 0.21453051446773702
Loss at iteration [1343]: 0.2145305084001527
Loss at iteration [1344]: 0.21453050223561537
Loss at iteration [1345]: 0.21453049599943572
Loss at iteration [1346]: 0.21453048994679969
Loss at iteration [1347]: 0.21453048403792488
Loss at iteration [1348]: 0.2145304779771431
Loss at iteration [1349]: 0.21453047178024484
Loss at iteration [1350]: 0.21453046574908277
Loss at iteration [1351]: 0.21453045980272215
Loss at iteration [1352]: 0.21453045408423013
Loss at iteration [1353]: 0.21453044830446438
Loss at iteration [1354]: 0.21453044217584058
Loss at iteration [1355]: 0.2145304362329883
Loss at iteration [1356]: 0.21453043059164997
Loss at iteration [1357]: 0.21453042489872018
Loss at iteration [1358]: 0.21453041922008578
Loss at iteration [1359]: 0.21453041355900831
Loss at iteration [1360]: 0.21453040782803007
Loss at iteration [1361]: 0.21453040212141894
Loss at iteration [1362]: 0.21453039649516337
Loss at iteration [1363]: 0.21453039083421294
Loss at iteration [1364]: 0.21453038550866174
Loss at iteration [1365]: 0.2145303805313179
Loss at iteration [1366]: 0.21453037510957687
Loss at iteration [1367]: 0.21453036948402324
Loss at iteration [1368]: 0.21453036398376693
Loss at iteration [1369]: 0.21453035881700075
Loss at iteration [1370]: 0.21453035358430936
Loss at iteration [1371]: 0.21453034808454785
Loss at iteration [1372]: 0.21453034256783254
Loss at iteration [1373]: 0.21453033727811713
Loss at iteration [1374]: 0.2145303324371209
Loss at iteration [1375]: 0.2145303270397114
Loss at iteration [1376]: 0.21453032153515014
Loss at iteration [1377]: 0.21453031658043095
Loss at iteration [1378]: 0.2145303115938401
Loss at iteration [1379]: 0.21453030634165038
Loss at iteration [1380]: 0.21453030123570602
Loss at iteration [1381]: 0.21453029628081935
Loss at iteration [1382]: 0.21453029124119422
Loss at iteration [1383]: 0.21453028602863686
Loss at iteration [1384]: 0.21453028098778046
Loss at iteration [1385]: 0.21453027603495312
Loss at iteration [1386]: 0.21453027103637723
Loss at iteration [1387]: 0.2145302662799642
Loss at iteration [1388]: 0.21453026144729828
Loss at iteration [1389]: 0.21453025643294044
Loss at iteration [1390]: 0.21453025146367086
Loss at iteration [1391]: 0.2145302466952423
Loss at iteration [1392]: 0.2145302420458711
Loss at iteration [1393]: 0.21453023730555063
Loss at iteration [1394]: 0.21453023256527576
Loss at iteration [1395]: 0.2145302278438091
Loss at iteration [1396]: 0.2145302231105137
Loss at iteration [1397]: 0.214530218423309
Loss at iteration [1398]: 0.21453021384040527
Loss at iteration [1399]: 0.21453020984535648
Loss at iteration [1400]: 0.2145302053902186
Loss at iteration [1401]: 0.21453020040088766
Loss at iteration [1402]: 0.21453019593245057
Loss at iteration [1403]: 0.2145301918659064
Loss at iteration [1404]: 0.21453018741363838
Loss at iteration [1405]: 0.2145301826727686
Loss at iteration [1406]: 0.21453017822247528
Loss at iteration [1407]: 0.21453017395502313
Loss at iteration [1408]: 0.2145301695113211
Loss at iteration [1409]: 0.21453016521536203
Loss at iteration [1410]: 0.21453016084655147
Loss at iteration [1411]: 0.2145301566616372
Loss at iteration [1412]: 0.2145301523641025
Loss at iteration [1413]: 0.2145301479398566
Loss at iteration [1414]: 0.21453014364896192
Loss at iteration [1415]: 0.2145301396761499
Loss at iteration [1416]: 0.2145301353662922
Loss at iteration [1417]: 0.21453013103411223
Loss at iteration [1418]: 0.2145301268913013
Loss at iteration [1419]: 0.21453012286840215
Loss at iteration [1420]: 0.21453011880758874
Loss at iteration [1421]: 0.21453011465535496
Loss at iteration [1422]: 0.21453011060779117
Loss at iteration [1423]: 0.21453010663112773
Loss at iteration [1424]: 0.2145301026694204
Loss at iteration [1425]: 0.21453009867036205
Loss at iteration [1426]: 0.21453009468760756
Loss at iteration [1427]: 0.21453009073480744
Loss at iteration [1428]: 0.2145300868149111
Loss at iteration [1429]: 0.21453008284169092
Loss at iteration [1430]: 0.21453007898687237
Loss at iteration [1431]: 0.21453007517287562
Loss at iteration [1432]: 0.21453007189151424
Loss at iteration [1433]: 0.2145300684333204
Loss at iteration [1434]: 0.2145300643251053
Loss at iteration [1435]: 0.2145300604087287
Loss at iteration [1436]: 0.2145300569786464
Loss at iteration [1437]: 0.21453005337863146
Loss at iteration [1438]: 0.2145300493869628
Loss at iteration [1439]: 0.2145300455488011
Loss at iteration [1440]: 0.21453004230763595
Loss at iteration [1441]: 0.2145300387029215
Loss at iteration [1442]: 0.2145300347418647
Loss at iteration [1443]: 0.21453003129675224
Loss at iteration [1444]: 0.21453002796553247
Loss at iteration [1445]: 0.21453002443631333
Loss at iteration [1446]: 0.2145300208337504
Loss at iteration [1447]: 0.2145300173275607
Loss at iteration [1448]: 0.21453001388282356
Loss at iteration [1449]: 0.2145300103764978
Loss at iteration [1450]: 0.21453000681749107
Loss at iteration [1451]: 0.21453000334888467
Loss at iteration [1452]: 0.21452999990493146
Loss at iteration [1453]: 0.21452999656417623
Loss at iteration [1454]: 0.2145299932416046
Loss at iteration [1455]: 0.21452998977791155
Loss at iteration [1456]: 0.21452998645210303
Loss at iteration [1457]: 0.2145299831736359
Loss at iteration [1458]: 0.21452997992687586
Loss at iteration [1459]: 0.21452997668468934
Loss at iteration [1460]: 0.21452997347985903
Loss at iteration [1461]: 0.2145299702552996
Loss at iteration [1462]: 0.21452996701525343
Loss at iteration [1463]: 0.21452996377483957
Loss at iteration [1464]: 0.21452996103973757
Loss at iteration [1465]: 0.21452995788401363
Loss at iteration [1466]: 0.21452995486476076
Loss at iteration [1467]: 0.21452995142259323
Loss at iteration [1468]: 0.2145299482530216
Loss at iteration [1469]: 0.21452994542760312
Loss at iteration [1470]: 0.21452994238254552
Loss at iteration [1471]: 0.21452993916887578
Loss at iteration [1472]: 0.21452993613547355
Loss at iteration [1473]: 0.21452993328886028
Loss at iteration [1474]: 0.21452993037121662
Loss at iteration [1475]: 0.21452992728367104
Loss at iteration [1476]: 0.2145299243237221
Loss at iteration [1477]: 0.21452992144460575
Loss at iteration [1478]: 0.2145299185089707
Loss at iteration [1479]: 0.2145299156405762
Loss at iteration [1480]: 0.21452991277089756
Loss at iteration [1481]: 0.21452990981772008
Loss at iteration [1482]: 0.21452990697924
Loss at iteration [1483]: 0.21452990415897788
Loss at iteration [1484]: 0.21452990133652117
Loss at iteration [1485]: 0.21452989853196158
Loss at iteration [1486]: 0.21452989579703644
Loss at iteration [1487]: 0.2145298930203833
Loss at iteration [1488]: 0.214529890277693
Loss at iteration [1489]: 0.21452988759806527
Loss at iteration [1490]: 0.21452988485445565
Loss at iteration [1491]: 0.2145298821454896
Loss at iteration [1492]: 0.21452987952696634
Loss at iteration [1493]: 0.21452987684989358
Loss at iteration [1494]: 0.21452987432894707
Loss at iteration [1495]: 0.21452987191581843
Loss at iteration [1496]: 0.21452986948482597
Loss at iteration [1497]: 0.21452986674793645
Loss at iteration [1498]: 0.21452986409538774
Loss at iteration [1499]: 0.2145298617675024
Loss at iteration [1500]: 0.21452985928847085
Loss at iteration [1501]: 0.21452985666321997
Loss at iteration [1502]: 0.214529854099665
Loss at iteration [1503]: 0.21452985170379552
Loss at iteration [1504]: 0.21452984916079307
Loss at iteration [1505]: 0.21452984655042895
Loss at iteration [1506]: 0.2145298440915782
Loss at iteration [1507]: 0.21452984183111862
Loss at iteration [1508]: 0.21452983942531714
Loss at iteration [1509]: 0.21452983690298322
Loss at iteration [1510]: 0.21452983446824106
Loss at iteration [1511]: 0.21452983215010685
Loss at iteration [1512]: 0.21452982983175536
Loss at iteration [1513]: 0.21452982746512728
Loss at iteration [1514]: 0.21452982511284185
Loss at iteration [1515]: 0.21452982283722447
Loss at iteration [1516]: 0.2145298205456708
Loss at iteration [1517]: 0.21452981820849124
Loss at iteration [1518]: 0.21452981591621204
Loss at iteration [1519]: 0.2145298136886377
Loss at iteration [1520]: 0.21452981144042924
Loss at iteration [1521]: 0.21452980922918743
Loss at iteration [1522]: 0.21452980701854493
Loss at iteration [1523]: 0.21452980483986325
Loss at iteration [1524]: 0.21452980263980195
Loss at iteration [1525]: 0.2145298005581169
Loss at iteration [1526]: 0.21452979868345298
Loss at iteration [1527]: 0.21452979665521635
Loss at iteration [1528]: 0.21452979427854552
Loss at iteration [1529]: 0.2145297920987408
Loss at iteration [1530]: 0.21452979025198543
Loss at iteration [1531]: 0.2145297881498234
Loss at iteration [1532]: 0.21452978588955454
Loss at iteration [1533]: 0.21452978394604147
Loss at iteration [1534]: 0.21452978203270284
Loss at iteration [1535]: 0.2145297798164655
Loss at iteration [1536]: 0.21452977781250251
Loss at iteration [1537]: 0.2145297759296483
Loss at iteration [1538]: 0.2145297739938135
Loss at iteration [1539]: 0.21452977191319222
Loss at iteration [1540]: 0.21452976997447162
Loss at iteration [1541]: 0.21452976808928909
Loss at iteration [1542]: 0.21452976610871763
Loss at iteration [1543]: 0.21452976410562064
Loss at iteration [1544]: 0.21452976218122694
Loss at iteration [1545]: 0.21452976027644885
Loss at iteration [1546]: 0.21452975832980545
Loss at iteration [1547]: 0.214529756582693
Loss at iteration [1548]: 0.21452975473553756
Loss at iteration [1549]: 0.21452975279622524
Loss at iteration [1550]: 0.21452975085056636
Loss at iteration [1551]: 0.2145297490793533
Loss at iteration [1552]: 0.21452974725746507
Loss at iteration [1553]: 0.2145297454588615
Loss at iteration [1554]: 0.21452974368934064
Loss at iteration [1555]: 0.2145297419002308
Loss at iteration [1556]: 0.21452974042002063
Loss at iteration [1557]: 0.21452973858424548
Loss at iteration [1558]: 0.214529736905792
Loss at iteration [1559]: 0.21452973502712985
Loss at iteration [1560]: 0.2145297333332509
Loss at iteration [1561]: 0.21452973173942477
Loss at iteration [1562]: 0.21452973002599243
Loss at iteration [1563]: 0.21452972822062089
Loss at iteration [1564]: 0.21452972669292766
Loss at iteration [1565]: 0.21452972506705703
Loss at iteration [1566]: 0.21452972325212089
Loss at iteration [1567]: 0.21452972165630502
Loss at iteration [1568]: 0.2145297201255233
Loss at iteration [1569]: 0.2145297185099352
Loss at iteration [1570]: 0.21452971687209701
Loss at iteration [1571]: 0.21452971529230164
Loss at iteration [1572]: 0.21452971373222524
Loss at iteration [1573]: 0.21452971211371227
Loss at iteration [1574]: 0.21452971052534783
Loss at iteration [1575]: 0.21452970896376558
Loss at iteration [1576]: 0.21452970737583352
Loss at iteration [1577]: 0.21452970579271938
Loss at iteration [1578]: 0.214529704367973
Loss at iteration [1579]: 0.21452970289987336
Loss at iteration [1580]: 0.21452970134315666
Loss at iteration [1581]: 0.21452969980434708
Loss at iteration [1582]: 0.2145296983655025
Loss at iteration [1583]: 0.21452969702805558
Loss at iteration [1584]: 0.21452969577375036
Loss at iteration [1585]: 0.21452969422047924
Loss at iteration [1586]: 0.21452969268391833
Loss at iteration [1587]: 0.2145296913734656
Loss at iteration [1588]: 0.21452968997308375
Loss at iteration [1589]: 0.21452968844530146
Loss at iteration [1590]: 0.21452968701885208
Loss at iteration [1591]: 0.2145296856849228
Loss at iteration [1592]: 0.21452968427053346
Loss at iteration [1593]: 0.21452968285321056
Loss at iteration [1594]: 0.2145296815672608
Loss at iteration [1595]: 0.21452968024435937
Loss at iteration [1596]: 0.21452967884299667
Loss at iteration [1597]: 0.21452967749357718
Loss at iteration [1598]: 0.21452967620055535
Loss at iteration [1599]: 0.21452967485913935
Loss at iteration [1600]: 0.21452967352199673
Loss at iteration [1601]: 0.21452967223443192
Loss at iteration [1602]: 0.21452967097824388
Loss at iteration [1603]: 0.2145296696613032
Loss at iteration [1604]: 0.21452966837289186
Loss at iteration [1605]: 0.21452966713526514
Loss at iteration [1606]: 0.2145296658965065
Loss at iteration [1607]: 0.21452966465656878
Loss at iteration [1608]: 0.2145296634293772
Loss at iteration [1609]: 0.21452966218542113
Loss at iteration [1610]: 0.21452966096281595
Loss at iteration [1611]: 0.21452965974089802
Loss at iteration [1612]: 0.21452965863768067
Loss at iteration [1613]: 0.21452965757411158
Loss at iteration [1614]: 0.21452965637624574
Loss at iteration [1615]: 0.214529655136029
Loss at iteration [1616]: 0.21452965397737855
Loss at iteration [1617]: 0.21452965294541482
Loss at iteration [1618]: 0.21452965173808766
Loss at iteration [1619]: 0.21452965056134027
Loss at iteration [1620]: 0.21452964944394345
Loss at iteration [1621]: 0.21452964834423421
Loss at iteration [1622]: 0.21452964716757386
Loss at iteration [1623]: 0.21452964609006211
Loss at iteration [1624]: 0.21452964504215333
Loss at iteration [1625]: 0.2145296439248554
Loss at iteration [1626]: 0.21452964282145534
Loss at iteration [1627]: 0.2145296417349436
Loss at iteration [1628]: 0.21452964071505876
Loss at iteration [1629]: 0.21452963965335392
Loss at iteration [1630]: 0.2145296385576049
Loss at iteration [1631]: 0.2145296375239785
Loss at iteration [1632]: 0.21452963649398976
Loss at iteration [1633]: 0.21452963543909406
Loss at iteration [1634]: 0.2145296343868627
Loss at iteration [1635]: 0.21452963340206954
