Model name                            : MLP_Multistep
The number of input features          : 5
The number of output features         : 2
Optimizer name                        : LBFGS
Learning rate                         : 0.1
Total number of function evaluations  : 844
Total number of iterations            : 496
Max number of iterations              : 3000
Number of samples in training data    : 122
Number of samples in tests data       : 52
Total training time                   : 10.816409587860107
Total number of parameters            : 202302
Percentage of parameters < 1e-9       : 50.029164318691855%
Percentage of parameters < 1e-7       : 50.029164318691855%
Percentage of parameters < 1e-6       : 50.032130181609666%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.5739365853307146
Loss at iteration [2]: 0.644706646091289
Loss at iteration [3]: 0.4625823584210972
Loss at iteration [4]: 0.2711184686123128
Loss at iteration [5]: 0.24684443261027258
Loss at iteration [6]: 0.22624817386865512
Loss at iteration [7]: 0.2104173378689341
Loss at iteration [8]: 0.18376791342972182
Loss at iteration [9]: 0.13722230581070796
Loss at iteration [10]: 0.09982631052225849
Loss at iteration [11]: 0.07991365052648146
Loss at iteration [12]: 0.07063426671722822
Loss at iteration [13]: 0.0639735998683649
Loss at iteration [14]: 0.06031670705800504
Loss at iteration [15]: 0.056838095224822
Loss at iteration [16]: 0.05366976240638907
Loss at iteration [17]: 0.05208526199508222
Loss at iteration [18]: 0.0515489568230002
Loss at iteration [19]: 0.05130294215398776
Loss at iteration [20]: 0.051175310628140486
Loss at iteration [21]: 0.051150776027040275
Loss at iteration [22]: 0.05113312552090849
Loss at iteration [23]: 0.051109421551465486
Loss at iteration [24]: 0.05108028844334298
Loss at iteration [25]: 0.0510570090968876
Loss at iteration [26]: 0.051041272006260276
Loss at iteration [27]: 0.051031173121334386
Loss at iteration [28]: 0.05101364651886851
Loss at iteration [29]: 0.05099106352919817
Loss at iteration [30]: 0.0509854011995571
Loss at iteration [31]: 0.050981494685322454
Loss at iteration [32]: 0.05097635888786129
Loss at iteration [33]: 0.050971520580053074
