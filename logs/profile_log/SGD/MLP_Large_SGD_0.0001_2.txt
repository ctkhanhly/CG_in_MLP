Model name                            : MLP_Large
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : SGD
Learning rate                         : 0.0001
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 35.902098655700684
Total number of parameters            : 402001
Percentage of parameters < 1e-9       : 49.86131875293843%
Percentage of parameters < 1e-7       : 49.861816264138646%
Percentage of parameters < 1e-6       : 49.86330879773931%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.9775561567288084
Loss at iteration [2]: 0.9763919248054892
Loss at iteration [3]: 0.9746475946561167
Loss at iteration [4]: 0.972615838311386
Loss at iteration [5]: 0.9704431825884555
Loss at iteration [6]: 0.9682026259886122
Loss at iteration [7]: 0.9659308568272368
Loss at iteration [8]: 0.9636462389940875
Loss at iteration [9]: 0.9613581799838025
Loss at iteration [10]: 0.9590714011958603
Loss at iteration [11]: 0.9567877657491113
Loss at iteration [12]: 0.9545081654485643
Loss at iteration [13]: 0.9522329913576906
Loss at iteration [14]: 0.949962580361484
Loss at iteration [15]: 0.9476976797476263
Loss at iteration [16]: 0.9454381909438933
Loss at iteration [17]: 0.943183751784781
Loss at iteration [18]: 0.9409340397678185
Loss at iteration [19]: 0.9386891694205558
Loss at iteration [20]: 0.9364492136600282
Loss at iteration [21]: 0.9342142779007807
Loss at iteration [22]: 0.9319843960494658
Loss at iteration [23]: 0.9297601640395493
Loss at iteration [24]: 0.9275408411117559
Loss at iteration [25]: 0.9253265318903969
Loss at iteration [26]: 0.923117313971782
Loss at iteration [27]: 0.9209132834387368
Loss at iteration [28]: 0.9187143951408165
Loss at iteration [29]: 0.9165206065888745
Loss at iteration [30]: 0.9143317612648405
Loss at iteration [31]: 0.9121478351329843
Loss at iteration [32]: 0.909969174770027
Loss at iteration [33]: 0.907795874311126
Loss at iteration [34]: 0.9056276947537742
Loss at iteration [35]: 0.9034646873689838
Loss at iteration [36]: 0.9013066699093778
Loss at iteration [37]: 0.8991537377572647
Loss at iteration [38]: 0.8970057543340361
Loss at iteration [39]: 0.8948630491017129
Loss at iteration [40]: 0.8927258480693561
Loss at iteration [41]: 0.8905938164486505
Loss at iteration [42]: 0.8884669725829475
Loss at iteration [43]: 0.8863451909279204
Loss at iteration [44]: 0.8842286535822906
Loss at iteration [45]: 0.8821173263944024
Loss at iteration [46]: 0.8800109765324309
Loss at iteration [47]: 0.8779096340591411
Loss at iteration [48]: 0.8758133750866008
Loss at iteration [49]: 0.8737226290156151
Loss at iteration [50]: 0.87163726609012
Loss at iteration [51]: 0.8695579645660435
Loss at iteration [52]: 0.867484684565792
Loss at iteration [53]: 0.8654171011913476
Loss at iteration [54]: 0.8633551444261933
Loss at iteration [55]: 0.8612994567706312
Loss at iteration [56]: 0.8592499871749603
Loss at iteration [57]: 0.8572055845107289
Loss at iteration [58]: 0.8551665285090948
Loss at iteration [59]: 0.8531326136199406
Loss at iteration [60]: 0.8511035121179815
Loss at iteration [61]: 0.849079607108055
Loss at iteration [62]: 0.8470612222468992
Loss at iteration [63]: 0.8450475487062822
Loss at iteration [64]: 0.8430386464673651
Loss at iteration [65]: 0.8410348808873728
Loss at iteration [66]: 0.8390358808562582
Loss at iteration [67]: 0.8370416199876709
Loss at iteration [68]: 0.8350521303785178
Loss at iteration [69]: 0.8330674308849674
Loss at iteration [70]: 0.8310876364023794
Loss at iteration [71]: 0.8291122131296786
Loss at iteration [72]: 0.8271414330969394
Loss at iteration [73]: 0.8251752876290348
Loss at iteration [74]: 0.8232135027230697
Loss at iteration [75]: 0.8212558125933759
Loss at iteration [76]: 0.8193026757603415
Loss at iteration [77]: 0.8173540902646418
Loss at iteration [78]: 0.8154097525467998
Loss at iteration [79]: 0.8134699040270355
Loss at iteration [80]: 0.8115344992496886
Loss at iteration [81]: 0.8096033748261563
Loss at iteration [82]: 0.8076767188010243
Loss at iteration [83]: 0.8057542843074653
Loss at iteration [84]: 0.8038359707654832
Loss at iteration [85]: 0.8019221442896072
Loss at iteration [86]: 0.8000124630631424
Loss at iteration [87]: 0.7981067063882031
Loss at iteration [88]: 0.7962047016783157
Loss at iteration [89]: 0.7943064395841372
Loss at iteration [90]: 0.7924118628958262
Loss at iteration [91]: 0.7905212613377868
Loss at iteration [92]: 0.7886346145519754
Loss at iteration [93]: 0.7867519138436893
Loss at iteration [94]: 0.7848731611773601
Loss at iteration [95]: 0.7829986500270011
Loss at iteration [96]: 0.7811283048392919
Loss at iteration [97]: 0.7792621490643139
Loss at iteration [98]: 0.7774005404568876
Loss at iteration [99]: 0.7755424954600934
Loss at iteration [100]: 0.7736879770739775
Loss at iteration [101]: 0.7718366434162978
Loss at iteration [102]: 0.769988636869669
Loss at iteration [103]: 0.7681438225189232
Loss at iteration [104]: 0.7663019594968434
Loss at iteration [105]: 0.7644634976945917
Loss at iteration [106]: 0.7626288636622154
Loss at iteration [107]: 0.7607980071375076
Loss at iteration [108]: 0.7589709580096797
Loss at iteration [109]: 0.757147870753071
Loss at iteration [110]: 0.7553287101509448
Loss at iteration [111]: 0.7535134307210068
Loss at iteration [112]: 0.7517017794005295
Loss at iteration [113]: 0.7498933902033859
Loss at iteration [114]: 0.7480881047625356
Loss at iteration [115]: 0.7462860809592343
Loss at iteration [116]: 0.7444871883265518
Loss at iteration [117]: 0.7426914247561167
Loss at iteration [118]: 0.7408989956142936
Loss at iteration [119]: 0.7391100712670101
Loss at iteration [120]: 0.7373244554216003
Loss at iteration [121]: 0.7355422415594429
Loss at iteration [122]: 0.7337635242496395
Loss at iteration [123]: 0.731988573979738
Loss at iteration [124]: 0.7302175386872699
Loss at iteration [125]: 0.7284502967966642
Loss at iteration [126]: 0.7266869108039994
Loss at iteration [127]: 0.7249274609965441
Loss at iteration [128]: 0.7231718586523369
Loss at iteration [129]: 0.7214200692321742
Loss at iteration [130]: 0.7196718188095035
Loss at iteration [131]: 0.7179269087306698
Loss at iteration [132]: 0.7161850751465204
Loss at iteration [133]: 0.7144465214380091
Loss at iteration [134]: 0.7127112129677629
Loss at iteration [135]: 0.7109789548595914
Loss at iteration [136]: 0.7092496117849204
Loss at iteration [137]: 0.7075230614462129
Loss at iteration [138]: 0.7057993907159333
Loss at iteration [139]: 0.7040783912055472
Loss at iteration [140]: 0.7023602075026266
Loss at iteration [141]: 0.7006450063167672
Loss at iteration [142]: 0.6989327223168649
Loss at iteration [143]: 0.697223372370058
Loss at iteration [144]: 0.6955169048592612
Loss at iteration [145]: 0.693813082223086
Loss at iteration [146]: 0.6921120671893791
Loss at iteration [147]: 0.6904140822435662
Loss at iteration [148]: 0.6887187254049024
Loss at iteration [149]: 0.6870260936568986
Loss at iteration [150]: 0.6853364354860533
Loss at iteration [151]: 0.6836499658929687
Loss at iteration [152]: 0.6819665845486941
Loss at iteration [153]: 0.6802863071719792
Loss at iteration [154]: 0.6786087489062322
Loss at iteration [155]: 0.6769338352318839
Loss at iteration [156]: 0.6752614463777968
Loss at iteration [157]: 0.6735914167314836
Loss at iteration [158]: 0.6719237366243366
Loss at iteration [159]: 0.6702591875343131
Loss at iteration [160]: 0.6685977208543162
Loss at iteration [161]: 0.6669391728594721
Loss at iteration [162]: 0.6652835302935373
Loss at iteration [163]: 0.6636311361078813
Loss at iteration [164]: 0.6619820851610675
Loss at iteration [165]: 0.6603359943311412
Loss at iteration [166]: 0.6586931333222593
Loss at iteration [167]: 0.6570529464401831
Loss at iteration [168]: 0.6554158428556361
Loss at iteration [169]: 0.6537816135087291
Loss at iteration [170]: 0.6521503309856476
Loss at iteration [171]: 0.6505216764674772
Loss at iteration [172]: 0.6488956503641767
Loss at iteration [173]: 0.6472722330577029
Loss at iteration [174]: 0.6456518243141007
Loss at iteration [175]: 0.6440341425608256
Loss at iteration [176]: 0.6424189226081682
Loss at iteration [177]: 0.6408064689115518
Loss at iteration [178]: 0.6391968590636611
Loss at iteration [179]: 0.6375899109004511
Loss at iteration [180]: 0.6359857266898258
Loss at iteration [181]: 0.6343841264904848
Loss at iteration [182]: 0.6327848813820656
Loss at iteration [183]: 0.6311880315811443
Loss at iteration [184]: 0.6295935672512791
Loss at iteration [185]: 0.6280014239057147
Loss at iteration [186]: 0.6264116024076463
Loss at iteration [187]: 0.6248238526646249
Loss at iteration [188]: 0.6232387688939887
Loss at iteration [189]: 0.6216561564550461
Loss at iteration [190]: 0.6200760277716904
Loss at iteration [191]: 0.6184985446915305
Loss at iteration [192]: 0.6169235500150697
Loss at iteration [193]: 0.6153511135625424
Loss at iteration [194]: 0.6137816424690318
Loss at iteration [195]: 0.6122151002080691
Loss at iteration [196]: 0.6106516450106891
Loss at iteration [197]: 0.6090913138554461
Loss at iteration [198]: 0.6075340335066208
Loss at iteration [199]: 0.6059805717220048
Loss at iteration [200]: 0.6044302577879296
Loss at iteration [201]: 0.6028829165188871
Loss at iteration [202]: 0.6013389390194882
Loss at iteration [203]: 0.5997984520810725
Loss at iteration [204]: 0.5982617445106345
Loss at iteration [205]: 0.5967283468360126
Loss at iteration [206]: 0.5951983821990889
Loss at iteration [207]: 0.5936717488530922
Loss at iteration [208]: 0.5921485130398404
Loss at iteration [209]: 0.5906288497298623
Loss at iteration [210]: 0.5891126072555347
Loss at iteration [211]: 0.5875998580010093
Loss at iteration [212]: 0.5860905643134589
Loss at iteration [213]: 0.5845842958979189
Loss at iteration [214]: 0.5830812438595436
Loss at iteration [215]: 0.5815811205789712
Loss at iteration [216]: 0.5800842278055055
Loss at iteration [217]: 0.5785900868348656
Loss at iteration [218]: 0.5770986804590229
Loss at iteration [219]: 0.5756098637644806
Loss at iteration [220]: 0.5741234016159017
Loss at iteration [221]: 0.5726391860173525
Loss at iteration [222]: 0.5711572543277365
Loss at iteration [223]: 0.5696775790719951
Loss at iteration [224]: 0.5682003672856358
Loss at iteration [225]: 0.5667256225427781
Loss at iteration [226]: 0.5652534236527534
Loss at iteration [227]: 0.5637838356010315
Loss at iteration [228]: 0.5623168981090495
Loss at iteration [229]: 0.5608523795956795
Loss at iteration [230]: 0.5593904040953347
Loss at iteration [231]: 0.557930935043664
Loss at iteration [232]: 0.5564740445332189
Loss at iteration [233]: 0.5550197973351789
Loss at iteration [234]: 0.5535682484582364
Loss at iteration [235]: 0.5521190699921239
Loss at iteration [236]: 0.5506722364173267
Loss at iteration [237]: 0.5492277669361934
Loss at iteration [238]: 0.5477856353360506
Loss at iteration [239]: 0.5463458204237139
Loss at iteration [240]: 0.544908373467923
Loss at iteration [241]: 0.5434731984662708
Loss at iteration [242]: 0.5420403604239836
Loss at iteration [243]: 0.5406100377817649
Loss at iteration [244]: 0.539182081331206
Loss at iteration [245]: 0.5377566073828274
Loss at iteration [246]: 0.5363335859277004
Loss at iteration [247]: 0.5349129468336769
Loss at iteration [248]: 0.5334945609265757
Loss at iteration [249]: 0.5320786957373624
Loss at iteration [250]: 0.5306653064530218
Loss at iteration [251]: 0.5292544613044377
Loss at iteration [252]: 0.5278460847574812
Loss at iteration [253]: 0.5264401631083018
Loss at iteration [254]: 0.52503666330995
Loss at iteration [255]: 0.5236355295798343
Loss at iteration [256]: 0.5222367841412341
Loss at iteration [257]: 0.520840410322601
Loss at iteration [258]: 0.5194463379141193
Loss at iteration [259]: 0.5180544884935967
Loss at iteration [260]: 0.5166649964187948
Loss at iteration [261]: 0.5152777942083053
Loss at iteration [262]: 0.5138929055228274
Loss at iteration [263]: 0.5125104167478146
Loss at iteration [264]: 0.5111302271324173
Loss at iteration [265]: 0.509752326412571
Loss at iteration [266]: 0.508376850656498
Loss at iteration [267]: 0.5070038517550081
Loss at iteration [268]: 0.5056332572420831
Loss at iteration [269]: 0.5042652363262061
Loss at iteration [270]: 0.5028997882786173
Loss at iteration [271]: 0.5015371601326706
Loss at iteration [272]: 0.5001774315605878
Loss at iteration [273]: 0.4988206656511468
Loss at iteration [274]: 0.4974673045849255
Loss at iteration [275]: 0.496117395251858
Loss at iteration [276]: 0.4947712206870158
Loss at iteration [277]: 0.4934287407868138
Loss at iteration [278]: 0.4920895527189797
Loss at iteration [279]: 0.4907532560049186
Loss at iteration [280]: 0.48941977847992046
Loss at iteration [281]: 0.48808945329074804
Loss at iteration [282]: 0.48676195864132243
Loss at iteration [283]: 0.48543749144478976
Loss at iteration [284]: 0.4841161589489718
Loss at iteration [285]: 0.4827977129385319
Loss at iteration [286]: 0.4814822845327977
Loss at iteration [287]: 0.4801699722440907
Loss at iteration [288]: 0.47886083876212465
Loss at iteration [289]: 0.4775545724400633
Loss at iteration [290]: 0.4762510669913356
Loss at iteration [291]: 0.4749503913094567
Loss at iteration [292]: 0.47365248683509487
Loss at iteration [293]: 0.4723573267923026
Loss at iteration [294]: 0.4710650151251457
Loss at iteration [295]: 0.469775324676192
Loss at iteration [296]: 0.46848818807767784
Loss at iteration [297]: 0.4672037923752119
Loss at iteration [298]: 0.46592216418359444
Loss at iteration [299]: 0.46464335400380696
Loss at iteration [300]: 0.46336719532355786
Loss at iteration [301]: 0.4620937219850109
Loss at iteration [302]: 0.4608228063867923
Loss at iteration [303]: 0.4595544935034742
Loss at iteration [304]: 0.4582887532347138
Loss at iteration [305]: 0.45702566230499714
Loss at iteration [306]: 0.4557652754183594
Loss at iteration [307]: 0.45450750327928197
Loss at iteration [308]: 0.4532521812663894
Loss at iteration [309]: 0.45199920719959336
Loss at iteration [310]: 0.4507487476653584
Loss at iteration [311]: 0.44950082022630355
Loss at iteration [312]: 0.44825539004767806
Loss at iteration [313]: 0.44701252872152275
Loss at iteration [314]: 0.44577230636933785
Loss at iteration [315]: 0.44453464339734583
Loss at iteration [316]: 0.4432993642581864
Loss at iteration [317]: 0.44206661392735075
Loss at iteration [318]: 0.4408365050893326
Loss at iteration [319]: 0.43960883871788736
Loss at iteration [320]: 0.4383838147267684
Loss at iteration [321]: 0.43716127171871577
Loss at iteration [322]: 0.4359410761257676
Loss at iteration [323]: 0.4347231287854549
Loss at iteration [324]: 0.43350739084689677
Loss at iteration [325]: 0.43229377474036185
Loss at iteration [326]: 0.4310823365197733
Loss at iteration [327]: 0.42987316080217475
Loss at iteration [328]: 0.4286663013530515
Loss at iteration [329]: 0.42746172921349934
Loss at iteration [330]: 0.42625936551147303
Loss at iteration [331]: 0.4250591474494942
Loss at iteration [332]: 0.4238609295020975
Loss at iteration [333]: 0.4226647933124564
Loss at iteration [334]: 0.421470804138349
Loss at iteration [335]: 0.42027901397127565
Loss at iteration [336]: 0.41908950121881994
Loss at iteration [337]: 0.41790214843419526
Loss at iteration [338]: 0.416716931597438
Loss at iteration [339]: 0.4155337663748062
Loss at iteration [340]: 0.4143527824022517
Loss at iteration [341]: 0.4131739047863001
Loss at iteration [342]: 0.41199703010457966
Loss at iteration [343]: 0.4108222530028617
Loss at iteration [344]: 0.40964955729447
Loss at iteration [345]: 0.40847886825453517
Loss at iteration [346]: 0.4073103062332054
Loss at iteration [347]: 0.4061439241457405
Loss at iteration [348]: 0.4049796167009608
Loss at iteration [349]: 0.4038174441772937
Loss at iteration [350]: 0.4026574985087853
Loss at iteration [351]: 0.40149979920335227
Loss at iteration [352]: 0.40034415902949866
Loss at iteration [353]: 0.3991906185811957
Loss at iteration [354]: 0.398039171136286
Loss at iteration [355]: 0.39688969267062535
Loss at iteration [356]: 0.3957421804632755
Loss at iteration [357]: 0.3945966195567839
Loss at iteration [358]: 0.39345313120892744
Loss at iteration [359]: 0.39231172919115204
Loss at iteration [360]: 0.39117241532849095
Loss at iteration [361]: 0.39003507794068487
Loss at iteration [362]: 0.3888996774844302
Loss at iteration [363]: 0.38776642260669175
Loss at iteration [364]: 0.3866352126346502
Loss at iteration [365]: 0.38550599467058655
Loss at iteration [366]: 0.38437872278542895
Loss at iteration [367]: 0.3832534203738119
Loss at iteration [368]: 0.3821301144087194
Loss at iteration [369]: 0.3810088093591447
Loss at iteration [370]: 0.37988953688307564
Loss at iteration [371]: 0.3787723034424188
Loss at iteration [372]: 0.3776571552000341
Loss at iteration [373]: 0.376544068664402
Loss at iteration [374]: 0.37543300260254536
Loss at iteration [375]: 0.37432394253753415
Loss at iteration [376]: 0.3732168386911315
Loss at iteration [377]: 0.3721116958749377
Loss at iteration [378]: 0.3710085278338402
Loss at iteration [379]: 0.36990731995538645
Loss at iteration [380]: 0.3688080715661057
Loss at iteration [381]: 0.3677108133590714
Loss at iteration [382]: 0.36661558968772745
Loss at iteration [383]: 0.3655222688076014
Loss at iteration [384]: 0.3644308371048273
Loss at iteration [385]: 0.3633413837770866
Loss at iteration [386]: 0.362253941345115
Loss at iteration [387]: 0.3611684559573487
Loss at iteration [388]: 0.3600849256687938
Loss at iteration [389]: 0.3590033303573253
Loss at iteration [390]: 0.35792369123165824
Loss at iteration [391]: 0.3568460109197568
Loss at iteration [392]: 0.35577035438985866
Loss at iteration [393]: 0.35469669446472685
Loss at iteration [394]: 0.35362503452116373
Loss at iteration [395]: 0.35255534060132093
Loss at iteration [396]: 0.35148762133179845
Loss at iteration [397]: 0.35042186630093114
Loss at iteration [398]: 0.34935811702479147
Loss at iteration [399]: 0.34829636139686987
Loss at iteration [400]: 0.34723659476628016
Loss at iteration [401]: 0.34617876922496255
Loss at iteration [402]: 0.34512292100576564
Loss at iteration [403]: 0.34406909614118675
Loss at iteration [404]: 0.34301737441812347
Loss at iteration [405]: 0.34196772811239295
Loss at iteration [406]: 0.3409201140821732
Loss at iteration [407]: 0.33987448080277455
Loss at iteration [408]: 0.3388308794683463
Loss at iteration [409]: 0.33778928377354606
Loss at iteration [410]: 0.33674968627759644
Loss at iteration [411]: 0.3357121155920674
Loss at iteration [412]: 0.3346766431443197
Loss at iteration [413]: 0.33364320926299174
Loss at iteration [414]: 0.3326120055807074
Loss at iteration [415]: 0.33158330299204075
Loss at iteration [416]: 0.33055683228356414
Loss at iteration [417]: 0.3295323945150309
Loss at iteration [418]: 0.32850993724576805
Loss at iteration [419]: 0.3274896123131863
Loss at iteration [420]: 0.3264714066725564
Loss at iteration [421]: 0.3254552240195231
Loss at iteration [422]: 0.3244410130690348
Loss at iteration [423]: 0.3234288228483244
Loss at iteration [424]: 0.3224187158086304
Loss at iteration [425]: 0.3214107372581593
Loss at iteration [426]: 0.3204048765056892
Loss at iteration [427]: 0.3194011625613532
Loss at iteration [428]: 0.3183995074553672
Loss at iteration [429]: 0.31739978676008734
Loss at iteration [430]: 0.31640196243789637
Loss at iteration [431]: 0.3154060589441472
Loss at iteration [432]: 0.3144121399042859
Loss at iteration [433]: 0.3134202381240507
Loss at iteration [434]: 0.3124302917238725
Loss at iteration [435]: 0.31144242729779914
Loss at iteration [436]: 0.31045652073229474
Loss at iteration [437]: 0.30947266009993474
Loss at iteration [438]: 0.30849078459426466
Loss at iteration [439]: 0.3075108627963294
Loss at iteration [440]: 0.3065329546687997
Loss at iteration [441]: 0.3055570327199454
Loss at iteration [442]: 0.3045830824561269
Loss at iteration [443]: 0.303611079617207
Loss at iteration [444]: 0.3026410623780496
Loss at iteration [445]: 0.3016730639580302
Loss at iteration [446]: 0.3007071860589454
Loss at iteration [447]: 0.29974331876440125
Loss at iteration [448]: 0.2987814974213028
Loss at iteration [449]: 0.2978216704128538
Loss at iteration [450]: 0.2968638635759378
Loss at iteration [451]: 0.2959080746639101
Loss at iteration [452]: 0.29495429281027796
Loss at iteration [453]: 0.2940025792406266
Loss at iteration [454]: 0.2930528275669114
Loss at iteration [455]: 0.2921050755302465
Loss at iteration [456]: 0.29115944688638584
Loss at iteration [457]: 0.2902158312671825
Loss at iteration [458]: 0.2892741678686155
Loss at iteration [459]: 0.2883344374693096
Loss at iteration [460]: 0.28739670005498613
Loss at iteration [461]: 0.28646097789120184
Loss at iteration [462]: 0.2855272612785082
Loss at iteration [463]: 0.28459561156692204
Loss at iteration [464]: 0.28366598975457114
Loss at iteration [465]: 0.2827383612116548
Loss at iteration [466]: 0.2818127654722578
Loss at iteration [467]: 0.28088923424528967
Loss at iteration [468]: 0.27996773718229767
Loss at iteration [469]: 0.2790482915960528
Loss at iteration [470]: 0.2781309651285789
Loss at iteration [471]: 0.27721570761129405
Loss at iteration [472]: 0.2763024329101694
Loss at iteration [473]: 0.2753912448993288
Loss at iteration [474]: 0.2744822679358371
Loss at iteration [475]: 0.27357555899442937
Loss at iteration [476]: 0.2726710068181786
Loss at iteration [477]: 0.2717686260855139
Loss at iteration [478]: 0.27086844821505784
Loss at iteration [479]: 0.26997055949128873
Loss at iteration [480]: 0.2690749113110701
Loss at iteration [481]: 0.2681813833040296
Loss at iteration [482]: 0.2672900092866624
Loss at iteration [483]: 0.26640074066112734
Loss at iteration [484]: 0.2655136360032892
Loss at iteration [485]: 0.2646286505755636
Loss at iteration [486]: 0.2637457289266138
Loss at iteration [487]: 0.26286483945217654
Loss at iteration [488]: 0.261986015023755
Loss at iteration [489]: 0.2611092128774256
Loss at iteration [490]: 0.2602344953235078
Loss at iteration [491]: 0.2593618448599051
Loss at iteration [492]: 0.25849121415207915
Loss at iteration [493]: 0.2576225871728453
Loss at iteration [494]: 0.25675599073937616
Loss at iteration [495]: 0.25589149550328083
Loss at iteration [496]: 0.25502908102826494
Loss at iteration [497]: 0.2541687778597112
Loss at iteration [498]: 0.25331051828596013
Loss at iteration [499]: 0.25245440818433024
Loss at iteration [500]: 0.2516005081714937
Loss at iteration [501]: 0.25074891208192696
Loss at iteration [502]: 0.24989956495887264
Loss at iteration [503]: 0.24905239924223097
Loss at iteration [504]: 0.24820748643764942
Loss at iteration [505]: 0.2473646691866493
Loss at iteration [506]: 0.2465238703329911
Loss at iteration [507]: 0.24568512988665014
Loss at iteration [508]: 0.2448484982232537
Loss at iteration [509]: 0.24401396731650565
Loss at iteration [510]: 0.2431815933120896
Loss at iteration [511]: 0.24235148479509094
Loss at iteration [512]: 0.2415235203604337
Loss at iteration [513]: 0.2406977267310874
Loss at iteration [514]: 0.2398740073372885
Loss at iteration [515]: 0.23905239778631043
Loss at iteration [516]: 0.23823291959880713
Loss at iteration [517]: 0.2374154951361459
Loss at iteration [518]: 0.23660011579405743
Loss at iteration [519]: 0.23578677240462106
Loss at iteration [520]: 0.2349755122169905
Loss at iteration [521]: 0.23416625849699263
Loss at iteration [522]: 0.23335911940526113
Loss at iteration [523]: 0.23255416565793233
Loss at iteration [524]: 0.23175128960882457
Loss at iteration [525]: 0.2309504964587615
Loss at iteration [526]: 0.2301518445707909
Loss at iteration [527]: 0.22935537740823542
Loss at iteration [528]: 0.22856117898710915
Loss at iteration [529]: 0.22776916443191556
Loss at iteration [530]: 0.22697937235112534
Loss at iteration [531]: 0.22619192038610045
Loss at iteration [532]: 0.22540663421013965
Loss at iteration [533]: 0.22462360517710345
Loss at iteration [534]: 0.22384293190962837
Loss at iteration [535]: 0.2230646085355494
Loss at iteration [536]: 0.22228863399075544
Loss at iteration [537]: 0.22151488793710702
Loss at iteration [538]: 0.22074351097963427
Loss at iteration [539]: 0.21997448873566403
Loss at iteration [540]: 0.21920764933199047
Loss at iteration [541]: 0.21844298861641406
Loss at iteration [542]: 0.21768045062229738
Loss at iteration [543]: 0.21691990229875718
Loss at iteration [544]: 0.21616143752896408
Loss at iteration [545]: 0.21540500941010246
Loss at iteration [546]: 0.2146506112876965
Loss at iteration [547]: 0.21389816715328622
Loss at iteration [548]: 0.21314764744527082
Loss at iteration [549]: 0.21239905510271048
Loss at iteration [550]: 0.2116524782916807
Loss at iteration [551]: 0.21090784669507032
Loss at iteration [552]: 0.2101652189157748
Loss at iteration [553]: 0.20942464616623407
Loss at iteration [554]: 0.20868609109255257
Loss at iteration [555]: 0.20794952082691165
Loss at iteration [556]: 0.20721492980072684
Loss at iteration [557]: 0.2064823244127094
Loss at iteration [558]: 0.20575169456704484
Loss at iteration [559]: 0.20502299024284226
Loss at iteration [560]: 0.20429621000814746
Loss at iteration [561]: 0.20357135721236416
Loss at iteration [562]: 0.20284847697965758
Loss at iteration [563]: 0.20212760430864457
Loss at iteration [564]: 0.20140872165738335
Loss at iteration [565]: 0.20069187370714134
Loss at iteration [566]: 0.19997709089949017
Loss at iteration [567]: 0.19926430487196858
Loss at iteration [568]: 0.19855354974900144
Loss at iteration [569]: 0.197844812650741
Loss at iteration [570]: 0.19713807460745789
Loss at iteration [571]: 0.19643348678245137
Loss at iteration [572]: 0.19573104573893843
Loss at iteration [573]: 0.19503067566715937
Loss at iteration [574]: 0.1943323154245078
Loss at iteration [575]: 0.19363598161639028
Loss at iteration [576]: 0.19294164038066133
Loss at iteration [577]: 0.1922493751581956
Loss at iteration [578]: 0.191559313695142
Loss at iteration [579]: 0.19087140342687775
Loss at iteration [580]: 0.19018562402168698
Loss at iteration [581]: 0.18950202948709138
Loss at iteration [582]: 0.18882053952225963
Loss at iteration [583]: 0.18814118872476962
Loss at iteration [584]: 0.18746400299635596
Loss at iteration [585]: 0.1867889010831221
Loss at iteration [586]: 0.1861158016685285
Loss at iteration [587]: 0.1854447579042328
Loss at iteration [588]: 0.18477572300237047
Loss at iteration [589]: 0.18410863210151293
Loss at iteration [590]: 0.18344352439745942
Loss at iteration [591]: 0.1827803761777899
Loss at iteration [592]: 0.18211918983226266
Loss at iteration [593]: 0.18146002168787748
Loss at iteration [594]: 0.18080281713178942
Loss at iteration [595]: 0.18014756015063396
Loss at iteration [596]: 0.17949421496351856
Loss at iteration [597]: 0.1788427822666048
Loss at iteration [598]: 0.1781932436498928
Loss at iteration [599]: 0.1775455711737945
Loss at iteration [600]: 0.17689979342768103
Loss at iteration [601]: 0.17625587785797042
Loss at iteration [602]: 0.1756138297421751
Loss at iteration [603]: 0.1749736392232525
Loss at iteration [604]: 0.17433534750356874
Loss at iteration [605]: 0.17369895461297996
Loss at iteration [606]: 0.1730644174232793
Loss at iteration [607]: 0.17243173852606591
Loss at iteration [608]: 0.1718010068757987
Loss at iteration [609]: 0.17117217571908674
Loss at iteration [610]: 0.1705452139970843
Loss at iteration [611]: 0.16992010698183796
Loss at iteration [612]: 0.169296835417223
Loss at iteration [613]: 0.16867542192196772
Loss at iteration [614]: 0.1680558832904858
Loss at iteration [615]: 0.1674381805858413
Loss at iteration [616]: 0.16682233302991506
Loss at iteration [617]: 0.16620835173576615
Loss at iteration [618]: 0.165596191713311
Loss at iteration [619]: 0.16498586669714743
Loss at iteration [620]: 0.1643773566443653
Loss at iteration [621]: 0.16377068388045926
Loss at iteration [622]: 0.16316582435220517
Loss at iteration [623]: 0.16256280191893413
Loss at iteration [624]: 0.16196160073873822
Loss at iteration [625]: 0.16136219896733803
Loss at iteration [626]: 0.16076460982966256
Loss at iteration [627]: 0.16016878874759616
Loss at iteration [628]: 0.15957475353925565
Loss at iteration [629]: 0.15898253418655156
Loss at iteration [630]: 0.15839211066769174
Loss at iteration [631]: 0.15780343245833023
Loss at iteration [632]: 0.15721649779007849
Loss at iteration [633]: 0.15663130810788806
Loss at iteration [634]: 0.15604789181781037
Loss at iteration [635]: 0.15546625426510766
Loss at iteration [636]: 0.15488638194980803
Loss at iteration [637]: 0.15430828678083927
Loss at iteration [638]: 0.15373195980076607
Loss at iteration [639]: 0.1531574168759595
Loss at iteration [640]: 0.15258465232240154
Loss at iteration [641]: 0.15201362094159337
Loss at iteration [642]: 0.1514443584505931
Loss at iteration [643]: 0.15087684910204535
Loss at iteration [644]: 0.15031108767316897
Loss at iteration [645]: 0.14974705792837928
Loss at iteration [646]: 0.14918475220470817
Loss at iteration [647]: 0.14862418576573327
Loss at iteration [648]: 0.14806534552473866
Loss at iteration [649]: 0.14750819582241054
Loss at iteration [650]: 0.14695273424237926
Loss at iteration [651]: 0.14639895282588997
Loss at iteration [652]: 0.14584687077178704
Loss at iteration [653]: 0.14529649913163012
Loss at iteration [654]: 0.14474785497409542
Loss at iteration [655]: 0.1442009084194565
Loss at iteration [656]: 0.14365565003330286
Loss at iteration [657]: 0.14311206563910514
Loss at iteration [658]: 0.14257015003369064
Loss at iteration [659]: 0.1420299215569758
Loss at iteration [660]: 0.14149136924657238
Loss at iteration [661]: 0.14095450674224824
Loss at iteration [662]: 0.14041932675326016
Loss at iteration [663]: 0.1398858091568324
Loss at iteration [664]: 0.13935394777106777
Loss at iteration [665]: 0.13882373919051014
Loss at iteration [666]: 0.13829518335746344
Loss at iteration [667]: 0.13776827395823063
Loss at iteration [668]: 0.13724300741783826
Loss at iteration [669]: 0.1367193779849361
Loss at iteration [670]: 0.13619740618210419
Loss at iteration [671]: 0.13567711086685005
Loss at iteration [672]: 0.13515848036500666
Loss at iteration [673]: 0.13464150711000755
Loss at iteration [674]: 0.13412617630173582
Loss at iteration [675]: 0.13361248950690183
Loss at iteration [676]: 0.13310044656603515
Loss at iteration [677]: 0.13259003075925954
Loss at iteration [678]: 0.13208122881779003
Loss at iteration [679]: 0.13157404336500536
Loss at iteration [680]: 0.13106847483069897
Loss at iteration [681]: 0.13056451966479019
Loss at iteration [682]: 0.13006218717251464
Loss at iteration [683]: 0.12956146840613544
Loss at iteration [684]: 0.12906235360157542
Loss at iteration [685]: 0.12856484952702496
Loss at iteration [686]: 0.12806896521860425
Loss at iteration [687]: 0.12757468773032227
Loss at iteration [688]: 0.12708202405378333
Loss at iteration [689]: 0.1265909666834261
Loss at iteration [690]: 0.12610150070458373
Loss at iteration [691]: 0.12561362450874955
Loss at iteration [692]: 0.1251273420134241
Loss at iteration [693]: 0.12464264920663562
Loss at iteration [694]: 0.12415953948991333
Loss at iteration [695]: 0.12367802831168982
Loss at iteration [696]: 0.12319811697859
Loss at iteration [697]: 0.12271978083176971
Loss at iteration [698]: 0.12224301780120496
Loss at iteration [699]: 0.12176782416099467
Loss at iteration [700]: 0.12129419864487945
Loss at iteration [701]: 0.12082215002490976
Loss at iteration [702]: 0.12035167272998727
Loss at iteration [703]: 0.11988276110350138
Loss at iteration [704]: 0.11941541023324585
Loss at iteration [705]: 0.11894961273777954
Loss at iteration [706]: 0.11848536601810658
Loss at iteration [707]: 0.11802266965980057
Loss at iteration [708]: 0.1175615211571737
Loss at iteration [709]: 0.1171019271786661
Loss at iteration [710]: 0.11664386924685459
Loss at iteration [711]: 0.11618736376355646
Loss at iteration [712]: 0.11573240426515535
Loss at iteration [713]: 0.11527897451895674
Loss at iteration [714]: 0.1148270689896488
Loss at iteration [715]: 0.11437668145688704
Loss at iteration [716]: 0.11392781733420825
Loss at iteration [717]: 0.11348047014155616
Loss at iteration [718]: 0.11303463391314925
Loss at iteration [719]: 0.1125903026515683
Loss at iteration [720]: 0.11214747717045075
Loss at iteration [721]: 0.11170615646869861
Loss at iteration [722]: 0.11126635879881276
Loss at iteration [723]: 0.11082805890532507
Loss at iteration [724]: 0.11039125247561213
Loss at iteration [725]: 0.10995594112636124
Loss at iteration [726]: 0.10952215043143992
Loss at iteration [727]: 0.10908989905505734
Loss at iteration [728]: 0.10865914285597024
Loss at iteration [729]: 0.10822987517677667
Loss at iteration [730]: 0.10780209026806202
Loss at iteration [731]: 0.10737578022651105
Loss at iteration [732]: 0.10695094507495786
Loss at iteration [733]: 0.10652759606078667
Loss at iteration [734]: 0.10610572287910236
Loss at iteration [735]: 0.10568532126454608
Loss at iteration [736]: 0.10526638814160842
Loss at iteration [737]: 0.10484893004618609
Loss at iteration [738]: 0.10443292512936357
Loss at iteration [739]: 0.10401837917520304
Loss at iteration [740]: 0.10360528940822442
Loss at iteration [741]: 0.10319364793891672
Loss at iteration [742]: 0.10278345855274093
Loss at iteration [743]: 0.10237471624876537
Loss at iteration [744]: 0.10196741829824113
Loss at iteration [745]: 0.10156155061797031
Loss at iteration [746]: 0.10115711451880365
Loss at iteration [747]: 0.10075409914047717
Loss at iteration [748]: 0.10035250805566232
Loss at iteration [749]: 0.09995236306880602
Loss at iteration [750]: 0.09955364942300932
Loss at iteration [751]: 0.09915634976851957
Loss at iteration [752]: 0.09876045924787132
Loss at iteration [753]: 0.09836597441909062
Loss at iteration [754]: 0.09797289765657857
Loss at iteration [755]: 0.09758123216705558
Loss at iteration [756]: 0.09719096530284557
Loss at iteration [757]: 0.09680209401649156
Loss at iteration [758]: 0.09641461419817748
Loss at iteration [759]: 0.09602852261323942
Loss at iteration [760]: 0.09564381137041508
Loss at iteration [761]: 0.09526048053282697
Loss at iteration [762]: 0.09487853381451004
Loss at iteration [763]: 0.09449796220800101
Loss at iteration [764]: 0.09411876880533479
Loss at iteration [765]: 0.0937409434028193
Loss at iteration [766]: 0.09336447588044972
Loss at iteration [767]: 0.09298936232368446
Loss at iteration [768]: 0.09261560389150365
Loss at iteration [769]: 0.09224320648014142
Loss at iteration [770]: 0.09187216325518387
Loss at iteration [771]: 0.09150247548818045
Loss at iteration [772]: 0.09113413230454986
Loss at iteration [773]: 0.09076713861714188
Loss at iteration [774]: 0.09040149167614439
Loss at iteration [775]: 0.09003718217388713
Loss at iteration [776]: 0.08967420375429953
Loss at iteration [777]: 0.08931255351586487
Loss at iteration [778]: 0.08895223162461299
Loss at iteration [779]: 0.08859323525557004
Loss at iteration [780]: 0.08823555614707558
Loss at iteration [781]: 0.08787919287084467
Loss at iteration [782]: 0.08752415182474058
Loss at iteration [783]: 0.087170421724485
Loss at iteration [784]: 0.08681800313903364
Loss at iteration [785]: 0.08646688965119335
Loss at iteration [786]: 0.08611708113364507
Loss at iteration [787]: 0.08576857935627626
Loss at iteration [788]: 0.08542139662151431
Loss at iteration [789]: 0.08507552050657703
Loss at iteration [790]: 0.0847309375303469
Loss at iteration [791]: 0.08438764204476501
Loss at iteration [792]: 0.08404563324150427
Loss at iteration [793]: 0.08370491111220531
Loss at iteration [794]: 0.08336547698987119
Loss at iteration [795]: 0.08302732465942846
Loss at iteration [796]: 0.0826904505290534
Loss at iteration [797]: 0.08235484341496925
Loss at iteration [798]: 0.0820205055316342
Loss at iteration [799]: 0.08168743168366614
Loss at iteration [800]: 0.08135561133058022
Loss at iteration [801]: 0.08102504582467716
Loss at iteration [802]: 0.08069574781814363
Loss at iteration [803]: 0.08036770939751305
Loss at iteration [804]: 0.08004091734659574
Loss at iteration [805]: 0.07971536952109232
Loss at iteration [806]: 0.079391061879949
Loss at iteration [807]: 0.07906798731932893
Loss at iteration [808]: 0.07874614175370545
Loss at iteration [809]: 0.07842552421025226
Loss at iteration [810]: 0.07810613688501085
Loss at iteration [811]: 0.0777879705887563
Loss at iteration [812]: 0.07747102227949876
Loss at iteration [813]: 0.07715528573042975
Loss at iteration [814]: 0.0768407608690012
Loss at iteration [815]: 0.0765274443812777
Loss at iteration [816]: 0.07621532977700123
Loss at iteration [817]: 0.07590441300570183
Loss at iteration [818]: 0.07559469757918152
Loss at iteration [819]: 0.07528617888226272
Loss at iteration [820]: 0.07497885658315959
Loss at iteration [821]: 0.0746727292527374
Loss at iteration [822]: 0.07436779185077073
Loss at iteration [823]: 0.07406403858702192
Loss at iteration [824]: 0.07376146723185684
Loss at iteration [825]: 0.07346007693115708
Loss at iteration [826]: 0.07315986211388058
Loss at iteration [827]: 0.07286082060182678
Loss at iteration [828]: 0.07256294504587327
Loss at iteration [829]: 0.07226624012812378
Loss at iteration [830]: 0.07197070105673767
Loss at iteration [831]: 0.07167632216545744
Loss at iteration [832]: 0.07138310461195908
Loss at iteration [833]: 0.0710910332449717
Loss at iteration [834]: 0.07080010644144345
Loss at iteration [835]: 0.07051032063888567
Loss at iteration [836]: 0.07022167266641145
Loss at iteration [837]: 0.06993416340935797
Loss at iteration [838]: 0.06964778246549812
Loss at iteration [839]: 0.06936252507848335
Loss at iteration [840]: 0.06907839093245323
Loss at iteration [841]: 0.06879537580429201
Loss at iteration [842]: 0.06851347994584386
Loss at iteration [843]: 0.06823270131482165
Loss at iteration [844]: 0.06795303844951131
Loss at iteration [845]: 0.0676744845941806
Loss at iteration [846]: 0.06739703462242533
Loss at iteration [847]: 0.06712069354707699
Loss at iteration [848]: 0.06684546590781171
Loss at iteration [849]: 0.06657135266607643
Loss at iteration [850]: 0.06629833454011423
Loss at iteration [851]: 0.06602640648739877
Loss at iteration [852]: 0.06575556358199916
Loss at iteration [853]: 0.06548580636092102
Loss at iteration [854]: 0.0652171338073769
Loss at iteration [855]: 0.06494953839250517
Loss at iteration [856]: 0.0646830168989457
Loss at iteration [857]: 0.06441756803206033
Loss at iteration [858]: 0.06415319786346892
Loss at iteration [859]: 0.06388989844612247
Loss at iteration [860]: 0.06362766690389825
Loss at iteration [861]: 0.06336648830111509
Loss at iteration [862]: 0.06310636299202052
Loss at iteration [863]: 0.06284728992092338
Loss at iteration [864]: 0.06258926627014012
Loss at iteration [865]: 0.06233228780082866
Loss at iteration [866]: 0.0620763555958357
Loss at iteration [867]: 0.061821464704988935
Loss at iteration [868]: 0.061567607689719805
Loss at iteration [869]: 0.0613147820285896
Loss at iteration [870]: 0.061062984631568014
Loss at iteration [871]: 0.06081221459594276
Loss at iteration [872]: 0.06056246848342324
Loss at iteration [873]: 0.06031374138708167
Loss at iteration [874]: 0.06006603006529461
Loss at iteration [875]: 0.05981933094410491
Loss at iteration [876]: 0.05957364421150016
Loss at iteration [877]: 0.0593289683485887
Loss at iteration [878]: 0.059085303416232526
Loss at iteration [879]: 0.05884263517273482
Loss at iteration [880]: 0.05860096416953205
Loss at iteration [881]: 0.058360289314119254
Loss at iteration [882]: 0.058120609429282176
Loss at iteration [883]: 0.05788192085640427
Loss at iteration [884]: 0.05764421590074821
Loss at iteration [885]: 0.057407491044786346
Loss at iteration [886]: 0.05717174285256313
Loss at iteration [887]: 0.056936968172924006
Loss at iteration [888]: 0.056703165679377256
Loss at iteration [889]: 0.05647034012004724
Loss at iteration [890]: 0.05623848833481397
Loss at iteration [891]: 0.056007603902024965
Loss at iteration [892]: 0.055777681475162405
Loss at iteration [893]: 0.055548715356043644
Loss at iteration [894]: 0.05532070185517637
Loss at iteration [895]: 0.05509364030493695
Loss at iteration [896]: 0.054867531235434114
Loss at iteration [897]: 0.0546423735266332
Loss at iteration [898]: 0.0544181753911634
Loss at iteration [899]: 0.05419492997432761
Loss at iteration [900]: 0.053972624735322224
Loss at iteration [901]: 0.05375125450439221
Loss at iteration [902]: 0.05353082334954113
Loss at iteration [903]: 0.05331131886573841
Loss at iteration [904]: 0.05309274063532326
Loss at iteration [905]: 0.052875084859238614
Loss at iteration [906]: 0.052658348322750764
Loss at iteration [907]: 0.052442524779213316
Loss at iteration [908]: 0.052227609602715566
Loss at iteration [909]: 0.05201360051466769
Loss at iteration [910]: 0.05180049601105164
Loss at iteration [911]: 0.05158830145663543
Loss at iteration [912]: 0.05137700721167979
Loss at iteration [913]: 0.05116661756815344
Loss at iteration [914]: 0.05095714805971805
Loss at iteration [915]: 0.0507485729446301
Loss at iteration [916]: 0.050540888234226124
Loss at iteration [917]: 0.050334092586564724
Loss at iteration [918]: 0.05012818562620291
Loss at iteration [919]: 0.04992317121012988
Loss at iteration [920]: 0.04971903352978038
Loss at iteration [921]: 0.04951576694276971
Loss at iteration [922]: 0.04931337427195061
Loss at iteration [923]: 0.04911186346400119
Loss at iteration [924]: 0.04891122416757728
Loss at iteration [925]: 0.0487114460773891
Loss at iteration [926]: 0.04851252847811907
Loss at iteration [927]: 0.04831448592001886
Loss at iteration [928]: 0.048117314901145694
Loss at iteration [929]: 0.04792102499800306
Loss at iteration [930]: 0.04772561027499264
Loss at iteration [931]: 0.047531069501780696
Loss at iteration [932]: 0.047337388513432666
Loss at iteration [933]: 0.04714456654668668
Loss at iteration [934]: 0.046952583373889606
Loss at iteration [935]: 0.04676143872487321
Loss at iteration [936]: 0.04657113241512146
Loss at iteration [937]: 0.046381667703718606
Loss at iteration [938]: 0.046193053704300865
Loss at iteration [939]: 0.04600526737100918
Loss at iteration [940]: 0.04581831955604575
Loss at iteration [941]: 0.045632199473708064
Loss at iteration [942]: 0.04544692209509056
Loss at iteration [943]: 0.04526246644098705
Loss at iteration [944]: 0.045078821436412425
Loss at iteration [945]: 0.044895984840547645
Loss at iteration [946]: 0.0447139503343241
Loss at iteration [947]: 0.04453271290627409
Loss at iteration [948]: 0.04435226871268639
Loss at iteration [949]: 0.04417261202091179
Loss at iteration [950]: 0.04399373952678878
Loss at iteration [951]: 0.04381565225227739
Loss at iteration [952]: 0.04363834691282592
Loss at iteration [953]: 0.04346182560471959
Loss at iteration [954]: 0.043286085521805705
Loss at iteration [955]: 0.04311113012233665
Loss at iteration [956]: 0.04293694938180269
Loss at iteration [957]: 0.042763545485270914
Loss at iteration [958]: 0.04259090956878601
Loss at iteration [959]: 0.04241904383139787
Loss at iteration [960]: 0.0422479414664825
Loss at iteration [961]: 0.042077596170371004
Loss at iteration [962]: 0.041908005314608726
Loss at iteration [963]: 0.041739167084102524
Loss at iteration [964]: 0.04157107349036577
Loss at iteration [965]: 0.0414037237936291
Loss at iteration [966]: 0.04123711603058811
Loss at iteration [967]: 0.04107125728618699
Loss at iteration [968]: 0.040906145257171046
Loss at iteration [969]: 0.040741770336696556
Loss at iteration [970]: 0.04057812887415341
Loss at iteration [971]: 0.040415221190536844
Loss at iteration [972]: 0.04025303968897296
Loss at iteration [973]: 0.04009158781077707
Loss at iteration [974]: 0.03993086000207125
Loss at iteration [975]: 0.0397708496962977
Loss at iteration [976]: 0.03961155295242057
Loss at iteration [977]: 0.0394529689954738
Loss at iteration [978]: 0.03929509581088472
Loss at iteration [979]: 0.039137930297648366
Loss at iteration [980]: 0.038981467907047436
Loss at iteration [981]: 0.03882570328290353
Loss at iteration [982]: 0.03867063569370467
Loss at iteration [983]: 0.03851626594186307
Loss at iteration [984]: 0.03836259360742714
Loss at iteration [985]: 0.03820961390942152
Loss at iteration [986]: 0.03805732327886514
Loss at iteration [987]: 0.03790572204774223
Loss at iteration [988]: 0.03775480368809593
Loss at iteration [989]: 0.03760456389460243
Loss at iteration [990]: 0.037455000372263035
Loss at iteration [991]: 0.03730611009774084
Loss at iteration [992]: 0.03715789463891173
Loss at iteration [993]: 0.037010348629011404
Loss at iteration [994]: 0.03686347631595972
Loss at iteration [995]: 0.03671726897234704
Loss at iteration [996]: 0.036571722949181325
Loss at iteration [997]: 0.03642683851765561
Loss at iteration [998]: 0.03628261216588775
Loss at iteration [999]: 0.03613904131071919
Loss at iteration [1000]: 0.03599612199654181
Loss at iteration [1001]: 0.0358538568410096
Loss at iteration [1002]: 0.03571224115376642
Loss at iteration [1003]: 0.03557126949187714
Loss at iteration [1004]: 0.0354309440224343
Loss at iteration [1005]: 0.03529126314698601
Loss at iteration [1006]: 0.03515221934873739
Loss at iteration [1007]: 0.035013814125233744
Loss at iteration [1008]: 0.03487604020125006
Loss at iteration [1009]: 0.03473889481310575
Loss at iteration [1010]: 0.03460237438633431
Loss at iteration [1011]: 0.034466477417193955
Loss at iteration [1012]: 0.034331200454116716
Loss at iteration [1013]: 0.034196540927867794
Loss at iteration [1014]: 0.03406249772489925
Loss at iteration [1015]: 0.03392907306979861
Loss at iteration [1016]: 0.03379625846860294
Loss at iteration [1017]: 0.03366405244427525
Loss at iteration [1018]: 0.03353245294937696
Loss at iteration [1019]: 0.03340145884912699
Loss at iteration [1020]: 0.033271065600934305
Loss at iteration [1021]: 0.033141271235114095
Loss at iteration [1022]: 0.033012074485597925
Loss at iteration [1023]: 0.03288347663461085
Loss at iteration [1024]: 0.03275547266170718
Loss at iteration [1025]: 0.03262806026825701
Loss at iteration [1026]: 0.032501238997799636
Loss at iteration [1027]: 0.03237500544248912
Loss at iteration [1028]: 0.03224935855403165
Loss at iteration [1029]: 0.03212429211363762
Loss at iteration [1030]: 0.03199980250773436
Loss at iteration [1031]: 0.03187588754908207
Loss at iteration [1032]: 0.03175254660754939
Loss at iteration [1033]: 0.03162977613769697
Loss at iteration [1034]: 0.03150757213371173
Loss at iteration [1035]: 0.03138593382480465
Loss at iteration [1036]: 0.0312648589058376
Loss at iteration [1037]: 0.031144344038444672
Loss at iteration [1038]: 0.0310243869463305
Loss at iteration [1039]: 0.030904986555077205
Loss at iteration [1040]: 0.03078614409569347
Loss at iteration [1041]: 0.030667853842644907
Loss at iteration [1042]: 0.03055011310391699
Loss at iteration [1043]: 0.030432920947091834
Loss at iteration [1044]: 0.03031627392980388
Loss at iteration [1045]: 0.03020017011547458
Loss at iteration [1046]: 0.030084611305359738
Loss at iteration [1047]: 0.029969592790849785
Loss at iteration [1048]: 0.02985511127947328
Loss at iteration [1049]: 0.029741165619060313
Loss at iteration [1050]: 0.02962775158454959
Loss at iteration [1051]: 0.029514866261847333
Loss at iteration [1052]: 0.029402507847655406
Loss at iteration [1053]: 0.029290675768518005
Loss at iteration [1054]: 0.029179368105499245
Loss at iteration [1055]: 0.0290685850167244
Loss at iteration [1056]: 0.02895832015533176
Loss at iteration [1057]: 0.02884857246161434
Loss at iteration [1058]: 0.028739339844017404
Loss at iteration [1059]: 0.028630618930512858
Loss at iteration [1060]: 0.02852240834242164
Loss at iteration [1061]: 0.028414705722147687
Loss at iteration [1062]: 0.028307509418123104
Loss at iteration [1063]: 0.028200816502271804
Loss at iteration [1064]: 0.028094624225131044
Loss at iteration [1065]: 0.0279889309387215
Loss at iteration [1066]: 0.027883735504268366
Loss at iteration [1067]: 0.027779035262696258
Loss at iteration [1068]: 0.027674831656300233
Loss at iteration [1069]: 0.02757113285029208
Loss at iteration [1070]: 0.02746792606281776
Loss at iteration [1071]: 0.027365206815172387
Loss at iteration [1072]: 0.027262972216344928
Loss at iteration [1073]: 0.02716122048728332
Loss at iteration [1074]: 0.027059952457115448
Loss at iteration [1075]: 0.026959168802639648
Loss at iteration [1076]: 0.026858865958704833
Loss at iteration [1077]: 0.026759045737767315
Loss at iteration [1078]: 0.026659706163489918
Loss at iteration [1079]: 0.02656083985373503
Loss at iteration [1080]: 0.02646244366065863
Loss at iteration [1081]: 0.02636451517934362
Loss at iteration [1082]: 0.026267051891385368
Loss at iteration [1083]: 0.026170051528729164
Loss at iteration [1084]: 0.02607351208387171
Loss at iteration [1085]: 0.025977430458538252
Loss at iteration [1086]: 0.025881805174046774
Loss at iteration [1087]: 0.02578663406423959
Loss at iteration [1088]: 0.025691916609467732
Loss at iteration [1089]: 0.02559765431669034
Loss at iteration [1090]: 0.025503845715073525
Loss at iteration [1091]: 0.025410488202855866
Loss at iteration [1092]: 0.025317578843930894
Loss at iteration [1093]: 0.02522511350489053
Loss at iteration [1094]: 0.025133090583718307
Loss at iteration [1095]: 0.025041509068085624
Loss at iteration [1096]: 0.024950366242381818
Loss at iteration [1097]: 0.02485965900796895
Loss at iteration [1098]: 0.02476938484482584
Loss at iteration [1099]: 0.02467954204405656
Loss at iteration [1100]: 0.02459012864898468
Loss at iteration [1101]: 0.024501143000859503
Loss at iteration [1102]: 0.024412583963061323
Loss at iteration [1103]: 0.024324449478498385
Loss at iteration [1104]: 0.024236736462684948
Loss at iteration [1105]: 0.02414944249414601
Loss at iteration [1106]: 0.024062565816273175
Loss at iteration [1107]: 0.023976104734255252
Loss at iteration [1108]: 0.023890057785033624
Loss at iteration [1109]: 0.023804423634687728
Loss at iteration [1110]: 0.023719200990450818
Loss at iteration [1111]: 0.02363438924213983
Loss at iteration [1112]: 0.023549985426455967
Loss at iteration [1113]: 0.02346598707736149
Loss at iteration [1114]: 0.02338239222820191
Loss at iteration [1115]: 0.023299198952999017
Loss at iteration [1116]: 0.023216406488551583
Loss at iteration [1117]: 0.02313401251913601
Loss at iteration [1118]: 0.02305201578463327
Loss at iteration [1119]: 0.022970415521466617
Loss at iteration [1120]: 0.0228892111936578
Loss at iteration [1121]: 0.02280840552196442
Loss at iteration [1122]: 0.022727990780677852
Loss at iteration [1123]: 0.022647964719017883
Loss at iteration [1124]: 0.022568327080639983
Loss at iteration [1125]: 0.022489076706160835
Loss at iteration [1126]: 0.022410209723059224
Loss at iteration [1127]: 0.02233172472012135
Loss at iteration [1128]: 0.022253618424674004
Loss at iteration [1129]: 0.022175890406227906
Loss at iteration [1130]: 0.02209853959735705
Loss at iteration [1131]: 0.02202156445268205
Loss at iteration [1132]: 0.02194496353993983
Loss at iteration [1133]: 0.02186873427133761
Loss at iteration [1134]: 0.021792874691995427
Loss at iteration [1135]: 0.021717383568647084
Loss at iteration [1136]: 0.021642259250060993
Loss at iteration [1137]: 0.021567501538045944
Loss at iteration [1138]: 0.021493107756176612
Loss at iteration [1139]: 0.02141907513940397
Loss at iteration [1140]: 0.02134540317867087
Loss at iteration [1141]: 0.02127208960027263
Loss at iteration [1142]: 0.021199133584344065
Loss at iteration [1143]: 0.02112653496681817
Loss at iteration [1144]: 0.021054294101295445
Loss at iteration [1145]: 0.02098240735206937
Loss at iteration [1146]: 0.020910873625896362
Loss at iteration [1147]: 0.020839689363852647
Loss at iteration [1148]: 0.020768854372388932
Loss at iteration [1149]: 0.020698367514818485
Loss at iteration [1150]: 0.020628225118810954
Loss at iteration [1151]: 0.020558424623841637
Loss at iteration [1152]: 0.0204889648966263
Loss at iteration [1153]: 0.020419844359355243
Loss at iteration [1154]: 0.020351062068655
Loss at iteration [1155]: 0.02028261743241631
Loss at iteration [1156]: 0.02021451105799215
Loss at iteration [1157]: 0.020146739272357682
Loss at iteration [1158]: 0.02007929973412084
Loss at iteration [1159]: 0.02001219088727095
Loss at iteration [1160]: 0.019945411972590612
Loss at iteration [1161]: 0.019878961884228632
Loss at iteration [1162]: 0.019812839644303516
Loss at iteration [1163]: 0.019747041588130627
Loss at iteration [1164]: 0.019681566556038015
Loss at iteration [1165]: 0.019616412436247576
Loss at iteration [1166]: 0.01955157880702435
Loss at iteration [1167]: 0.019487063655128856
Loss at iteration [1168]: 0.019422864499112985
Loss at iteration [1169]: 0.019358978342685258
Loss at iteration [1170]: 0.01929540634531585
Loss at iteration [1171]: 0.01923215194507866
Loss at iteration [1172]: 0.019169211585469043
Loss at iteration [1173]: 0.019106586196845313
Loss at iteration [1174]: 0.01904426936932089
Loss at iteration [1175]: 0.01898226038634656
Loss at iteration [1176]: 0.018920557045715547
Loss at iteration [1177]: 0.018859157756368726
Loss at iteration [1178]: 0.01879806235035781
Loss at iteration [1179]: 0.018737268422843945
Loss at iteration [1180]: 0.018676776699996348
Loss at iteration [1181]: 0.01861658619981681
Loss at iteration [1182]: 0.018556694185352253
Loss at iteration [1183]: 0.018497098089392948
Loss at iteration [1184]: 0.018437796892694428
Loss at iteration [1185]: 0.018378788087335136
Loss at iteration [1186]: 0.01832007078641885
Loss at iteration [1187]: 0.018261644046476316
Loss at iteration [1188]: 0.01820350950936411
Loss at iteration [1189]: 0.018145665340536344
Loss at iteration [1190]: 0.01808810830604599
Loss at iteration [1191]: 0.01803083708214986
Loss at iteration [1192]: 0.017973849607895366
Loss at iteration [1193]: 0.01791714657451544
Loss at iteration [1194]: 0.017860723961705252
Loss at iteration [1195]: 0.017804579380553784
Loss at iteration [1196]: 0.017748712472661028
Loss at iteration [1197]: 0.017693121298922202
Loss at iteration [1198]: 0.01763780438160964
Loss at iteration [1199]: 0.017582761488971536
Loss at iteration [1200]: 0.017527990649241657
Loss at iteration [1201]: 0.017473490978835816
Loss at iteration [1202]: 0.017419261988804793
Loss at iteration [1203]: 0.01736530233441357
Loss at iteration [1204]: 0.017311609015980008
Loss at iteration [1205]: 0.01725818154356591
Loss at iteration [1206]: 0.01720501917143749
Loss at iteration [1207]: 0.017152121255748193
Loss at iteration [1208]: 0.017099484876767025
Loss at iteration [1209]: 0.0170471092274914
Loss at iteration [1210]: 0.016994993956257955
Loss at iteration [1211]: 0.016943138340972986
Loss at iteration [1212]: 0.016891541723601543
Loss at iteration [1213]: 0.016840202040136948
Loss at iteration [1214]: 0.016789117330406046
Loss at iteration [1215]: 0.016738286093954897
Loss at iteration [1216]: 0.016687706850765434
Loss at iteration [1217]: 0.01663737821876957
Loss at iteration [1218]: 0.016587299493088396
Loss at iteration [1219]: 0.016537469471450707
Loss at iteration [1220]: 0.016487886202996193
Loss at iteration [1221]: 0.016438549373718365
Loss at iteration [1222]: 0.016389457886113103
Loss at iteration [1223]: 0.016340612385437967
Loss at iteration [1224]: 0.0162920101861079
Loss at iteration [1225]: 0.016243650048222483
Loss at iteration [1226]: 0.0161955297587598
Loss at iteration [1227]: 0.016147649179354243
Loss at iteration [1228]: 0.016100008511443397
Loss at iteration [1229]: 0.016052605368161138
Loss at iteration [1230]: 0.016005438789341703
Loss at iteration [1231]: 0.015958509391057897
Loss at iteration [1232]: 0.01591181477474935
Loss at iteration [1233]: 0.015865352535610815
Loss at iteration [1234]: 0.01581912292085121
Loss at iteration [1235]: 0.01577312378889934
Loss at iteration [1236]: 0.015727353634700663
Loss at iteration [1237]: 0.015681813576847566
Loss at iteration [1238]: 0.0156365013998804
Loss at iteration [1239]: 0.015591415076734514
Loss at iteration [1240]: 0.015546552976123194
Loss at iteration [1241]: 0.015501914510453753
Loss at iteration [1242]: 0.015457498406413087
Loss at iteration [1243]: 0.01541330484505614
Loss at iteration [1244]: 0.015369331297132286
Loss at iteration [1245]: 0.015325576589891716
Loss at iteration [1246]: 0.015282040529148288
Loss at iteration [1247]: 0.015238721184504884
Loss at iteration [1248]: 0.01519561759875978
Loss at iteration [1249]: 0.015152728740730445
Loss at iteration [1250]: 0.015110053018721628
Loss at iteration [1251]: 0.015067589738610731
Loss at iteration [1252]: 0.015025337928571875
Loss at iteration [1253]: 0.014983297669599667
Loss at iteration [1254]: 0.014941468577996279
Loss at iteration [1255]: 0.014899848058476276
Loss at iteration [1256]: 0.01485843603240173
Loss at iteration [1257]: 0.01481723030964623
Loss at iteration [1258]: 0.014776230038438466
Loss at iteration [1259]: 0.014735437287523861
Loss at iteration [1260]: 0.014694848227385093
Loss at iteration [1261]: 0.014654461584655581
Loss at iteration [1262]: 0.01461427631739896
Loss at iteration [1263]: 0.014574292371159649
Loss at iteration [1264]: 0.014534509171001199
Loss at iteration [1265]: 0.014494925563356709
Loss at iteration [1266]: 0.014455539830366043
Loss at iteration [1267]: 0.014416350308299955
Loss at iteration [1268]: 0.014377356450681915
Loss at iteration [1269]: 0.01433855773732917
Loss at iteration [1270]: 0.01429995266703349
Loss at iteration [1271]: 0.014261540828548979
Loss at iteration [1272]: 0.014223320158464222
Loss at iteration [1273]: 0.01418529012523594
Loss at iteration [1274]: 0.014147450796523872
Loss at iteration [1275]: 0.01410980177317325
Loss at iteration [1276]: 0.014072343369248619
Loss at iteration [1277]: 0.014035072921061873
Loss at iteration [1278]: 0.01399798856011216
Loss at iteration [1279]: 0.013961089457067545
Loss at iteration [1280]: 0.013924375494179448
Loss at iteration [1281]: 0.013887847449800718
Loss at iteration [1282]: 0.013851502967564431
Loss at iteration [1283]: 0.013815340243406329
Loss at iteration [1284]: 0.013779358756039941
Loss at iteration [1285]: 0.013743556621382774
Loss at iteration [1286]: 0.013707933087467815
Loss at iteration [1287]: 0.013672487610106015
Loss at iteration [1288]: 0.013637221746941498
Loss at iteration [1289]: 0.013602132497566312
Loss at iteration [1290]: 0.013567218612632381
Loss at iteration [1291]: 0.013532478830347439
Loss at iteration [1292]: 0.013497913216739077
Loss at iteration [1293]: 0.013463520561611325
Loss at iteration [1294]: 0.013429299422103348
Loss at iteration [1295]: 0.013395250030287627
Loss at iteration [1296]: 0.01336137141024669
Loss at iteration [1297]: 0.013327662286172168
Loss at iteration [1298]: 0.013294121736674
Loss at iteration [1299]: 0.013260750550933348
Loss at iteration [1300]: 0.01322754638016285
Loss at iteration [1301]: 0.013194508630571892
Loss at iteration [1302]: 0.013161636342494114
Loss at iteration [1303]: 0.0131289283921149
Loss at iteration [1304]: 0.013096384066935812
Loss at iteration [1305]: 0.01306400265651451
Loss at iteration [1306]: 0.01303178373048627
Loss at iteration [1307]: 0.01299972614360663
Loss at iteration [1308]: 0.012967829080857909
Loss at iteration [1309]: 0.012936091563342897
Loss at iteration [1310]: 0.012904512391831102
Loss at iteration [1311]: 0.012873091236676518
Loss at iteration [1312]: 0.012841827593831618
Loss at iteration [1313]: 0.01281072129303585
Loss at iteration [1314]: 0.01277977218464492
Loss at iteration [1315]: 0.012748979130999654
Loss at iteration [1316]: 0.01271834011681822
Loss at iteration [1317]: 0.012687854354886832
Loss at iteration [1318]: 0.012657520587777513
Loss at iteration [1319]: 0.01262733790286462
Loss at iteration [1320]: 0.012597305529931397
Loss at iteration [1321]: 0.012567423929098626
Loss at iteration [1322]: 0.012537692827764804
Loss at iteration [1323]: 0.01250811067616157
Loss at iteration [1324]: 0.012478676730692563
Loss at iteration [1325]: 0.012449390493474486
Loss at iteration [1326]: 0.012420251926098969
Loss at iteration [1327]: 0.012391259000898566
Loss at iteration [1328]: 0.012362411624746732
Loss at iteration [1329]: 0.012333711684200771
Loss at iteration [1330]: 0.01230515887973332
Loss at iteration [1331]: 0.012276749196950558
Loss at iteration [1332]: 0.012248481837808247
Loss at iteration [1333]: 0.01222035758879195
Loss at iteration [1334]: 0.012192374599166377
Loss at iteration [1335]: 0.012164532440032754
Loss at iteration [1336]: 0.012136830105130964
Loss at iteration [1337]: 0.012109267424542143
Loss at iteration [1338]: 0.012081842146052978
Loss at iteration [1339]: 0.012054553545288905
Loss at iteration [1340]: 0.012027401123794522
Loss at iteration [1341]: 0.012000384098166577
Loss at iteration [1342]: 0.011973502246763381
Loss at iteration [1343]: 0.011946754496589522
Loss at iteration [1344]: 0.011920139778169254
Loss at iteration [1345]: 0.011893657869237031
Loss at iteration [1346]: 0.01186731006525621
Loss at iteration [1347]: 0.011841093881150996
Loss at iteration [1348]: 0.01181500833323048
Loss at iteration [1349]: 0.011789052964663224
Loss at iteration [1350]: 0.01176322676102131
Loss at iteration [1351]: 0.011737529043689658
Loss at iteration [1352]: 0.011711959669948003
Loss at iteration [1353]: 0.011686518097377231
Loss at iteration [1354]: 0.011661204090812977
Loss at iteration [1355]: 0.01163601601518154
Loss at iteration [1356]: 0.011610953053606406
Loss at iteration [1357]: 0.011586014523727043
Loss at iteration [1358]: 0.011561199671530653
Loss at iteration [1359]: 0.011536507950573316
Loss at iteration [1360]: 0.011511938607553021
Loss at iteration [1361]: 0.011487491054971133
Loss at iteration [1362]: 0.011463164738739418
Loss at iteration [1363]: 0.011438958710469386
Loss at iteration [1364]: 0.011414873004790192
Loss at iteration [1365]: 0.01139090829454104
Loss at iteration [1366]: 0.011367062880120621
Loss at iteration [1367]: 0.01134333597351724
Loss at iteration [1368]: 0.011319726557126304
Loss at iteration [1369]: 0.01129623462496189
Loss at iteration [1370]: 0.01127285994552606
Loss at iteration [1371]: 0.011249601181725737
Loss at iteration [1372]: 0.011226458723660388
Loss at iteration [1373]: 0.01120343192327229
Loss at iteration [1374]: 0.011180519440798288
Loss at iteration [1375]: 0.01115772042543718
Loss at iteration [1376]: 0.011135034137108377
Loss at iteration [1377]: 0.011112459931436985
Loss at iteration [1378]: 0.011089998135555617
Loss at iteration [1379]: 0.011067648241451544
Loss at iteration [1380]: 0.011045410858335648
Loss at iteration [1381]: 0.011023283946356498
Loss at iteration [1382]: 0.011001266514286607
Loss at iteration [1383]: 0.01097935788705765
Loss at iteration [1384]: 0.010957557532081946
Loss at iteration [1385]: 0.010935865140076944
Loss at iteration [1386]: 0.010914282128105435
Loss at iteration [1387]: 0.010892808008810128
Loss at iteration [1388]: 0.01087144032864768
Loss at iteration [1389]: 0.010850178920986707
Loss at iteration [1390]: 0.010829023250869747
Loss at iteration [1391]: 0.010807972279745896
Loss at iteration [1392]: 0.010787025209384097
Loss at iteration [1393]: 0.01076618144273771
Loss at iteration [1394]: 0.010745441090495494
Loss at iteration [1395]: 0.010724806281670538
Loss at iteration [1396]: 0.010704273755605538
Loss at iteration [1397]: 0.010683843002748225
Loss at iteration [1398]: 0.010663515375400187
Loss at iteration [1399]: 0.010643291198268841
Loss at iteration [1400]: 0.010623169570335472
Loss at iteration [1401]: 0.010603148529398967
Loss at iteration [1402]: 0.010583227345475881
Loss at iteration [1403]: 0.0105634062080511
Loss at iteration [1404]: 0.0105436847297416
Loss at iteration [1405]: 0.01052406088549892
Loss at iteration [1406]: 0.01050453416535665
Loss at iteration [1407]: 0.010485103902874379
Loss at iteration [1408]: 0.010465769864341149
Loss at iteration [1409]: 0.010446531890074258
Loss at iteration [1410]: 0.01042738879132237
Loss at iteration [1411]: 0.010408340241514314
Loss at iteration [1412]: 0.010389385439077532
Loss at iteration [1413]: 0.010370524371761097
Loss at iteration [1414]: 0.010351756488462854
Loss at iteration [1415]: 0.010333080780627647
Loss at iteration [1416]: 0.010314496408916077
Loss at iteration [1417]: 0.010296002847804606
Loss at iteration [1418]: 0.010277599544907267
Loss at iteration [1419]: 0.010259286480751141
Loss at iteration [1420]: 0.010241063227108538
Loss at iteration [1421]: 0.010222929284040881
Loss at iteration [1422]: 0.010204884327908484
Loss at iteration [1423]: 0.010186927303522941
Loss at iteration [1424]: 0.01016905837019806
Loss at iteration [1425]: 0.010151277830119427
Loss at iteration [1426]: 0.010133585282755648
Loss at iteration [1427]: 0.010115979115701565
Loss at iteration [1428]: 0.010098458637360556
Loss at iteration [1429]: 0.01008102394548228
Loss at iteration [1430]: 0.010063674531664717
Loss at iteration [1431]: 0.010046410446883817
Loss at iteration [1432]: 0.01002923123986155
Loss at iteration [1433]: 0.010012135562820516
Loss at iteration [1434]: 0.00999512285362529
Loss at iteration [1435]: 0.009978192758789214
Loss at iteration [1436]: 0.009961344936432616
Loss at iteration [1437]: 0.009944579345171877
Loss at iteration [1438]: 0.009927896390626205
Loss at iteration [1439]: 0.009911296286925556
Loss at iteration [1440]: 0.009894778177586674
Loss at iteration [1441]: 0.009878341468275847
Loss at iteration [1442]: 0.009861984746418986
Loss at iteration [1443]: 0.00984570804971482
Loss at iteration [1444]: 0.009829511414431382
Loss at iteration [1445]: 0.009813395769418927
Loss at iteration [1446]: 0.009797359213280758
Loss at iteration [1447]: 0.009781401582238565
Loss at iteration [1448]: 0.009765521903781346
Loss at iteration [1449]: 0.009749719394188948
Loss at iteration [1450]: 0.009733993758768676
Loss at iteration [1451]: 0.009718344911091715
Loss at iteration [1452]: 0.009702772033039332
Loss at iteration [1453]: 0.009687275027682256
Loss at iteration [1454]: 0.009671853787575289
Loss at iteration [1455]: 0.009656508811288583
Loss at iteration [1456]: 0.009641238114901451
Loss at iteration [1457]: 0.009626042382657605
Loss at iteration [1458]: 0.009610920590118676
Loss at iteration [1459]: 0.009595872581769159
Loss at iteration [1460]: 0.009580897835107124
Loss at iteration [1461]: 0.00956599555305751
Loss at iteration [1462]: 0.009551164866889115
Loss at iteration [1463]: 0.009536405243753503
Loss at iteration [1464]: 0.009521716154018154
Loss at iteration [1465]: 0.00950709716734451
Loss at iteration [1466]: 0.00949254796851476
Loss at iteration [1467]: 0.009478068454856377
Loss at iteration [1468]: 0.009463658029340702
Loss at iteration [1469]: 0.009449316904876574
Loss at iteration [1470]: 0.00943504622177468
Loss at iteration [1471]: 0.009420844633805707
Loss at iteration [1472]: 0.00940671219591122
Loss at iteration [1473]: 0.009392648936696413
Loss at iteration [1474]: 0.009378653023754735
Loss at iteration [1475]: 0.00936472540812157
Loss at iteration [1476]: 0.00935086639087835
Loss at iteration [1477]: 0.009337074028013986
Loss at iteration [1478]: 0.009323349607595698
Loss at iteration [1479]: 0.009309694794276537
Loss at iteration [1480]: 0.009296106511307065
Loss at iteration [1481]: 0.009282583720088595
Loss at iteration [1482]: 0.009269126051740349
Loss at iteration [1483]: 0.009255734074344187
Loss at iteration [1484]: 0.009242406891748281
Loss at iteration [1485]: 0.009229143958987754
Loss at iteration [1486]: 0.0092159463587276
Loss at iteration [1487]: 0.009202812602950841
Loss at iteration [1488]: 0.009189741307877171
Loss at iteration [1489]: 0.009176733022412504
Loss at iteration [1490]: 0.009163787810198306
Loss at iteration [1491]: 0.009150904439849903
Loss at iteration [1492]: 0.009138082012110546
Loss at iteration [1493]: 0.009125321685095502
Loss at iteration [1494]: 0.009112621865602948
Loss at iteration [1495]: 0.009099982154716938
Loss at iteration [1496]: 0.009087402259595008
Loss at iteration [1497]: 0.00907488163919495
Loss at iteration [1498]: 0.009062420286271407
Loss at iteration [1499]: 0.009050017947217931
Loss at iteration [1500]: 0.009037673922710009
Loss at iteration [1501]: 0.00902538767210964
Loss at iteration [1502]: 0.009013158707262695
Loss at iteration [1503]: 0.009000986688560418
Loss at iteration [1504]: 0.00898887156148272
Loss at iteration [1505]: 0.008976813925749005
Loss at iteration [1506]: 0.008964814125928549
Loss at iteration [1507]: 0.00895287080006179
Loss at iteration [1508]: 0.008940983591454125
Loss at iteration [1509]: 0.008929151988120566
Loss at iteration [1510]: 0.00891737596570315
Loss at iteration [1511]: 0.008905655240754727
Loss at iteration [1512]: 0.008893989557279675
Loss at iteration [1513]: 0.008882377996670706
Loss at iteration [1514]: 0.008870821101136711
Loss at iteration [1515]: 0.008859319001896659
Loss at iteration [1516]: 0.008847870446782006
Loss at iteration [1517]: 0.008836475000528388
Loss at iteration [1518]: 0.008825132437948134
Loss at iteration [1519]: 0.008813842452469616
Loss at iteration [1520]: 0.008802604997266896
Loss at iteration [1521]: 0.0087914198832342
Loss at iteration [1522]: 0.00878028685281209
Loss at iteration [1523]: 0.008769205349013813
Loss at iteration [1524]: 0.008758174961005111
Loss at iteration [1525]: 0.008747196378393749
Loss at iteration [1526]: 0.008736269046389637
Loss at iteration [1527]: 0.008725393843890957
Loss at iteration [1528]: 0.008714569784178073
Loss at iteration [1529]: 0.008703797024250746
Loss at iteration [1530]: 0.008693075141681059
Loss at iteration [1531]: 0.008682404547589092
Loss at iteration [1532]: 0.008671784869875665
Loss at iteration [1533]: 0.008661214348392657
Loss at iteration [1534]: 0.008650692238884742
Loss at iteration [1535]: 0.0086402184207636
Loss at iteration [1536]: 0.008629793058189669
Loss at iteration [1537]: 0.008619415896406123
Loss at iteration [1538]: 0.008609087301011764
Loss at iteration [1539]: 0.008598806010633947
Loss at iteration [1540]: 0.008588571564696008
Loss at iteration [1541]: 0.008578383882073035
Loss at iteration [1542]: 0.008568242743320085
Loss at iteration [1543]: 0.00855814818246771
Loss at iteration [1544]: 0.008548099911753801
Loss at iteration [1545]: 0.008538097795189699
Loss at iteration [1546]: 0.008528141041443369
Loss at iteration [1547]: 0.008518229382126971
Loss at iteration [1548]: 0.008508362729867972
Loss at iteration [1549]: 0.008498540547707064
Loss at iteration [1550]: 0.008488762549138804
Loss at iteration [1551]: 0.008479028401242966
Loss at iteration [1552]: 0.008469337444348442
Loss at iteration [1553]: 0.008459690338495572
Loss at iteration [1554]: 0.008450088758750845
Loss at iteration [1555]: 0.008440531689802484
Loss at iteration [1556]: 0.008431019305938954
Loss at iteration [1557]: 0.00842155070751339
Loss at iteration [1558]: 0.008412125708398535
Loss at iteration [1559]: 0.008402743318909561
Loss at iteration [1560]: 0.008393403064180916
Loss at iteration [1561]: 0.008384104842542704
Loss at iteration [1562]: 0.008374848456323938
Loss at iteration [1563]: 0.008365635514792105
Loss at iteration [1564]: 0.008356463946378198
Loss at iteration [1565]: 0.008347333552421196
Loss at iteration [1566]: 0.008338244124534648
Loss at iteration [1567]: 0.008329195300352862
Loss at iteration [1568]: 0.008320186949765149
Loss at iteration [1569]: 0.008311218838003972
Loss at iteration [1570]: 0.00830229108498218
Loss at iteration [1571]: 0.008293403533964856
Loss at iteration [1572]: 0.008284556843297755
Loss at iteration [1573]: 0.008275750367711263
Loss at iteration [1574]: 0.008266983853969795
Loss at iteration [1575]: 0.008258256732699842
Loss at iteration [1576]: 0.008249568625607658
Loss at iteration [1577]: 0.008240919031293988
Loss at iteration [1578]: 0.008232307764429481
Loss at iteration [1579]: 0.008223734515575743
Loss at iteration [1580]: 0.00821519913772261
Loss at iteration [1581]: 0.008206701197593539
Loss at iteration [1582]: 0.00819824079889905
Loss at iteration [1583]: 0.008189817586289307
Loss at iteration [1584]: 0.008181432509031606
Loss at iteration [1585]: 0.008173084651859078
Loss at iteration [1586]: 0.008164773921412054
Loss at iteration [1587]: 0.00815650076787893
Loss at iteration [1588]: 0.008148266063678689
Loss at iteration [1589]: 0.008140067525964084
Loss at iteration [1590]: 0.008131904602576028
Loss at iteration [1591]: 0.008123777388264522
Loss at iteration [1592]: 0.008115686686297911
Loss at iteration [1593]: 0.008107632017428262
Loss at iteration [1594]: 0.008099612270454498
Loss at iteration [1595]: 0.008091627019806386
Loss at iteration [1596]: 0.008083676019230233
Loss at iteration [1597]: 0.008075758716523317
Loss at iteration [1598]: 0.00806787537583181
Loss at iteration [1599]: 0.008060026078588967
Loss at iteration [1600]: 0.008052210719675105
Loss at iteration [1601]: 0.008044428828097612
Loss at iteration [1602]: 0.008036680778246427
Loss at iteration [1603]: 0.008028966352223782
Loss at iteration [1604]: 0.008021285156227518
Loss at iteration [1605]: 0.008013637381142944
Loss at iteration [1606]: 0.008006022574630726
Loss at iteration [1607]: 0.007998440602934823
Loss at iteration [1608]: 0.007990890973470275
Loss at iteration [1609]: 0.00798337326097066
Loss at iteration [1610]: 0.007975887747920034
Loss at iteration [1611]: 0.00796843408383039
Loss at iteration [1612]: 0.007961012755562413
Loss at iteration [1613]: 0.007953622553465505
Loss at iteration [1614]: 0.007946262880161538
Loss at iteration [1615]: 0.007938933393553772
Loss at iteration [1616]: 0.007931634060682242
Loss at iteration [1617]: 0.007924365870300447
Loss at iteration [1618]: 0.00791712758857138
Loss at iteration [1619]: 0.007909920206714601
Loss at iteration [1620]: 0.007902743858002156
Loss at iteration [1621]: 0.007895597585697451
Loss at iteration [1622]: 0.007888481423445606
Loss at iteration [1623]: 0.007881395204790457
Loss at iteration [1624]: 0.007874338635688795
Loss at iteration [1625]: 0.007867311245246271
Loss at iteration [1626]: 0.00786031307045946
Loss at iteration [1627]: 0.007853344496352221
Loss at iteration [1628]: 0.0078464050326118
Loss at iteration [1629]: 0.007839494615474805
Loss at iteration [1630]: 0.007832613585015087
Loss at iteration [1631]: 0.007825761464079014
Loss at iteration [1632]: 0.007818937737999718
Loss at iteration [1633]: 0.007812142221474795
Loss at iteration [1634]: 0.0078053749880407685
Loss at iteration [1635]: 0.007798635725294914
Loss at iteration [1636]: 0.007791923934122905
Loss at iteration [1637]: 0.007785239941844355
Loss at iteration [1638]: 0.00777858457359131
Loss at iteration [1639]: 0.007771956712242113
Loss at iteration [1640]: 0.007765356284420857
Loss at iteration [1641]: 0.007758783008745452
Loss at iteration [1642]: 0.0077522367616755855
Loss at iteration [1643]: 0.007745717138018893
Loss at iteration [1644]: 0.007739224499875231
Loss at iteration [1645]: 0.007732758644329055
Loss at iteration [1646]: 0.007726319180877259
Loss at iteration [1647]: 0.00771990620156626
Loss at iteration [1648]: 0.007713519449957792
Loss at iteration [1649]: 0.007707159401608961
Loss at iteration [1650]: 0.007700826163381242
Loss at iteration [1651]: 0.007694518460672688
Loss at iteration [1652]: 0.007688237171725416
Loss at iteration [1653]: 0.007681982028960339
Loss at iteration [1654]: 0.007675752913353402
Loss at iteration [1655]: 0.007669548884914494
Loss at iteration [1656]: 0.0076633694986257585
Loss at iteration [1657]: 0.007657214746959155
Loss at iteration [1658]: 0.007651085112192503
Loss at iteration [1659]: 0.007644980615327339
Loss at iteration [1660]: 0.0076389004463912015
Loss at iteration [1661]: 0.007632844371962774
Loss at iteration [1662]: 0.007626812060789557
Loss at iteration [1663]: 0.0076208039649796125
Loss at iteration [1664]: 0.007614819756743147
Loss at iteration [1665]: 0.0076088597492374906
Loss at iteration [1666]: 0.0076029234593178304
Loss at iteration [1667]: 0.007597010892418923
Loss at iteration [1668]: 0.007591122381315743
Loss at iteration [1669]: 0.007585257515346319
Loss at iteration [1670]: 0.007579416865382468
Loss at iteration [1671]: 0.007573599893898397
Loss at iteration [1672]: 0.00756780681911042
Loss at iteration [1673]: 0.007562036716235084
Loss at iteration [1674]: 0.007556288627973731
Loss at iteration [1675]: 0.007550563008404925
Loss at iteration [1676]: 0.007544859521147003
Loss at iteration [1677]: 0.007539178142730152
Loss at iteration [1678]: 0.007533518918138468
Loss at iteration [1679]: 0.007527882028173044
Loss at iteration [1680]: 0.00752226729336959
Loss at iteration [1681]: 0.0075166745181776675
Loss at iteration [1682]: 0.007511103909009817
Loss at iteration [1683]: 0.007505554576084498
Loss at iteration [1684]: 0.007500026429512335
Loss at iteration [1685]: 0.007494519640024928
Loss at iteration [1686]: 0.007489034831228518
Loss at iteration [1687]: 0.0074835726195357066
Loss at iteration [1688]: 0.007478132013488095
Loss at iteration [1689]: 0.007472712654258184
Loss at iteration [1690]: 0.007467314537140649
Loss at iteration [1691]: 0.007461937391326114
Loss at iteration [1692]: 0.007456580789985154
Loss at iteration [1693]: 0.007451244904725625
Loss at iteration [1694]: 0.00744592975622192
Loss at iteration [1695]: 0.007440636243278425
Loss at iteration [1696]: 0.007435363425998318
Loss at iteration [1697]: 0.007430111089723634
Loss at iteration [1698]: 0.007424880998206781
Loss at iteration [1699]: 0.0074196719503498414
Loss at iteration [1700]: 0.00741448336427117
Loss at iteration [1701]: 0.007409314482495885
Loss at iteration [1702]: 0.007404164983465931
Loss at iteration [1703]: 0.007399034999324501
Loss at iteration [1704]: 0.007393925599228801
Loss at iteration [1705]: 0.007388836786113399
Loss at iteration [1706]: 0.007383767078235881
Loss at iteration [1707]: 0.007378716200224649
Loss at iteration [1708]: 0.007373684031063563
Loss at iteration [1709]: 0.007368670161342923
Loss at iteration [1710]: 0.007363674181180862
Loss at iteration [1711]: 0.007358696438783718
Loss at iteration [1712]: 0.007353736847249518
Loss at iteration [1713]: 0.007348796059951353
Loss at iteration [1714]: 0.007343873877344163
Loss at iteration [1715]: 0.007338970658375797
Loss at iteration [1716]: 0.007334085687791675
Loss at iteration [1717]: 0.0073292185976557315
Loss at iteration [1718]: 0.007324369132708807
Loss at iteration [1719]: 0.007319537326134295
Loss at iteration [1720]: 0.007314723226055927
Loss at iteration [1721]: 0.007309926300208968
Loss at iteration [1722]: 0.007305146667391099
Loss at iteration [1723]: 0.007300384510089866
Loss at iteration [1724]: 0.0072956401096938754
Loss at iteration [1725]: 0.00729091280032993
Loss at iteration [1726]: 0.007286203540126673
Loss at iteration [1727]: 0.0072815113632525965
Loss at iteration [1728]: 0.0072768361820816675
Loss at iteration [1729]: 0.0072721781249088235
Loss at iteration [1730]: 0.007267536441719683
Loss at iteration [1731]: 0.007262910996408883
Loss at iteration [1732]: 0.007258302489381405
Loss at iteration [1733]: 0.00725371089649368
Loss at iteration [1734]: 0.007249136149000133
Loss at iteration [1735]: 0.007244578959002172
Loss at iteration [1736]: 0.007240038152666585
Loss at iteration [1737]: 0.007235513737247652
Loss at iteration [1738]: 0.007231005721750687
Loss at iteration [1739]: 0.007226514104046867
Loss at iteration [1740]: 0.007222039112158649
Loss at iteration [1741]: 0.00721758017803582
Loss at iteration [1742]: 0.007213136879357582
Loss at iteration [1743]: 0.007208709587992904
Loss at iteration [1744]: 0.007204298027985162
Loss at iteration [1745]: 0.007199902071781417
Loss at iteration [1746]: 0.007195521110311584
Loss at iteration [1747]: 0.007191155195895826
Loss at iteration [1748]: 0.00718680491730653
Loss at iteration [1749]: 0.007182470449903951
Loss at iteration [1750]: 0.007178151029498793
Loss at iteration [1751]: 0.0071738464568924295
Loss at iteration [1752]: 0.007169556951504122
Loss at iteration [1753]: 0.007165282718703194
Loss at iteration [1754]: 0.007161024107913266
Loss at iteration [1755]: 0.007156780709881035
Loss at iteration [1756]: 0.007152551808170273
Loss at iteration [1757]: 0.007148337277539744
Loss at iteration [1758]: 0.007144137556467203
Loss at iteration [1759]: 0.007139952827796653
Loss at iteration [1760]: 0.007135783065339959
Loss at iteration [1761]: 0.007131627463298141
Loss at iteration [1762]: 0.007127485762964213
Loss at iteration [1763]: 0.007123358415503483
Loss at iteration [1764]: 0.007119245356580497
Loss at iteration [1765]: 0.007115146069960705
Loss at iteration [1766]: 0.007111060532369155
Loss at iteration [1767]: 0.007106989067918276
Loss at iteration [1768]: 0.007102932169844764
Loss at iteration [1769]: 0.007098888765210826
Loss at iteration [1770]: 0.007094858567812598
Loss at iteration [1771]: 0.007090841573727739
Loss at iteration [1772]: 0.007086837279717085
Loss at iteration [1773]: 0.007082845536043705
Loss at iteration [1774]: 0.007078866789174407
Loss at iteration [1775]: 0.007074902208115832
Loss at iteration [1776]: 0.007070951728434426
Loss at iteration [1777]: 0.007067015137281658
Loss at iteration [1778]: 0.007063091827204153
Loss at iteration [1779]: 0.0070591817566160175
Loss at iteration [1780]: 0.007055284430906724
Loss at iteration [1781]: 0.0070514003751267745
Loss at iteration [1782]: 0.007047529253332724
Loss at iteration [1783]: 0.007043670691769078
Loss at iteration [1784]: 0.0070398243956024545
Loss at iteration [1785]: 0.007035990388652442
Loss at iteration [1786]: 0.007032169154492437
Loss at iteration [1787]: 0.007028361257038357
Loss at iteration [1788]: 0.007024565566218231
Loss at iteration [1789]: 0.007020782749413424
Loss at iteration [1790]: 0.007017012218039163
Loss at iteration [1791]: 0.007013253826439164
Loss at iteration [1792]: 0.007009507188797078
Loss at iteration [1793]: 0.007005773227954652
Loss at iteration [1794]: 0.007002051622836048
Loss at iteration [1795]: 0.006998341997063289
Loss at iteration [1796]: 0.006994644441257233
Loss at iteration [1797]: 0.00699095864724651
Loss at iteration [1798]: 0.006987284313973595
Loss at iteration [1799]: 0.006983621839721549
Loss at iteration [1800]: 0.006979970876289501
Loss at iteration [1801]: 0.006976332452233633
Loss at iteration [1802]: 0.006972705798364821
Loss at iteration [1803]: 0.006969091333358985
Loss at iteration [1804]: 0.006965489339868234
Loss at iteration [1805]: 0.0069618993069683055
Loss at iteration [1806]: 0.006958321234307697
Loss at iteration [1807]: 0.006954754900872486
Loss at iteration [1808]: 0.0069512000249793635
Loss at iteration [1809]: 0.0069476559040040345
Loss at iteration [1810]: 0.006944122690531278
Loss at iteration [1811]: 0.006940600811564408
Loss at iteration [1812]: 0.006937089793287153
Loss at iteration [1813]: 0.006933589303914675
Loss at iteration [1814]: 0.006930099229019171
Loss at iteration [1815]: 0.006926619597485203
Loss at iteration [1816]: 0.006923150715117646
Loss at iteration [1817]: 0.006919692185984476
Loss at iteration [1818]: 0.006916243969225114
Loss at iteration [1819]: 0.006912806001413288
Loss at iteration [1820]: 0.006909378502778572
Loss at iteration [1821]: 0.00690596151248341
Loss at iteration [1822]: 0.006902554621350781
Loss at iteration [1823]: 0.0068991580096343375
Loss at iteration [1824]: 0.00689577142720364
Loss at iteration [1825]: 0.006892394704461879
Loss at iteration [1826]: 0.006889028039222009
Loss at iteration [1827]: 0.0068856716988597135
Loss at iteration [1828]: 0.006882325274307356
Loss at iteration [1829]: 0.006878988749054383
Loss at iteration [1830]: 0.006875662349156279
Loss at iteration [1831]: 0.006872346341456707
Loss at iteration [1832]: 0.006869040632770888
Loss at iteration [1833]: 0.006865744188691907
Loss at iteration [1834]: 0.006862457459753644
Loss at iteration [1835]: 0.006859180536203734
Loss at iteration [1836]: 0.0068559133242512005
Loss at iteration [1837]: 0.00685265556517622
Loss at iteration [1838]: 0.006849407265695742
Loss at iteration [1839]: 0.0068461685741933774
Loss at iteration [1840]: 0.006842938960105143
Loss at iteration [1841]: 0.006839718643694577
Loss at iteration [1842]: 0.006836507572849329
Loss at iteration [1843]: 0.006833305698021884
Loss at iteration [1844]: 0.006830112795746167
Loss at iteration [1845]: 0.0068269291231697025
Loss at iteration [1846]: 0.006823754626886174
Loss at iteration [1847]: 0.006820588836310888
Loss at iteration [1848]: 0.00681743178807448
Loss at iteration [1849]: 0.006814284095407615
Loss at iteration [1850]: 0.0068111454528571305
Loss at iteration [1851]: 0.006808015966238973
Loss at iteration [1852]: 0.006804895764802519
Loss at iteration [1853]: 0.006801784806472068
Loss at iteration [1854]: 0.006798682995817947
Loss at iteration [1855]: 0.006795590289219899
Loss at iteration [1856]: 0.006792506667154061
Loss at iteration [1857]: 0.006789431886731419
Loss at iteration [1858]: 0.006786367728681766
Loss at iteration [1859]: 0.00678331216254697
Loss at iteration [1860]: 0.0067802652424248265
Loss at iteration [1861]: 0.006777226920943463
Loss at iteration [1862]: 0.0067741968236740375
Loss at iteration [1863]: 0.0067711754297227625
Loss at iteration [1864]: 0.006768162550620286
Loss at iteration [1865]: 0.006765158504401317
Loss at iteration [1866]: 0.006762163147646638
Loss at iteration [1867]: 0.00675917699543523
Loss at iteration [1868]: 0.006756200785018432
Loss at iteration [1869]: 0.006753235496699278
Loss at iteration [1870]: 0.0067502789148674155
Loss at iteration [1871]: 0.006747330549890204
Loss at iteration [1872]: 0.006744390243523313
Loss at iteration [1873]: 0.006741457772672631
Loss at iteration [1874]: 0.006738532937708249
Loss at iteration [1875]: 0.006735615779413196
Loss at iteration [1876]: 0.006732706232778175
Loss at iteration [1877]: 0.006729804135843424
Loss at iteration [1878]: 0.00672690963911993
Loss at iteration [1879]: 0.00672402279859668
Loss at iteration [1880]: 0.006721143121231753
Loss at iteration [1881]: 0.0067182710457801805
Loss at iteration [1882]: 0.006715406622009139
Loss at iteration [1883]: 0.006712549555139784
Loss at iteration [1884]: 0.006709700292735166
Loss at iteration [1885]: 0.006706858880886264
Loss at iteration [1886]: 0.006704024898218974
Loss at iteration [1887]: 0.006701198079679144
Loss at iteration [1888]: 0.006698378263313694
Loss at iteration [1889]: 0.006695566053653686
Loss at iteration [1890]: 0.006692761112753103
Loss at iteration [1891]: 0.00668996302652761
Loss at iteration [1892]: 0.0066871717806412205
Loss at iteration [1893]: 0.006684387755989519
Loss at iteration [1894]: 0.00668161137564697
Loss at iteration [1895]: 0.006678841992848794
Loss at iteration [1896]: 0.006676079465615872
Loss at iteration [1897]: 0.0066733235440894255
Loss at iteration [1898]: 0.006670574330638053
Loss at iteration [1899]: 0.0066678318152331405
Loss at iteration [1900]: 0.006665095727692238
Loss at iteration [1901]: 0.006662366853664074
Loss at iteration [1902]: 0.006659645459038597
Loss at iteration [1903]: 0.006656930798188452
Loss at iteration [1904]: 0.0066542229181748265
Loss at iteration [1905]: 0.006651521650428627
Loss at iteration [1906]: 0.0066488267797638586
Loss at iteration [1907]: 0.0066461378802401315
Loss at iteration [1908]: 0.006643455341526623
Loss at iteration [1909]: 0.006640779119145978
Loss at iteration [1910]: 0.006638109483838357
Loss at iteration [1911]: 0.006635446056005355
Loss at iteration [1912]: 0.006632788854026259
Loss at iteration [1913]: 0.00663013804103683
Loss at iteration [1914]: 0.006627493539438613
Loss at iteration [1915]: 0.006624855167915051
Loss at iteration [1916]: 0.006622222899211927
Loss at iteration [1917]: 0.006619597144652421
Loss at iteration [1918]: 0.0066169783383399905
Loss at iteration [1919]: 0.00661436569893711
Loss at iteration [1920]: 0.0066117594058746915
Loss at iteration [1921]: 0.00660915930333854
Loss at iteration [1922]: 0.006606565362965636
Loss at iteration [1923]: 0.0066039768957663735
Loss at iteration [1924]: 0.006601394537288117
Loss at iteration [1925]: 0.006598817996108053
Loss at iteration [1926]: 0.006596247404402559
Loss at iteration [1927]: 0.006593682705073569
Loss at iteration [1928]: 0.006591123753424864
Loss at iteration [1929]: 0.006588570530989261
Loss at iteration [1930]: 0.006586023925075085
Loss at iteration [1931]: 0.0065834828855713245
Loss at iteration [1932]: 0.0065809474703142365
Loss at iteration [1933]: 0.0065784176392697565
Loss at iteration [1934]: 0.006575893281278803
Loss at iteration [1935]: 0.006573374356564409
Loss at iteration [1936]: 0.006570860810621745
Loss at iteration [1937]: 0.006568352542898025
Loss at iteration [1938]: 0.006565849720358033
Loss at iteration [1939]: 0.006563352265460003
Loss at iteration [1940]: 0.006560860129090166
Loss at iteration [1941]: 0.006558373752162316
Loss at iteration [1942]: 0.006555892775549516
Loss at iteration [1943]: 0.006553417260629579
Loss at iteration [1944]: 0.0065509471598560525
Loss at iteration [1945]: 0.0065484822720323415
Loss at iteration [1946]: 0.006546022807043162
Loss at iteration [1947]: 0.006543568913382566
Loss at iteration [1948]: 0.006541120822728785
Loss at iteration [1949]: 0.006538678530798512
Loss at iteration [1950]: 0.00653624139031332
Loss at iteration [1951]: 0.006533809333565893
Loss at iteration [1952]: 0.006531382692583915
Loss at iteration [1953]: 0.006528961514320544
Loss at iteration [1954]: 0.0065265462369204115
Loss at iteration [1955]: 0.006524136371542663
Loss at iteration [1956]: 0.006521732981262553
Loss at iteration [1957]: 0.0065193364827327615
Loss at iteration [1958]: 0.006516945792434146
Loss at iteration [1959]: 0.0065145606276028134
Loss at iteration [1960]: 0.006512180642155478
Loss at iteration [1961]: 0.006509805872627179
Loss at iteration [1962]: 0.006507436337909113
Loss at iteration [1963]: 0.006505071858043557
Loss at iteration [1964]: 0.0065027122804418875
Loss at iteration [1965]: 0.006500357385522618
Loss at iteration [1966]: 0.006498007045933445
Loss at iteration [1967]: 0.006495661532226497
Loss at iteration [1968]: 0.006493320528941633
Loss at iteration [1969]: 0.006490983667016517
Loss at iteration [1970]: 0.006488651413828235
Loss at iteration [1971]: 0.006486324291344122
Loss at iteration [1972]: 0.006484002084236414
Loss at iteration [1973]: 0.006481684661685429
Loss at iteration [1974]: 0.006479371772790176
Loss at iteration [1975]: 0.006477063399260999
Loss at iteration [1976]: 0.0064747603686376425
Loss at iteration [1977]: 0.006472461967274812
Loss at iteration [1978]: 0.006470168110283757
Loss at iteration [1979]: 0.006467878683818578
Loss at iteration [1980]: 0.006465594249342436
Loss at iteration [1981]: 0.006463314949189683
Loss at iteration [1982]: 0.00646104031992477
Loss at iteration [1983]: 0.00645877011730602
Loss at iteration [1984]: 0.006456505459273687
Loss at iteration [1985]: 0.006454245777072664
Loss at iteration [1986]: 0.006451991060083346
Loss at iteration [1987]: 0.0064497407257662846
Loss at iteration [1988]: 0.006447494659509321
Loss at iteration [1989]: 0.006445252999885391
Loss at iteration [1990]: 0.00644301543122429
Loss at iteration [1991]: 0.006440781903047811
Loss at iteration [1992]: 0.006438553279724748
Loss at iteration [1993]: 0.006436329030753929
Loss at iteration [1994]: 0.0064341093230352335
Loss at iteration [1995]: 0.00643189395280643
Loss at iteration [1996]: 0.006429682963385491
Loss at iteration [1997]: 0.006427476039423437
Loss at iteration [1998]: 0.006425273198199622
Loss at iteration [1999]: 0.006423074466651994
Loss at iteration [2000]: 0.006420879869757971
Loss at iteration [2001]: 0.0064186894765812744
Loss at iteration [2002]: 0.006416503636701767
Loss at iteration [2003]: 0.006414321824523102
Loss at iteration [2004]: 0.006412143922169436
Loss at iteration [2005]: 0.006409969793020887
Loss at iteration [2006]: 0.006407799288412342
Loss at iteration [2007]: 0.006405632783730187
Loss at iteration [2008]: 0.006403470475682148
Loss at iteration [2009]: 0.006401312051464606
Loss at iteration [2010]: 0.006399157586458321
Loss at iteration [2011]: 0.006397007027304182
Loss at iteration [2012]: 0.006394860525295122
Loss at iteration [2013]: 0.006392718397608652
Loss at iteration [2014]: 0.006390580119101116
Loss at iteration [2015]: 0.00638844558740909
Loss at iteration [2016]: 0.006386314601484908
Loss at iteration [2017]: 0.006384186682607386
Loss at iteration [2018]: 0.006382062218364585
Loss at iteration [2019]: 0.006379941226880402
Loss at iteration [2020]: 0.006377823913414626
Loss at iteration [2021]: 0.006375710181679892
Loss at iteration [2022]: 0.006373600179821489
Loss at iteration [2023]: 0.006371493884486153
Loss at iteration [2024]: 0.00636939108287648
Loss at iteration [2025]: 0.00636729171453288
Loss at iteration [2026]: 0.006365196003530931
Loss at iteration [2027]: 0.006363103850404105
Loss at iteration [2028]: 0.00636101516590541
Loss at iteration [2029]: 0.006358930478239197
Loss at iteration [2030]: 0.006356849428368599
Loss at iteration [2031]: 0.006354771768066587
Loss at iteration [2032]: 0.006352697474953004
Loss at iteration [2033]: 0.0063506265828201045
Loss at iteration [2034]: 0.006348559181926876
Loss at iteration [2035]: 0.00634649508564353
Loss at iteration [2036]: 0.006344434370817404
Loss at iteration [2037]: 0.006342377154688232
Loss at iteration [2038]: 0.006340323334423649
Loss at iteration [2039]: 0.00633827284984037
Loss at iteration [2040]: 0.006336225647140791
Loss at iteration [2041]: 0.006334181987440584
Loss at iteration [2042]: 0.0063321422294450045
Loss at iteration [2043]: 0.006330106141683465
Loss at iteration [2044]: 0.006328073646773877
Loss at iteration [2045]: 0.0063260447593677365
Loss at iteration [2046]: 0.006324019280000708
Loss at iteration [2047]: 0.006321997174385542
Loss at iteration [2048]: 0.00631997863252774
Loss at iteration [2049]: 0.006317963959751844
Loss at iteration [2050]: 0.006315952783751544
Loss at iteration [2051]: 0.0063139450196282925
Loss at iteration [2052]: 0.006311940515682922
Loss at iteration [2053]: 0.006309939601400977
Loss at iteration [2054]: 0.006307941952014156
Loss at iteration [2055]: 0.006305947496710023
Loss at iteration [2056]: 0.006303956365480284
Loss at iteration [2057]: 0.006301969580093992
Loss at iteration [2058]: 0.006299986364390259
Loss at iteration [2059]: 0.006298006678642162
Loss at iteration [2060]: 0.006296030749419082
Loss at iteration [2061]: 0.006294057958993882
Loss at iteration [2062]: 0.006292088803237746
Loss at iteration [2063]: 0.006290123708911069
Loss at iteration [2064]: 0.006288161677522049
Loss at iteration [2065]: 0.006286203246286725
Loss at iteration [2066]: 0.006284248091095409
Loss at iteration [2067]: 0.006282296227142533
Loss at iteration [2068]: 0.006280347780516657
Loss at iteration [2069]: 0.006278403075566365
Loss at iteration [2070]: 0.006276461725751491
Loss at iteration [2071]: 0.006274523357881465
Loss at iteration [2072]: 0.006272588147895272
Loss at iteration [2073]: 0.006270655923104753
Loss at iteration [2074]: 0.00626872656040712
Loss at iteration [2075]: 0.006266799969262728
Loss at iteration [2076]: 0.0062648766210719195
Loss at iteration [2077]: 0.00626295596019003
Loss at iteration [2078]: 0.006261038236158596
Loss at iteration [2079]: 0.006259123477790655
Loss at iteration [2080]: 0.0062572115812215305
Loss at iteration [2081]: 0.006255302508347111
Loss at iteration [2082]: 0.00625339640920582
Loss at iteration [2083]: 0.0062514928463125955
Loss at iteration [2084]: 0.006249592046645511
Loss at iteration [2085]: 0.006247694138985186
Loss at iteration [2086]: 0.006245798972567255
Loss at iteration [2087]: 0.006243906495061871
Loss at iteration [2088]: 0.006242016822879401
Loss at iteration [2089]: 0.006240129618416185
Loss at iteration [2090]: 0.006238244739562262
Loss at iteration [2091]: 0.0062363623448453195
Loss at iteration [2092]: 0.006234482701968301
Loss at iteration [2093]: 0.006232606055454986
Loss at iteration [2094]: 0.006230732102783284
Loss at iteration [2095]: 0.006228861017499166
Loss at iteration [2096]: 0.006226992668945727
Loss at iteration [2097]: 0.0062251272176464725
Loss at iteration [2098]: 0.006223264225987496
Loss at iteration [2099]: 0.006221403348579441
Loss at iteration [2100]: 0.006219545125046473
Loss at iteration [2101]: 0.006217689780440427
Loss at iteration [2102]: 0.006215837996298533
Loss at iteration [2103]: 0.006213988743680184
Loss at iteration [2104]: 0.00621214195345719
Loss at iteration [2105]: 0.0062102980536547425
Loss at iteration [2106]: 0.006208456740283683
Loss at iteration [2107]: 0.006206618422937622
Loss at iteration [2108]: 0.0062047838277860924
Loss at iteration [2109]: 0.006202952809525596
Loss at iteration [2110]: 0.006201124867013316
Loss at iteration [2111]: 0.006199299831015289
Loss at iteration [2112]: 0.006197477820435363
Loss at iteration [2113]: 0.006195659073963823
Loss at iteration [2114]: 0.006193844214966178
Loss at iteration [2115]: 0.006192032393718592
Loss at iteration [2116]: 0.006190223719142181
Loss at iteration [2117]: 0.006188417693828661
Loss at iteration [2118]: 0.006186614321721428
Loss at iteration [2119]: 0.006184813449474332
Loss at iteration [2120]: 0.006183014789874504
Loss at iteration [2121]: 0.006181218426007111
Loss at iteration [2122]: 0.006179424635834489
Loss at iteration [2123]: 0.006177633437655232
Loss at iteration [2124]: 0.006175844561025017
Loss at iteration [2125]: 0.006174058908169449
Loss at iteration [2126]: 0.00617227607081591
Loss at iteration [2127]: 0.0061704956152828375
Loss at iteration [2128]: 0.006168717312347157
Loss at iteration [2129]: 0.006166941409243194
Loss at iteration [2130]: 0.006165167935023681
Loss at iteration [2131]: 0.006163396833763759
Loss at iteration [2132]: 0.00616162819588784
Loss at iteration [2133]: 0.006159861847390678
Loss at iteration [2134]: 0.006158098037211572
Loss at iteration [2135]: 0.006156336523510563
Loss at iteration [2136]: 0.006154577281829144
Loss at iteration [2137]: 0.006152820445075962
Loss at iteration [2138]: 0.006151065801295679
Loss at iteration [2139]: 0.006149313304204275
Loss at iteration [2140]: 0.006147562948678342
Loss at iteration [2141]: 0.006145814598241153
Loss at iteration [2142]: 0.006144068221373203
Loss at iteration [2143]: 0.0061423239175900255
Loss at iteration [2144]: 0.00614058180913382
Loss at iteration [2145]: 0.006138841986227251
Loss at iteration [2146]: 0.006137104137193245
Loss at iteration [2147]: 0.006135368340456113
Loss at iteration [2148]: 0.006133635065916732
Loss at iteration [2149]: 0.006131903741289151
Loss at iteration [2150]: 0.006130175048131773
Loss at iteration [2151]: 0.006128448445467613
Loss at iteration [2152]: 0.006126724058002791
Loss at iteration [2153]: 0.006125002252787307
Loss at iteration [2154]: 0.006123282549928611
Loss at iteration [2155]: 0.006121564700384353
Loss at iteration [2156]: 0.006119848576291582
Loss at iteration [2157]: 0.006118134537711437
Loss at iteration [2158]: 0.006116422546519033
Loss at iteration [2159]: 0.0061147127988964165
Loss at iteration [2160]: 0.006113005521391629
Loss at iteration [2161]: 0.006111300294991292
Loss at iteration [2162]: 0.00610959713530887
Loss at iteration [2163]: 0.006107896012961234
Loss at iteration [2164]: 0.006106196770227124
Loss at iteration [2165]: 0.006104499470702707
Loss at iteration [2166]: 0.006102803943963299
Loss at iteration [2167]: 0.006101110113292648
Loss at iteration [2168]: 0.0060994180277475
Loss at iteration [2169]: 0.006097728062232764
Loss at iteration [2170]: 0.0060960399366672595
Loss at iteration [2171]: 0.006094354080600614
Loss at iteration [2172]: 0.006092670293753945
Loss at iteration [2173]: 0.006090988355658
Loss at iteration [2174]: 0.0060893081171634255
Loss at iteration [2175]: 0.006087629672331205
Loss at iteration [2176]: 0.0060859531022303
Loss at iteration [2177]: 0.006084279393086647
Loss at iteration [2178]: 0.0060826079951941765
Loss at iteration [2179]: 0.0060809386531340825
Loss at iteration [2180]: 0.006079271418322405
Loss at iteration [2181]: 0.006077606022395832
Loss at iteration [2182]: 0.006075942419823731
Loss at iteration [2183]: 0.0060742803649850505
Loss at iteration [2184]: 0.00607261976099723
Loss at iteration [2185]: 0.0060709607453716926
Loss at iteration [2186]: 0.00606930331180823
Loss at iteration [2187]: 0.006067647487631083
Loss at iteration [2188]: 0.006065993603497415
Loss at iteration [2189]: 0.006064341291047804
Loss at iteration [2190]: 0.006062690748541313
Loss at iteration [2191]: 0.0060610419004229355
Loss at iteration [2192]: 0.006059395026397397
Loss at iteration [2193]: 0.006057749551143946
Loss at iteration [2194]: 0.006056105712834094
Loss at iteration [2195]: 0.006054463666402502
Loss at iteration [2196]: 0.006052823426203318
Loss at iteration [2197]: 0.006051185034940393
Loss at iteration [2198]: 0.006049548945214953
Loss at iteration [2199]: 0.0060479147317442404
Loss at iteration [2200]: 0.006046282319707082
Loss at iteration [2201]: 0.006044651522063742
Loss at iteration [2202]: 0.0060430225303566565
Loss at iteration [2203]: 0.0060413951746059605
Loss at iteration [2204]: 0.006039769218600836
Loss at iteration [2205]: 0.006038144637054975
Loss at iteration [2206]: 0.006036521629471585
Loss at iteration [2207]: 0.006034900098462339
Loss at iteration [2208]: 0.006033280260265971
Loss at iteration [2209]: 0.006031661930563044
Loss at iteration [2210]: 0.006030045323842293
Loss at iteration [2211]: 0.006028430317411507
Loss at iteration [2212]: 0.0060268168468757535
Loss at iteration [2213]: 0.006025204912248694
Loss at iteration [2214]: 0.006023594582478488
Loss at iteration [2215]: 0.006021986030020964
Loss at iteration [2216]: 0.0060203791793818585
Loss at iteration [2217]: 0.006018774070804999
Loss at iteration [2218]: 0.006017170557330672
Loss at iteration [2219]: 0.006015568584838225
Loss at iteration [2220]: 0.006013968303465411
Loss at iteration [2221]: 0.006012369842341739
Loss at iteration [2222]: 0.006010772944524191
Loss at iteration [2223]: 0.0060091777791205165
Loss at iteration [2224]: 0.006007584202980111
Loss at iteration [2225]: 0.006005993011585171
Loss at iteration [2226]: 0.006004403549839019
Loss at iteration [2227]: 0.006002815705473191
Loss at iteration [2228]: 0.006001229552031619
Loss at iteration [2229]: 0.0059996449584504
Loss at iteration [2230]: 0.005998061821114615
Loss at iteration [2231]: 0.005996480233851605
Loss at iteration [2232]: 0.005994899945254064
Loss at iteration [2233]: 0.005993321095710222
Loss at iteration [2234]: 0.005991744104996936
Loss at iteration [2235]: 0.005990169978156944
Loss at iteration [2236]: 0.005988597956144083
Loss at iteration [2237]: 0.005987028238122652
Loss at iteration [2238]: 0.005985460893646904
Loss at iteration [2239]: 0.005983895386760672
Loss at iteration [2240]: 0.00598233162726106
Loss at iteration [2241]: 0.00598076957571545
Loss at iteration [2242]: 0.005979209178034083
Loss at iteration [2243]: 0.005977651783913629
Loss at iteration [2244]: 0.0059760975200227485
Loss at iteration [2245]: 0.005974546158812312
Loss at iteration [2246]: 0.005972997261405079
Loss at iteration [2247]: 0.005971450573774071
Loss at iteration [2248]: 0.005969905650393364
Loss at iteration [2249]: 0.0059683622197999366
Loss at iteration [2250]: 0.005966820212461394
Loss at iteration [2251]: 0.005965279611378401
Loss at iteration [2252]: 0.005963740433697144
Loss at iteration [2253]: 0.005962202765610661
Loss at iteration [2254]: 0.005960666573824099
Loss at iteration [2255]: 0.005959131772315964
Loss at iteration [2256]: 0.00595759869196948
Loss at iteration [2257]: 0.005956067936350489
Loss at iteration [2258]: 0.005954539441470802
Loss at iteration [2259]: 0.005953012509690828
Loss at iteration [2260]: 0.005951487012966079
Loss at iteration [2261]: 0.005949963030994949
Loss at iteration [2262]: 0.005948441777460513
Loss at iteration [2263]: 0.005946922838261762
Loss at iteration [2264]: 0.005945405551485283
Loss at iteration [2265]: 0.005943889934300578
Loss at iteration [2266]: 0.005942376322980066
Loss at iteration [2267]: 0.00594086423129616
Loss at iteration [2268]: 0.005939353493659675
Loss at iteration [2269]: 0.005937844056674099
Loss at iteration [2270]: 0.005936337014006633
Loss at iteration [2271]: 0.005934831554924385
Loss at iteration [2272]: 0.005933327637065347
Loss at iteration [2273]: 0.005931825064257127
Loss at iteration [2274]: 0.005930323777379047
Loss at iteration [2275]: 0.005928823837827509
Loss at iteration [2276]: 0.005927325129196815
Loss at iteration [2277]: 0.005925827959347914
Loss at iteration [2278]: 0.005924332262324651
Loss at iteration [2279]: 0.005922838218009626
Loss at iteration [2280]: 0.0059213465455243116
Loss at iteration [2281]: 0.005919856518264636
Loss at iteration [2282]: 0.005918368174133422
Loss at iteration [2283]: 0.005916881399854629
Loss at iteration [2284]: 0.005915396675211644
Loss at iteration [2285]: 0.005913913390906377
Loss at iteration [2286]: 0.005912431414583116
Loss at iteration [2287]: 0.005910950795796414
Loss at iteration [2288]: 0.00590947185094164
Loss at iteration [2289]: 0.005907994678577074
Loss at iteration [2290]: 0.005906518928921363
Loss at iteration [2291]: 0.005905044430160718
Loss at iteration [2292]: 0.00590357110882483
Loss at iteration [2293]: 0.005902099028429278
Loss at iteration [2294]: 0.0059006281596676235
Loss at iteration [2295]: 0.0058991584569297525
Loss at iteration [2296]: 0.005897689870289915
Loss at iteration [2297]: 0.005896222384152748
Loss at iteration [2298]: 0.005894756151115692
Loss at iteration [2299]: 0.005893291629548461
Loss at iteration [2300]: 0.005891829202094694
Loss at iteration [2301]: 0.005890368174278787
Loss at iteration [2302]: 0.005888908580194601
Loss at iteration [2303]: 0.005887450758370582
Loss at iteration [2304]: 0.005885994940097327
Loss at iteration [2305]: 0.005884540760296538
Loss at iteration [2306]: 0.005883088309456565
Loss at iteration [2307]: 0.005881637232170642
Loss at iteration [2308]: 0.005880187528844121
Loss at iteration [2309]: 0.005878738997956436
Loss at iteration [2310]: 0.005877291601308934
Loss at iteration [2311]: 0.005875845393090021
Loss at iteration [2312]: 0.0058744008703532635
Loss at iteration [2313]: 0.005872958499751873
Loss at iteration [2314]: 0.00587151753200439
Loss at iteration [2315]: 0.005870077860653259
Loss at iteration [2316]: 0.005868639495423583
Loss at iteration [2317]: 0.005867202173183984
Loss at iteration [2318]: 0.005865765682951137
Loss at iteration [2319]: 0.005864330154092789
Loss at iteration [2320]: 0.005862896197697761
Loss at iteration [2321]: 0.005861463450720368
Loss at iteration [2322]: 0.005860032075711137
Loss at iteration [2323]: 0.005858601997160956
Loss at iteration [2324]: 0.005857173490110117
Loss at iteration [2325]: 0.005855746535234023
Loss at iteration [2326]: 0.005854320735633566
Loss at iteration [2327]: 0.005852896368121812
Loss at iteration [2328]: 0.0058514734454829555
Loss at iteration [2329]: 0.005850051526488348
Loss at iteration [2330]: 0.005848630632689048
Loss at iteration [2331]: 0.005847210846442682
Loss at iteration [2332]: 0.005845792173591053
Loss at iteration [2333]: 0.005844374733553018
Loss at iteration [2334]: 0.005842958950358878
Loss at iteration [2335]: 0.005841544367028802
Loss at iteration [2336]: 0.0058401307654305104
Loss at iteration [2337]: 0.005838718050235945
Loss at iteration [2338]: 0.005837307440909081
Loss at iteration [2339]: 0.005835898530363141
Loss at iteration [2340]: 0.005834491300247867
Loss at iteration [2341]: 0.005833085289114644
Loss at iteration [2342]: 0.005831680358178413
Loss at iteration [2343]: 0.005830277286979541
Loss at iteration [2344]: 0.0058288754675543475
Loss at iteration [2345]: 0.00582747488150731
Loss at iteration [2346]: 0.005826075310776063
Loss at iteration [2347]: 0.005824676794563159
Loss at iteration [2348]: 0.005823279351969669
Loss at iteration [2349]: 0.005821883069897351
Loss at iteration [2350]: 0.005820488434771039
Loss at iteration [2351]: 0.005819095021660766
Loss at iteration [2352]: 0.005817702429517626
Loss at iteration [2353]: 0.005816311054509434
Loss at iteration [2354]: 0.00581492094587823
Loss at iteration [2355]: 0.0058135318892489395
Loss at iteration [2356]: 0.005812143780174856
Loss at iteration [2357]: 0.005810756577569642
Loss at iteration [2358]: 0.0058093703092231734
Loss at iteration [2359]: 0.00580798550048554
Loss at iteration [2360]: 0.00580660217497987
Loss at iteration [2361]: 0.005805220051122151
Loss at iteration [2362]: 0.005803839191399594
Loss at iteration [2363]: 0.00580245990909906
Loss at iteration [2364]: 0.005801082122930601
Loss at iteration [2365]: 0.0057997056471871195
Loss at iteration [2366]: 0.005798330500953412
Loss at iteration [2367]: 0.005796957036283913
Loss at iteration [2368]: 0.00579558553265822
Loss at iteration [2369]: 0.005794216012598028
Loss at iteration [2370]: 0.005792848284613716
Loss at iteration [2371]: 0.005791482396670008
Loss at iteration [2372]: 0.005790117687412969
Loss at iteration [2373]: 0.005788754446166426
Loss at iteration [2374]: 0.005787392475080956
Loss at iteration [2375]: 0.005786032180078922
Loss at iteration [2376]: 0.00578467362381919
Loss at iteration [2377]: 0.0057833162298341016
Loss at iteration [2378]: 0.005781959947784026
Loss at iteration [2379]: 0.005780604826143712
Loss at iteration [2380]: 0.005779250698161294
Loss at iteration [2381]: 0.005777897671242505
Loss at iteration [2382]: 0.005776545581001952
Loss at iteration [2383]: 0.0057751943453103645
Loss at iteration [2384]: 0.005773844020223999
Loss at iteration [2385]: 0.0057724945784778945
Loss at iteration [2386]: 0.005771146019651164
Loss at iteration [2387]: 0.0057697985921466985
Loss at iteration [2388]: 0.005768452574378501
Loss at iteration [2389]: 0.005767107628107346
Loss at iteration [2390]: 0.005765763665592526
Loss at iteration [2391]: 0.00576442076519375
Loss at iteration [2392]: 0.00576307887227556
Loss at iteration [2393]: 0.005761738150566679
Loss at iteration [2394]: 0.005760398373440271
Loss at iteration [2395]: 0.0057590597181668545
Loss at iteration [2396]: 0.005757722231677902
Loss at iteration [2397]: 0.005756385797125766
Loss at iteration [2398]: 0.0057550523924445535
Loss at iteration [2399]: 0.0057537204714751405
Loss at iteration [2400]: 0.0057523895215145894
Loss at iteration [2401]: 0.005751059598397288
Loss at iteration [2402]: 0.005749730984630571
Loss at iteration [2403]: 0.00574840382585097
Loss at iteration [2404]: 0.005747077711903599
Loss at iteration [2405]: 0.005745752728615857
Loss at iteration [2406]: 0.005744428670810561
Loss at iteration [2407]: 0.005743105596277946
Loss at iteration [2408]: 0.005741783483394293
Loss at iteration [2409]: 0.005740463426282484
Loss at iteration [2410]: 0.005739144952840892
Loss at iteration [2411]: 0.005737827639515596
Loss at iteration [2412]: 0.005736511283768886
Loss at iteration [2413]: 0.005735196430173602
Loss at iteration [2414]: 0.005733882516656527
Loss at iteration [2415]: 0.0057325697768850215
Loss at iteration [2416]: 0.0057312580942417805
Loss at iteration [2417]: 0.005729947283392274
Loss at iteration [2418]: 0.005728637292791797
Loss at iteration [2419]: 0.005727328105465446
Loss at iteration [2420]: 0.005726019804037535
Loss at iteration [2421]: 0.005724712540454462
Loss at iteration [2422]: 0.005723406376510866
Loss at iteration [2423]: 0.005722101669356763
Loss at iteration [2424]: 0.0057207980900691995
Loss at iteration [2425]: 0.005719496107024324
Loss at iteration [2426]: 0.0057181950849538475
Loss at iteration [2427]: 0.0057168951158977615
Loss at iteration [2428]: 0.005715596622398323
Loss at iteration [2429]: 0.005714298976497907
Loss at iteration [2430]: 0.0057130021729414615
Loss at iteration [2431]: 0.0057117063688932775
Loss at iteration [2432]: 0.005710411515094611
Loss at iteration [2433]: 0.005709117545842842
Loss at iteration [2434]: 0.0057078244259184995
Loss at iteration [2435]: 0.005706532187778353
Loss at iteration [2436]: 0.005705240787668919
Loss at iteration [2437]: 0.005703950498755435
Loss at iteration [2438]: 0.005702661748797709
Loss at iteration [2439]: 0.005701373992094375
Loss at iteration [2440]: 0.005700087013242461
Loss at iteration [2441]: 0.005698801681096135
Loss at iteration [2442]: 0.005697518387708111
Loss at iteration [2443]: 0.005696236335284521
Loss at iteration [2444]: 0.005694956540309404
Loss at iteration [2445]: 0.005693678042085745
Loss at iteration [2446]: 0.005692400715631179
Loss at iteration [2447]: 0.005691124248994175
Loss at iteration [2448]: 0.0056898485847905154
Loss at iteration [2449]: 0.005688573781848052
Loss at iteration [2450]: 0.005687299843669844
Loss at iteration [2451]: 0.005686026673004826
Loss at iteration [2452]: 0.005684754341331378
Loss at iteration [2453]: 0.005683482820246942
Loss at iteration [2454]: 0.005682212072363467
Loss at iteration [2455]: 0.00568094206657902
Loss at iteration [2456]: 0.0056796727883682
Loss at iteration [2457]: 0.00567840422018014
Loss at iteration [2458]: 0.005677136420197134
Loss at iteration [2459]: 0.005675869339529961
Loss at iteration [2460]: 0.005674602898420361
Loss at iteration [2461]: 0.005673337031873743
Loss at iteration [2462]: 0.005672071914833038
Loss at iteration [2463]: 0.005670807919993207
Loss at iteration [2464]: 0.005669545003740212
Loss at iteration [2465]: 0.0056682829924595375
Loss at iteration [2466]: 0.005667022153096992
Loss at iteration [2467]: 0.005665762799221271
Loss at iteration [2468]: 0.0056645051989211385
Loss at iteration [2469]: 0.0056632495033110495
Loss at iteration [2470]: 0.005661995334546175
Loss at iteration [2471]: 0.00566074230332077
Loss at iteration [2472]: 0.0056594900725052836
Loss at iteration [2473]: 0.005658238801855929
Loss at iteration [2474]: 0.005656989553078397
Loss at iteration [2475]: 0.005655741455802776
Loss at iteration [2476]: 0.005654494499050934
Loss at iteration [2477]: 0.005653248506874027
Loss at iteration [2478]: 0.005652003359015236
Loss at iteration [2479]: 0.005650758935591082
Loss at iteration [2480]: 0.005649515330475354
Loss at iteration [2481]: 0.005648273124858145
Loss at iteration [2482]: 0.005647031748706437
Loss at iteration [2483]: 0.0056457913646297524
Loss at iteration [2484]: 0.00564455213618454
Loss at iteration [2485]: 0.005643313877522606
Loss at iteration [2486]: 0.0056420763838539245
Loss at iteration [2487]: 0.005640839592505478
Loss at iteration [2488]: 0.005639603431255237
Loss at iteration [2489]: 0.005638367644695039
Loss at iteration [2490]: 0.005637132812797123
Loss at iteration [2491]: 0.005635899328431786
Loss at iteration [2492]: 0.005634666560383898
Loss at iteration [2493]: 0.00563343448983748
Loss at iteration [2494]: 0.005632203184158916
Loss at iteration [2495]: 0.005630973060329203
Loss at iteration [2496]: 0.00562974568181042
Loss at iteration [2497]: 0.005628519355188897
Loss at iteration [2498]: 0.0056272938940136324
Loss at iteration [2499]: 0.005626069200643359
Loss at iteration [2500]: 0.005624845165798016
Loss at iteration [2501]: 0.005623621839467492
Loss at iteration [2502]: 0.005622399271574869
Loss at iteration [2503]: 0.005621177413787357
Loss at iteration [2504]: 0.005619956811179669
Loss at iteration [2505]: 0.005618737487489792
Loss at iteration [2506]: 0.005617519400088919
Loss at iteration [2507]: 0.005616302601589521
Loss at iteration [2508]: 0.005615087127417475
Loss at iteration [2509]: 0.005613872431836275
Loss at iteration [2510]: 0.00561265842872083
Loss at iteration [2511]: 0.005611445143940258
Loss at iteration [2512]: 0.0056102324454576444
Loss at iteration [2513]: 0.00560902021241789
Loss at iteration [2514]: 0.005607808677325895
Loss at iteration [2515]: 0.005606598430285574
Loss at iteration [2516]: 0.005605389487765614
Loss at iteration [2517]: 0.005604181521525195
Loss at iteration [2518]: 0.005602974600412862
Loss at iteration [2519]: 0.00560176863006143
Loss at iteration [2520]: 0.005600563837568382
Loss at iteration [2521]: 0.005599360585197071
Loss at iteration [2522]: 0.005598158239373971
Loss at iteration [2523]: 0.0055969566902242555
Loss at iteration [2524]: 0.0055957554488849474
Loss at iteration [2525]: 0.005594554807519954
Loss at iteration [2526]: 0.005593354763701448
Loss at iteration [2527]: 0.005592155553587305
Loss at iteration [2528]: 0.005590957055359275
Loss at iteration [2529]: 0.005589759152539303
Loss at iteration [2530]: 0.005588561982154398
Loss at iteration [2531]: 0.005587365864556612
Loss at iteration [2532]: 0.005586170814302939
Loss at iteration [2533]: 0.005584976826738312
Loss at iteration [2534]: 0.005583783771405335
Loss at iteration [2535]: 0.0055825914024353746
Loss at iteration [2536]: 0.005581399581212783
Loss at iteration [2537]: 0.005580208556107262
Loss at iteration [2538]: 0.005579018264634436
Loss at iteration [2539]: 0.005577828607088298
Loss at iteration [2540]: 0.005576639677576536
Loss at iteration [2541]: 0.00557545155941464
Loss at iteration [2542]: 0.0055742644168396355
Loss at iteration [2543]: 0.005573078068759482
Loss at iteration [2544]: 0.005571892483470125
Loss at iteration [2545]: 0.005570707877118325
Loss at iteration [2546]: 0.0055695239184624015
Loss at iteration [2547]: 0.005568340756261713
Loss at iteration [2548]: 0.005567159071728751
Loss at iteration [2549]: 0.005565978278111772
Loss at iteration [2550]: 0.005564798211615312
Loss at iteration [2551]: 0.005563619306582637
Loss at iteration [2552]: 0.005562441939343975
Loss at iteration [2553]: 0.005561265306011633
Loss at iteration [2554]: 0.005560089265608473
Loss at iteration [2555]: 0.005558913946210913
Loss at iteration [2556]: 0.005557739560544339
Loss at iteration [2557]: 0.0055565666578409655
Loss at iteration [2558]: 0.0055553952968525906
Loss at iteration [2559]: 0.0055542246236625304
Loss at iteration [2560]: 0.005553054698767019
Loss at iteration [2561]: 0.005551885680026525
Loss at iteration [2562]: 0.005550717940262195
Loss at iteration [2563]: 0.005549551348074052
Loss at iteration [2564]: 0.005548385652471379
Loss at iteration [2565]: 0.005547220873203055
Loss at iteration [2566]: 0.005546056839815495
Loss at iteration [2567]: 0.005544893564945555
Loss at iteration [2568]: 0.0055437309426366686
Loss at iteration [2569]: 0.0055425689190173166
Loss at iteration [2570]: 0.005541407480919477
Loss at iteration [2571]: 0.005540246438429492
Loss at iteration [2572]: 0.0055390861276124895
Loss at iteration [2573]: 0.005537926578541764
Loss at iteration [2574]: 0.005536767627972908
Loss at iteration [2575]: 0.00553560924592508
Loss at iteration [2576]: 0.005534451419946397
Loss at iteration [2577]: 0.0055332939769899
Loss at iteration [2578]: 0.005532136903253704
Loss at iteration [2579]: 0.005530980354901383
Loss at iteration [2580]: 0.005529824368470141
Loss at iteration [2581]: 0.005528668947265256
Loss at iteration [2582]: 0.00552751423442172
Loss at iteration [2583]: 0.005526360715111031
Loss at iteration [2584]: 0.005525208177917181
Loss at iteration [2585]: 0.005524056279701502
Loss at iteration [2586]: 0.005522906242411332
Loss at iteration [2587]: 0.00552175759916742
Loss at iteration [2588]: 0.00552061005109172
Loss at iteration [2589]: 0.0055194637023286645
Loss at iteration [2590]: 0.005518318646720381
Loss at iteration [2591]: 0.005517174802646985
Loss at iteration [2592]: 0.005516031694977345
Loss at iteration [2593]: 0.005514889260438556
Loss at iteration [2594]: 0.005513747456312503
Loss at iteration [2595]: 0.005512606182259889
Loss at iteration [2596]: 0.005511465573938597
Loss at iteration [2597]: 0.005510325585586805
Loss at iteration [2598]: 0.00550918615251537
Loss at iteration [2599]: 0.00550804732347558
Loss at iteration [2600]: 0.005506909307904469
Loss at iteration [2601]: 0.005505772970159276
Loss at iteration [2602]: 0.005504638273779442
Loss at iteration [2603]: 0.005503504540430265
Loss at iteration [2604]: 0.005502371781213661
Loss at iteration [2605]: 0.005501239651977466
Loss at iteration [2606]: 0.005500108154228386
Loss at iteration [2607]: 0.00549897738512086
Loss at iteration [2608]: 0.005497847467683941
Loss at iteration [2609]: 0.005496718126365698
Loss at iteration [2610]: 0.005495589404753379
Loss at iteration [2611]: 0.005494462257403706
Loss at iteration [2612]: 0.0054933365993382515
Loss at iteration [2613]: 0.005492211727354144
Loss at iteration [2614]: 0.005491087498691856
Loss at iteration [2615]: 0.005489963906518262
Loss at iteration [2616]: 0.005488841711145073
Loss at iteration [2617]: 0.005487720691769552
Loss at iteration [2618]: 0.00548660088297169
Loss at iteration [2619]: 0.005485481758359906
Loss at iteration [2620]: 0.0054843632382316106
Loss at iteration [2621]: 0.005483245948364914
Loss at iteration [2622]: 0.005482129625699175
Loss at iteration [2623]: 0.005481013725604995
Loss at iteration [2624]: 0.005479898385742091
Loss at iteration [2625]: 0.005478784138541417
Loss at iteration [2626]: 0.005477670985781782
Loss at iteration [2627]: 0.005476558813875084
Loss at iteration [2628]: 0.005475447842960147
Loss at iteration [2629]: 0.005474337750733033
Loss at iteration [2630]: 0.005473228479753195
Loss at iteration [2631]: 0.005472120991309169
Loss at iteration [2632]: 0.005471014453101001
Loss at iteration [2633]: 0.005469908838203397
Loss at iteration [2634]: 0.005468804079019667
Loss at iteration [2635]: 0.005467700129967845
Loss at iteration [2636]: 0.005466596969712282
Loss at iteration [2637]: 0.005465495232612208
Loss at iteration [2638]: 0.005464394407380601
Loss at iteration [2639]: 0.00546329420760911
Loss at iteration [2640]: 0.005462194673101089
Loss at iteration [2641]: 0.005461096548743194
Loss at iteration [2642]: 0.00546000097074476
Loss at iteration [2643]: 0.005458906301184996
Loss at iteration [2644]: 0.005457812471455274
Loss at iteration [2645]: 0.005456719338970486
Loss at iteration [2646]: 0.005455626759484018
Loss at iteration [2647]: 0.0054545347998791295
Loss at iteration [2648]: 0.005453443366479409
Loss at iteration [2649]: 0.005452352340474677
Loss at iteration [2650]: 0.005451261850694161
Loss at iteration [2651]: 0.00545017277184883
Loss at iteration [2652]: 0.005449084687432413
Loss at iteration [2653]: 0.0054479976862712755
Loss at iteration [2654]: 0.00544691131520602
Loss at iteration [2655]: 0.005445825489348468
Loss at iteration [2656]: 0.005444740549497789
Loss at iteration [2657]: 0.0054436571997163955
Loss at iteration [2658]: 0.0054425745525206876
Loss at iteration [2659]: 0.005441492488496046
Loss at iteration [2660]: 0.005440410899960341
Loss at iteration [2661]: 0.0054393298004956825
Loss at iteration [2662]: 0.005438249198401461
Loss at iteration [2663]: 0.005437169072872509
Loss at iteration [2664]: 0.005436089207289708
Loss at iteration [2665]: 0.00543501001583366
Loss at iteration [2666]: 0.005433931547754454
Loss at iteration [2667]: 0.005432853985929387
Loss at iteration [2668]: 0.005431777820936687
Loss at iteration [2669]: 0.005430702394390507
Loss at iteration [2670]: 0.005429627744659756
Loss at iteration [2671]: 0.005428553837141596
Loss at iteration [2672]: 0.005427480656781818
Loss at iteration [2673]: 0.005426408262110181
Loss at iteration [2674]: 0.005425336589694504
Loss at iteration [2675]: 0.005424265597530094
Loss at iteration [2676]: 0.005423195266977352
Loss at iteration [2677]: 0.005422126040620476
Loss at iteration [2678]: 0.005421057357942276
Loss at iteration [2679]: 0.0054199891497797754
Loss at iteration [2680]: 0.005418921593986726
Loss at iteration [2681]: 0.0054178547150766304
Loss at iteration [2682]: 0.005416788430418377
Loss at iteration [2683]: 0.005415722683298429
Loss at iteration [2684]: 0.0054146571893187705
Loss at iteration [2685]: 0.00541359249097649
Loss at iteration [2686]: 0.005412528300580194
Loss at iteration [2687]: 0.005411464558086854
Loss at iteration [2688]: 0.0054104013128016245
Loss at iteration [2689]: 0.005409338483648627
Loss at iteration [2690]: 0.005408276108027797
Loss at iteration [2691]: 0.0054072141649200295
Loss at iteration [2692]: 0.005406152511250036
Loss at iteration [2693]: 0.005405091885780184
Loss at iteration [2694]: 0.005404032864227579
Loss at iteration [2695]: 0.005402974731943498
Loss at iteration [2696]: 0.00540191774237848
Loss at iteration [2697]: 0.005400861320434473
Loss at iteration [2698]: 0.005399805430783198
Loss at iteration [2699]: 0.005398750004931653
Loss at iteration [2700]: 0.005397694931905683
Loss at iteration [2701]: 0.0053966403413159125
Loss at iteration [2702]: 0.005395586427799475
Loss at iteration [2703]: 0.005394533041667982
Loss at iteration [2704]: 0.00539348007541675
Loss at iteration [2705]: 0.005392427668314066
Loss at iteration [2706]: 0.005391376390908234
Loss at iteration [2707]: 0.0053903264866630145
Loss at iteration [2708]: 0.005389277441237064
Loss at iteration [2709]: 0.005388229367935805
Loss at iteration [2710]: 0.005387182894436517
Loss at iteration [2711]: 0.005386137176409203
Loss at iteration [2712]: 0.005385092008222874
Loss at iteration [2713]: 0.0053840473700085415
Loss at iteration [2714]: 0.0053830034672520954
Loss at iteration [2715]: 0.005381960550423724
Loss at iteration [2716]: 0.00538091819212028
Loss at iteration [2717]: 0.005379876313639566
Loss at iteration [2718]: 0.0053788348412916465
Loss at iteration [2719]: 0.0053777941618192784
Loss at iteration [2720]: 0.005376754092946367
Loss at iteration [2721]: 0.005375714599619456
Loss at iteration [2722]: 0.005374675967769115
Loss at iteration [2723]: 0.0053736379885897575
Loss at iteration [2724]: 0.00537260103465093
Loss at iteration [2725]: 0.005371564824713927
Loss at iteration [2726]: 0.005370529247454214
Loss at iteration [2727]: 0.005369494781014808
Loss at iteration [2728]: 0.005368461450270329
Loss at iteration [2729]: 0.005367428880886885
Loss at iteration [2730]: 0.005366396928763359
Loss at iteration [2731]: 0.005365365445851261
Loss at iteration [2732]: 0.005364334541403353
Loss at iteration [2733]: 0.005363304490998166
Loss at iteration [2734]: 0.00536227489688615
Loss at iteration [2735]: 0.005361245813496566
Loss at iteration [2736]: 0.0053602171475817416
Loss at iteration [2737]: 0.005359189136752658
Loss at iteration [2738]: 0.005358161563878709
Loss at iteration [2739]: 0.005357134374946065
Loss at iteration [2740]: 0.005356108100246993
Loss at iteration [2741]: 0.0053550826321792306
Loss at iteration [2742]: 0.005354057759879086
Loss at iteration [2743]: 0.00535303329660072
Loss at iteration [2744]: 0.005352009229904415
Loss at iteration [2745]: 0.005350985583054268
Loss at iteration [2746]: 0.005349962362097799
Loss at iteration [2747]: 0.005348939795667858
Loss at iteration [2748]: 0.005347917718440839
Loss at iteration [2749]: 0.005346896145674414
Loss at iteration [2750]: 0.005345874939411263
Loss at iteration [2751]: 0.0053448540935274414
Loss at iteration [2752]: 0.005343833631506138
Loss at iteration [2753]: 0.0053428135634694595
Loss at iteration [2754]: 0.00534179401466296
Loss at iteration [2755]: 0.005340775435068303
Loss at iteration [2756]: 0.005339757694036386
Loss at iteration [2757]: 0.00533874200671634
Loss at iteration [2758]: 0.005337727950758982
Loss at iteration [2759]: 0.005336715424137787
Loss at iteration [2760]: 0.005335703606024512
Loss at iteration [2761]: 0.005334692920661223
Loss at iteration [2762]: 0.005333682940997193
Loss at iteration [2763]: 0.0053326732094526085
Loss at iteration [2764]: 0.0053316638091435616
Loss at iteration [2765]: 0.005330654981843014
Loss at iteration [2766]: 0.005329647485421356
Loss at iteration [2767]: 0.00532864128749259
Loss at iteration [2768]: 0.005327635829626999
Loss at iteration [2769]: 0.005326631068491451
Loss at iteration [2770]: 0.005325626728601907
Loss at iteration [2771]: 0.00532462276919607
Loss at iteration [2772]: 0.005323619341695248
Loss at iteration [2773]: 0.005322616577715254
Loss at iteration [2774]: 0.005321614485368463
Loss at iteration [2775]: 0.00532061331256118
Loss at iteration [2776]: 0.005319612625147927
Loss at iteration [2777]: 0.005318612330610942
Loss at iteration [2778]: 0.005317612399562158
Loss at iteration [2779]: 0.005316612953308306
Loss at iteration [2780]: 0.005315614702126833
Loss at iteration [2781]: 0.005314617078302
Loss at iteration [2782]: 0.005313620010754623
Loss at iteration [2783]: 0.0053126234696874285
Loss at iteration [2784]: 0.005311627406509045
Loss at iteration [2785]: 0.005310632052063219
Loss at iteration [2786]: 0.005309638517036073
Loss at iteration [2787]: 0.005308645971394614
Loss at iteration [2788]: 0.005307654035153268
Loss at iteration [2789]: 0.005306662624043757
Loss at iteration [2790]: 0.005305672873451833
Loss at iteration [2791]: 0.005304684682834782
Loss at iteration [2792]: 0.00530369729632766
Loss at iteration [2793]: 0.005302711160675004
Loss at iteration [2794]: 0.0053017259073525665
Loss at iteration [2795]: 0.005300741568608162
Loss at iteration [2796]: 0.005299758090976703
Loss at iteration [2797]: 0.005298774946362172
Loss at iteration [2798]: 0.0052977919535800635
Loss at iteration [2799]: 0.005296809316657014
Loss at iteration [2800]: 0.005295827137551066
Loss at iteration [2801]: 0.005294845309557211
Loss at iteration [2802]: 0.005293864370143378
Loss at iteration [2803]: 0.005292884128007365
Loss at iteration [2804]: 0.005291904344871254
Loss at iteration [2805]: 0.005290925027258232
Loss at iteration [2806]: 0.005289946068369941
Loss at iteration [2807]: 0.005288968165648139
Loss at iteration [2808]: 0.005287991050829651
Loss at iteration [2809]: 0.0052870144326841945
Loss at iteration [2810]: 0.005286038259955427
Loss at iteration [2811]: 0.00528506242469519
Loss at iteration [2812]: 0.0052840870811727714
Loss at iteration [2813]: 0.005283112330403555
Loss at iteration [2814]: 0.00528213834809318
Loss at iteration [2815]: 0.005281165224768169
Loss at iteration [2816]: 0.0052801929728158595
Loss at iteration [2817]: 0.005279221935827809
Loss at iteration [2818]: 0.005278251728559643
Loss at iteration [2819]: 0.005277282723477416
Loss at iteration [2820]: 0.005276314303853311
Loss at iteration [2821]: 0.00527534645078556
Loss at iteration [2822]: 0.005274379027228494
Loss at iteration [2823]: 0.005273412215822976
Loss at iteration [2824]: 0.005272445823815203
Loss at iteration [2825]: 0.005271479908919897
Loss at iteration [2826]: 0.005270514674666243
Loss at iteration [2827]: 0.005269550341652189
Loss at iteration [2828]: 0.005268586884553756
Loss at iteration [2829]: 0.005267624013260706
Loss at iteration [2830]: 0.005266661628675999
Loss at iteration [2831]: 0.0052656996650033315
Loss at iteration [2832]: 0.005264738753694088
Loss at iteration [2833]: 0.005263778860307654
Loss at iteration [2834]: 0.005262819555730112
Loss at iteration [2835]: 0.0052618607127464774
Loss at iteration [2836]: 0.005260902275113153
Loss at iteration [2837]: 0.005259944368067352
Loss at iteration [2838]: 0.005258987001547975
Loss at iteration [2839]: 0.005258030016232343
Loss at iteration [2840]: 0.005257073820855266
Loss at iteration [2841]: 0.005256118276401448
Loss at iteration [2842]: 0.005255163130786028
Loss at iteration [2843]: 0.005254208426550816
Loss at iteration [2844]: 0.005253254089945199
Loss at iteration [2845]: 0.0052523001007210865
Loss at iteration [2846]: 0.005251346750023427
Loss at iteration [2847]: 0.005250393724559589
Loss at iteration [2848]: 0.005249441244444112
Loss at iteration [2849]: 0.0052484894909608825
Loss at iteration [2850]: 0.005247538991734498
Loss at iteration [2851]: 0.005246589318302361
Loss at iteration [2852]: 0.005245640116965093
Loss at iteration [2853]: 0.005244691418149233
Loss at iteration [2854]: 0.0052437431098149
Loss at iteration [2855]: 0.005242795236929939
Loss at iteration [2856]: 0.005241847799831811
Loss at iteration [2857]: 0.005240900794582572
Loss at iteration [2858]: 0.005239953914108511
Loss at iteration [2859]: 0.005239008078820909
Loss at iteration [2860]: 0.0052380628777335065
Loss at iteration [2861]: 0.005237118395663579
Loss at iteration [2862]: 0.005236174755974834
Loss at iteration [2863]: 0.005235231466087684
Loss at iteration [2864]: 0.005234288511087545
Loss at iteration [2865]: 0.005233345883026506
Loss at iteration [2866]: 0.005232403484032569
Loss at iteration [2867]: 0.005231461541685831
Loss at iteration [2868]: 0.005230520817262043
Loss at iteration [2869]: 0.005229580491973399
Loss at iteration [2870]: 0.005228640546905288
Loss at iteration [2871]: 0.005227701283948252
Loss at iteration [2872]: 0.00522676246967229
Loss at iteration [2873]: 0.005225824434598506
Loss at iteration [2874]: 0.005224887291727714
Loss at iteration [2875]: 0.005223950923884704
Loss at iteration [2876]: 0.005223015368200901
Loss at iteration [2877]: 0.005222080740201479
Loss at iteration [2878]: 0.0052211473658333495
Loss at iteration [2879]: 0.005220214901711846
Loss at iteration [2880]: 0.005219283763472386
Loss at iteration [2881]: 0.0052183534924384505
Loss at iteration [2882]: 0.005217423867448347
Loss at iteration [2883]: 0.005216495391146803
Loss at iteration [2884]: 0.005215567370933313
Loss at iteration [2885]: 0.005214639744789356
Loss at iteration [2886]: 0.005213712859690347
Loss at iteration [2887]: 0.005212786521842464
Loss at iteration [2888]: 0.005211860518380617
Loss at iteration [2889]: 0.0052109348407162965
Loss at iteration [2890]: 0.005210009742612727
Loss at iteration [2891]: 0.005209085198354305
Loss at iteration [2892]: 0.005208161547945628
Loss at iteration [2893]: 0.00520723883940114
Loss at iteration [2894]: 0.005206316783322277
Loss at iteration [2895]: 0.005205395293029841
Loss at iteration [2896]: 0.005204474240433614
Loss at iteration [2897]: 0.005203554033963815
Loss at iteration [2898]: 0.0052026358491375135
Loss at iteration [2899]: 0.0052017184198089195
Loss at iteration [2900]: 0.00520080185239386
Loss at iteration [2901]: 0.005199886291494297
Loss at iteration [2902]: 0.005198972427747416
Loss at iteration [2903]: 0.005198059435554374
Loss at iteration [2904]: 0.005197147190646408
Loss at iteration [2905]: 0.005196235446716668
Loss at iteration [2906]: 0.00519532410074547
Loss at iteration [2907]: 0.005194413087822729
Loss at iteration [2908]: 0.005193502355644204
Loss at iteration [2909]: 0.0051925917866381946
Loss at iteration [2910]: 0.005191681938622394
Loss at iteration [2911]: 0.00519077310034267
Loss at iteration [2912]: 0.005189864940981602
Loss at iteration [2913]: 0.005188957346150527
Loss at iteration [2914]: 0.0051880501921101815
Loss at iteration [2915]: 0.0051871434104366985
Loss at iteration [2916]: 0.005186237096059856
Loss at iteration [2917]: 0.005185331739602521
Loss at iteration [2918]: 0.005184427066076602
Loss at iteration [2919]: 0.005183523510166252
Loss at iteration [2920]: 0.005182620445288038
Loss at iteration [2921]: 0.0051817178349993125
Loss at iteration [2922]: 0.005180815665003138
Loss at iteration [2923]: 0.005179913922522066
Loss at iteration [2924]: 0.005179012513638222
Loss at iteration [2925]: 0.005178111784572697
Loss at iteration [2926]: 0.005177212387309618
Loss at iteration [2927]: 0.005176313974165028
Loss at iteration [2928]: 0.005175416075848281
Loss at iteration [2929]: 0.0051745186509066995
Loss at iteration [2930]: 0.005173622199903144
Loss at iteration [2931]: 0.00517272640374853
Loss at iteration [2932]: 0.005171831174191591
Loss at iteration [2933]: 0.005170936623535664
Loss at iteration [2934]: 0.005170042780544073
Loss at iteration [2935]: 0.0051691494432207705
Loss at iteration [2936]: 0.00516825654182207
Loss at iteration [2937]: 0.0051673642660429505
Loss at iteration [2938]: 0.0051664724316336135
Loss at iteration [2939]: 0.005165580977862388
Loss at iteration [2940]: 0.00516469009930493
Loss at iteration [2941]: 0.005163799944686896
Loss at iteration [2942]: 0.005162910631956205
Loss at iteration [2943]: 0.005162021801213527
Loss at iteration [2944]: 0.005161133340936215
Loss at iteration [2945]: 0.005160245397208098
Loss at iteration [2946]: 0.005159357973979171
Loss at iteration [2947]: 0.00515847093976169
Loss at iteration [2948]: 0.005157584472843273
Loss at iteration [2949]: 0.005156698471639289
Loss at iteration [2950]: 0.005155814454488056
Loss at iteration [2951]: 0.005154931214417876
Loss at iteration [2952]: 0.005154048444918484
Loss at iteration [2953]: 0.005153166111641735
Loss at iteration [2954]: 0.005152284091054747
Loss at iteration [2955]: 0.005151402144532676
Loss at iteration [2956]: 0.005150520300904878
Loss at iteration [2957]: 0.005149638731902976
Loss at iteration [2958]: 0.005148757369357571
Loss at iteration [2959]: 0.005147876257242602
Loss at iteration [2960]: 0.00514699545204412
Loss at iteration [2961]: 0.0051461149773955
Loss at iteration [2962]: 0.005145234780325598
Loss at iteration [2963]: 0.0051443549198754174
Loss at iteration [2964]: 0.005143475445596304
Loss at iteration [2965]: 0.005142596355664171
Loss at iteration [2966]: 0.005141717618253334
Loss at iteration [2967]: 0.005140839451177013
Loss at iteration [2968]: 0.0051399615625763295
Loss at iteration [2969]: 0.005139084046154404
Loss at iteration [2970]: 0.005138206887137103
Loss at iteration [2971]: 0.005137330100346531
Loss at iteration [2972]: 0.005136454179238377
Loss at iteration [2973]: 0.005135578728125659
Loss at iteration [2974]: 0.005134703651512179
Loss at iteration [2975]: 0.005133828852564599
Loss at iteration [2976]: 0.005132954339996315
Loss at iteration [2977]: 0.005132080676343284
Loss at iteration [2978]: 0.005131207662707758
Loss at iteration [2979]: 0.005130335131703664
Loss at iteration [2980]: 0.005129462969876837
Loss at iteration [2981]: 0.005128591144602495
Loss at iteration [2982]: 0.00512771966973931
Loss at iteration [2983]: 0.005126848475299452
Loss at iteration [2984]: 0.005125977485112335
Loss at iteration [2985]: 0.0051251067495681115
Loss at iteration [2986]: 0.005124236228892135
Loss at iteration [2987]: 0.005123366026310484
Loss at iteration [2988]: 0.005122496392099625
Loss at iteration [2989]: 0.005121627214297015
Loss at iteration [2990]: 0.005120758454415948
Loss at iteration [2991]: 0.005119890060917128
Loss at iteration [2992]: 0.005119022012365117
Loss at iteration [2993]: 0.005118154721198704
Loss at iteration [2994]: 0.005117288258924269
Loss at iteration [2995]: 0.005116422404925573
Loss at iteration [2996]: 0.005115557060372116
Loss at iteration [2997]: 0.00511469231351241
Loss at iteration [2998]: 0.005113828325328752
Loss at iteration [2999]: 0.0051129648178149245
Loss at iteration [3000]: 0.005112101758423662
