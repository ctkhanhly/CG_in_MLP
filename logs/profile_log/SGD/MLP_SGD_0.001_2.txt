Model name                            : MLP
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : SGD
Learning rate                         : 0.001
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 11.507769107818604
Total number of parameters            : 101001
Percentage of parameters < 1e-9       : 49.788615954297484%
Percentage of parameters < 1e-7       : 49.788615954297484%
Percentage of parameters < 1e-6       : 49.788615954297484%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.963630733976577
Loss at iteration [2]: 0.957007229601854
Loss at iteration [3]: 0.9471163691304499
Loss at iteration [4]: 0.9356755020814568
Loss at iteration [5]: 0.9236433213398586
Loss at iteration [6]: 0.9114861204682315
Loss at iteration [7]: 0.899383410832591
Loss at iteration [8]: 0.8874412167155852
Loss at iteration [9]: 0.8756485220057327
Loss at iteration [10]: 0.8639916753260601
Loss at iteration [11]: 0.8524635171422347
Loss at iteration [12]: 0.8410709414991795
Loss at iteration [13]: 0.8298267292831325
Loss at iteration [14]: 0.8188971882056931
Loss at iteration [15]: 0.8081742126359667
Loss at iteration [16]: 0.7975705888439398
Loss at iteration [17]: 0.7870757626517539
Loss at iteration [18]: 0.7767054348503148
Loss at iteration [19]: 0.7664542656012617
Loss at iteration [20]: 0.7562981797840367
Loss at iteration [21]: 0.7462319879829663
Loss at iteration [22]: 0.7362437420768413
Loss at iteration [23]: 0.7263230168161329
Loss at iteration [24]: 0.716474866819139
Loss at iteration [25]: 0.7067054808079188
Loss at iteration [26]: 0.6970209880398106
Loss at iteration [27]: 0.6874123317617284
Loss at iteration [28]: 0.6778771558070359
Loss at iteration [29]: 0.668488739220749
Loss at iteration [30]: 0.6592632116347963
Loss at iteration [31]: 0.6501277563234376
Loss at iteration [32]: 0.6410728080390806
Loss at iteration [33]: 0.632167658206217
Loss at iteration [34]: 0.6233889355748901
Loss at iteration [35]: 0.6146952656187943
Loss at iteration [36]: 0.606090312841108
Loss at iteration [37]: 0.5975717087466795
Loss at iteration [38]: 0.5891198647885802
Loss at iteration [39]: 0.5807315720020434
Loss at iteration [40]: 0.5724030800173131
Loss at iteration [41]: 0.5641331983904686
Loss at iteration [42]: 0.5559215333142448
Loss at iteration [43]: 0.5477803860371057
Loss at iteration [44]: 0.5397203112396946
Loss at iteration [45]: 0.5317277048005125
Loss at iteration [46]: 0.5238106536757029
Loss at iteration [47]: 0.5159596996960628
Loss at iteration [48]: 0.5081472149048893
Loss at iteration [49]: 0.5003789383231585
Loss at iteration [50]: 0.49266153319296174
Loss at iteration [51]: 0.484996001386015
Loss at iteration [52]: 0.47738074881350123
Loss at iteration [53]: 0.4698149210454831
Loss at iteration [54]: 0.46230140695130906
Loss at iteration [55]: 0.45484063274753506
Loss at iteration [56]: 0.4474338298957736
Loss at iteration [57]: 0.44008519251623085
Loss at iteration [58]: 0.4327950988044845
Loss at iteration [59]: 0.42556645281650757
Loss at iteration [60]: 0.4183992454243271
Loss at iteration [61]: 0.4112934854128425
Loss at iteration [62]: 0.40424718703900825
Loss at iteration [63]: 0.39726066770513313
Loss at iteration [64]: 0.39033378519972284
Loss at iteration [65]: 0.3834669088564274
Loss at iteration [66]: 0.37665974907659655
Loss at iteration [67]: 0.3699130620687075
Loss at iteration [68]: 0.3632287592432827
Loss at iteration [69]: 0.3566071567602908
Loss at iteration [70]: 0.35004932300046604
Loss at iteration [71]: 0.343556395398378
Loss at iteration [72]: 0.33712793041618955
Loss at iteration [73]: 0.3307648237923912
Loss at iteration [74]: 0.32446866063399343
Loss at iteration [75]: 0.3182398439759808
Loss at iteration [76]: 0.31207802408692864
Loss at iteration [77]: 0.30598447957257163
Loss at iteration [78]: 0.29995900028455247
Loss at iteration [79]: 0.2940030753579988
Loss at iteration [80]: 0.2881167112058498
Loss at iteration [81]: 0.28229723174222726
Loss at iteration [82]: 0.2765421392218876
Loss at iteration [83]: 0.2708501154646359
Loss at iteration [84]: 0.2652254867315182
Loss at iteration [85]: 0.2596732123124622
Loss at iteration [86]: 0.25419548151171817
Loss at iteration [87]: 0.2487932765224571
Loss at iteration [88]: 0.24346746535905156
Loss at iteration [89]: 0.23821841012154193
Loss at iteration [90]: 0.23304747366249995
Loss at iteration [91]: 0.22795483659188331
Loss at iteration [92]: 0.22294046094253045
Loss at iteration [93]: 0.21800464034828132
Loss at iteration [94]: 0.21314864666019107
Loss at iteration [95]: 0.20837242535711373
Loss at iteration [96]: 0.20367648654888598
Loss at iteration [97]: 0.19906082034837685
Loss at iteration [98]: 0.19452493841327853
Loss at iteration [99]: 0.19006901227220563
Loss at iteration [100]: 0.18569284474631848
Loss at iteration [101]: 0.1813953190273731
Loss at iteration [102]: 0.17717640972997686
Loss at iteration [103]: 0.17303572267962505
Loss at iteration [104]: 0.16897251975430583
Loss at iteration [105]: 0.16498664995605236
Loss at iteration [106]: 0.16107719802616097
Loss at iteration [107]: 0.15724334058076145
Loss at iteration [108]: 0.15348423168859054
Loss at iteration [109]: 0.14979923759766195
Loss at iteration [110]: 0.1461882560498857
Loss at iteration [111]: 0.14265035691958577
Loss at iteration [112]: 0.13918509330218562
Loss at iteration [113]: 0.13579164073814412
Loss at iteration [114]: 0.1324696915586173
Loss at iteration [115]: 0.1292184611396211
Loss at iteration [116]: 0.1260371814613363
Loss at iteration [117]: 0.12292505168421636
Loss at iteration [118]: 0.11988157583183096
Loss at iteration [119]: 0.11690588534291821
Loss at iteration [120]: 0.11399724632553347
Loss at iteration [121]: 0.11115486093871497
Loss at iteration [122]: 0.1083778960597879
Loss at iteration [123]: 0.10566579029980312
Loss at iteration [124]: 0.1030177748539984
Loss at iteration [125]: 0.10043292566359656
Loss at iteration [126]: 0.09791012278959711
Loss at iteration [127]: 0.09544847343513713
Loss at iteration [128]: 0.09304717205268866
Loss at iteration [129]: 0.09070482344247621
Loss at iteration [130]: 0.08842074413890728
Loss at iteration [131]: 0.08619409359371383
Loss at iteration [132]: 0.08402368420420603
Loss at iteration [133]: 0.08190885981714469
Loss at iteration [134]: 0.07984837521006734
Loss at iteration [135]: 0.07784114407036184
Loss at iteration [136]: 0.07588638631281391
Loss at iteration [137]: 0.07398340115211134
Loss at iteration [138]: 0.0721310471866872
Loss at iteration [139]: 0.07032833170041357
Loss at iteration [140]: 0.06857415216234648
Loss at iteration [141]: 0.06686762462090877
Loss at iteration [142]: 0.06520755266627788
Loss at iteration [143]: 0.06359312283243386
Loss at iteration [144]: 0.06202356538099725
Loss at iteration [145]: 0.0604979138279907
Loss at iteration [146]: 0.05901530147907924
Loss at iteration [147]: 0.05757490763509916
Loss at iteration [148]: 0.05617579998194382
Loss at iteration [149]: 0.054817069496463595
Loss at iteration [150]: 0.0534977564089596
Loss at iteration [151]: 0.05221690037795232
Loss at iteration [152]: 0.050973545908498855
Loss at iteration [153]: 0.04976668562807683
Loss at iteration [154]: 0.048595409656615886
Loss at iteration [155]: 0.04745883239038941
Loss at iteration [156]: 0.04635599297216188
Loss at iteration [157]: 0.04528602926225517
Loss at iteration [158]: 0.04424809529986804
Loss at iteration [159]: 0.04324132046714833
Loss at iteration [160]: 0.042264908908674396
Loss at iteration [161]: 0.04131807946192554
Loss at iteration [162]: 0.040400025380026974
Loss at iteration [163]: 0.03951000017261043
Loss at iteration [164]: 0.03864721587024635
Loss at iteration [165]: 0.037810915425203484
Loss at iteration [166]: 0.037000364135491584
Loss at iteration [167]: 0.036214866380753406
Loss at iteration [168]: 0.03545382994374628
Loss at iteration [169]: 0.03471679322697424
Loss at iteration [170]: 0.03400353088196242
Loss at iteration [171]: 0.033313180625221164
Loss at iteration [172]: 0.0326448573383472
Loss at iteration [173]: 0.03199788306125489
Loss at iteration [174]: 0.03137174027980413
Loss at iteration [175]: 0.030766010409676487
Loss at iteration [176]: 0.030179845296771424
Loss at iteration [177]: 0.029612641676728464
Loss at iteration [178]: 0.029063783846985453
Loss at iteration [179]: 0.028532596004017106
Loss at iteration [180]: 0.02801838143488345
Loss at iteration [181]: 0.027520578713827647
Loss at iteration [182]: 0.027038686391052346
Loss at iteration [183]: 0.026572158673819762
Loss at iteration [184]: 0.02612054782740226
Loss at iteration [185]: 0.025683354671052563
Loss at iteration [186]: 0.025260111336698525
Loss at iteration [187]: 0.024850409530936923
Loss at iteration [188]: 0.02445381473932687
Loss at iteration [189]: 0.024069877168699582
Loss at iteration [190]: 0.02369821758580503
Loss at iteration [191]: 0.023338437300227038
Loss at iteration [192]: 0.022990188029479303
Loss at iteration [193]: 0.022653091008822183
Loss at iteration [194]: 0.02232676714607412
Loss at iteration [195]: 0.02201080102871648
Loss at iteration [196]: 0.021704845504475725
Loss at iteration [197]: 0.021408604775502185
Loss at iteration [198]: 0.021121731477310973
Loss at iteration [199]: 0.02084391129532062
Loss at iteration [200]: 0.02057483772414153
Loss at iteration [201]: 0.02031421540157986
Loss at iteration [202]: 0.0200617563813757
Loss at iteration [203]: 0.019817191853692552
Loss at iteration [204]: 0.019580252517539948
Loss at iteration [205]: 0.01935069663199514
Loss at iteration [206]: 0.01912825939005063
Loss at iteration [207]: 0.018912724403822568
Loss at iteration [208]: 0.018703840130407046
Loss at iteration [209]: 0.018501380146419097
Loss at iteration [210]: 0.01830510500806588
Loss at iteration [211]: 0.01811479024097396
Loss at iteration [212]: 0.017930209162226173
Loss at iteration [213]: 0.01775119847119713
Loss at iteration [214]: 0.01757755228520085
Loss at iteration [215]: 0.017409068850647438
Loss at iteration [216]: 0.017245579950274825
Loss at iteration [217]: 0.01708691943549913
Loss at iteration [218]: 0.016932918971030275
Loss at iteration [219]: 0.016783428170884736
Loss at iteration [220]: 0.016638280981664193
Loss at iteration [221]: 0.01649730664775654
Loss at iteration [222]: 0.016360341625739534
Loss at iteration [223]: 0.01622723466278342
Loss at iteration [224]: 0.01609784262325605
Loss at iteration [225]: 0.01597203731435182
Loss at iteration [226]: 0.015849711080253594
Loss at iteration [227]: 0.01573075000164107
Loss at iteration [228]: 0.015615020641298006
Loss at iteration [229]: 0.015502493839753937
Loss at iteration [230]: 0.015393000870972522
Loss at iteration [231]: 0.015286427094530358
Loss at iteration [232]: 0.015182651893068324
Loss at iteration [233]: 0.015081581668904342
Loss at iteration [234]: 0.014983144722309707
Loss at iteration [235]: 0.014887236045714328
Loss at iteration [236]: 0.014793724735559633
Loss at iteration [237]: 0.014702540924062327
Loss at iteration [238]: 0.014613612181881211
Loss at iteration [239]: 0.014526850668403389
Loss at iteration [240]: 0.014442232978139092
Loss at iteration [241]: 0.01435962493877004
Loss at iteration [242]: 0.014279018703607328
Loss at iteration [243]: 0.014200275464023063
Loss at iteration [244]: 0.014123337328599779
Loss at iteration [245]: 0.014048148349522099
Loss at iteration [246]: 0.01397464240612696
Loss at iteration [247]: 0.01390279582033899
Loss at iteration [248]: 0.013832535520751456
Loss at iteration [249]: 0.013763815349991394
Loss at iteration [250]: 0.013696567809444508
Loss at iteration [251]: 0.013630739717381133
Loss at iteration [252]: 0.01356627088800479
Loss at iteration [253]: 0.013503125334782455
Loss at iteration [254]: 0.013441244999430377
Loss at iteration [255]: 0.013380584983063777
Loss at iteration [256]: 0.013321134250952748
Loss at iteration [257]: 0.013262852180536964
Loss at iteration [258]: 0.013205709700667392
Loss at iteration [259]: 0.013149633909245043
Loss at iteration [260]: 0.013094570575115986
Loss at iteration [261]: 0.0130405092634249
Loss at iteration [262]: 0.012987400900620021
Loss at iteration [263]: 0.012935226432226657
Loss at iteration [264]: 0.012883951966933739
Loss at iteration [265]: 0.012833564430131837
Loss at iteration [266]: 0.012784032509467386
Loss at iteration [267]: 0.01273531041457124
Loss at iteration [268]: 0.012687379331473106
Loss at iteration [269]: 0.012640213778758853
Loss at iteration [270]: 0.012593802869008686
Loss at iteration [271]: 0.012548079900739693
Loss at iteration [272]: 0.012503033290837141
Loss at iteration [273]: 0.012458668207129028
Loss at iteration [274]: 0.012414951811812024
Loss at iteration [275]: 0.012371855570666059
Loss at iteration [276]: 0.012329366707306156
Loss at iteration [277]: 0.01228747574650169
Loss at iteration [278]: 0.012246177212404206
Loss at iteration [279]: 0.01220546369324264
Loss at iteration [280]: 0.012165355109520272
Loss at iteration [281]: 0.012125792321336936
Loss at iteration [282]: 0.012086759527921655
Loss at iteration [283]: 0.012048215347147789
Loss at iteration [284]: 0.012010137159584775
Loss at iteration [285]: 0.01197250797450605
Loss at iteration [286]: 0.011935291841244885
Loss at iteration [287]: 0.011898495421199291
Loss at iteration [288]: 0.011862151020015149
Loss at iteration [289]: 0.011826251291856087
Loss at iteration [290]: 0.01179075247582723
Loss at iteration [291]: 0.011755643328654038
Loss at iteration [292]: 0.011720907254446017
Loss at iteration [293]: 0.01168652547365705
Loss at iteration [294]: 0.011652516393869503
Loss at iteration [295]: 0.011618861070915603
Loss at iteration [296]: 0.01158554988765388
Loss at iteration [297]: 0.011552570917907764
Loss at iteration [298]: 0.011519901398120706
Loss at iteration [299]: 0.011487525841130669
Loss at iteration [300]: 0.011455438793370201
Loss at iteration [301]: 0.011423627600264219
Loss at iteration [302]: 0.011392084274570094
Loss at iteration [303]: 0.011360808198465144
Loss at iteration [304]: 0.011329756611655745
Loss at iteration [305]: 0.011298937760143927
Loss at iteration [306]: 0.0112683504800678
Loss at iteration [307]: 0.011237979155992507
Loss at iteration [308]: 0.01120781814485243
Loss at iteration [309]: 0.011177883823944702
Loss at iteration [310]: 0.011148169753998781
Loss at iteration [311]: 0.011118691453251322
Loss at iteration [312]: 0.011089425582656298
Loss at iteration [313]: 0.011060355368018018
Loss at iteration [314]: 0.011031542720873361
Loss at iteration [315]: 0.01100294768712048
Loss at iteration [316]: 0.0109745394787714
Loss at iteration [317]: 0.0109463006077305
Loss at iteration [318]: 0.010918248941098795
Loss at iteration [319]: 0.01089038128568528
Loss at iteration [320]: 0.010862688641752645
Loss at iteration [321]: 0.010835163988589394
Loss at iteration [322]: 0.010807784034536338
Loss at iteration [323]: 0.010780546447644965
Loss at iteration [324]: 0.010753445229467631
Loss at iteration [325]: 0.010726494417930629
Loss at iteration [326]: 0.010699682808697411
Loss at iteration [327]: 0.01067300576435548
Loss at iteration [328]: 0.010646471215739178
Loss at iteration [329]: 0.010620078641697395
Loss at iteration [330]: 0.010593816317474745
Loss at iteration [331]: 0.010567689802937817
Loss at iteration [332]: 0.010541699533226371
Loss at iteration [333]: 0.010515854159070769
Loss at iteration [334]: 0.010490152374724766
Loss at iteration [335]: 0.010464582296721226
Loss at iteration [336]: 0.010439146157830514
Loss at iteration [337]: 0.010413836132844969
Loss at iteration [338]: 0.010388643600994184
Loss at iteration [339]: 0.010363569124073324
Loss at iteration [340]: 0.010338622852331565
Loss at iteration [341]: 0.010313823447483236
Loss at iteration [342]: 0.010289135057993401
Loss at iteration [343]: 0.010264550689907588
Loss at iteration [344]: 0.010240070562490837
Loss at iteration [345]: 0.010215719335387941
Loss at iteration [346]: 0.010191492712148042
Loss at iteration [347]: 0.010167389105302899
Loss at iteration [348]: 0.010143421084551572
Loss at iteration [349]: 0.010119579762811685
Loss at iteration [350]: 0.010095853307115132
Loss at iteration [351]: 0.01007224468030233
Loss at iteration [352]: 0.010048774030757102
Loss at iteration [353]: 0.010025447630354766
Loss at iteration [354]: 0.010002248095100995
Loss at iteration [355]: 0.009979154246340083
Loss at iteration [356]: 0.009956168085198431
Loss at iteration [357]: 0.009933300049225002
Loss at iteration [358]: 0.009910537332394123
Loss at iteration [359]: 0.009887848366994715
Loss at iteration [360]: 0.009865254348326098
Loss at iteration [361]: 0.009842755657864685
Loss at iteration [362]: 0.0098203460256556
Loss at iteration [363]: 0.009798033772553527
Loss at iteration [364]: 0.00977582952634412
Loss at iteration [365]: 0.009753717497010825
Loss at iteration [366]: 0.00973170101330858
Loss at iteration [367]: 0.009709776321824603
Loss at iteration [368]: 0.009687937912113859
Loss at iteration [369]: 0.009666210499300146
Loss at iteration [370]: 0.009644575506845166
Loss at iteration [371]: 0.009623030749959526
Loss at iteration [372]: 0.00960158621693011
Loss at iteration [373]: 0.00958023486064578
Loss at iteration [374]: 0.009558983840509665
Loss at iteration [375]: 0.009537861289666978
Loss at iteration [376]: 0.0095168743571192
Loss at iteration [377]: 0.009495991581831722
Loss at iteration [378]: 0.009475205544884487
Loss at iteration [379]: 0.009454514582410973
Loss at iteration [380]: 0.00943391123463025
Loss at iteration [381]: 0.0094133937502733
Loss at iteration [382]: 0.009392964008887053
Loss at iteration [383]: 0.009372615074589143
Loss at iteration [384]: 0.009352344377850071
Loss at iteration [385]: 0.009332160627097082
Loss at iteration [386]: 0.009312057168905713
Loss at iteration [387]: 0.009292033890060671
Loss at iteration [388]: 0.009272112044287408
Loss at iteration [389]: 0.009252294937095626
Loss at iteration [390]: 0.009232566764747305
Loss at iteration [391]: 0.009212935007734952
Loss at iteration [392]: 0.009193381087786945
Loss at iteration [393]: 0.009173904197087232
Loss at iteration [394]: 0.009154504851454057
Loss at iteration [395]: 0.009135181255921582
Loss at iteration [396]: 0.009115937253421767
Loss at iteration [397]: 0.009096767485032645
Loss at iteration [398]: 0.00907766899552204
Loss at iteration [399]: 0.00905863909447004
Loss at iteration [400]: 0.009039687338115793
Loss at iteration [401]: 0.00902081665162898
Loss at iteration [402]: 0.009002027764743169
Loss at iteration [403]: 0.008983314802681108
Loss at iteration [404]: 0.008964678697673237
Loss at iteration [405]: 0.008946114653058895
Loss at iteration [406]: 0.008927617105603726
Loss at iteration [407]: 0.008909197816418371
Loss at iteration [408]: 0.008890866042786919
Loss at iteration [409]: 0.008872608506663897
Loss at iteration [410]: 0.008854410588828328
Loss at iteration [411]: 0.008836292536103095
Loss at iteration [412]: 0.008818253944197985
Loss at iteration [413]: 0.008800300706677821
Loss at iteration [414]: 0.008782435936840822
Loss at iteration [415]: 0.008764642603025325
Loss at iteration [416]: 0.008746916049631032
Loss at iteration [417]: 0.008729242328868743
Loss at iteration [418]: 0.008711651468255942
Loss at iteration [419]: 0.008694146225850316
Loss at iteration [420]: 0.00867671253707379
Loss at iteration [421]: 0.008659339441340886
Loss at iteration [422]: 0.008642025374161642
Loss at iteration [423]: 0.008624786724154496
Loss at iteration [424]: 0.00860762531593802
Loss at iteration [425]: 0.008590551851497078
Loss at iteration [426]: 0.00857355833796184
Loss at iteration [427]: 0.008556630732548205
Loss at iteration [428]: 0.008539765104781234
Loss at iteration [429]: 0.008522975805074256
Loss at iteration [430]: 0.00850626553292756
Loss at iteration [431]: 0.008489643529858735
Loss at iteration [432]: 0.008473090198118795
Loss at iteration [433]: 0.008456610805996525
Loss at iteration [434]: 0.008440202244133476
Loss at iteration [435]: 0.008423874414774374
Loss at iteration [436]: 0.008407599472032665
Loss at iteration [437]: 0.008391385148765548
Loss at iteration [438]: 0.00837523464292211
Loss at iteration [439]: 0.008359139942983514
Loss at iteration [440]: 0.008343102880411402
Loss at iteration [441]: 0.008327138761605228
Loss at iteration [442]: 0.008311252778295005
Loss at iteration [443]: 0.008295425792679724
Loss at iteration [444]: 0.008279671232251344
Loss at iteration [445]: 0.008263983901374615
Loss at iteration [446]: 0.008248358674761024
Loss at iteration [447]: 0.008232803195568282
Loss at iteration [448]: 0.008217307827158496
Loss at iteration [449]: 0.008201872560747371
Loss at iteration [450]: 0.008186511461334318
Loss at iteration [451]: 0.008171219180830299
Loss at iteration [452]: 0.008155991153784176
Loss at iteration [453]: 0.008140817188368397
Loss at iteration [454]: 0.008125700908175444
Loss at iteration [455]: 0.008110660673955697
Loss at iteration [456]: 0.008095695371751772
Loss at iteration [457]: 0.0080808103063117
Loss at iteration [458]: 0.008065983064980771
Loss at iteration [459]: 0.008051219164803437
Loss at iteration [460]: 0.008036518783549995
Loss at iteration [461]: 0.008021894606404902
Loss at iteration [462]: 0.008007350780939546
Loss at iteration [463]: 0.007992846113261703
Loss at iteration [464]: 0.007978391541374868
Loss at iteration [465]: 0.007963999089806948
Loss at iteration [466]: 0.007949668719782144
Loss at iteration [467]: 0.007935424897804735
Loss at iteration [468]: 0.007921251188245073
Loss at iteration [469]: 0.007907140433348057
Loss at iteration [470]: 0.007893085440298481
Loss at iteration [471]: 0.00787908955577976
Loss at iteration [472]: 0.007865158637945336
Loss at iteration [473]: 0.007851289942422988
Loss at iteration [474]: 0.007837479441134899
Loss at iteration [475]: 0.007823721857188437
Loss at iteration [476]: 0.007810010697808871
Loss at iteration [477]: 0.007796346537163199
Loss at iteration [478]: 0.007782727928370969
Loss at iteration [479]: 0.0077691522581447795
Loss at iteration [480]: 0.007755631292017837
Loss at iteration [481]: 0.007742168178810883
Loss at iteration [482]: 0.007728776609307327
Loss at iteration [483]: 0.007715450678986996
Loss at iteration [484]: 0.007702175036866133
Loss at iteration [485]: 0.0076889589683535675
Loss at iteration [486]: 0.00767580709899449
Loss at iteration [487]: 0.007662739496816467
Loss at iteration [488]: 0.007649745274245747
Loss at iteration [489]: 0.007636834073440525
Loss at iteration [490]: 0.007624004207930249
Loss at iteration [491]: 0.007611268415586495
Loss at iteration [492]: 0.0075985965235479255
Loss at iteration [493]: 0.007585977067992583
Loss at iteration [494]: 0.007573411937938747
Loss at iteration [495]: 0.007560905978911988
Loss at iteration [496]: 0.0075484660415148465
Loss at iteration [497]: 0.007536096724688261
Loss at iteration [498]: 0.007523788963624182
Loss at iteration [499]: 0.007511556460307563
Loss at iteration [500]: 0.0074993932491583684
Loss at iteration [501]: 0.007487298469441294
Loss at iteration [502]: 0.007475255008246641
Loss at iteration [503]: 0.007463262006602477
Loss at iteration [504]: 0.0074513166904975
Loss at iteration [505]: 0.0074394110307644725
Loss at iteration [506]: 0.007427550053338695
Loss at iteration [507]: 0.0074157530600212525
Loss at iteration [508]: 0.007404021112013492
Loss at iteration [509]: 0.00739234062986586
Loss at iteration [510]: 0.007380720524690772
Loss at iteration [511]: 0.007369151859955163
Loss at iteration [512]: 0.007357630904635762
Loss at iteration [513]: 0.007346159631111446
Loss at iteration [514]: 0.007334750091896747
Loss at iteration [515]: 0.007323388275321622
Loss at iteration [516]: 0.007312071126970876
Loss at iteration [517]: 0.007300791959131375
Loss at iteration [518]: 0.00728956032433812
Loss at iteration [519]: 0.007278383962308372
Loss at iteration [520]: 0.007267259252808902
Loss at iteration [521]: 0.007256191271670816
Loss at iteration [522]: 0.007245172470910092
Loss at iteration [523]: 0.007234199155012576
Loss at iteration [524]: 0.007223268186477236
Loss at iteration [525]: 0.007212382481269919
Loss at iteration [526]: 0.0072015378383367135
Loss at iteration [527]: 0.007190741406780284
Loss at iteration [528]: 0.007179983882610503
Loss at iteration [529]: 0.007169267128613948
Loss at iteration [530]: 0.007158584096663339
Loss at iteration [531]: 0.007147931774178413
Loss at iteration [532]: 0.007137312275113735
Loss at iteration [533]: 0.007126732482136232
Loss at iteration [534]: 0.007116200887722384
Loss at iteration [535]: 0.0071057118894284465
Loss at iteration [536]: 0.007095272740658444
Loss at iteration [537]: 0.007084887949577682
Loss at iteration [538]: 0.007074545141608467
Loss at iteration [539]: 0.007064244487718406
Loss at iteration [540]: 0.007053978838155958
Loss at iteration [541]: 0.007043752424275385
Loss at iteration [542]: 0.007033572281449369
Loss at iteration [543]: 0.007023435877773677
Loss at iteration [544]: 0.007013333215075064
Loss at iteration [545]: 0.00700326765264022
Loss at iteration [546]: 0.006993236096391738
Loss at iteration [547]: 0.0069832394854844404
Loss at iteration [548]: 0.006973281446655785
Loss at iteration [549]: 0.006963352906337454
Loss at iteration [550]: 0.00695345081131077
Loss at iteration [551]: 0.006943578537454144
Loss at iteration [552]: 0.006933737862324246
Loss at iteration [553]: 0.006923931613778529
Loss at iteration [554]: 0.006914155151100862
Loss at iteration [555]: 0.006904417397655795
Loss at iteration [556]: 0.006894720598800992
Loss at iteration [557]: 0.006885060368239021
Loss at iteration [558]: 0.006875430254793272
Loss at iteration [559]: 0.0068658330059002196
Loss at iteration [560]: 0.006856270432549848
Loss at iteration [561]: 0.006846750735353221
Loss at iteration [562]: 0.006837266695835758
Loss at iteration [563]: 0.00682781580020951
Loss at iteration [564]: 0.006818395225742426
Loss at iteration [565]: 0.006809000748064932
Loss at iteration [566]: 0.006799631662971111
Loss at iteration [567]: 0.006790305003918447
Loss at iteration [568]: 0.0067810117970092945
Loss at iteration [569]: 0.006771750760600902
Loss at iteration [570]: 0.006762515195561064
Loss at iteration [571]: 0.0067533101203950735
Loss at iteration [572]: 0.006744130966660469
Loss at iteration [573]: 0.00673497867599324
Loss at iteration [574]: 0.006725851425463319
Loss at iteration [575]: 0.006716752594714503
Loss at iteration [576]: 0.006707697416515099
Loss at iteration [577]: 0.006698682413738035
Loss at iteration [578]: 0.006689701831019408
Loss at iteration [579]: 0.006680746706858819
Loss at iteration [580]: 0.006671813716640764
Loss at iteration [581]: 0.006662904783826992
Loss at iteration [582]: 0.006654026035821888
Loss at iteration [583]: 0.006645177990206368
Loss at iteration [584]: 0.006636356708067214
Loss at iteration [585]: 0.00662755687993657
Loss at iteration [586]: 0.006618788963566719
Loss at iteration [587]: 0.006610051790626439
Loss at iteration [588]: 0.006601345733314033
Loss at iteration [589]: 0.00659267146178519
Loss at iteration [590]: 0.006584020911839888
Loss at iteration [591]: 0.006575396631367071
Loss at iteration [592]: 0.006566800546595724
Loss at iteration [593]: 0.006558235787827194
Loss at iteration [594]: 0.006549699783314273
Loss at iteration [595]: 0.00654118885367308
Loss at iteration [596]: 0.006532702620087336
Loss at iteration [597]: 0.006524233968362095
Loss at iteration [598]: 0.006515782653077509
Loss at iteration [599]: 0.006507353674123394
Loss at iteration [600]: 0.0064989479075237624
Loss at iteration [601]: 0.006490566677344186
Loss at iteration [602]: 0.006482202855212097
Loss at iteration [603]: 0.006473860518428174
Loss at iteration [604]: 0.0064655388535183374
Loss at iteration [605]: 0.006457239582121018
Loss at iteration [606]: 0.006448962747678564
Loss at iteration [607]: 0.006440710079447488
Loss at iteration [608]: 0.0064324823983166225
Loss at iteration [609]: 0.0064242806851819295
Loss at iteration [610]: 0.006416101463545925
Loss at iteration [611]: 0.006407944281113611
Loss at iteration [612]: 0.006399810002330602
Loss at iteration [613]: 0.006391700984212277
Loss at iteration [614]: 0.006383619182639272
Loss at iteration [615]: 0.006375564672811537
Loss at iteration [616]: 0.006367538468914081
Loss at iteration [617]: 0.006359529832782446
Loss at iteration [618]: 0.0063515432499800205
Loss at iteration [619]: 0.006343579971166097
Loss at iteration [620]: 0.006335644703967284
Loss at iteration [621]: 0.006327740225647467
Loss at iteration [622]: 0.006319864833696983
Loss at iteration [623]: 0.006312015476139954
Loss at iteration [624]: 0.006304191766496718
Loss at iteration [625]: 0.006296389921963011
Loss at iteration [626]: 0.006288611557234751
Loss at iteration [627]: 0.006280854412286823
Loss at iteration [628]: 0.006273118937161527
Loss at iteration [629]: 0.006265404986679852
Loss at iteration [630]: 0.006257714801296109
Loss at iteration [631]: 0.0062500493026896335
Loss at iteration [632]: 0.006242409958157898
Loss at iteration [633]: 0.006234791174454178
Loss at iteration [634]: 0.006227185901262358
Loss at iteration [635]: 0.006219599182591307
Loss at iteration [636]: 0.006212033125041017
Loss at iteration [637]: 0.0062044903244617925
Loss at iteration [638]: 0.006196975006393891
Loss at iteration [639]: 0.006189486610258851
Loss at iteration [640]: 0.0061820251217781525
Loss at iteration [641]: 0.006174584682738859
Loss at iteration [642]: 0.006167168092163141
Loss at iteration [643]: 0.006159775638585349
Loss at iteration [644]: 0.006152406344574493
Loss at iteration [645]: 0.006145059911938346
Loss at iteration [646]: 0.006137731461632937
Loss at iteration [647]: 0.006130424852620142
Loss at iteration [648]: 0.0061231401742811754
Loss at iteration [649]: 0.006115876840829373
Loss at iteration [650]: 0.006108636268652494
Loss at iteration [651]: 0.006101419027341839
Loss at iteration [652]: 0.006094224997179742
Loss at iteration [653]: 0.006087051390588504
Loss at iteration [654]: 0.0060799015938931425
Loss at iteration [655]: 0.006072774464614049
Loss at iteration [656]: 0.006065669553500821
Loss at iteration [657]: 0.006058586383791149
Loss at iteration [658]: 0.006051520619733154
Loss at iteration [659]: 0.006044474095450583
Loss at iteration [660]: 0.006037447173470627
Loss at iteration [661]: 0.006030441774973628
Loss at iteration [662]: 0.006023461880745891
Loss at iteration [663]: 0.006016503783748403
Loss at iteration [664]: 0.006009569097407512
Loss at iteration [665]: 0.006002661097537316
Loss at iteration [666]: 0.005995779178316123
Loss at iteration [667]: 0.005988917402324607
Loss at iteration [668]: 0.005982086683587426
Loss at iteration [669]: 0.005975279910803353
Loss at iteration [670]: 0.005968498189781813
Loss at iteration [671]: 0.00596173753489067
Loss at iteration [672]: 0.005955000474526501
Loss at iteration [673]: 0.005948284089999473
Loss at iteration [674]: 0.0059415905458353015
Loss at iteration [675]: 0.005934917424603526
Loss at iteration [676]: 0.0059282633116474965
Loss at iteration [677]: 0.005921627660015832
Loss at iteration [678]: 0.005915011789500796
Loss at iteration [679]: 0.005908417978235028
Loss at iteration [680]: 0.005901846843917411
Loss at iteration [681]: 0.005895297103368891
Loss at iteration [682]: 0.005888766446160191
Loss at iteration [683]: 0.00588225717985156
Loss at iteration [684]: 0.005875771207815807
Loss at iteration [685]: 0.005869308148883444
Loss at iteration [686]: 0.005862864847588929
Loss at iteration [687]: 0.005856444538737966
Loss at iteration [688]: 0.005850045401292531
Loss at iteration [689]: 0.005843666312790216
Loss at iteration [690]: 0.005837306626655355
Loss at iteration [691]: 0.005830965691595826
Loss at iteration [692]: 0.005824642612364149
Loss at iteration [693]: 0.005818336784611513
Loss at iteration [694]: 0.00581205266877347
Loss at iteration [695]: 0.005805791110729518
Loss at iteration [696]: 0.005799548141956195
Loss at iteration [697]: 0.005793324403404371
Loss at iteration [698]: 0.005787119445546341
Loss at iteration [699]: 0.005780930519464578
Loss at iteration [700]: 0.005774757664305054
Loss at iteration [701]: 0.005768603331384325
Loss at iteration [702]: 0.005762468036622904
Loss at iteration [703]: 0.005756353026474464
Loss at iteration [704]: 0.005750257649667412
Loss at iteration [705]: 0.005744181334611441
Loss at iteration [706]: 0.005738122607557599
Loss at iteration [707]: 0.005732082937909662
Loss at iteration [708]: 0.0057260598938770986
Loss at iteration [709]: 0.005720055707500377
Loss at iteration [710]: 0.005714067077689098
Loss at iteration [711]: 0.00570809550192389
Loss at iteration [712]: 0.0057021420626475255
Loss at iteration [713]: 0.005696207137016496
Loss at iteration [714]: 0.005690289744046844
Loss at iteration [715]: 0.005684392772791421
Loss at iteration [716]: 0.005678514478129647
Loss at iteration [717]: 0.0056726547720465734
Loss at iteration [718]: 0.005666814998787509
Loss at iteration [719]: 0.0056609952215791685
Loss at iteration [720]: 0.005655195030260208
Loss at iteration [721]: 0.005649415238234688
Loss at iteration [722]: 0.005643653158411128
Loss at iteration [723]: 0.005637909359446662
Loss at iteration [724]: 0.00563218222789814
Loss at iteration [725]: 0.0056264732778054
Loss at iteration [726]: 0.005620782287908431
Loss at iteration [727]: 0.0056151053491463624
Loss at iteration [728]: 0.0056094415314821445
Loss at iteration [729]: 0.005603792023314585
Loss at iteration [730]: 0.00559815215869909
Loss at iteration [731]: 0.005592527266187731
Loss at iteration [732]: 0.005586917713417016
Loss at iteration [733]: 0.005581325834106486
Loss at iteration [734]: 0.0055757515725322355
Loss at iteration [735]: 0.005570195061811406
Loss at iteration [736]: 0.005564655378738365
Loss at iteration [737]: 0.005559131671635547
Loss at iteration [738]: 0.00555362468324139
Loss at iteration [739]: 0.005548132145076166
Loss at iteration [740]: 0.005542651406497073
Loss at iteration [741]: 0.005537184158205755
Loss at iteration [742]: 0.005531733328043739
Loss at iteration [743]: 0.005526296086875065
Loss at iteration [744]: 0.005520874350040683
Loss at iteration [745]: 0.005515467711953864
Loss at iteration [746]: 0.00551007559009955
Loss at iteration [747]: 0.005504699569022393
Loss at iteration [748]: 0.0054993381770164634
Loss at iteration [749]: 0.005493991252558994
Loss at iteration [750]: 0.005488658852745844
Loss at iteration [751]: 0.005483339691064269
Loss at iteration [752]: 0.005478034607031257
Loss at iteration [753]: 0.005472745764440507
Loss at iteration [754]: 0.005467466777453265
Loss at iteration [755]: 0.005462201502190996
Loss at iteration [756]: 0.005456952588734625
Loss at iteration [757]: 0.005451718765481466
Loss at iteration [758]: 0.00544650033058272
Loss at iteration [759]: 0.005441296450927187
Loss at iteration [760]: 0.005436107224529856
Loss at iteration [761]: 0.005430934413026301
Loss at iteration [762]: 0.005425775696599948
Loss at iteration [763]: 0.005420630557797314
Loss at iteration [764]: 0.005415497817535293
Loss at iteration [765]: 0.005410378585641246
Loss at iteration [766]: 0.005405272137859655
Loss at iteration [767]: 0.005400178670566744
Loss at iteration [768]: 0.005395098939721936
Loss at iteration [769]: 0.005390034918494369
Loss at iteration [770]: 0.0053849848910885725
Loss at iteration [771]: 0.005379956391808817
Loss at iteration [772]: 0.0053749446617332155
Loss at iteration [773]: 0.005369948026404387
Loss at iteration [774]: 0.005364965178426305
Loss at iteration [775]: 0.00535999795618724
Loss at iteration [776]: 0.0053550462341041515
Loss at iteration [777]: 0.005350108941295476
Loss at iteration [778]: 0.0053451850943035326
Loss at iteration [779]: 0.0053402744892849475
Loss at iteration [780]: 0.005335380486455463
Loss at iteration [781]: 0.005330504945574478
Loss at iteration [782]: 0.005325643137040484
Loss at iteration [783]: 0.005320795764383609
Loss at iteration [784]: 0.0053159647742369726
Loss at iteration [785]: 0.005311148250509041
Loss at iteration [786]: 0.0053063443867826885
Loss at iteration [787]: 0.005301552776919295
Loss at iteration [788]: 0.00529677916019875
Loss at iteration [789]: 0.005292039113703459
Loss at iteration [790]: 0.005287320636331437
Loss at iteration [791]: 0.005282621901203023
Loss at iteration [792]: 0.005277941536164384
Loss at iteration [793]: 0.005273282973338314
Loss at iteration [794]: 0.005268639515315692
Loss at iteration [795]: 0.005264010863508607
Loss at iteration [796]: 0.005259398780513752
Loss at iteration [797]: 0.005254803670210089
Loss at iteration [798]: 0.005250224672034395
Loss at iteration [799]: 0.005245658517627339
Loss at iteration [800]: 0.005241105021956664
Loss at iteration [801]: 0.00523656744068149
Loss at iteration [802]: 0.005232045154750202
Loss at iteration [803]: 0.005227535910247745
Loss at iteration [804]: 0.005223039197984873
Loss at iteration [805]: 0.00521855464982683
Loss at iteration [806]: 0.005214081467516922
Loss at iteration [807]: 0.005209620307418785
Loss at iteration [808]: 0.005205171430808058
Loss at iteration [809]: 0.0052007346686355135
Loss at iteration [810]: 0.005196311560687686
Loss at iteration [811]: 0.005191913654421231
Loss at iteration [812]: 0.005187529555142361
Loss at iteration [813]: 0.0051831574754518245
Loss at iteration [814]: 0.0051788000798369755
Loss at iteration [815]: 0.005174455502954776
Loss at iteration [816]: 0.005170126310165507
Loss at iteration [817]: 0.005165811171054089
Loss at iteration [818]: 0.005161511599526902
Loss at iteration [819]: 0.0051572366925166325
Loss at iteration [820]: 0.005152976067800264
Loss at iteration [821]: 0.005148728636677423
Loss at iteration [822]: 0.005144492772089153
Loss at iteration [823]: 0.005140269243398697
Loss at iteration [824]: 0.005136060906226301
Loss at iteration [825]: 0.005131865170449521
Loss at iteration [826]: 0.005127681653156053
Loss at iteration [827]: 0.005123509776194915
Loss at iteration [828]: 0.00511935383820195
Loss at iteration [829]: 0.00511521140258126
Loss at iteration [830]: 0.005111080769442461
Loss at iteration [831]: 0.005106962216114109
Loss at iteration [832]: 0.005102856970741764
Loss at iteration [833]: 0.005098761958806565
Loss at iteration [834]: 0.005094678124595098
Loss at iteration [835]: 0.0050906099058031
Loss at iteration [836]: 0.005086554140869201
Loss at iteration [837]: 0.005082510423755456
Loss at iteration [838]: 0.005078477060931029
Loss at iteration [839]: 0.005074454332884118
Loss at iteration [840]: 0.00507044320033216
Loss at iteration [841]: 0.005066441674555478
Loss at iteration [842]: 0.005062449696209096
Loss at iteration [843]: 0.005058467203374297
Loss at iteration [844]: 0.005054493784730421
Loss at iteration [845]: 0.005050529629131091
Loss at iteration [846]: 0.00504657455952631
Loss at iteration [847]: 0.005042628391463555
Loss at iteration [848]: 0.005038691792330072
Loss at iteration [849]: 0.005034764044387836
Loss at iteration [850]: 0.005030847109461723
Loss at iteration [851]: 0.0050269422482549005
Loss at iteration [852]: 0.005023048676487375
Loss at iteration [853]: 0.0050191652443360045
Loss at iteration [854]: 0.005015294344319304
Loss at iteration [855]: 0.005011433972835574
Loss at iteration [856]: 0.0050075832927132195
Loss at iteration [857]: 0.00500374169194938
Loss at iteration [858]: 0.004999910149573615
Loss at iteration [859]: 0.0049960898116338005
Loss at iteration [860]: 0.0049922786955311094
Loss at iteration [861]: 0.0049884763074617075
Loss at iteration [862]: 0.00498468379075203
Loss at iteration [863]: 0.004980900401987237
Loss at iteration [864]: 0.004977125427574299
Loss at iteration [865]: 0.004973358743944987
Loss at iteration [866]: 0.004969600817058907
Loss at iteration [867]: 0.00496585128805742
Loss at iteration [868]: 0.00496211109076349
Loss at iteration [869]: 0.0049583825872274185
Loss at iteration [870]: 0.004954664059516847
Loss at iteration [871]: 0.004950955403143669
Loss at iteration [872]: 0.004947258975102688
Loss at iteration [873]: 0.0049435748800166395
Loss at iteration [874]: 0.0049399008810430915
Loss at iteration [875]: 0.004936237505048893
Loss at iteration [876]: 0.004932583952405331
Loss at iteration [877]: 0.004928940386440032
Loss at iteration [878]: 0.00492530527947022
Loss at iteration [879]: 0.00492167871032762
Loss at iteration [880]: 0.004918060434622766
Loss at iteration [881]: 0.004914450176730989
Loss at iteration [882]: 0.004910848097085997
Loss at iteration [883]: 0.004907257252221575
Loss at iteration [884]: 0.00490367614272697
Loss at iteration [885]: 0.004900103764609334
Loss at iteration [886]: 0.0048965410545165336
Loss at iteration [887]: 0.0048929879281037645
Loss at iteration [888]: 0.004889443384733496
Loss at iteration [889]: 0.004885906747655011
Loss at iteration [890]: 0.004882378652638123
Loss at iteration [891]: 0.004878858562282863
Loss at iteration [892]: 0.0048753473879678865
Loss at iteration [893]: 0.004871846514010691
Loss at iteration [894]: 0.004868356093434632
Loss at iteration [895]: 0.004864876190330429
Loss at iteration [896]: 0.004861404831187933
Loss at iteration [897]: 0.004857942794441675
Loss at iteration [898]: 0.0048544896575952855
Loss at iteration [899]: 0.004851043823249912
Loss at iteration [900]: 0.004847605161090177
Loss at iteration [901]: 0.004844174550790847
Loss at iteration [902]: 0.004840752305755128
Loss at iteration [903]: 0.004837337294006293
Loss at iteration [904]: 0.004833929797303788
Loss at iteration [905]: 0.004830530304289494
Loss at iteration [906]: 0.004827137885429068
Loss at iteration [907]: 0.004823753028505815
Loss at iteration [908]: 0.00482037680018229
Loss at iteration [909]: 0.004817008130320017
Loss at iteration [910]: 0.004813646933621887
Loss at iteration [911]: 0.00481029279567151
Loss at iteration [912]: 0.004806947176213466
Loss at iteration [913]: 0.0048036135633864625
Loss at iteration [914]: 0.004800290228466979
Loss at iteration [915]: 0.00479697511701768
Loss at iteration [916]: 0.0047936691747368435
Loss at iteration [917]: 0.00479037190163627
Loss at iteration [918]: 0.0047870821446280715
Loss at iteration [919]: 0.00478379950484988
Loss at iteration [920]: 0.004780523826950799
Loss at iteration [921]: 0.004777256418383342
Loss at iteration [922]: 0.004773997131484524
Loss at iteration [923]: 0.004770745021886824
Loss at iteration [924]: 0.004767499805859114
Loss at iteration [925]: 0.004764261175595172
Loss at iteration [926]: 0.004761029894072604
Loss at iteration [927]: 0.004757806158979434
Loss at iteration [928]: 0.0047545893624570046
Loss at iteration [929]: 0.004751379846600727
Loss at iteration [930]: 0.004748177515145964
Loss at iteration [931]: 0.00474498219531837
Loss at iteration [932]: 0.004741793771701476
Loss at iteration [933]: 0.004738613391524161
Loss at iteration [934]: 0.004735442438864775
Loss at iteration [935]: 0.004732280063374328
Loss at iteration [936]: 0.004729124883017433
Loss at iteration [937]: 0.004725977736710439
Loss at iteration [938]: 0.004722838557064051
Loss at iteration [939]: 0.004719707379636228
Loss at iteration [940]: 0.00471658365763139
Loss at iteration [941]: 0.004713468817202983
Loss at iteration [942]: 0.004710362278658635
Loss at iteration [943]: 0.00470726275806133
Loss at iteration [944]: 0.004704170159414371
Loss at iteration [945]: 0.004701084203029179
Loss at iteration [946]: 0.004698004695629488
Loss at iteration [947]: 0.00469493338672845
Loss at iteration [948]: 0.004691870957975277
Loss at iteration [949]: 0.004688815417845307
Loss at iteration [950]: 0.004685766735493902
Loss at iteration [951]: 0.00468272556797033
Loss at iteration [952]: 0.004679692843844018
Loss at iteration [953]: 0.004676667151476065
Loss at iteration [954]: 0.004673648856242269
Loss at iteration [955]: 0.0046706377879484565
Loss at iteration [956]: 0.0046676329206170935
Loss at iteration [957]: 0.004664634667229593
Loss at iteration [958]: 0.004661643287362863
Loss at iteration [959]: 0.004658659595372578
Loss at iteration [960]: 0.004655683296472812
Loss at iteration [961]: 0.004652713457116616
Loss at iteration [962]: 0.0046497495346362995
Loss at iteration [963]: 0.004646791797312924
Loss at iteration [964]: 0.004643839691638689
Loss at iteration [965]: 0.00464089164730065
Loss at iteration [966]: 0.004637949997083567
Loss at iteration [967]: 0.004635014094741231
Loss at iteration [968]: 0.004632084307020738
Loss at iteration [969]: 0.004629160798617206
Loss at iteration [970]: 0.00462624474717386
Loss at iteration [971]: 0.004623335205185281
Loss at iteration [972]: 0.0046204331345830315
Loss at iteration [973]: 0.004617539670567648
Loss at iteration [974]: 0.004614652818603278
Loss at iteration [975]: 0.004611772300896265
Loss at iteration [976]: 0.00460889806197745
Loss at iteration [977]: 0.0046060300396554114
Loss at iteration [978]: 0.004603168627807389
Loss at iteration [979]: 0.004600313992453983
Loss at iteration [980]: 0.004597465484115831
Loss at iteration [981]: 0.004594622750167423
Loss at iteration [982]: 0.004591786172723611
Loss at iteration [983]: 0.004588955633526057
Loss at iteration [984]: 0.0045861309926189895
Loss at iteration [985]: 0.004583311919961254
Loss at iteration [986]: 0.00458049911588527
Loss at iteration [987]: 0.0045776924477717255
Loss at iteration [988]: 0.004574891725392722
Loss at iteration [989]: 0.004572097067089986
Loss at iteration [990]: 0.004569308861693277
Loss at iteration [991]: 0.004566526393814087
Loss at iteration [992]: 0.004563749565649147
Loss at iteration [993]: 0.004560978174124919
Loss at iteration [994]: 0.004558212497762347
Loss at iteration [995]: 0.004555452790386842
Loss at iteration [996]: 0.004552698423834671
Loss at iteration [997]: 0.004549949278340801
Loss at iteration [998]: 0.004547205578631694
Loss at iteration [999]: 0.004544467855594486
Loss at iteration [1000]: 0.004541736252658612
Loss at iteration [1001]: 0.0045390112102694545
Loss at iteration [1002]: 0.004536292388647065
Loss at iteration [1003]: 0.004533579579402535
Loss at iteration [1004]: 0.004530872755909769
Loss at iteration [1005]: 0.004528172249287762
Loss at iteration [1006]: 0.004525476957682558
Loss at iteration [1007]: 0.004522787297316656
Loss at iteration [1008]: 0.004520102873391471
Loss at iteration [1009]: 0.004517423745282098
Loss at iteration [1010]: 0.004514749853688704
Loss at iteration [1011]: 0.004512080665224915
Loss at iteration [1012]: 0.004509417737246256
Loss at iteration [1013]: 0.004506762886290143
Loss at iteration [1014]: 0.004504113587121184
Loss at iteration [1015]: 0.004501470885993642
Loss at iteration [1016]: 0.004498835644383678
Loss at iteration [1017]: 0.004496206220517267
Loss at iteration [1018]: 0.004493582371594262
Loss at iteration [1019]: 0.004490963773766457
Loss at iteration [1020]: 0.004488350009526612
Loss at iteration [1021]: 0.004485741428950945
Loss at iteration [1022]: 0.004483139445551639
Loss at iteration [1023]: 0.004480542707708728
Loss at iteration [1024]: 0.004477951754075283
Loss at iteration [1025]: 0.004475367078529877
Loss at iteration [1026]: 0.004472787591515739
Loss at iteration [1027]: 0.004470212991652174
Loss at iteration [1028]: 0.004467643103157582
Loss at iteration [1029]: 0.004465078189875578
Loss at iteration [1030]: 0.004462517843768885
Loss at iteration [1031]: 0.004459962274946113
Loss at iteration [1032]: 0.0044574119917399424
Loss at iteration [1033]: 0.004454867357870202
Loss at iteration [1034]: 0.004452324420924177
Loss at iteration [1035]: 0.004449786114711287
Loss at iteration [1036]: 0.004447252574651777
Loss at iteration [1037]: 0.004444724545154165
Loss at iteration [1038]: 0.004442202102352973
Loss at iteration [1039]: 0.0044396841715700335
Loss at iteration [1040]: 0.004437171226753224
Loss at iteration [1041]: 0.004434663549569667
Loss at iteration [1042]: 0.004432161608199013
Loss at iteration [1043]: 0.0044296660191901404
Loss at iteration [1044]: 0.004427179169628189
Loss at iteration [1045]: 0.0044247006400047134
Loss at iteration [1046]: 0.004422228671244068
Loss at iteration [1047]: 0.004419762791201364
Loss at iteration [1048]: 0.004417302733951758
Loss at iteration [1049]: 0.004414847894862755
Loss at iteration [1050]: 0.004412398133103176
Loss at iteration [1051]: 0.004409953243170446
Loss at iteration [1052]: 0.004407512959336282
Loss at iteration [1053]: 0.00440507718176506
Loss at iteration [1054]: 0.0044026460470664155
Loss at iteration [1055]: 0.004400219854852503
Loss at iteration [1056]: 0.004397799203960182
Loss at iteration [1057]: 0.004395381596602421
Loss at iteration [1058]: 0.00439296838005789
Loss at iteration [1059]: 0.004390559966818476
Loss at iteration [1060]: 0.004388155471283413
Loss at iteration [1061]: 0.0043857557821737865
Loss at iteration [1062]: 0.004383361764974194
Loss at iteration [1063]: 0.004380973244561307
Loss at iteration [1064]: 0.00437858993343406
Loss at iteration [1065]: 0.004376211438342038
Loss at iteration [1066]: 0.004373837380263128
Loss at iteration [1067]: 0.004371468231887472
Loss at iteration [1068]: 0.004369103835935067
Loss at iteration [1069]: 0.004366744349904932
Loss at iteration [1070]: 0.004364391911252954
Loss at iteration [1071]: 0.0043620446027905265
Loss at iteration [1072]: 0.004359702085976922
Loss at iteration [1073]: 0.004357364002961132
Loss at iteration [1074]: 0.004355031883643778
Loss at iteration [1075]: 0.004352704451089503
Loss at iteration [1076]: 0.0043503815189833445
Loss at iteration [1077]: 0.0043480639736671505
Loss at iteration [1078]: 0.004345751297305788
Loss at iteration [1079]: 0.004343443137112549
Loss at iteration [1080]: 0.004341139413920284
Loss at iteration [1081]: 0.004338840111635243
Loss at iteration [1082]: 0.004336545301968947
Loss at iteration [1083]: 0.004334254796344552
Loss at iteration [1084]: 0.00433196841331864
Loss at iteration [1085]: 0.004329687167127997
Loss at iteration [1086]: 0.004327410697387787
Loss at iteration [1087]: 0.004325138950726673
Loss at iteration [1088]: 0.00432287237401855
Loss at iteration [1089]: 0.004320611073114217
Loss at iteration [1090]: 0.004318355110888484
Loss at iteration [1091]: 0.004316104747769543
Loss at iteration [1092]: 0.004313859558479258
Loss at iteration [1093]: 0.004311618678616282
Loss at iteration [1094]: 0.004309382248141617
Loss at iteration [1095]: 0.004307150440463282
Loss at iteration [1096]: 0.0043049229074089545
Loss at iteration [1097]: 0.004302700103033583
Loss at iteration [1098]: 0.004300481629477756
Loss at iteration [1099]: 0.00429826779201786
Loss at iteration [1100]: 0.004296059427571098
Loss at iteration [1101]: 0.0042938567308877925
Loss at iteration [1102]: 0.004291658752040898
Loss at iteration [1103]: 0.004289465661522198
Loss at iteration [1104]: 0.004287277097695419
Loss at iteration [1105]: 0.004285092857459136
Loss at iteration [1106]: 0.004282912677354011
Loss at iteration [1107]: 0.0042807365192913055
Loss at iteration [1108]: 0.004278564615825724
Loss at iteration [1109]: 0.004276397921032842
Loss at iteration [1110]: 0.004274235743847152
Loss at iteration [1111]: 0.0042720778987659185
Loss at iteration [1112]: 0.0042699240045839726
Loss at iteration [1113]: 0.004267774775930152
Loss at iteration [1114]: 0.004265629902685361
Loss at iteration [1115]: 0.004263489610228693
Loss at iteration [1116]: 0.004261353845212416
Loss at iteration [1117]: 0.004259222247078617
Loss at iteration [1118]: 0.004257095427685489
Loss at iteration [1119]: 0.004254972482848998
Loss at iteration [1120]: 0.0042528535937571615
Loss at iteration [1121]: 0.004250738548813514
Loss at iteration [1122]: 0.004248627669980865
Loss at iteration [1123]: 0.004246519835269843
Loss at iteration [1124]: 0.0042444149655354825
Loss at iteration [1125]: 0.004242314005253702
Loss at iteration [1126]: 0.004240216541612358
Loss at iteration [1127]: 0.004238122156638648
Loss at iteration [1128]: 0.004236031581330145
Loss at iteration [1129]: 0.004233944889346996
Loss at iteration [1130]: 0.004231862082618855
Loss at iteration [1131]: 0.004229782987578571
Loss at iteration [1132]: 0.004227707684705781
Loss at iteration [1133]: 0.004225636101801764
Loss at iteration [1134]: 0.004223568428021522
Loss at iteration [1135]: 0.004221504656021429
Loss at iteration [1136]: 0.004219444572651179
Loss at iteration [1137]: 0.004217388241532104
Loss at iteration [1138]: 0.004215335941363273
Loss at iteration [1139]: 0.004213288091551412
Loss at iteration [1140]: 0.004211243740424626
Loss at iteration [1141]: 0.004209202905942045
Loss at iteration [1142]: 0.004207165866608858
Loss at iteration [1143]: 0.004205132352097046
Loss at iteration [1144]: 0.004203102436741468
Loss at iteration [1145]: 0.004201076361277154
Loss at iteration [1146]: 0.004199054444621594
Loss at iteration [1147]: 0.004197036180273502
Loss at iteration [1148]: 0.004195022214938387
Loss at iteration [1149]: 0.004193012952494247
Loss at iteration [1150]: 0.0041910080547126255
Loss at iteration [1151]: 0.004189007504748894
Loss at iteration [1152]: 0.004187010919072021
Loss at iteration [1153]: 0.004185018237844477
Loss at iteration [1154]: 0.004183029528242038
Loss at iteration [1155]: 0.004181044304808152
Loss at iteration [1156]: 0.004179062314137711
Loss at iteration [1157]: 0.0041770836933834295
Loss at iteration [1158]: 0.00417510838992322
Loss at iteration [1159]: 0.004173136816716205
Loss at iteration [1160]: 0.004171168735279744
Loss at iteration [1161]: 0.004169204166785511
Loss at iteration [1162]: 0.004167242649890734
Loss at iteration [1163]: 0.004165284225460168
Loss at iteration [1164]: 0.0041633285762302935
Loss at iteration [1165]: 0.004161376624270291
Loss at iteration [1166]: 0.004159427783298652
Loss at iteration [1167]: 0.004157482167477266
Loss at iteration [1168]: 0.004155540036323546
Loss at iteration [1169]: 0.0041536006916494455
Loss at iteration [1170]: 0.004151664835781098
Loss at iteration [1171]: 0.004149732947295786
Loss at iteration [1172]: 0.0041478071655187375
Loss at iteration [1173]: 0.004145885036593782
Loss at iteration [1174]: 0.004143966359165677
Loss at iteration [1175]: 0.004142051296504427
Loss at iteration [1176]: 0.0041401397186126305
Loss at iteration [1177]: 0.004138231212173262
Loss at iteration [1178]: 0.004136325347506298
Loss at iteration [1179]: 0.004134422352969361
Loss at iteration [1180]: 0.004132523099232998
Loss at iteration [1181]: 0.004130628347785209
Loss at iteration [1182]: 0.004128736759660175
Loss at iteration [1183]: 0.004126847619504983
Loss at iteration [1184]: 0.004124961789508587
Loss at iteration [1185]: 0.004123079455247773
Loss at iteration [1186]: 0.004121200095182103
Loss at iteration [1187]: 0.004119324662266354
Loss at iteration [1188]: 0.004117452141009233
Loss at iteration [1189]: 0.004115583250040677
Loss at iteration [1190]: 0.0041137180116435235
Loss at iteration [1191]: 0.004111856578283502
Loss at iteration [1192]: 0.004109999677661197
Loss at iteration [1193]: 0.004108146570179813
Loss at iteration [1194]: 0.004106296905156458
Loss at iteration [1195]: 0.00410445142188789
Loss at iteration [1196]: 0.004102609909318001
Loss at iteration [1197]: 0.00410077166470179
Loss at iteration [1198]: 0.004098936890634879
Loss at iteration [1199]: 0.004097104704798424
Loss at iteration [1200]: 0.004095275384938463
Loss at iteration [1201]: 0.004093449090946905
Loss at iteration [1202]: 0.004091625737906694
Loss at iteration [1203]: 0.004089805550868293
Loss at iteration [1204]: 0.004087988677692737
Loss at iteration [1205]: 0.004086174492361867
Loss at iteration [1206]: 0.004084362979740489
Loss at iteration [1207]: 0.0040825538606278754
Loss at iteration [1208]: 0.004080747268229939
Loss at iteration [1209]: 0.0040789441941076485
Loss at iteration [1210]: 0.004077144603389773
Loss at iteration [1211]: 0.004075346332207881
Loss at iteration [1212]: 0.0040735507656850245
Loss at iteration [1213]: 0.004071757949588225
Loss at iteration [1214]: 0.004069968615689109
Loss at iteration [1215]: 0.004068183270589581
Loss at iteration [1216]: 0.004066402277687645
Loss at iteration [1217]: 0.004064624458313267
Loss at iteration [1218]: 0.004062850823664291
Loss at iteration [1219]: 0.004061081263441349
Loss at iteration [1220]: 0.004059314635688243
Loss at iteration [1221]: 0.00405755006693431
Loss at iteration [1222]: 0.004055788260160967
Loss at iteration [1223]: 0.004054029940123406
Loss at iteration [1224]: 0.004052274709492742
Loss at iteration [1225]: 0.004050522576705189
Loss at iteration [1226]: 0.0040487734066184675
Loss at iteration [1227]: 0.004047027261717024
Loss at iteration [1228]: 0.004045284068502443
Loss at iteration [1229]: 0.004043543987050856
Loss at iteration [1230]: 0.004041806488364955
Loss at iteration [1231]: 0.0040400706446405464
Loss at iteration [1232]: 0.0040383381945070795
Loss at iteration [1233]: 0.004036608744217683
Loss at iteration [1234]: 0.004034882282954455
Loss at iteration [1235]: 0.0040331582520301565
Loss at iteration [1236]: 0.0040314364850132485
Loss at iteration [1237]: 0.004029717402078945
Loss at iteration [1238]: 0.00402800104078776
Loss at iteration [1239]: 0.004026287244242936
Loss at iteration [1240]: 0.004024576332410898
Loss at iteration [1241]: 0.00402286871153892
Loss at iteration [1242]: 0.004021164299749148
Loss at iteration [1243]: 0.004019462644194874
Loss at iteration [1244]: 0.004017763029765394
Loss at iteration [1245]: 0.004016066212288059
Loss at iteration [1246]: 0.004014372088427194
Loss at iteration [1247]: 0.00401268065270238
Loss at iteration [1248]: 0.004010991536115478
Loss at iteration [1249]: 0.004009305354158482
Loss at iteration [1250]: 0.004007622524655246
Loss at iteration [1251]: 0.004005942358350746
Loss at iteration [1252]: 0.00400426515152323
Loss at iteration [1253]: 0.004002590651458148
Loss at iteration [1254]: 0.004000918411154548
Loss at iteration [1255]: 0.0039992488405337055
Loss at iteration [1256]: 0.003997582109898664
Loss at iteration [1257]: 0.003995918134072366
Loss at iteration [1258]: 0.003994257219779593
Loss at iteration [1259]: 0.003992599161458289
Loss at iteration [1260]: 0.003990943831556918
Loss at iteration [1261]: 0.003989291453460534
Loss at iteration [1262]: 0.0039876422200150596
Loss at iteration [1263]: 0.003985995885797208
Loss at iteration [1264]: 0.003984351362287619
Loss at iteration [1265]: 0.003982709110783909
Loss at iteration [1266]: 0.003981068894134676
Loss at iteration [1267]: 0.003979431358043335
Loss at iteration [1268]: 0.003977796581871906
Loss at iteration [1269]: 0.003976164550164628
Loss at iteration [1270]: 0.00397453524840464
Loss at iteration [1271]: 0.003972908606740685
Loss at iteration [1272]: 0.003971285109371044
Loss at iteration [1273]: 0.003969664679394264
Loss at iteration [1274]: 0.003968045676165289
Loss at iteration [1275]: 0.003966428035202287
Loss at iteration [1276]: 0.003964812392613463
Loss at iteration [1277]: 0.003963199377514361
Loss at iteration [1278]: 0.003961588274356644
Loss at iteration [1279]: 0.003959978461386048
Loss at iteration [1280]: 0.003958371319213169
Loss at iteration [1281]: 0.003956767197483974
Loss at iteration [1282]: 0.003955165837056339
Loss at iteration [1283]: 0.00395356556224361
Loss at iteration [1284]: 0.003951968093948932
Loss at iteration [1285]: 0.0039503731494502925
Loss at iteration [1286]: 0.003948779635889743
Loss at iteration [1287]: 0.003947188382429502
Loss at iteration [1288]: 0.003945599354583709
Loss at iteration [1289]: 0.003944012853570026
Loss at iteration [1290]: 0.003942428898267507
Loss at iteration [1291]: 0.003940847679380748
Loss at iteration [1292]: 0.003939269444285217
Loss at iteration [1293]: 0.003937693492774161
Loss at iteration [1294]: 0.003936119232216138
Loss at iteration [1295]: 0.00393454777516519
Loss at iteration [1296]: 0.003932978840917209
Loss at iteration [1297]: 0.003931412151002332
Loss at iteration [1298]: 0.0039298481727240665
Loss at iteration [1299]: 0.003928285843550083
Loss at iteration [1300]: 0.00392672602092018
Loss at iteration [1301]: 0.003925167260184109
Loss at iteration [1302]: 0.0039236111482298785
Loss at iteration [1303]: 0.0039220575350319906
Loss at iteration [1304]: 0.003920505930634961
Loss at iteration [1305]: 0.003918957066561644
Loss at iteration [1306]: 0.00391741087204674
Loss at iteration [1307]: 0.003915867246469376
Loss at iteration [1308]: 0.003914326044673814
Loss at iteration [1309]: 0.003912787373118929
Loss at iteration [1310]: 0.003911251240274072
Loss at iteration [1311]: 0.003909717148893071
Loss at iteration [1312]: 0.003908185095815289
Loss at iteration [1313]: 0.003906654999010926
Loss at iteration [1314]: 0.0039051272560127926
Loss at iteration [1315]: 0.003903601905658037
Loss at iteration [1316]: 0.003902078823122877
Loss at iteration [1317]: 0.003900558090233086
Loss at iteration [1318]: 0.003899039652601125
Loss at iteration [1319]: 0.003897523686176799
Loss at iteration [1320]: 0.0038960105631334935
Loss at iteration [1321]: 0.003894500050774025
Loss at iteration [1322]: 0.0038929922157641874
Loss at iteration [1323]: 0.003891487106673036
Loss at iteration [1324]: 0.0038899846224101087
Loss at iteration [1325]: 0.003888484681120017
Loss at iteration [1326]: 0.003886987041534417
Loss at iteration [1327]: 0.003885492183374727
Loss at iteration [1328]: 0.003884000062130238
Loss at iteration [1329]: 0.0038825104328076504
Loss at iteration [1330]: 0.0038810237169717913
Loss at iteration [1331]: 0.003879539876971734
Loss at iteration [1332]: 0.0038780584363905597
Loss at iteration [1333]: 0.0038765797137238823
Loss at iteration [1334]: 0.0038751035246440513
Loss at iteration [1335]: 0.0038736296685041877
Loss at iteration [1336]: 0.003872158216338848
Loss at iteration [1337]: 0.0038706893594731805
Loss at iteration [1338]: 0.003869222986717406
Loss at iteration [1339]: 0.003867758813375992
Loss at iteration [1340]: 0.0038662969438716765
Loss at iteration [1341]: 0.00386483742852906
Loss at iteration [1342]: 0.0038633800749352147
Loss at iteration [1343]: 0.0038619252117406554
Loss at iteration [1344]: 0.0038604728692536337
Loss at iteration [1345]: 0.0038590223805653667
Loss at iteration [1346]: 0.0038575740623686917
Loss at iteration [1347]: 0.0038561279732914214
Loss at iteration [1348]: 0.0038546845465042296
Loss at iteration [1349]: 0.003853243951625947
Loss at iteration [1350]: 0.0038518057703658243
Loss at iteration [1351]: 0.0038503698029803894
Loss at iteration [1352]: 0.0038489361722661036
Loss at iteration [1353]: 0.003847504990491247
Loss at iteration [1354]: 0.003846075712104153
Loss at iteration [1355]: 0.003844648696777727
Loss at iteration [1356]: 0.0038432240415644425
Loss at iteration [1357]: 0.0038418015140899244
Loss at iteration [1358]: 0.0038403813658999483
Loss at iteration [1359]: 0.0038389637864531673
Loss at iteration [1360]: 0.003837548783031368
Loss at iteration [1361]: 0.0038361364091357452
Loss at iteration [1362]: 0.003834726378237598
Loss at iteration [1363]: 0.003833318630052516
Loss at iteration [1364]: 0.003831913651894802
Loss at iteration [1365]: 0.0038305109972714157
Loss at iteration [1366]: 0.0038291105026103953
Loss at iteration [1367]: 0.0038277121508091968
Loss at iteration [1368]: 0.0038263155773159553
Loss at iteration [1369]: 0.0038249212069809586
Loss at iteration [1370]: 0.003823529049999501
Loss at iteration [1371]: 0.00382213933007094
Loss at iteration [1372]: 0.003820751907521088
Loss at iteration [1373]: 0.0038193669272678452
Loss at iteration [1374]: 0.0038179842128468837
Loss at iteration [1375]: 0.00381660433752078
Loss at iteration [1376]: 0.0038152267540252395
Loss at iteration [1377]: 0.003813851443940773
Loss at iteration [1378]: 0.0038124783381712057
Loss at iteration [1379]: 0.0038111074168292076
Loss at iteration [1380]: 0.003809738750115682
Loss at iteration [1381]: 0.003808372367670873
Loss at iteration [1382]: 0.0038070080851896164
Loss at iteration [1383]: 0.003805645913230922
Loss at iteration [1384]: 0.003804286128417871
Loss at iteration [1385]: 0.0038029282636495073
Loss at iteration [1386]: 0.003801572625914265
Loss at iteration [1387]: 0.0038002194997657393
Loss at iteration [1388]: 0.003798868642273076
Loss at iteration [1389]: 0.003797520337797783
Loss at iteration [1390]: 0.003796174439362008
Loss at iteration [1391]: 0.0037948307503672413
Loss at iteration [1392]: 0.003793488965782849
Loss at iteration [1393]: 0.003792148915046234
Loss at iteration [1394]: 0.0037908117108884035
Loss at iteration [1395]: 0.0037894762816824998
Loss at iteration [1396]: 0.0037881423591586386
Loss at iteration [1397]: 0.0037868106969397653
Loss at iteration [1398]: 0.0037854810864219727
Loss at iteration [1399]: 0.0037841536337449243
Loss at iteration [1400]: 0.003782828305660438
Loss at iteration [1401]: 0.003781505135481872
Loss at iteration [1402]: 0.003780184324264764
Loss at iteration [1403]: 0.0037788653756344877
Loss at iteration [1404]: 0.003777548269233427
Loss at iteration [1405]: 0.0037762333297266595
Loss at iteration [1406]: 0.00377492073653239
Loss at iteration [1407]: 0.0037736101772999375
Loss at iteration [1408]: 0.003772301682984654
Loss at iteration [1409]: 0.003770995272729803
Loss at iteration [1410]: 0.0037696906147940347
Loss at iteration [1411]: 0.003768388156328835
Loss at iteration [1412]: 0.003767088079157693
Loss at iteration [1413]: 0.003765790332433421
Loss at iteration [1414]: 0.003764495098712514
Loss at iteration [1415]: 0.003763201889489528
Loss at iteration [1416]: 0.003761910641335355
Loss at iteration [1417]: 0.0037606214321307444
Loss at iteration [1418]: 0.00375933404228326
Loss at iteration [1419]: 0.003758047841182674
Loss at iteration [1420]: 0.003756762721526669
Loss at iteration [1421]: 0.0037554786933230518
Loss at iteration [1422]: 0.0037541962953478564
Loss at iteration [1423]: 0.003752915533568571
Loss at iteration [1424]: 0.0037516367838219284
Loss at iteration [1425]: 0.0037503598699358725
Loss at iteration [1426]: 0.0037490844979394164
Loss at iteration [1427]: 0.0037478096461648143
Loss at iteration [1428]: 0.003746535442656258
Loss at iteration [1429]: 0.0037452629463402246
Loss at iteration [1430]: 0.0037439922298453054
Loss at iteration [1431]: 0.003742723821644205
Loss at iteration [1432]: 0.003741457259372887
Loss at iteration [1433]: 0.0037401927443895915
Loss at iteration [1434]: 0.0037389301188427973
Loss at iteration [1435]: 0.0037376693587783997
Loss at iteration [1436]: 0.0037364107433362
Loss at iteration [1437]: 0.003735154395235113
Loss at iteration [1438]: 0.00373389988614676
Loss at iteration [1439]: 0.003732647236809186
Loss at iteration [1440]: 0.0037313967383567955
Loss at iteration [1441]: 0.0037301481570164783
Loss at iteration [1442]: 0.0037289019307087017
Loss at iteration [1443]: 0.003727657943335664
Loss at iteration [1444]: 0.0037264158985826266
Loss at iteration [1445]: 0.0037251758100648015
Loss at iteration [1446]: 0.0037239378816591555
Loss at iteration [1447]: 0.0037227019255389633
Loss at iteration [1448]: 0.0037214680826467704
Loss at iteration [1449]: 0.0037202357868917277
Loss at iteration [1450]: 0.0037190083885441957
Loss at iteration [1451]: 0.003717783079814209
Loss at iteration [1452]: 0.0037165600048644602
Loss at iteration [1453]: 0.0037153385721528905
Loss at iteration [1454]: 0.003714118487718989
Loss at iteration [1455]: 0.003712900219132121
Loss at iteration [1456]: 0.003711683939690874
Loss at iteration [1457]: 0.0037104692936632236
Loss at iteration [1458]: 0.003709256575537712
Loss at iteration [1459]: 0.003708045810870409
Loss at iteration [1460]: 0.0037068368945677036
Loss at iteration [1461]: 0.00370563014358005
Loss at iteration [1462]: 0.0037044251036429067
Loss at iteration [1463]: 0.003703221857715547
Loss at iteration [1464]: 0.0037020204021106663
Loss at iteration [1465]: 0.003700820887907054
Loss at iteration [1466]: 0.003699623517765273
Loss at iteration [1467]: 0.0036984286049696023
Loss at iteration [1468]: 0.0036972356583228217
Loss at iteration [1469]: 0.0036960448099342047
Loss at iteration [1470]: 0.0036948561705746064
Loss at iteration [1471]: 0.0036936694218411906
Loss at iteration [1472]: 0.0036924841088475384
Loss at iteration [1473]: 0.003691300597762252
Loss at iteration [1474]: 0.0036901189341139768
Loss at iteration [1475]: 0.003688938831939624
Loss at iteration [1476]: 0.003687760569601361
Loss at iteration [1477]: 0.0036865839873371853
Loss at iteration [1478]: 0.003685409137300344
Loss at iteration [1479]: 0.0036842360834511033
Loss at iteration [1480]: 0.0036830646082253856
Loss at iteration [1481]: 0.003681895089126017
Loss at iteration [1482]: 0.0036807273565860714
Loss at iteration [1483]: 0.0036795612779080243
Loss at iteration [1484]: 0.0036783973973747632
Loss at iteration [1485]: 0.0036772345307148667
Loss at iteration [1486]: 0.0036760737086779585
Loss at iteration [1487]: 0.0036749142099162246
Loss at iteration [1488]: 0.003673756586291336
Loss at iteration [1489]: 0.003672600681083847
Loss at iteration [1490]: 0.003671446565148376
Loss at iteration [1491]: 0.0036702940807633072
Loss at iteration [1492]: 0.003669143170841011
Loss at iteration [1493]: 0.003667993981978001
Loss at iteration [1494]: 0.003666846351230926
Loss at iteration [1495]: 0.003665700576091268
Loss at iteration [1496]: 0.003664556530752298
Loss at iteration [1497]: 0.0036634142020440874
Loss at iteration [1498]: 0.0036622736250095456
Loss at iteration [1499]: 0.0036611345247616845
Loss at iteration [1500]: 0.003659997203400349
Loss at iteration [1501]: 0.0036588615906422046
Loss at iteration [1502]: 0.003657727517135308
Loss at iteration [1503]: 0.0036565949840149554
Loss at iteration [1504]: 0.003655464134472646
Loss at iteration [1505]: 0.0036543349678295816
Loss at iteration [1506]: 0.0036532074025581096
Loss at iteration [1507]: 0.003652081656925318
Loss at iteration [1508]: 0.003650957582305594
Loss at iteration [1509]: 0.003649835177012804
Loss at iteration [1510]: 0.0036487148811634733
Loss at iteration [1511]: 0.0036475956053045235
Loss at iteration [1512]: 0.0036464755961465997
Loss at iteration [1513]: 0.003645356850621834
Loss at iteration [1514]: 0.00364423931847636
Loss at iteration [1515]: 0.0036431235964445334
Loss at iteration [1516]: 0.0036420095340812058
Loss at iteration [1517]: 0.0036408975501877254
Loss at iteration [1518]: 0.003639787386672308
Loss at iteration [1519]: 0.003638679272684651
Loss at iteration [1520]: 0.0036375728632251077
Loss at iteration [1521]: 0.0036364680063428172
Loss at iteration [1522]: 0.0036353651063740573
Loss at iteration [1523]: 0.0036342637384123543
Loss at iteration [1524]: 0.003633163956767414
Loss at iteration [1525]: 0.003632067379048825
Loss at iteration [1526]: 0.003630974336236071
Loss at iteration [1527]: 0.00362988392470379
Loss at iteration [1528]: 0.003628795220546242
Loss at iteration [1529]: 0.003627707987629017
Loss at iteration [1530]: 0.003626622320370006
Loss at iteration [1531]: 0.00362553837075065
Loss at iteration [1532]: 0.0036244558369079066
Loss at iteration [1533]: 0.003623375111708028
Loss at iteration [1534]: 0.003622296666513275
Loss at iteration [1535]: 0.003621220089894721
Loss at iteration [1536]: 0.0036201453115483426
Loss at iteration [1537]: 0.0036190717994402525
Loss at iteration [1538]: 0.0036179999435642495
Loss at iteration [1539]: 0.0036169297683714434
Loss at iteration [1540]: 0.003615861456746179
Loss at iteration [1541]: 0.0036147949996824832
Loss at iteration [1542]: 0.003613730167843366
Loss at iteration [1543]: 0.0036126673402107085
Loss at iteration [1544]: 0.0036116062603947945
Loss at iteration [1545]: 0.003610546622155818
Loss at iteration [1546]: 0.003609488304284074
Loss at iteration [1547]: 0.0036084314463742536
Loss at iteration [1548]: 0.0036073762377960006
Loss at iteration [1549]: 0.003606322490551627
Loss at iteration [1550]: 0.0036052704263927426
Loss at iteration [1551]: 0.0036042198529830853
Loss at iteration [1552]: 0.003603171078652376
Loss at iteration [1553]: 0.0036021237819420723
Loss at iteration [1554]: 0.003601077505735493
Loss at iteration [1555]: 0.003600031854933845
Loss at iteration [1556]: 0.003598986894426125
Loss at iteration [1557]: 0.0035979431498649873
Loss at iteration [1558]: 0.0035969002527065667
Loss at iteration [1559]: 0.003595858573589496
Loss at iteration [1560]: 0.00359481853947702
Loss at iteration [1561]: 0.003593780311526639
Loss at iteration [1562]: 0.003592743969715696
Loss at iteration [1563]: 0.003591710076199444
Loss at iteration [1564]: 0.0035906779505412148
Loss at iteration [1565]: 0.0035896473501200775
Loss at iteration [1566]: 0.0035886180300929117
Loss at iteration [1567]: 0.0035875904186640456
Loss at iteration [1568]: 0.0035865642803532705
Loss at iteration [1569]: 0.003585539710761441
Loss at iteration [1570]: 0.0035845155979937204
Loss at iteration [1571]: 0.0035834931121022902
Loss at iteration [1572]: 0.0035824724741008404
Loss at iteration [1573]: 0.0035814531901136176
Loss at iteration [1574]: 0.003580435546186868
Loss at iteration [1575]: 0.0035794195870027926
Loss at iteration [1576]: 0.0035784055730175893
Loss at iteration [1577]: 0.003577393389899608
Loss at iteration [1578]: 0.003576382678911765
Loss at iteration [1579]: 0.0035753733266148517
Loss at iteration [1580]: 0.0035743657302259656
Loss at iteration [1581]: 0.003573359703664157
Loss at iteration [1582]: 0.0035723553071102536
Loss at iteration [1583]: 0.003571352823217917
Loss at iteration [1584]: 0.003570351476102607
Loss at iteration [1585]: 0.0035693518811481173
Loss at iteration [1586]: 0.003568354082151714
Loss at iteration [1587]: 0.003567357928489241
Loss at iteration [1588]: 0.0035663632924654975
Loss at iteration [1589]: 0.0035653700164136226
Loss at iteration [1590]: 0.0035643784516271866
Loss at iteration [1591]: 0.0035633883065995997
Loss at iteration [1592]: 0.0035623990293843196
Loss at iteration [1593]: 0.0035614098664509667
Loss at iteration [1594]: 0.0035604216312979707
Loss at iteration [1595]: 0.003559434774544427
Loss at iteration [1596]: 0.003558449028738276
Loss at iteration [1597]: 0.0035574649752131925
Loss at iteration [1598]: 0.0035564829268646195
Loss at iteration [1599]: 0.0035555023373113025
Loss at iteration [1600]: 0.003554523441284733
Loss at iteration [1601]: 0.0035535457931173075
Loss at iteration [1602]: 0.003552569499565736
Loss at iteration [1603]: 0.0035515945857006767
Loss at iteration [1604]: 0.0035506206598883506
Loss at iteration [1605]: 0.0035496482415566877
Loss at iteration [1606]: 0.0035486771892411064
Loss at iteration [1607]: 0.0035477074589132093
Loss at iteration [1608]: 0.0035467390976241502
Loss at iteration [1609]: 0.003545772033636496
Loss at iteration [1610]: 0.0035448064842504455
Loss at iteration [1611]: 0.0035438423700797916
Loss at iteration [1612]: 0.003542879635567023
Loss at iteration [1613]: 0.0035419182654263253
Loss at iteration [1614]: 0.0035409586195415386
Loss at iteration [1615]: 0.0035400005661788245
Loss at iteration [1616]: 0.003539044071754599
Loss at iteration [1617]: 0.003538088886526672
Loss at iteration [1618]: 0.0035371351299884743
Loss at iteration [1619]: 0.00353618268308527
Loss at iteration [1620]: 0.0035352315750768457
Loss at iteration [1621]: 0.0035342818730130076
Loss at iteration [1622]: 0.003533333825125487
Loss at iteration [1623]: 0.0035323871852929747
Loss at iteration [1624]: 0.003531442069309316
Loss at iteration [1625]: 0.003530498352744781
Loss at iteration [1626]: 0.0035295560128926987
Loss at iteration [1627]: 0.0035286149094886144
Loss at iteration [1628]: 0.0035276749600102668
Loss at iteration [1629]: 0.0035267363715023293
Loss at iteration [1630]: 0.0035257994125716292
Loss at iteration [1631]: 0.0035248646967873795
Loss at iteration [1632]: 0.0035239346109649607
Loss at iteration [1633]: 0.003523006979226055
Loss at iteration [1634]: 0.0035220793456769805
Loss at iteration [1635]: 0.003521155311205795
Loss at iteration [1636]: 0.0035202385335144333
Loss at iteration [1637]: 0.003519323755094888
Loss at iteration [1638]: 0.0035184100118963056
Loss at iteration [1639]: 0.00351749744145645
Loss at iteration [1640]: 0.0035165864566238433
Loss at iteration [1641]: 0.0035156765601637714
Loss at iteration [1642]: 0.0035147680086757053
Loss at iteration [1643]: 0.003513860760876765
Loss at iteration [1644]: 0.003512954728365578
Loss at iteration [1645]: 0.0035120498367508524
Loss at iteration [1646]: 0.0035111461981738577
Loss at iteration [1647]: 0.0035102441113725627
Loss at iteration [1648]: 0.003509343388966652
Loss at iteration [1649]: 0.0035084438446760435
Loss at iteration [1650]: 0.003507544900772867
Loss at iteration [1651]: 0.0035066469558436906
Loss at iteration [1652]: 0.003505750344148921
Loss at iteration [1653]: 0.0035048548755221356
Loss at iteration [1654]: 0.0035039605403870246
Loss at iteration [1655]: 0.003503067219410158
Loss at iteration [1656]: 0.0035021751955654186
Loss at iteration [1657]: 0.003501284380507788
Loss at iteration [1658]: 0.003500394952290212
Loss at iteration [1659]: 0.0034995073002542934
Loss at iteration [1660]: 0.00349862113445995
Loss at iteration [1661]: 0.003497736498937665
Loss at iteration [1662]: 0.0034968528930450246
Loss at iteration [1663]: 0.0034959705084029527
Loss at iteration [1664]: 0.003495089618941067
Loss at iteration [1665]: 0.0034942097548454607
Loss at iteration [1666]: 0.003493329258203225
Loss at iteration [1667]: 0.0034924497575585176
Loss at iteration [1668]: 0.003491571287244425
Loss at iteration [1669]: 0.0034906939707223536
Loss at iteration [1670]: 0.0034898179663038543
Loss at iteration [1671]: 0.003488943332918687
Loss at iteration [1672]: 0.0034880701708257097
Loss at iteration [1673]: 0.0034871984410690293
Loss at iteration [1674]: 0.0034863283610243267
Loss at iteration [1675]: 0.0034854597040898196
Loss at iteration [1676]: 0.003484592115144311
Loss at iteration [1677]: 0.0034837251582788805
Loss at iteration [1678]: 0.003482859441181951
Loss at iteration [1679]: 0.0034819947400195153
Loss at iteration [1680]: 0.0034811312685614775
Loss at iteration [1681]: 0.0034802694051865573
Loss at iteration [1682]: 0.003479409413048323
Loss at iteration [1683]: 0.003478551720583681
Loss at iteration [1684]: 0.0034776971615827885
Loss at iteration [1685]: 0.003476844340912101
Loss at iteration [1686]: 0.0034759928449467985
Loss at iteration [1687]: 0.003475142407430741
Loss at iteration [1688]: 0.0034742932864663314
Loss at iteration [1689]: 0.003473445363605235
Loss at iteration [1690]: 0.0034725990523088884
Loss at iteration [1691]: 0.0034717551207774627
Loss at iteration [1692]: 0.0034709125991337735
Loss at iteration [1693]: 0.003470072606062816
Loss at iteration [1694]: 0.00346923410931599
Loss at iteration [1695]: 0.0034683969606740467
Loss at iteration [1696]: 0.003467561025190438
Loss at iteration [1697]: 0.003466727005145358
Loss at iteration [1698]: 0.00346589458230989
Loss at iteration [1699]: 0.003465063553788356
Loss at iteration [1700]: 0.0034642339765768217
Loss at iteration [1701]: 0.0034634054914861514
Loss at iteration [1702]: 0.003462578260426762
Loss at iteration [1703]: 0.0034617522004616393
Loss at iteration [1704]: 0.0034609274599648903
Loss at iteration [1705]: 0.00346010422700442
Loss at iteration [1706]: 0.0034592832679359205
Loss at iteration [1707]: 0.003458463852601312
Loss at iteration [1708]: 0.003457645965853788
Loss at iteration [1709]: 0.0034568291650170775
Loss at iteration [1710]: 0.0034560136586792257
Loss at iteration [1711]: 0.0034551991274990594
Loss at iteration [1712]: 0.0034543858290468194
Loss at iteration [1713]: 0.003453573919411717
Loss at iteration [1714]: 0.0034527632373669327
Loss at iteration [1715]: 0.0034519535183970933
Loss at iteration [1716]: 0.003451145195483745
Loss at iteration [1717]: 0.0034503379783398804
Loss at iteration [1718]: 0.0034495318824163406
Loss at iteration [1719]: 0.0034487269318463154
Loss at iteration [1720]: 0.003447923137373426
Loss at iteration [1721]: 0.0034471204911372105
Loss at iteration [1722]: 0.0034463190016149497
Loss at iteration [1723]: 0.0034455185462730076
Loss at iteration [1724]: 0.0034447188095287173
Loss at iteration [1725]: 0.003443919489135899
Loss at iteration [1726]: 0.0034431210586156817
Loss at iteration [1727]: 0.003442323645856039
Loss at iteration [1728]: 0.0034415269650245285
Loss at iteration [1729]: 0.0034407313785080403
Loss at iteration [1730]: 0.0034399367380238987
Loss at iteration [1731]: 0.003439143320764389
Loss at iteration [1732]: 0.0034383515305209597
Loss at iteration [1733]: 0.0034375611877976416
Loss at iteration [1734]: 0.003436772158985359
Loss at iteration [1735]: 0.003435984352587845
Loss at iteration [1736]: 0.003435197859143703
Loss at iteration [1737]: 0.0034344131843145735
Loss at iteration [1738]: 0.003433629720401199
Loss at iteration [1739]: 0.0034328473234299323
Loss at iteration [1740]: 0.0034320661604847797
Loss at iteration [1741]: 0.0034312864320598046
Loss at iteration [1742]: 0.0034305077808652303
Loss at iteration [1743]: 0.003429730321979782
Loss at iteration [1744]: 0.003428953921860301
Loss at iteration [1745]: 0.0034281785688981587
Loss at iteration [1746]: 0.0034274049948463605
Loss at iteration [1747]: 0.003426632919547214
Loss at iteration [1748]: 0.003425861997038376
Loss at iteration [1749]: 0.003425092427729933
Loss at iteration [1750]: 0.003424324089214626
Loss at iteration [1751]: 0.0034235567773819426
Loss at iteration [1752]: 0.0034227906684007043
Loss at iteration [1753]: 0.003422026299825356
Loss at iteration [1754]: 0.0034212646212817125
Loss at iteration [1755]: 0.003420504551986769
Loss at iteration [1756]: 0.0034197457226882873
Loss at iteration [1757]: 0.0034189881768780703
Loss at iteration [1758]: 0.0034182317657657567
Loss at iteration [1759]: 0.0034174768107056905
Loss at iteration [1760]: 0.0034167236297676686
Loss at iteration [1761]: 0.0034159715809099172
Loss at iteration [1762]: 0.003415220663888545
Loss at iteration [1763]: 0.003414470774905529
Loss at iteration [1764]: 0.0034137219187429274
Loss at iteration [1765]: 0.0034129747040519726
Loss at iteration [1766]: 0.003412230866806198
Loss at iteration [1767]: 0.0034114885892480556
Loss at iteration [1768]: 0.0034107476641382513
Loss at iteration [1769]: 0.0034100079093636214
Loss at iteration [1770]: 0.00340926923910737
Loss at iteration [1771]: 0.003408531549228544
Loss at iteration [1772]: 0.003407794950755666
Loss at iteration [1773]: 0.003407059550596738
Loss at iteration [1774]: 0.003406325243879495
Loss at iteration [1775]: 0.0034055919321981545
Loss at iteration [1776]: 0.0034048595437013106
Loss at iteration [1777]: 0.0034041284403870417
Loss at iteration [1778]: 0.0034033986234586542
Loss at iteration [1779]: 0.0034026701698533393
Loss at iteration [1780]: 0.0034019429835708778
Loss at iteration [1781]: 0.0034012171576745798
Loss at iteration [1782]: 0.003400491825581755
Loss at iteration [1783]: 0.0033997674428299838
Loss at iteration [1784]: 0.003399044051852167
Loss at iteration [1785]: 0.003398321712878403
Loss at iteration [1786]: 0.0033976003374437238
Loss at iteration [1787]: 0.0033968800030207795
Loss at iteration [1788]: 0.0033961609914414667
Loss at iteration [1789]: 0.003395442951341511
Loss at iteration [1790]: 0.0033947259084355507
Loss at iteration [1791]: 0.003394009553508061
Loss at iteration [1792]: 0.0033932942298965816
Loss at iteration [1793]: 0.0033925799679447185
Loss at iteration [1794]: 0.0033918665767577677
Loss at iteration [1795]: 0.0033911541581122607
Loss at iteration [1796]: 0.0033904427081734843
Loss at iteration [1797]: 0.00338973244988764
Loss at iteration [1798]: 0.0033890231924505855
Loss at iteration [1799]: 0.0033883150020893624
Loss at iteration [1800]: 0.003387607719560913
Loss at iteration [1801]: 0.0033869014963110325
Loss at iteration [1802]: 0.003386196333771719
Loss at iteration [1803]: 0.0033854922197531197
Loss at iteration [1804]: 0.003384789105792699
Loss at iteration [1805]: 0.0033840872104140504
Loss at iteration [1806]: 0.003383386185820955
Loss at iteration [1807]: 0.003382685992047877
Loss at iteration [1808]: 0.003381987779288361
Loss at iteration [1809]: 0.0033812905581702022
Loss at iteration [1810]: 0.0033805943236669043
Loss at iteration [1811]: 0.0033798990471146004
Loss at iteration [1812]: 0.003379204735391366
Loss at iteration [1813]: 0.0033785115873200774
Loss at iteration [1814]: 0.003377819366578367
Loss at iteration [1815]: 0.003377127947541765
Loss at iteration [1816]: 0.003376437277168399
Loss at iteration [1817]: 0.0033757474766830733
Loss at iteration [1818]: 0.003375058573032472
Loss at iteration [1819]: 0.0033743706654139867
Loss at iteration [1820]: 0.0033736837277600867
Loss at iteration [1821]: 0.0033729977485995534
Loss at iteration [1822]: 0.0033723127406161076
Loss at iteration [1823]: 0.0033716287221076074
Loss at iteration [1824]: 0.003370945601021891
Loss at iteration [1825]: 0.0033702635064457556
Loss at iteration [1826]: 0.0033695824855914723
Loss at iteration [1827]: 0.003368902460867797
Loss at iteration [1828]: 0.0033682229223905708
Loss at iteration [1829]: 0.0033675439492926876
Loss at iteration [1830]: 0.0033668658029942667
Loss at iteration [1831]: 0.0033661894958702957
Loss at iteration [1832]: 0.003365514783240421
Loss at iteration [1833]: 0.0033648416466691058
Loss at iteration [1834]: 0.003364169555065601
Loss at iteration [1835]: 0.0033634985702051395
Loss at iteration [1836]: 0.0033628295600732242
Loss at iteration [1837]: 0.003362164458885208
Loss at iteration [1838]: 0.00336150084674094
Loss at iteration [1839]: 0.0033608385324852713
Loss at iteration [1840]: 0.0033601774783779542
Loss at iteration [1841]: 0.0033595174536107967
Loss at iteration [1842]: 0.0033588585314604483
Loss at iteration [1843]: 0.0033582006121463935
Loss at iteration [1844]: 0.0033575435339129123
Loss at iteration [1845]: 0.0033568874640889684
Loss at iteration [1846]: 0.0033562323458192823
Loss at iteration [1847]: 0.0033555781708187985
Loss at iteration [1848]: 0.0033549246681374625
Loss at iteration [1849]: 0.003354271891257196
Loss at iteration [1850]: 0.003353620027735605
Loss at iteration [1851]: 0.0033529691711950025
Loss at iteration [1852]: 0.003352318762330339
Loss at iteration [1853]: 0.0033516679824920972
Loss at iteration [1854]: 0.003351017845435281
Loss at iteration [1855]: 0.003350367802226758
Loss at iteration [1856]: 0.0033497181612847974
Loss at iteration [1857]: 0.003349069137349007
Loss at iteration [1858]: 0.0033484208741808756
Loss at iteration [1859]: 0.003347776040493737
Loss at iteration [1860]: 0.00334713199898247
Loss at iteration [1861]: 0.0033464892600792305
Loss at iteration [1862]: 0.0033458478203419787
Loss at iteration [1863]: 0.00334520796573126
Loss at iteration [1864]: 0.003344570108720778
Loss at iteration [1865]: 0.003343933158649411
Loss at iteration [1866]: 0.00334329731155752
Loss at iteration [1867]: 0.0033426622141648457
Loss at iteration [1868]: 0.003342027912271764
Loss at iteration [1869]: 0.0033413943950591158
Loss at iteration [1870]: 0.003340761934661567
Loss at iteration [1871]: 0.0033401301384864295
Loss at iteration [1872]: 0.0033394990064559045
Loss at iteration [1873]: 0.003338868674969672
Loss at iteration [1874]: 0.003338239100414374
Loss at iteration [1875]: 0.00333761031539085
Loss at iteration [1876]: 0.003336982421939534
Loss at iteration [1877]: 0.003336355203736163
Loss at iteration [1878]: 0.0033357289170935335
Loss at iteration [1879]: 0.003335103432888365
Loss at iteration [1880]: 0.0033344788066810164
Loss at iteration [1881]: 0.0033338550786878186
Loss at iteration [1882]: 0.0033332315462056674
Loss at iteration [1883]: 0.0033326088651421436
Loss at iteration [1884]: 0.0033319873656163625
Loss at iteration [1885]: 0.0033313667510815916
Loss at iteration [1886]: 0.0033307469869587256
Loss at iteration [1887]: 0.003330128111896677
Loss at iteration [1888]: 0.0033295100793926677
Loss at iteration [1889]: 0.0033288928670882055
Loss at iteration [1890]: 0.0033282765272386106
Loss at iteration [1891]: 0.0033276606613646467
Loss at iteration [1892]: 0.0033270457419940767
Loss at iteration [1893]: 0.003326431644591087
Loss at iteration [1894]: 0.0033258182943026625
Loss at iteration [1895]: 0.003325205747506582
Loss at iteration [1896]: 0.0033245942569120465
Loss at iteration [1897]: 0.003323983506191419
Loss at iteration [1898]: 0.0033233738269416685
Loss at iteration [1899]: 0.003322765051016152
Loss at iteration [1900]: 0.003322157298064021
Loss at iteration [1901]: 0.0033215506311850187
Loss at iteration [1902]: 0.0033209447513117872
Loss at iteration [1903]: 0.003320339862822373
Loss at iteration [1904]: 0.0033197357588506888
Loss at iteration [1905]: 0.003319132379972855
Loss at iteration [1906]: 0.003318529670544249
Loss at iteration [1907]: 0.0033179277593411547
Loss at iteration [1908]: 0.0033173267160981203
Loss at iteration [1909]: 0.003316726522570169
Loss at iteration [1910]: 0.0033161272326997313
Loss at iteration [1911]: 0.003315528925340276
Loss at iteration [1912]: 0.0033149314591118823
Loss at iteration [1913]: 0.003314334867595411
Loss at iteration [1914]: 0.0033137392034499323
Loss at iteration [1915]: 0.003313144170451195
Loss at iteration [1916]: 0.0033125493871664614
Loss at iteration [1917]: 0.003311955240044782
Loss at iteration [1918]: 0.003311362228180086
Loss at iteration [1919]: 0.003310770195382469
Loss at iteration [1920]: 0.0033101791537899217
Loss at iteration [1921]: 0.0033095890030655447
Loss at iteration [1922]: 0.003308999732110749
Loss at iteration [1923]: 0.0033084115739732156
Loss at iteration [1924]: 0.0033078243009759074
Loss at iteration [1925]: 0.0033072378895155088
Loss at iteration [1926]: 0.0033066524540968875
Loss at iteration [1927]: 0.003306067745611772
Loss at iteration [1928]: 0.003305483795535843
Loss at iteration [1929]: 0.0033049006062815327
Loss at iteration [1930]: 0.003304318032279312
Loss at iteration [1931]: 0.0033037358898070153
Loss at iteration [1932]: 0.003303154387407702
Loss at iteration [1933]: 0.0033025736000390597
Loss at iteration [1934]: 0.003301993747495911
Loss at iteration [1935]: 0.003301414578775299
Loss at iteration [1936]: 0.0033008361605055825
Loss at iteration [1937]: 0.00330025845772146
Loss at iteration [1938]: 0.003299681493132358
Loss at iteration [1939]: 0.003299104971857514
Loss at iteration [1940]: 0.0032985294497395574
Loss at iteration [1941]: 0.0032979547354270652
Loss at iteration [1942]: 0.003297380965863694
Loss at iteration [1943]: 0.0032968080155541053
Loss at iteration [1944]: 0.0032962359187729507
Loss at iteration [1945]: 0.0032956646028456274
Loss at iteration [1946]: 0.003295094209102229
Loss at iteration [1947]: 0.0032945244079358917
Loss at iteration [1948]: 0.0032939555171294724
Loss at iteration [1949]: 0.0032933874271776973
Loss at iteration [1950]: 0.0032928201253965405
Loss at iteration [1951]: 0.0032922533323731045
Loss at iteration [1952]: 0.0032916873006153683
Loss at iteration [1953]: 0.0032911219269803893
Loss at iteration [1954]: 0.0032905573417470737
Loss at iteration [1955]: 0.003289993652767702
Loss at iteration [1956]: 0.0032894307683888698
Loss at iteration [1957]: 0.003288868721029193
Loss at iteration [1958]: 0.003288307561043001
Loss at iteration [1959]: 0.0032877472979489513
Loss at iteration [1960]: 0.0032871875761297693
Loss at iteration [1961]: 0.0032866277388006993
Loss at iteration [1962]: 0.0032860685307127646
Loss at iteration [1963]: 0.003285510038904393
Loss at iteration [1964]: 0.0032849524375225658
Loss at iteration [1965]: 0.0032843957070523883
Loss at iteration [1966]: 0.003283839564751513
Loss at iteration [1967]: 0.003283284397188769
Loss at iteration [1968]: 0.003282730130350293
Loss at iteration [1969]: 0.0032821764890456403
Loss at iteration [1970]: 0.0032816237883891214
Loss at iteration [1971]: 0.0032810723920150154
Loss at iteration [1972]: 0.0032805220641859948
Loss at iteration [1973]: 0.003279972674369394
Loss at iteration [1974]: 0.0032794241652166966
Loss at iteration [1975]: 0.0032788765920266226
Loss at iteration [1976]: 0.0032783295631608083
Loss at iteration [1977]: 0.003277783464915477
Loss at iteration [1978]: 0.0032772381806721747
Loss at iteration [1979]: 0.003276693353454363
Loss at iteration [1980]: 0.003276149422607766
Loss at iteration [1981]: 0.003275606254739947
Loss at iteration [1982]: 0.003275063966070509
Loss at iteration [1983]: 0.00327452244574989
Loss at iteration [1984]: 0.003273981781860597
Loss at iteration [1985]: 0.003273441956266682
Loss at iteration [1986]: 0.0032729027296342543
Loss at iteration [1987]: 0.003272364254063472
Loss at iteration [1988]: 0.0032718265287623874
Loss at iteration [1989]: 0.003271289476065758
Loss at iteration [1990]: 0.003270753079668896
Loss at iteration [1991]: 0.0032702165624617593
Loss at iteration [1992]: 0.003269680275415963
Loss at iteration [1993]: 0.0032691446097463397
Loss at iteration [1994]: 0.0032686099246672447
Loss at iteration [1995]: 0.003268075811228772
Loss at iteration [1996]: 0.003267542331699657
Loss at iteration [1997]: 0.00326700953767539
Loss at iteration [1998]: 0.0032664778332214183
Loss at iteration [1999]: 0.0032659468778625028
Loss at iteration [2000]: 0.0032654166542864043
Loss at iteration [2001]: 0.003264886980927288
Loss at iteration [2002]: 0.0032643573029284946
Loss at iteration [2003]: 0.0032638279035861356
Loss at iteration [2004]: 0.0032632989175677037
Loss at iteration [2005]: 0.0032627705673423046
Loss at iteration [2006]: 0.003262242890429389
Loss at iteration [2007]: 0.0032617158835804004
Loss at iteration [2008]: 0.003261189640147444
Loss at iteration [2009]: 0.003260664189928883
Loss at iteration [2010]: 0.0032601393141288874
Loss at iteration [2011]: 0.003259615127317596
Loss at iteration [2012]: 0.0032590914873155295
Loss at iteration [2013]: 0.0032585678319182027
Loss at iteration [2014]: 0.0032580447058362825
Loss at iteration [2015]: 0.0032575221701584257
Loss at iteration [2016]: 0.0032570003853259507
Loss at iteration [2017]: 0.00325647927733012
Loss at iteration [2018]: 0.003255958842234851
Loss at iteration [2019]: 0.00325543919612148
Loss at iteration [2020]: 0.003254920341713532
Loss at iteration [2021]: 0.003254402159794348
Loss at iteration [2022]: 0.003253884722720237
Loss at iteration [2023]: 0.0032533679817899537
Loss at iteration [2024]: 0.0032528520025102755
Loss at iteration [2025]: 0.0032523367115020415
Loss at iteration [2026]: 0.003251821666912691
Loss at iteration [2027]: 0.003251306913919576
Loss at iteration [2028]: 0.0032507926965875166
Loss at iteration [2029]: 0.0032502790520198047
Loss at iteration [2030]: 0.0032497659745039085
Loss at iteration [2031]: 0.0032492534861709305
Loss at iteration [2032]: 0.003248741607494555
Loss at iteration [2033]: 0.003248230364568691
Loss at iteration [2034]: 0.0032477198119928866
Loss at iteration [2035]: 0.0032472098242219793
Loss at iteration [2036]: 0.003246700545306693
Loss at iteration [2037]: 0.0032461919282865954
Loss at iteration [2038]: 0.003245683969028963
Loss at iteration [2039]: 0.003245176727806321
Loss at iteration [2040]: 0.003244669986567668
Loss at iteration [2041]: 0.0032441632199267686
Loss at iteration [2042]: 0.003243656986422857
Loss at iteration [2043]: 0.0032431513430249267
Loss at iteration [2044]: 0.003242646355729057
Loss at iteration [2045]: 0.0032421420132289825
Loss at iteration [2046]: 0.003241638316320025
Loss at iteration [2047]: 0.0032411353227320646
Loss at iteration [2048]: 0.0032406330393264108
Loss at iteration [2049]: 0.0032401314016186167
Loss at iteration [2050]: 0.0032396303417963823
Loss at iteration [2051]: 0.0032391300287205535
Loss at iteration [2052]: 0.003238630444264444
Loss at iteration [2053]: 0.0032381313928153276
Loss at iteration [2054]: 0.0032376328880249342
Loss at iteration [2055]: 0.0032371348460603832
Loss at iteration [2056]: 0.0032366374413441666
Loss at iteration [2057]: 0.003236140675927584
Loss at iteration [2058]: 0.0032356445340518242
Loss at iteration [2059]: 0.003235149024362321
Loss at iteration [2060]: 0.0032346542073304657
Loss at iteration [2061]: 0.0032341599854670377
Loss at iteration [2062]: 0.0032336664167467604
Loss at iteration [2063]: 0.0032331734720401043
Loss at iteration [2064]: 0.00323268116219199
Loss at iteration [2065]: 0.0032321895364320636
Loss at iteration [2066]: 0.003231698568872624
Loss at iteration [2067]: 0.0032312082625559173
Loss at iteration [2068]: 0.003230718658855796
Loss at iteration [2069]: 0.0032302299277074007
Loss at iteration [2070]: 0.0032297418727267172
Loss at iteration [2071]: 0.003229254457685445
Loss at iteration [2072]: 0.0032287676250165914
Loss at iteration [2073]: 0.003228281301265719
Loss at iteration [2074]: 0.003227795560580351
Loss at iteration [2075]: 0.0032273104341953907
Loss at iteration [2076]: 0.003226825896217615
Loss at iteration [2077]: 0.003226342617511916
Loss at iteration [2078]: 0.003225860544647516
Loss at iteration [2079]: 0.003225379345995322
Loss at iteration [2080]: 0.0032248988767580897
Loss at iteration [2081]: 0.003224418924213676
Loss at iteration [2082]: 0.0032239396049921426
Loss at iteration [2083]: 0.003223460877845868
Loss at iteration [2084]: 0.003222982702458759
Loss at iteration [2085]: 0.0032225048606223973
Loss at iteration [2086]: 0.0032220275355140143
Loss at iteration [2087]: 0.003221550773969505
Loss at iteration [2088]: 0.003221074681902869
Loss at iteration [2089]: 0.003220599431544662
Loss at iteration [2090]: 0.003220124839034985
Loss at iteration [2091]: 0.0032196509153053408
Loss at iteration [2092]: 0.0032191776636929454
Loss at iteration [2093]: 0.003218705388605158
Loss at iteration [2094]: 0.0032182337694845005
Loss at iteration [2095]: 0.0032177627797036943
Loss at iteration [2096]: 0.0032172923364161407
Loss at iteration [2097]: 0.0032168223999016056
Loss at iteration [2098]: 0.0032163530008660064
Loss at iteration [2099]: 0.0032158842287881542
Loss at iteration [2100]: 0.0032154161867894286
Loss at iteration [2101]: 0.0032149489064580163
Loss at iteration [2102]: 0.0032144819224131393
Loss at iteration [2103]: 0.0032140150367820086
Loss at iteration [2104]: 0.003213548668463867
Loss at iteration [2105]: 0.003213082454548876
Loss at iteration [2106]: 0.00321261620938212
Loss at iteration [2107]: 0.0032121502679906375
Loss at iteration [2108]: 0.003211684773131074
Loss at iteration [2109]: 0.00321121980349561
Loss at iteration [2110]: 0.0032107553341859368
Loss at iteration [2111]: 0.00321029140529894
Loss at iteration [2112]: 0.00320982802772032
Loss at iteration [2113]: 0.003209365203377613
Loss at iteration [2114]: 0.003208903084368577
Loss at iteration [2115]: 0.003208441862264433
Loss at iteration [2116]: 0.003207981387460011
Loss at iteration [2117]: 0.0032075214454116824
Loss at iteration [2118]: 0.0032070621301257688
Loss at iteration [2119]: 0.0032066033955771545
Loss at iteration [2120]: 0.0032061452373185933
Loss at iteration [2121]: 0.003205687628101732
Loss at iteration [2122]: 0.003205230560481076
Loss at iteration [2123]: 0.0032047739248995
Loss at iteration [2124]: 0.0032043179156448125
Loss at iteration [2125]: 0.0032038624471569526
Loss at iteration [2126]: 0.0032034072922542743
Loss at iteration [2127]: 0.003202952878402774
Loss at iteration [2128]: 0.0032024992090292303
Loss at iteration [2129]: 0.0032020460803351154
Loss at iteration [2130]: 0.0032015935269427615
Loss at iteration [2131]: 0.0032011414832060375
Loss at iteration [2132]: 0.0032006900321687472
Loss at iteration [2133]: 0.003200239000413868
Loss at iteration [2134]: 0.003199788559517005
Loss at iteration [2135]: 0.0031993387117387083
Loss at iteration [2136]: 0.003198889400335972
Loss at iteration [2137]: 0.003198440571290039
Loss at iteration [2138]: 0.0031979923096189383
Loss at iteration [2139]: 0.0031975446234620546
Loss at iteration [2140]: 0.0031970974762770385
Loss at iteration [2141]: 0.003196650971823252
Loss at iteration [2142]: 0.0031962057432473987
Loss at iteration [2143]: 0.003195761646998861
Loss at iteration [2144]: 0.0031953182053945633
Loss at iteration [2145]: 0.00319487527877274
Loss at iteration [2146]: 0.0031944330053282834
Loss at iteration [2147]: 0.0031939914411175585
Loss at iteration [2148]: 0.0031935506520920373
Loss at iteration [2149]: 0.003193110450251118
Loss at iteration [2150]: 0.003192670837021683
Loss at iteration [2151]: 0.0031922316995464783
Loss at iteration [2152]: 0.0031917931156958492
Loss at iteration [2153]: 0.003191355051669765
Loss at iteration [2154]: 0.003190917629592356
Loss at iteration [2155]: 0.0031904806289756085
Loss at iteration [2156]: 0.0031900442892206964
Loss at iteration [2157]: 0.003189608326126528
Loss at iteration [2158]: 0.00318917266640572
Loss at iteration [2159]: 0.003188737565981791
Loss at iteration [2160]: 0.003188303061985489
Loss at iteration [2161]: 0.0031878692718680835
Loss at iteration [2162]: 0.003187436114657036
Loss at iteration [2163]: 0.0031870020896770154
Loss at iteration [2164]: 0.003186568374324205
Loss at iteration [2165]: 0.0031861350822068955
Loss at iteration [2166]: 0.0031857023486922638
Loss at iteration [2167]: 0.0031852700557820834
Loss at iteration [2168]: 0.0031848383606844556
Loss at iteration [2169]: 0.0031844072945047103
Loss at iteration [2170]: 0.003183976709177665
Loss at iteration [2171]: 0.0031835466640608013
Loss at iteration [2172]: 0.0031831172207457997
Loss at iteration [2173]: 0.003182688401173523
Loss at iteration [2174]: 0.0031822602942110116
Loss at iteration [2175]: 0.0031818327175533647
Loss at iteration [2176]: 0.003181405698970691
Loss at iteration [2177]: 0.0031809791380997517
Loss at iteration [2178]: 0.003180553088992912
Loss at iteration [2179]: 0.003180127504362897
Loss at iteration [2180]: 0.003179702429120711
Loss at iteration [2181]: 0.0031792778581606943
Loss at iteration [2182]: 0.003178853278758498
Loss at iteration [2183]: 0.003178429227599441
Loss at iteration [2184]: 0.003178006072950809
Loss at iteration [2185]: 0.003177583432642166
Loss at iteration [2186]: 0.0031771613575259225
Loss at iteration [2187]: 0.0031767397365583218
Loss at iteration [2188]: 0.00317631831629233
Loss at iteration [2189]: 0.003175897307701524
Loss at iteration [2190]: 0.0031754768606347353
Loss at iteration [2191]: 0.003175056970714
Loss at iteration [2192]: 0.003174637447926815
Loss at iteration [2193]: 0.0031742183943494363
Loss at iteration [2194]: 0.0031737998564446215
Loss at iteration [2195]: 0.003173381982112968
Loss at iteration [2196]: 0.00317296484676143
Loss at iteration [2197]: 0.0031725481236684378
Loss at iteration [2198]: 0.0031721320944455783
Loss at iteration [2199]: 0.0031717162995200813
Loss at iteration [2200]: 0.0031713011408314126
Loss at iteration [2201]: 0.0031708863887495494
Loss at iteration [2202]: 0.003170472106363249
Loss at iteration [2203]: 0.0031700585905818884
Loss at iteration [2204]: 0.00316964563727218
Loss at iteration [2205]: 0.003169233289390164
Loss at iteration [2206]: 0.003168821337157191
Loss at iteration [2207]: 0.0031684100489134705
Loss at iteration [2208]: 0.0031679991013770364
Loss at iteration [2209]: 0.0031675890207196983
Loss at iteration [2210]: 0.003167179352026987
Loss at iteration [2211]: 0.0031667700476917682
Loss at iteration [2212]: 0.003166361275429644
Loss at iteration [2213]: 0.0031659527976158407
Loss at iteration [2214]: 0.003165544981654813
Loss at iteration [2215]: 0.0031651376578524597
Loss at iteration [2216]: 0.003164730713892365
Loss at iteration [2217]: 0.0031643245583169166
Loss at iteration [2218]: 0.0031639188534150374
Loss at iteration [2219]: 0.0031635138762371373
Loss at iteration [2220]: 0.0031631093968578754
Loss at iteration [2221]: 0.003162705234081724
Loss at iteration [2222]: 0.0031623017287176402
Loss at iteration [2223]: 0.003161898410714375
Loss at iteration [2224]: 0.0031614956791442862
Loss at iteration [2225]: 0.0031610934085588385
Loss at iteration [2226]: 0.0031606915477772695
Loss at iteration [2227]: 0.003160290342198541
Loss at iteration [2228]: 0.0031598893803536808
Loss at iteration [2229]: 0.0031594890526271333
Loss at iteration [2230]: 0.003159089159105142
Loss at iteration [2231]: 0.0031586896877858987
Loss at iteration [2232]: 0.0031582909114448846
Loss at iteration [2233]: 0.003157892370254974
Loss at iteration [2234]: 0.0031574944871005594
Loss at iteration [2235]: 0.0031570972810636743
Loss at iteration [2236]: 0.0031567006890593635
Loss at iteration [2237]: 0.0031563046160123526
Loss at iteration [2238]: 0.0031559087653033535
Loss at iteration [2239]: 0.0031555143202059567
Loss at iteration [2240]: 0.0031551204084590222
Loss at iteration [2241]: 0.00315472696056178
Loss at iteration [2242]: 0.003154334098123416
Loss at iteration [2243]: 0.0031539418894157593
Loss at iteration [2244]: 0.003153550092029829
Loss at iteration [2245]: 0.0031531589156431287
Loss at iteration [2246]: 0.0031527679833842403
Loss at iteration [2247]: 0.0031523778279367487
Loss at iteration [2248]: 0.0031519881319858715
Loss at iteration [2249]: 0.0031515989921189584
Loss at iteration [2250]: 0.0031512103541127623
Loss at iteration [2251]: 0.0031508223185476867
Loss at iteration [2252]: 0.003150434663755326
Loss at iteration [2253]: 0.0031500475915925428
Loss at iteration [2254]: 0.003149661073266216
Loss at iteration [2255]: 0.003149275140448337
Loss at iteration [2256]: 0.0031488898820420455
Loss at iteration [2257]: 0.003148505036529182
Loss at iteration [2258]: 0.0031481206976661817
Loss at iteration [2259]: 0.003147737015314014
Loss at iteration [2260]: 0.003147353453994672
Loss at iteration [2261]: 0.0031469702508850027
Loss at iteration [2262]: 0.0031465875125272196
Loss at iteration [2263]: 0.003146205080169491
Loss at iteration [2264]: 0.0031458231023496984
Loss at iteration [2265]: 0.0031454418647385895
Loss at iteration [2266]: 0.0031450608828547106
Loss at iteration [2267]: 0.003144680716350772
Loss at iteration [2268]: 0.0031443008697188504
Loss at iteration [2269]: 0.0031439213885686157
Loss at iteration [2270]: 0.0031435422804847878
Loss at iteration [2271]: 0.0031431637883689366
Loss at iteration [2272]: 0.003142785442771496
Loss at iteration [2273]: 0.003142407772092786
Loss at iteration [2274]: 0.0031420304245987937
Loss at iteration [2275]: 0.003141653527367638
Loss at iteration [2276]: 0.003141277190409087
Loss at iteration [2277]: 0.0031409014727554634
Loss at iteration [2278]: 0.00314052592841938
Loss at iteration [2279]: 0.003140151112734589
Loss at iteration [2280]: 0.0031397767154617987
Loss at iteration [2281]: 0.0031394028345666683
Loss at iteration [2282]: 0.003139029470300816
Loss at iteration [2283]: 0.003138657085661961
Loss at iteration [2284]: 0.0031382849535998058
Loss at iteration [2285]: 0.00313791405437373
Loss at iteration [2286]: 0.0031375437644655985
Loss at iteration [2287]: 0.003137173820480142
Loss at iteration [2288]: 0.003136804301796846
Loss at iteration [2289]: 0.003136435314655779
Loss at iteration [2290]: 0.0031360666548567884
Loss at iteration [2291]: 0.003135698440523871
Loss at iteration [2292]: 0.0031353306936200637
Loss at iteration [2293]: 0.0031349632577873936
Loss at iteration [2294]: 0.003134596195817457
Loss at iteration [2295]: 0.003134229542406764
Loss at iteration [2296]: 0.0031338633717052796
Loss at iteration [2297]: 0.00313349756925369
Loss at iteration [2298]: 0.003133132134340354
Loss at iteration [2299]: 0.0031327672754603224
Loss at iteration [2300]: 0.0031324027743362794
Loss at iteration [2301]: 0.003132038176071314
Loss at iteration [2302]: 0.0031316742867001294
Loss at iteration [2303]: 0.003131310391237202
Loss at iteration [2304]: 0.0031309467112051017
Loss at iteration [2305]: 0.00313058330573521
Loss at iteration [2306]: 0.00313022044663449
Loss at iteration [2307]: 0.003129857303011704
Loss at iteration [2308]: 0.003129493957693354
Loss at iteration [2309]: 0.0031291308399641533
Loss at iteration [2310]: 0.003128767839283044
Loss at iteration [2311]: 0.0031284052890263774
Loss at iteration [2312]: 0.0031280431616548887
Loss at iteration [2313]: 0.003127681088723395
Loss at iteration [2314]: 0.003127319192753022
Loss at iteration [2315]: 0.003126957549442184
Loss at iteration [2316]: 0.003126596540875988
Loss at iteration [2317]: 0.003126236065639509
Loss at iteration [2318]: 0.00312587599245068
Loss at iteration [2319]: 0.0031255164135402923
Loss at iteration [2320]: 0.003125157280569609
Loss at iteration [2321]: 0.0031247985723382023
Loss at iteration [2322]: 0.003124440153473779
Loss at iteration [2323]: 0.003124081962439576
Loss at iteration [2324]: 0.0031237239860411586
Loss at iteration [2325]: 0.0031233664501504627
Loss at iteration [2326]: 0.003123009280689329
Loss at iteration [2327]: 0.0031226527262396774
Loss at iteration [2328]: 0.003122296364062243
Loss at iteration [2329]: 0.0031219405824933696
Loss at iteration [2330]: 0.0031215851856812547
Loss at iteration [2331]: 0.003121230200540008
Loss at iteration [2332]: 0.0031208755506835664
Loss at iteration [2333]: 0.003120521380608669
Loss at iteration [2334]: 0.0031201679208336217
Loss at iteration [2335]: 0.003119814941717816
Loss at iteration [2336]: 0.0031194625004647538
Loss at iteration [2337]: 0.003119110514740539
Loss at iteration [2338]: 0.003118758971583148
Loss at iteration [2339]: 0.0031184077096601576
Loss at iteration [2340]: 0.0031180564803655283
Loss at iteration [2341]: 0.003117705575047415
Loss at iteration [2342]: 0.0031173551211138135
Loss at iteration [2343]: 0.003117004909781428
Loss at iteration [2344]: 0.003116654143714533
Loss at iteration [2345]: 0.0031163036104112124
Loss at iteration [2346]: 0.003115953800016511
Loss at iteration [2347]: 0.0031156045187482402
Loss at iteration [2348]: 0.003115255732548038
Loss at iteration [2349]: 0.0031149073277030636
Loss at iteration [2350]: 0.0031145593661578755
Loss at iteration [2351]: 0.003114211865554064
Loss at iteration [2352]: 0.0031138648313959417
Loss at iteration [2353]: 0.0031135181380525815
Loss at iteration [2354]: 0.00311317187692756
Loss at iteration [2355]: 0.0031128260877934513
Loss at iteration [2356]: 0.003112480665044413
Loss at iteration [2357]: 0.003112135871028288
Loss at iteration [2358]: 0.0031117916531808606
Loss at iteration [2359]: 0.003111447994926163
Loss at iteration [2360]: 0.0031111046323678004
Loss at iteration [2361]: 0.003110761704496576
Loss at iteration [2362]: 0.0031104191713073356
Loss at iteration [2363]: 0.003110077141917491
Loss at iteration [2364]: 0.0031097354011640674
Loss at iteration [2365]: 0.003109394097977007
Loss at iteration [2366]: 0.0031090531124938077
Loss at iteration [2367]: 0.003108712499030917
Loss at iteration [2368]: 0.0031083726223128743
Loss at iteration [2369]: 0.003108032948379171
Loss at iteration [2370]: 0.0031076939272683514
Loss at iteration [2371]: 0.0031073553293935376
Loss at iteration [2372]: 0.0031070171644359983
Loss at iteration [2373]: 0.0031066793135585673
Loss at iteration [2374]: 0.0031063418319132027
Loss at iteration [2375]: 0.0031060046152820097
Loss at iteration [2376]: 0.003105667736464561
Loss at iteration [2377]: 0.0031053313081421422
Loss at iteration [2378]: 0.003104995092916404
Loss at iteration [2379]: 0.0031046593049629824
Loss at iteration [2380]: 0.0031043238438384527
Loss at iteration [2381]: 0.0031039887557510366
Loss at iteration [2382]: 0.003103654176102971
Loss at iteration [2383]: 0.0031033198144995635
Loss at iteration [2384]: 0.0031029858700196335
Loss at iteration [2385]: 0.003102652284976615
Loss at iteration [2386]: 0.003102319215718465
Loss at iteration [2387]: 0.0031019867991134526
Loss at iteration [2388]: 0.003101654504678193
Loss at iteration [2389]: 0.0031013227197616415
Loss at iteration [2390]: 0.0031009913518668386
Loss at iteration [2391]: 0.003100660505591921
Loss at iteration [2392]: 0.003100330176739873
Loss at iteration [2393]: 0.003100000097572078
Loss at iteration [2394]: 0.0030996705627732465
Loss at iteration [2395]: 0.0030993414162293047
Loss at iteration [2396]: 0.003099012589853848
Loss at iteration [2397]: 0.003098684283317203
Loss at iteration [2398]: 0.003098356265888704
Loss at iteration [2399]: 0.003098028857287549
Loss at iteration [2400]: 0.003097701779750896
Loss at iteration [2401]: 0.003097375131365367
Loss at iteration [2402]: 0.0030970490736298793
Loss at iteration [2403]: 0.003096723434913783
Loss at iteration [2404]: 0.003096398475966049
Loss at iteration [2405]: 0.003096074237807789
Loss at iteration [2406]: 0.0030957504478494537
Loss at iteration [2407]: 0.0030954270826779803
Loss at iteration [2408]: 0.0030951041612509392
Loss at iteration [2409]: 0.0030947814376785505
Loss at iteration [2410]: 0.0030944591408438075
Loss at iteration [2411]: 0.0030941371794533357
Loss at iteration [2412]: 0.0030938156186256795
Loss at iteration [2413]: 0.003093494441514924
Loss at iteration [2414]: 0.0030931730950852928
Loss at iteration [2415]: 0.003092851702987077
Loss at iteration [2416]: 0.003092530499952096
Loss at iteration [2417]: 0.0030922096620742807
Loss at iteration [2418]: 0.003091889161603307
Loss at iteration [2419]: 0.0030915690259417754
Loss at iteration [2420]: 0.003091249266822324
Loss at iteration [2421]: 0.00309092994696066
Loss at iteration [2422]: 0.0030906109345418395
Loss at iteration [2423]: 0.0030902921938536156
Loss at iteration [2424]: 0.0030899738022225074
Loss at iteration [2425]: 0.003089655966793463
Loss at iteration [2426]: 0.0030893382416466338
Loss at iteration [2427]: 0.0030890210691395864
Loss at iteration [2428]: 0.003088704857627484
Loss at iteration [2429]: 0.0030883890539845455
Loss at iteration [2430]: 0.003088073448290401
Loss at iteration [2431]: 0.0030877582399104126
Loss at iteration [2432]: 0.0030874433798947923
Loss at iteration [2433]: 0.0030871289877099682
Loss at iteration [2434]: 0.0030868148805798497
Loss at iteration [2435]: 0.0030865010966649228
Loss at iteration [2436]: 0.0030861877631005665
Loss at iteration [2437]: 0.0030858747672018396
Loss at iteration [2438]: 0.0030855623014839823
Loss at iteration [2439]: 0.003085249930877133
Loss at iteration [2440]: 0.0030849378179247
Loss at iteration [2441]: 0.0030846260018621
Loss at iteration [2442]: 0.003084314549783241
Loss at iteration [2443]: 0.0030840033711442756
Loss at iteration [2444]: 0.0030836925489587776
Loss at iteration [2445]: 0.003083382004801787
Loss at iteration [2446]: 0.003083071967773011
Loss at iteration [2447]: 0.003082762426438364
Loss at iteration [2448]: 0.003082453099162835
Loss at iteration [2449]: 0.003082144203263357
Loss at iteration [2450]: 0.0030818356251737598
Loss at iteration [2451]: 0.0030815273448177825
Loss at iteration [2452]: 0.003081219456562839
Loss at iteration [2453]: 0.0030809120260932373
Loss at iteration [2454]: 0.003080604962490808
Loss at iteration [2455]: 0.0030802982654135787
Loss at iteration [2456]: 0.003079991986966131
Loss at iteration [2457]: 0.003079686245564899
Loss at iteration [2458]: 0.0030793811730346447
Loss at iteration [2459]: 0.003079076631861723
Loss at iteration [2460]: 0.0030787724323010244
Loss at iteration [2461]: 0.0030784684507031306
Loss at iteration [2462]: 0.0030781648533068696
Loss at iteration [2463]: 0.0030778617729317996
Loss at iteration [2464]: 0.0030775589939196547
Loss at iteration [2465]: 0.003077256590910044
Loss at iteration [2466]: 0.0030769545430860386
Loss at iteration [2467]: 0.0030766527740484708
Loss at iteration [2468]: 0.0030763512998599404
Loss at iteration [2469]: 0.0030760500425420583
Loss at iteration [2470]: 0.0030757491306713453
Loss at iteration [2471]: 0.003075448384058685
Loss at iteration [2472]: 0.003075148144240311
Loss at iteration [2473]: 0.003074848015449938
Loss at iteration [2474]: 0.003074548336542965
Loss at iteration [2475]: 0.0030742489220472137
Loss at iteration [2476]: 0.003073949871490435
Loss at iteration [2477]: 0.0030736512448381603
Loss at iteration [2478]: 0.0030733529294099146
Loss at iteration [2479]: 0.0030730550099999456
Loss at iteration [2480]: 0.003072757390269967
Loss at iteration [2481]: 0.0030724601129882676
Loss at iteration [2482]: 0.003072163167017051
Loss at iteration [2483]: 0.003071866512366922
Loss at iteration [2484]: 0.003071570156435019
Loss at iteration [2485]: 0.003071274155830608
Loss at iteration [2486]: 0.003070978571663142
Loss at iteration [2487]: 0.0030706832666386285
Loss at iteration [2488]: 0.003070388242249653
Loss at iteration [2489]: 0.003070093625977968
Loss at iteration [2490]: 0.003069799362972078
Loss at iteration [2491]: 0.003069505542436175
Loss at iteration [2492]: 0.003069212017325644
Loss at iteration [2493]: 0.0030689188591396803
Loss at iteration [2494]: 0.003068626190299993
Loss at iteration [2495]: 0.003068333998877047
Loss at iteration [2496]: 0.003068041980056279
Loss at iteration [2497]: 0.0030677503591093553
Loss at iteration [2498]: 0.003067458933718985
Loss at iteration [2499]: 0.003067167603164268
Loss at iteration [2500]: 0.0030668765473342136
Loss at iteration [2501]: 0.0030665857252441375
Loss at iteration [2502]: 0.0030662954130753466
Loss at iteration [2503]: 0.003066004828135398
Loss at iteration [2504]: 0.003065714545598369
Loss at iteration [2505]: 0.003065424188394315
Loss at iteration [2506]: 0.0030651340397762758
Loss at iteration [2507]: 0.0030648442434290514
Loss at iteration [2508]: 0.003064554620363194
Loss at iteration [2509]: 0.0030642656557999413
Loss at iteration [2510]: 0.0030639766849486264
Loss at iteration [2511]: 0.0030636881203009165
Loss at iteration [2512]: 0.0030634000914089746
Loss at iteration [2513]: 0.0030631121121133227
Loss at iteration [2514]: 0.0030628243985660183
Loss at iteration [2515]: 0.003062537088988531
Loss at iteration [2516]: 0.0030622500757497726
Loss at iteration [2517]: 0.003061963333495389
Loss at iteration [2518]: 0.0030616769995704396
Loss at iteration [2519]: 0.0030613910040107662
Loss at iteration [2520]: 0.0030611052356380266
Loss at iteration [2521]: 0.0030608205243291874
Loss at iteration [2522]: 0.0030605381213738804
Loss at iteration [2523]: 0.0030602563818396553
Loss at iteration [2524]: 0.0030599752336769367
Loss at iteration [2525]: 0.0030596943833709794
Loss at iteration [2526]: 0.003059413791958483
Loss at iteration [2527]: 0.003059133669587394
Loss at iteration [2528]: 0.00305885381469261
Loss at iteration [2529]: 0.0030585743244495303
Loss at iteration [2530]: 0.0030582951833370924
Loss at iteration [2531]: 0.003058016258456531
Loss at iteration [2532]: 0.003057737708217902
Loss at iteration [2533]: 0.0030574593036026337
Loss at iteration [2534]: 0.003057181200540597
Loss at iteration [2535]: 0.003056903461892534
Loss at iteration [2536]: 0.003056626260503644
Loss at iteration [2537]: 0.003056349290322623
Loss at iteration [2538]: 0.0030560726425639863
Loss at iteration [2539]: 0.003055796365200957
Loss at iteration [2540]: 0.0030555203373641942
Loss at iteration [2541]: 0.0030552446996332124
Loss at iteration [2542]: 0.0030549692714972815
Loss at iteration [2543]: 0.003054694178656608
Loss at iteration [2544]: 0.0030544194812088593
Loss at iteration [2545]: 0.0030541447354673866
Loss at iteration [2546]: 0.0030538700853023405
Loss at iteration [2547]: 0.0030535957369629474
Loss at iteration [2548]: 0.0030533216873095685
Loss at iteration [2549]: 0.0030530478110431577
Loss at iteration [2550]: 0.0030527743605397164
Loss at iteration [2551]: 0.0030525011604619844
Loss at iteration [2552]: 0.0030522282103838823
Loss at iteration [2553]: 0.00305195564508917
Loss at iteration [2554]: 0.003051683274227303
Loss at iteration [2555]: 0.003051411068495337
Loss at iteration [2556]: 0.0030511392983352385
Loss at iteration [2557]: 0.0030508676250585887
Loss at iteration [2558]: 0.0030505966991297203
Loss at iteration [2559]: 0.0030503261316056937
Loss at iteration [2560]: 0.0030500559051523874
Loss at iteration [2561]: 0.003049785905223869
Loss at iteration [2562]: 0.003049516202805508
Loss at iteration [2563]: 0.0030492466370944903
Loss at iteration [2564]: 0.0030489773907410706
Loss at iteration [2565]: 0.003048708418351032
Loss at iteration [2566]: 0.003048439742984145
Loss at iteration [2567]: 0.00304817126082712
Loss at iteration [2568]: 0.003047903080689028
Loss at iteration [2569]: 0.0030476351462455573
Loss at iteration [2570]: 0.003047367495251525
Loss at iteration [2571]: 0.0030471000670750747
Loss at iteration [2572]: 0.0030468328412653635
Loss at iteration [2573]: 0.003046565812275265
Loss at iteration [2574]: 0.003046298974961401
Loss at iteration [2575]: 0.003046032460901739
Loss at iteration [2576]: 0.0030457661254709666
Loss at iteration [2577]: 0.0030455000642347534
Loss at iteration [2578]: 0.0030452343187757054
Loss at iteration [2579]: 0.003044968758000877
Loss at iteration [2580]: 0.0030447037588171313
Loss at iteration [2581]: 0.003044438964477924
Loss at iteration [2582]: 0.0030441743831356124
Loss at iteration [2583]: 0.0030439100577794973
Loss at iteration [2584]: 0.003043645980789191
Loss at iteration [2585]: 0.0030433822541502207
Loss at iteration [2586]: 0.0030431187432538327
Loss at iteration [2587]: 0.0030428556275415106
Loss at iteration [2588]: 0.0030425929245561393
Loss at iteration [2589]: 0.003042330498684776
Loss at iteration [2590]: 0.003042068392703473
Loss at iteration [2591]: 0.003041806578425094
Loss at iteration [2592]: 0.0030415450221243476
Loss at iteration [2593]: 0.0030412837492354676
Loss at iteration [2594]: 0.00304102258849436
Loss at iteration [2595]: 0.0030407617591642054
Loss at iteration [2596]: 0.003040501285482826
Loss at iteration [2597]: 0.003040241050380282
Loss at iteration [2598]: 0.003039981035340932
Loss at iteration [2599]: 0.0030397213683788257
Loss at iteration [2600]: 0.003039461941895494
Loss at iteration [2601]: 0.0030392027337927787
Loss at iteration [2602]: 0.0030389438904701383
Loss at iteration [2603]: 0.0030386852916538284
Loss at iteration [2604]: 0.0030384269234190525
Loss at iteration [2605]: 0.0030381688883154433
Loss at iteration [2606]: 0.0030379111120429213
Loss at iteration [2607]: 0.0030376536235979423
Loss at iteration [2608]: 0.00303739641103164
Loss at iteration [2609]: 0.0030371395742776726
Loss at iteration [2610]: 0.003036883130880754
Loss at iteration [2611]: 0.0030366270895594983
Loss at iteration [2612]: 0.0030363713777282635
Loss at iteration [2613]: 0.003036116288543582
Loss at iteration [2614]: 0.0030358622491271085
Loss at iteration [2615]: 0.0030356084487275503
Loss at iteration [2616]: 0.0030353551223538107
Loss at iteration [2617]: 0.0030351019245615737
Loss at iteration [2618]: 0.0030348491585941704
Loss at iteration [2619]: 0.0030345964853503503
Loss at iteration [2620]: 0.003034344160166394
Loss at iteration [2621]: 0.0030340920812972003
Loss at iteration [2622]: 0.003033840324136834
Loss at iteration [2623]: 0.003033588592181469
Loss at iteration [2624]: 0.0030333371757945344
Loss at iteration [2625]: 0.0030330859724546134
Loss at iteration [2626]: 0.0030328350416848238
Loss at iteration [2627]: 0.0030325844444656644
Loss at iteration [2628]: 0.003032334084464391
Loss at iteration [2629]: 0.0030320839779860837
Loss at iteration [2630]: 0.0030318341565500864
Loss at iteration [2631]: 0.0030315843503582415
Loss at iteration [2632]: 0.00303133466757935
Loss at iteration [2633]: 0.0030310852552849978
Loss at iteration [2634]: 0.003030836034755459
Loss at iteration [2635]: 0.0030305871344565817
Loss at iteration [2636]: 0.003030338435957718
Loss at iteration [2637]: 0.003030090060495404
Loss at iteration [2638]: 0.0030298417720058487
Loss at iteration [2639]: 0.003029593799241699
Loss at iteration [2640]: 0.003029345898586994
Loss at iteration [2641]: 0.0030290981559940554
Loss at iteration [2642]: 0.003028850600402051
Loss at iteration [2643]: 0.0030286033165457544
Loss at iteration [2644]: 0.0030283568434503515
Loss at iteration [2645]: 0.003028110785719995
Loss at iteration [2646]: 0.003027865191409309
Loss at iteration [2647]: 0.003027619767412605
Loss at iteration [2648]: 0.0030273747702943407
Loss at iteration [2649]: 0.0030271300011175846
Loss at iteration [2650]: 0.0030268855608468273
Loss at iteration [2651]: 0.0030266413088299946
Loss at iteration [2652]: 0.0030263973109788352
Loss at iteration [2653]: 0.0030261536538162682
Loss at iteration [2654]: 0.0030259103547828578
Loss at iteration [2655]: 0.003025667367544806
Loss at iteration [2656]: 0.003025424592384421
Loss at iteration [2657]: 0.0030251820322354057
Loss at iteration [2658]: 0.00302493961703712
Loss at iteration [2659]: 0.0030246973082514784
Loss at iteration [2660]: 0.003024455199846287
Loss at iteration [2661]: 0.003024213263798836
Loss at iteration [2662]: 0.0030239715858777837
Loss at iteration [2663]: 0.0030237302254346628
Loss at iteration [2664]: 0.003023489351115726
Loss at iteration [2665]: 0.0030232487547992956
Loss at iteration [2666]: 0.0030230082551939317
Loss at iteration [2667]: 0.003022768063650503
Loss at iteration [2668]: 0.0030225280565150414
Loss at iteration [2669]: 0.0030222881698253627
Loss at iteration [2670]: 0.003022048533084962
Loss at iteration [2671]: 0.003021809142578663
Loss at iteration [2672]: 0.0030215699612606913
Loss at iteration [2673]: 0.003021331026582853
Loss at iteration [2674]: 0.00302109235924674
Loss at iteration [2675]: 0.0030208540799915133
Loss at iteration [2676]: 0.003020616115922634
Loss at iteration [2677]: 0.0030203783481194666
Loss at iteration [2678]: 0.0030201408594241128
Loss at iteration [2679]: 0.003019903671652793
Loss at iteration [2680]: 0.0030196669057978927
Loss at iteration [2681]: 0.003019430413129136
Loss at iteration [2682]: 0.003019194309378807
Loss at iteration [2683]: 0.003018958719122781
Loss at iteration [2684]: 0.0030187240184519045
Loss at iteration [2685]: 0.003018489648717977
Loss at iteration [2686]: 0.003018255745604137
Loss at iteration [2687]: 0.0030180221424426262
Loss at iteration [2688]: 0.0030177889026111876
Loss at iteration [2689]: 0.003017555909674996
Loss at iteration [2690]: 0.0030173232092620367
Loss at iteration [2691]: 0.003017090799679333
Loss at iteration [2692]: 0.0030168586817085814
Loss at iteration [2693]: 0.0030166269416270403
Loss at iteration [2694]: 0.0030163953342688924
Loss at iteration [2695]: 0.00301616384588129
Loss at iteration [2696]: 0.003015932079049938
Loss at iteration [2697]: 0.003015700492475551
Loss at iteration [2698]: 0.003015469112108237
Loss at iteration [2699]: 0.0030152378965897617
Loss at iteration [2700]: 0.0030150070352867714
Loss at iteration [2701]: 0.0030147762693696297
Loss at iteration [2702]: 0.0030145460717737743
Loss at iteration [2703]: 0.003014316632066935
Loss at iteration [2704]: 0.003014087579689896
Loss at iteration [2705]: 0.003013858937996647
Loss at iteration [2706]: 0.003013630486510479
Loss at iteration [2707]: 0.0030134023614806302
Loss at iteration [2708]: 0.003013174415241806
Loss at iteration [2709]: 0.003012946764730869
Loss at iteration [2710]: 0.0030127193627104342
Loss at iteration [2711]: 0.003012492365685285
Loss at iteration [2712]: 0.0030122657869458705
Loss at iteration [2713]: 0.003012039550580301
Loss at iteration [2714]: 0.0030118137455829768
Loss at iteration [2715]: 0.003011588168126661
Loss at iteration [2716]: 0.003011362911453891
Loss at iteration [2717]: 0.003011137855722824
Loss at iteration [2718]: 0.003010913101543536
Loss at iteration [2719]: 0.003010688546336134
Loss at iteration [2720]: 0.003010464166316189
Loss at iteration [2721]: 0.003010240247428112
Loss at iteration [2722]: 0.0030100166288568528
Loss at iteration [2723]: 0.003009793221830889
Loss at iteration [2724]: 0.003009570009432918
Loss at iteration [2725]: 0.003009347096129363
Loss at iteration [2726]: 0.0030091244563498734
Loss at iteration [2727]: 0.0030089021392577017
Loss at iteration [2728]: 0.00300868006287232
Loss at iteration [2729]: 0.003008458244752094
Loss at iteration [2730]: 0.003008236609061447
Loss at iteration [2731]: 0.003008015228880732
Loss at iteration [2732]: 0.00300779425205672
Loss at iteration [2733]: 0.0030075736754225438
Loss at iteration [2734]: 0.003007353442917216
Loss at iteration [2735]: 0.0030071334267584666
Loss at iteration [2736]: 0.0030069136898168503
Loss at iteration [2737]: 0.0030066941925692868
Loss at iteration [2738]: 0.003006474862141608
Loss at iteration [2739]: 0.003006255931048896
Loss at iteration [2740]: 0.0030060373087930983
Loss at iteration [2741]: 0.003005818931498902
Loss at iteration [2742]: 0.0030056008236055516
Loss at iteration [2743]: 0.003005383026358769
Loss at iteration [2744]: 0.0030051653965974764
Loss at iteration [2745]: 0.003004948279300191
Loss at iteration [2746]: 0.0030047316695992325
Loss at iteration [2747]: 0.0030045152527103866
Loss at iteration [2748]: 0.0030042993448211644
Loss at iteration [2749]: 0.003004083594551194
Loss at iteration [2750]: 0.0030038681096251504
Loss at iteration [2751]: 0.003003652757658048
Loss at iteration [2752]: 0.0030034376236666195
Loss at iteration [2753]: 0.0030032228273242107
Loss at iteration [2754]: 0.003003008236623845
Loss at iteration [2755]: 0.0030027939413278994
Loss at iteration [2756]: 0.0030025798279127444
Loss at iteration [2757]: 0.003002366018395057
Loss at iteration [2758]: 0.003002152432515581
Loss at iteration [2759]: 0.0030019389859698687
Loss at iteration [2760]: 0.003001725738301741
Loss at iteration [2761]: 0.0030015125734024284
Loss at iteration [2762]: 0.0030012996268661235
Loss at iteration [2763]: 0.00300108690869479
Loss at iteration [2764]: 0.0030008743606156564
Loss at iteration [2765]: 0.0030006621673713506
Loss at iteration [2766]: 0.003000450107205044
Loss at iteration [2767]: 0.0030002382844778377
Loss at iteration [2768]: 0.0030000265607107324
Loss at iteration [2769]: 0.0029998150617448357
Loss at iteration [2770]: 0.002999603778289141
Loss at iteration [2771]: 0.002999392707054829
Loss at iteration [2772]: 0.0029991818785142
Loss at iteration [2773]: 0.0029989712329512594
Loss at iteration [2774]: 0.002998760777457895
Loss at iteration [2775]: 0.002998550571414852
Loss at iteration [2776]: 0.002998340483795243
Loss at iteration [2777]: 0.00299813085157811
Loss at iteration [2778]: 0.0029979214127247287
Loss at iteration [2779]: 0.0029977122777269088
Loss at iteration [2780]: 0.0029975033219179375
Loss at iteration [2781]: 0.002997294558675651
Loss at iteration [2782]: 0.0029970860933691864
Loss at iteration [2783]: 0.002996877725642068
Loss at iteration [2784]: 0.002996669657281005
Loss at iteration [2785]: 0.002996461762269312
Loss at iteration [2786]: 0.0029962540300492455
Loss at iteration [2787]: 0.0029960465604940583
Loss at iteration [2788]: 0.0029958392415648494
Loss at iteration [2789]: 0.002995632115457037
Loss at iteration [2790]: 0.002995425169938763
Loss at iteration [2791]: 0.0029952184566113768
Loss at iteration [2792]: 0.0029950120141049594
Loss at iteration [2793]: 0.0029948058740853455
Loss at iteration [2794]: 0.002994599981777312
Loss at iteration [2795]: 0.002994394332730101
Loss at iteration [2796]: 0.002994188904966909
Loss at iteration [2797]: 0.002993983696076156
Loss at iteration [2798]: 0.002993778661395551
Loss at iteration [2799]: 0.0029935738783815054
Loss at iteration [2800]: 0.002993369254167261
Loss at iteration [2801]: 0.0029931649237289336
Loss at iteration [2802]: 0.002992960745073933
Loss at iteration [2803]: 0.00299275681766761
Loss at iteration [2804]: 0.0029925532002139737
Loss at iteration [2805]: 0.0029923497455107435
Loss at iteration [2806]: 0.0029921466634402045
Loss at iteration [2807]: 0.002991943837735514
Loss at iteration [2808]: 0.002991741538575842
Loss at iteration [2809]: 0.0029915400569791428
Loss at iteration [2810]: 0.002991338846952323
Loss at iteration [2811]: 0.0029911379225806205
Loss at iteration [2812]: 0.0029909371859068124
Loss at iteration [2813]: 0.002990736650146511
Loss at iteration [2814]: 0.0029905363089112093
Loss at iteration [2815]: 0.0029903361830952518
Loss at iteration [2816]: 0.002990136317949122
Loss at iteration [2817]: 0.002989936578022644
Loss at iteration [2818]: 0.0029897371104107193
Loss at iteration [2819]: 0.002989537785560453
Loss at iteration [2820]: 0.002989338547087435
Loss at iteration [2821]: 0.0029891394374637835
Loss at iteration [2822]: 0.0029889404307473486
Loss at iteration [2823]: 0.0029887416562172525
Loss at iteration [2824]: 0.0029885431622154153
Loss at iteration [2825]: 0.0029883455807743512
Loss at iteration [2826]: 0.002988148524645799
Loss at iteration [2827]: 0.0029879517218840326
Loss at iteration [2828]: 0.002987755201674555
Loss at iteration [2829]: 0.0029875589053705402
Loss at iteration [2830]: 0.002987362848538549
Loss at iteration [2831]: 0.0029871671059188403
Loss at iteration [2832]: 0.002986971543928219
Loss at iteration [2833]: 0.0029867762346503994
Loss at iteration [2834]: 0.002986581052565077
Loss at iteration [2835]: 0.002986386135352618
Loss at iteration [2836]: 0.002986191419561344
Loss at iteration [2837]: 0.0029859968245011313
Loss at iteration [2838]: 0.002985802530535382
Loss at iteration [2839]: 0.0029856082785936016
Loss at iteration [2840]: 0.0029854144120127993
Loss at iteration [2841]: 0.002985220793143519
Loss at iteration [2842]: 0.0029850273590867234
Loss at iteration [2843]: 0.002984834207712507
Loss at iteration [2844]: 0.0029846412022003312
Loss at iteration [2845]: 0.0029844484976662014
Loss at iteration [2846]: 0.0029842561969642407
Loss at iteration [2847]: 0.002984064152362672
Loss at iteration [2848]: 0.0029838723244094137
Loss at iteration [2849]: 0.0029836807231960766
Loss at iteration [2850]: 0.00298348924544683
Loss at iteration [2851]: 0.0029832979683983843
Loss at iteration [2852]: 0.0029831068683560426
Loss at iteration [2853]: 0.002982916008432603
Loss at iteration [2854]: 0.002982726052214578
Loss at iteration [2855]: 0.0029825364982530743
Loss at iteration [2856]: 0.0029823470809837425
Loss at iteration [2857]: 0.0029821579347454686
Loss at iteration [2858]: 0.002981968908778138
Loss at iteration [2859]: 0.0029817800627180923
Loss at iteration [2860]: 0.0029815914417159442
Loss at iteration [2861]: 0.0029814028919583862
Loss at iteration [2862]: 0.0029812146191248224
Loss at iteration [2863]: 0.0029810264284547638
Loss at iteration [2864]: 0.0029808384852947536
Loss at iteration [2865]: 0.0029806506727178277
Loss at iteration [2866]: 0.0029804630269458306
Loss at iteration [2867]: 0.002980275631445777
Loss at iteration [2868]: 0.0029800884122073695
Loss at iteration [2869]: 0.0029799014314067086
Loss at iteration [2870]: 0.0029797146719323163
Loss at iteration [2871]: 0.002979528024499317
Loss at iteration [2872]: 0.0029793416886024614
Loss at iteration [2873]: 0.002979155399715937
Loss at iteration [2874]: 0.002978969428355018
Loss at iteration [2875]: 0.002978783586913243
Loss at iteration [2876]: 0.0029785979158753494
Loss at iteration [2877]: 0.002978412482053849
Loss at iteration [2878]: 0.0029782272208172295
Loss at iteration [2879]: 0.002978042117553669
Loss at iteration [2880]: 0.002977857127781698
Loss at iteration [2881]: 0.0029776722092296525
Loss at iteration [2882]: 0.002977487468541316
Loss at iteration [2883]: 0.002977302712441762
Loss at iteration [2884]: 0.002977118204212803
Loss at iteration [2885]: 0.0029769337875502682
Loss at iteration [2886]: 0.0029767495652381773
Loss at iteration [2887]: 0.0029765654831191805
Loss at iteration [2888]: 0.002976381559294043
Loss at iteration [2889]: 0.002976197746944449
Loss at iteration [2890]: 0.00297601406787924
Loss at iteration [2891]: 0.0029758306091144174
Loss at iteration [2892]: 0.0029756472472622798
Loss at iteration [2893]: 0.0029754641180688495
Loss at iteration [2894]: 0.002975281133043236
Loss at iteration [2895]: 0.0029750982605334666
Loss at iteration [2896]: 0.0029749156310609243
Loss at iteration [2897]: 0.002974733119222323
Loss at iteration [2898]: 0.0029745508130871964
Loss at iteration [2899]: 0.002974368682752693
Loss at iteration [2900]: 0.0029741866727452286
Loss at iteration [2901]: 0.0029740048695524697
Loss at iteration [2902]: 0.002973823199353483
Loss at iteration [2903]: 0.002973641768438263
Loss at iteration [2904]: 0.0029734604857570637
Loss at iteration [2905]: 0.0029732794149679546
Loss at iteration [2906]: 0.002973098439577443
Loss at iteration [2907]: 0.002972917685757226
Loss at iteration [2908]: 0.002972737096201392
Loss at iteration [2909]: 0.0029725565632150656
Loss at iteration [2910]: 0.002972376243600796
Loss at iteration [2911]: 0.0029721960164820443
Loss at iteration [2912]: 0.0029720159743501983
Loss at iteration [2913]: 0.002971836071712201
Loss at iteration [2914]: 0.002971656364028582
Loss at iteration [2915]: 0.0029714767865156528
Loss at iteration [2916]: 0.002971297332772632
Loss at iteration [2917]: 0.00297111799072865
Loss at iteration [2918]: 0.002970938813614948
Loss at iteration [2919]: 0.002970759837427706
Loss at iteration [2920]: 0.002970581033024843
Loss at iteration [2921]: 0.002970402455366632
Loss at iteration [2922]: 0.002970224154530721
Loss at iteration [2923]: 0.00297004599884321
Loss at iteration [2924]: 0.0029698681974351555
Loss at iteration [2925]: 0.0029696905047101973
Loss at iteration [2926]: 0.0029695131821856685
Loss at iteration [2927]: 0.002969335936705353
Loss at iteration [2928]: 0.00296915880920994
Loss at iteration [2929]: 0.0029689819213772725
Loss at iteration [2930]: 0.0029688051653753655
Loss at iteration [2931]: 0.002968628586313199
Loss at iteration [2932]: 0.0029684521869981413
Loss at iteration [2933]: 0.002968275841718738
Loss at iteration [2934]: 0.0029680997151369823
Loss at iteration [2935]: 0.0029679238336199737
Loss at iteration [2936]: 0.002967748335148018
Loss at iteration [2937]: 0.0029675731122857747
Loss at iteration [2938]: 0.0029673980494235347
Loss at iteration [2939]: 0.002967222965563817
Loss at iteration [2940]: 0.0029670480934558905
Loss at iteration [2941]: 0.002966873332112638
Loss at iteration [2942]: 0.0029666987479975582
Loss at iteration [2943]: 0.002966524411723269
Loss at iteration [2944]: 0.0029663501546774123
Loss at iteration [2945]: 0.0029661761792674104
Loss at iteration [2946]: 0.002966002325502602
Loss at iteration [2947]: 0.0029658286887070877
Loss at iteration [2948]: 0.0029656551662071416
Loss at iteration [2949]: 0.0029654820533245234
Loss at iteration [2950]: 0.0029653093018708774
Loss at iteration [2951]: 0.0029651367524369883
Loss at iteration [2952]: 0.0029649644150847986
Loss at iteration [2953]: 0.00296479224068616
Loss at iteration [2954]: 0.0029646202644838127
Loss at iteration [2955]: 0.0029644484218610168
Loss at iteration [2956]: 0.0029642767463565556
Loss at iteration [2957]: 0.0029641052969588003
Loss at iteration [2958]: 0.002963933857479413
Loss at iteration [2959]: 0.002963762635111921
Loss at iteration [2960]: 0.002963591672836921
Loss at iteration [2961]: 0.002963421087422939
Loss at iteration [2962]: 0.002963251034686567
Loss at iteration [2963]: 0.0029630811614847
Loss at iteration [2964]: 0.002962911502122412
Loss at iteration [2965]: 0.002962742008193834
Loss at iteration [2966]: 0.002962572850218525
Loss at iteration [2967]: 0.002962403827237687
Loss at iteration [2968]: 0.002962235106917961
Loss at iteration [2969]: 0.0029620665647382364
Loss at iteration [2970]: 0.002961898221246056
Loss at iteration [2971]: 0.0029617301112984658
Loss at iteration [2972]: 0.002961562051254717
Loss at iteration [2973]: 0.0029613943062723877
Loss at iteration [2974]: 0.002961226761958375
Loss at iteration [2975]: 0.0029610593162062993
Loss at iteration [2976]: 0.0029608920739394935
Loss at iteration [2977]: 0.002960724961472839
Loss at iteration [2978]: 0.0029605579438666874
Loss at iteration [2979]: 0.0029603911750897566
Loss at iteration [2980]: 0.0029602245394446712
Loss at iteration [2981]: 0.0029600580390198453
Loss at iteration [2982]: 0.002959891703296705
Loss at iteration [2983]: 0.002959725619953877
Loss at iteration [2984]: 0.0029595595355227985
Loss at iteration [2985]: 0.0029593936945617847
Loss at iteration [2986]: 0.0029592279489317214
Loss at iteration [2987]: 0.002959062354554644
Loss at iteration [2988]: 0.00295889691890309
Loss at iteration [2989]: 0.0029587319952556167
Loss at iteration [2990]: 0.002958567229878904
Loss at iteration [2991]: 0.002958402630121862
Loss at iteration [2992]: 0.0029582381928112455
Loss at iteration [2993]: 0.002958074054402647
Loss at iteration [2994]: 0.002957910217025849
Loss at iteration [2995]: 0.002957746626791152
Loss at iteration [2996]: 0.002957583164822255
Loss at iteration [2997]: 0.002957420022277795
Loss at iteration [2998]: 0.002957257043869362
Loss at iteration [2999]: 0.002957094263851367
Loss at iteration [3000]: 0.00295693163329627
