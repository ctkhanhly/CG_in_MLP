Model name                            : MLP_Multistep
The number of input features          : 20
The number of output features         : 2
Optimizer name                        : SGD
Learning rate                         : 0.3
Max number of iterations              : 3000
Number of samples in training data    : 39
Number of samples in tests data       : 16
Total training time                   : 0.04283881187438965
Total number of parameters            : 205302
Percentage of parameters < 1e-9       : 49.910375933989926%
Percentage of parameters < 1e-7       : 49.910375933989926%
Percentage of parameters < 1e-6       : 49.910863021305204%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 1.5206715676180085
Loss at iteration [2]: 1.3321173373536783
Loss at iteration [3]: 0.9939440187546936
Loss at iteration [4]: 0.4645970743614123
Loss at iteration [5]: 0.709128429016036
***** Warning: Loss has increased *****
Loss at iteration [6]: 0.6073245449636547
Loss at iteration [7]: 0.5437787508136904
Loss at iteration [8]: 0.4313865701261133
Loss at iteration [9]: 0.5495325019811824
***** Warning: Loss has increased *****
Loss at iteration [10]: 0.48355130284489745
Loss at iteration [11]: 0.46652237239227556
Loss at iteration [12]: 0.390678322287794
Loss at iteration [13]: 0.425273259985386
***** Warning: Loss has increased *****
Loss at iteration [14]: 0.42496300482621524
Loss at iteration [15]: 0.3932313579754252
Loss at iteration [16]: 0.3975193039255478
***** Warning: Loss has increased *****
Loss at iteration [17]: 0.3999088895897391
***** Warning: Loss has increased *****
Loss at iteration [18]: 0.38965810838163883
Loss at iteration [19]: 0.39036763958530757
***** Warning: Loss has increased *****
Loss at iteration [20]: 0.3905994470972433
***** Warning: Loss has increased *****
Loss at iteration [21]: 0.38929946931256015
Loss at iteration [22]: 0.38917934956439026
Loss at iteration [23]: 0.3892922629890785
***** Warning: Loss has increased *****
Loss at iteration [24]: 0.3891356570839116
Loss at iteration [25]: 0.3891028921870359
Loss at iteration [26]: 0.38911722188895026
***** Warning: Loss has increased *****
Loss at iteration [27]: 0.38910530076520244
Loss at iteration [28]: 0.3890971070111418
Loss at iteration [29]: 0.3890991407373577
***** Warning: Loss has increased *****
Loss at iteration [30]: 0.38909831388371974
Loss at iteration [31]: 0.38909717235853575
Loss at iteration [32]: 0.3890972218919352
***** Warning: Loss has increased *****
Loss at iteration [33]: 0.3890972622277149
***** Warning: Loss has increased *****
Loss at iteration [34]: 0.38909710067677344
Loss at iteration [35]: 0.38909708848559876
Loss at iteration [36]: 0.3890970991064993
***** Warning: Loss has increased *****
Loss at iteration [37]: 0.38909708435281043
Loss at iteration [38]: 0.3890970782206711
Loss at iteration [39]: 0.3890970804469812
***** Warning: Loss has increased *****
Loss at iteration [40]: 0.3890970791001656
Loss at iteration [41]: 0.38909707811537925
