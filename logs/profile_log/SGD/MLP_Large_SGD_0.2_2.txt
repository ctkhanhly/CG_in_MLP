Model name                            : MLP_Large
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : SGD
Learning rate                         : 0.2
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 36.04949474334717
Total number of parameters            : 402001
Percentage of parameters < 1e-9       : 55.35782249297887%
Percentage of parameters < 1e-7       : 55.35807124857899%
Percentage of parameters < 1e-6       : 55.35807124857899%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.9499461053486802
Loss at iteration [2]: 0.22444420064900794
Loss at iteration [3]: 1.407385629112355
***** Warning: Loss has increased *****
Loss at iteration [4]: 5.3561098885810585
***** Warning: Loss has increased *****
Loss at iteration [5]: 1.1194961240989965
Loss at iteration [6]: 1.13510161473248
***** Warning: Loss has increased *****
Loss at iteration [7]: 0.7635442284034993
Loss at iteration [8]: 0.40113721534390195
Loss at iteration [9]: 0.19891645315291587
Loss at iteration [10]: 0.19591242996913252
Loss at iteration [11]: 0.40539116439435047
***** Warning: Loss has increased *****
Loss at iteration [12]: 0.26816652193147006
Loss at iteration [13]: 0.6408766470419662
***** Warning: Loss has increased *****
Loss at iteration [14]: 0.10519262260342857
Loss at iteration [15]: 0.7957192034353615
***** Warning: Loss has increased *****
Loss at iteration [16]: 1.2451511227569405
***** Warning: Loss has increased *****
Loss at iteration [17]: 0.9485881505147441
Loss at iteration [18]: 0.6819930211287002
Loss at iteration [19]: 0.45188281403215874
Loss at iteration [20]: 0.4024568481266187
Loss at iteration [21]: 0.521086271715186
***** Warning: Loss has increased *****
Loss at iteration [22]: 0.37833691940055053
Loss at iteration [23]: 0.7959622507878044
***** Warning: Loss has increased *****
Loss at iteration [24]: 0.23604772192918416
Loss at iteration [25]: 0.18729621888562528
Loss at iteration [26]: 0.18836896995235883
***** Warning: Loss has increased *****
Loss at iteration [27]: 0.4785658262899617
***** Warning: Loss has increased *****
Loss at iteration [28]: 0.5789850337960467
***** Warning: Loss has increased *****
Loss at iteration [29]: 1.8677606943209917
***** Warning: Loss has increased *****
Loss at iteration [30]: 1.1309837401364544
Loss at iteration [31]: 0.6453554651541458
Loss at iteration [32]: 0.28874489023171296
Loss at iteration [33]: 0.3746462345712032
***** Warning: Loss has increased *****
Loss at iteration [34]: 0.8297958151782111
***** Warning: Loss has increased *****
Loss at iteration [35]: 0.28861409802101234
Loss at iteration [36]: 0.9569825270698095
***** Warning: Loss has increased *****
Loss at iteration [37]: 1.4539507002859051
***** Warning: Loss has increased *****
Loss at iteration [38]: 1.32090630430984
Loss at iteration [39]: 1.0771950926544112
Loss at iteration [40]: 0.9983697517416655
Loss at iteration [41]: 0.9997827013957008
***** Warning: Loss has increased *****
Loss at iteration [42]: 0.9769620025401314
Loss at iteration [43]: 0.9093957582396001
Loss at iteration [44]: 0.7816857880063617
Loss at iteration [45]: 0.5813436239374697
Loss at iteration [46]: 0.4487662178946817
Loss at iteration [47]: 0.3151292623723717
Loss at iteration [48]: 0.22543900296501562
Loss at iteration [49]: 0.1921109209044052
Loss at iteration [50]: 0.1977882772550819
***** Warning: Loss has increased *****
Loss at iteration [51]: 0.48726863649546065
***** Warning: Loss has increased *****
Loss at iteration [52]: 0.3104180844810836
Loss at iteration [53]: 0.92703703834983
***** Warning: Loss has increased *****
Loss at iteration [54]: 0.2036925789373976
Loss at iteration [55]: 1.023635877566742
***** Warning: Loss has increased *****
Loss at iteration [56]: 1.6160531433385312
***** Warning: Loss has increased *****
Loss at iteration [57]: 0.7619481288807788
Loss at iteration [58]: 0.7061579680183034
Loss at iteration [59]: 0.40125604988543445
Loss at iteration [60]: 0.42175540568154496
***** Warning: Loss has increased *****
Loss at iteration [61]: 0.49913945761121836
***** Warning: Loss has increased *****
Loss at iteration [62]: 0.21774644002232027
Loss at iteration [63]: 0.4650970560605476
***** Warning: Loss has increased *****
Loss at iteration [64]: 0.7786667523191044
***** Warning: Loss has increased *****
Loss at iteration [65]: 0.6277488895495138
Loss at iteration [66]: 0.11975546268580234
Loss at iteration [67]: 0.3817033768764063
***** Warning: Loss has increased *****
Loss at iteration [68]: 0.4445841923357775
***** Warning: Loss has increased *****
Loss at iteration [69]: 0.30764056704525844
Loss at iteration [70]: 0.08267843945677089
Loss at iteration [71]: 0.09252800029004321
***** Warning: Loss has increased *****
Loss at iteration [72]: 0.05677624149392078
Loss at iteration [73]: 0.041404462341572065
Loss at iteration [74]: 0.017154354173507653
Loss at iteration [75]: 0.01599587823832712
Loss at iteration [76]: 0.0054454393765166415
Loss at iteration [77]: 0.006159945313178812
***** Warning: Loss has increased *****
Loss at iteration [78]: 0.003988480119689061
Loss at iteration [79]: 0.0037989371568133536
Loss at iteration [80]: 0.0032588955320424764
Loss at iteration [81]: 0.0030917495899579423
Loss at iteration [82]: 0.002923969584249728
Loss at iteration [83]: 0.0028668329118950514
Loss at iteration [84]: 0.002807463038706877
Loss at iteration [85]: 0.002791847227494384
Loss at iteration [86]: 0.0027696144518879824
Loss at iteration [87]: 0.002761556986124577
Loss at iteration [88]: 0.0027510900877568763
Loss at iteration [89]: 0.0027442889646641373
Loss at iteration [90]: 0.002737256690249481
Loss at iteration [91]: 0.0027311908105132005
Loss at iteration [92]: 0.002725417581066868
Loss at iteration [93]: 0.0027200599288543935
Loss at iteration [94]: 0.002714959098124003
Loss at iteration [95]: 0.0027100907396216
Loss at iteration [96]: 0.002705379012756018
Loss at iteration [97]: 0.002700880324282197
Loss at iteration [98]: 0.002696547149906932
Loss at iteration [99]: 0.00269234541213594
Loss at iteration [100]: 0.002688327434250429
Loss at iteration [101]: 0.0026844611852378983
Loss at iteration [102]: 0.002680753647363286
Loss at iteration [103]: 0.002677174075972398
Loss at iteration [104]: 0.0026737208598251955
Loss at iteration [105]: 0.002670384852691759
Loss at iteration [106]: 0.0026672089299196217
Loss at iteration [107]: 0.0026641560527565712
Loss at iteration [108]: 0.0026612006824708627
Loss at iteration [109]: 0.0026583304942328304
Loss at iteration [110]: 0.0026555343702389356
Loss at iteration [111]: 0.0026528057635541707
Loss at iteration [112]: 0.0026501672563448053
Loss at iteration [113]: 0.0026476086651120063
Loss at iteration [114]: 0.002645131475605556
Loss at iteration [115]: 0.0026427363974886055
Loss at iteration [116]: 0.0026404124907079486
Loss at iteration [117]: 0.002638131494409652
Loss at iteration [118]: 0.0026359108084009616
Loss at iteration [119]: 0.0026337443998423536
Loss at iteration [120]: 0.002631625097337272
Loss at iteration [121]: 0.0026295219690712596
Loss at iteration [122]: 0.0026274757858388742
Loss at iteration [123]: 0.0026254826285965036
Loss at iteration [124]: 0.0026235453564632627
Loss at iteration [125]: 0.002621654761934462
Loss at iteration [126]: 0.002619807253502996
Loss at iteration [127]: 0.0026179868004858895
Loss at iteration [128]: 0.002616220790198283
Loss at iteration [129]: 0.0026145285588498506
Loss at iteration [130]: 0.0026128938724474227
Loss at iteration [131]: 0.002611299956147927
Loss at iteration [132]: 0.0026097478059665586
Loss at iteration [133]: 0.0026082402347229736
Loss at iteration [134]: 0.002606768635316476
Loss at iteration [135]: 0.00260533475285175
Loss at iteration [136]: 0.002603929906263491
Loss at iteration [137]: 0.0026025461221038603
Loss at iteration [138]: 0.002601186383430682
Loss at iteration [139]: 0.00259985161847889
Loss at iteration [140]: 0.0025985464560904573
Loss at iteration [141]: 0.002597262617020584
Loss at iteration [142]: 0.0025959996085901022
Loss at iteration [143]: 0.002594755703937421
Loss at iteration [144]: 0.002593529825804961
Loss at iteration [145]: 0.002592314483603789
Loss at iteration [146]: 0.002591115847122029
Loss at iteration [147]: 0.002589935859557767
Loss at iteration [148]: 0.0025887713800959652
Loss at iteration [149]: 0.0025876287151698
Loss at iteration [150]: 0.0025864980470900385
Loss at iteration [151]: 0.002585391941710885
Loss at iteration [152]: 0.0025843104274632335
Loss at iteration [153]: 0.0025832474609415157
Loss at iteration [154]: 0.0025821938222750926
Loss at iteration [155]: 0.0025811490851759644
Loss at iteration [156]: 0.0025801220338597794
Loss at iteration [157]: 0.002579108036794992
Loss at iteration [158]: 0.0025781076958757147
Loss at iteration [159]: 0.002577118464250764
Loss at iteration [160]: 0.002576140853188669
Loss at iteration [161]: 0.002575170887941904
Loss at iteration [162]: 0.002574211157214563
Loss at iteration [163]: 0.002573273910765189
Loss at iteration [164]: 0.0025723425203830652
Loss at iteration [165]: 0.00257142120693864
Loss at iteration [166]: 0.0025705080459635593
Loss at iteration [167]: 0.0025696003672072633
Loss at iteration [168]: 0.002568733483043125
Loss at iteration [169]: 0.0025678816832137817
Loss at iteration [170]: 0.0025670490146804405
Loss at iteration [171]: 0.0025662283378922856
Loss at iteration [172]: 0.002565447310426169
Loss at iteration [173]: 0.0025646887877299697
Loss at iteration [174]: 0.002563935975239296
Loss at iteration [175]: 0.002563194047535232
Loss at iteration [176]: 0.002562463313067578
Loss at iteration [177]: 0.0025617444145891828
Loss at iteration [178]: 0.0025610341670418454
Loss at iteration [179]: 0.0025603323220553323
Loss at iteration [180]: 0.0025596403139746967
Loss at iteration [181]: 0.0025589612288323075
Loss at iteration [182]: 0.002558298145388207
Loss at iteration [183]: 0.002557650832949594
Loss at iteration [184]: 0.0025570146552231143
Loss at iteration [185]: 0.0025563882683524437
Loss at iteration [186]: 0.0025557690428318386
Loss at iteration [187]: 0.0025551561936981186
Loss at iteration [188]: 0.0025545525485198045
Loss at iteration [189]: 0.002553956252273224
Loss at iteration [190]: 0.002553365702900665
Loss at iteration [191]: 0.002552789797223542
Loss at iteration [192]: 0.0025522262227268937
Loss at iteration [193]: 0.0025516743975054863
Loss at iteration [194]: 0.0025511325732058407
Loss at iteration [195]: 0.002550597995398258
Loss at iteration [196]: 0.0025500702011627815
Loss at iteration [197]: 0.0025495492294788295
Loss at iteration [198]: 0.0025490263771785057
Loss at iteration [199]: 0.0025485068599688586
Loss at iteration [200]: 0.002547993924094244
Loss at iteration [201]: 0.002547486531028151
Loss at iteration [202]: 0.0025469842773495157
Loss at iteration [203]: 0.002546483021366953
Loss at iteration [204]: 0.002545987860732322
Loss at iteration [205]: 0.002545498743405783
Loss at iteration [206]: 0.002545016966737317
Loss at iteration [207]: 0.002544543566541084
Loss at iteration [208]: 0.0025440806119586324
Loss at iteration [209]: 0.002543622241360188
Loss at iteration [210]: 0.0025431682019811516
Loss at iteration [211]: 0.0025427203865032344
Loss at iteration [212]: 0.0025422753924486054
Loss at iteration [213]: 0.0025418327351094854
Loss at iteration [214]: 0.0025413926600398188
Loss at iteration [215]: 0.002540956846680456
Loss at iteration [216]: 0.002540527938752167
Loss at iteration [217]: 0.0025401077391073255
Loss at iteration [218]: 0.002539695643340522
Loss at iteration [219]: 0.0025392880946937283
Loss at iteration [220]: 0.0025388864368064766
Loss at iteration [221]: 0.0025384918288758438
Loss at iteration [222]: 0.002538098573613251
Loss at iteration [223]: 0.0025377063221655185
Loss at iteration [224]: 0.0025373203640808263
Loss at iteration [225]: 0.002536941084366745
Loss at iteration [226]: 0.002536567665182486
Loss at iteration [227]: 0.0025361991284728533
Loss at iteration [228]: 0.0025358358166286637
Loss at iteration [229]: 0.0025354770804315967
Loss at iteration [230]: 0.0025351174069853967
Loss at iteration [231]: 0.00253476027138855
Loss at iteration [232]: 0.002534405166484532
Loss at iteration [233]: 0.0025340479093533875
Loss at iteration [234]: 0.0025336924362884023
Loss at iteration [235]: 0.002533338219992956
Loss at iteration [236]: 0.0025329859796168384
Loss at iteration [237]: 0.0025326376688166747
Loss at iteration [238]: 0.0025322913268052377
Loss at iteration [239]: 0.002531948352052967
Loss at iteration [240]: 0.0025316103421717377
Loss at iteration [241]: 0.002531275265719024
Loss at iteration [242]: 0.002530941501651552
Loss at iteration [243]: 0.002530605749867382
Loss at iteration [244]: 0.0025302730151720615
Loss at iteration [245]: 0.0025299440496498876
Loss at iteration [246]: 0.002529618190281732
Loss at iteration [247]: 0.0025292942248031055
Loss at iteration [248]: 0.002528975167848336
Loss at iteration [249]: 0.002528659639027669
Loss at iteration [250]: 0.0025283480377280756
Loss at iteration [251]: 0.0025280411561883877
Loss at iteration [252]: 0.002527735499890552
Loss at iteration [253]: 0.0025274319820489657
Loss at iteration [254]: 0.0025271304539161445
Loss at iteration [255]: 0.0025268324697697627
Loss at iteration [256]: 0.002526534468335198
Loss at iteration [257]: 0.0025262362669633627
Loss at iteration [258]: 0.0025259364332604686
Loss at iteration [259]: 0.0025256364071044057
Loss at iteration [260]: 0.002525335581720543
Loss at iteration [261]: 0.0025250318528907954
Loss at iteration [262]: 0.00252472663642333
Loss at iteration [263]: 0.002524421980509444
Loss at iteration [264]: 0.0025241182314921827
Loss at iteration [265]: 0.0025238164364956906
Loss at iteration [266]: 0.0025235159125053313
Loss at iteration [267]: 0.0025232192230573783
Loss at iteration [268]: 0.0025229271303228162
Loss at iteration [269]: 0.0025226371695029437
Loss at iteration [270]: 0.002522349643035618
Loss at iteration [271]: 0.0025220657510707334
Loss at iteration [272]: 0.00252178447481296
Loss at iteration [273]: 0.0025215063043660846
Loss at iteration [274]: 0.0025212302645128363
Loss at iteration [275]: 0.0025209579982073474
Loss at iteration [276]: 0.0025206893116076993
Loss at iteration [277]: 0.002520424702861838
Loss at iteration [278]: 0.002520160841639842
Loss at iteration [279]: 0.0025198956102295
Loss at iteration [280]: 0.0025196293183355548
Loss at iteration [281]: 0.002519364360523365
Loss at iteration [282]: 0.00251910083843512
Loss at iteration [283]: 0.0025188388172651937
Loss at iteration [284]: 0.002518578097439843
Loss at iteration [285]: 0.002518316403025765
Loss at iteration [286]: 0.0025180548493272496
Loss at iteration [287]: 0.002517794621767909
Loss at iteration [288]: 0.0025175363248597983
Loss at iteration [289]: 0.002517281229405132
Loss at iteration [290]: 0.0025170283947052964
Loss at iteration [291]: 0.002516777016377716
Loss at iteration [292]: 0.0025165242616308763
Loss at iteration [293]: 0.0025162808345121804
Loss at iteration [294]: 0.002516028229240119
Loss at iteration [295]: 0.002515784191304957
Loss at iteration [296]: 0.0025155402954678465
Loss at iteration [297]: 0.0025152966268593533
Loss at iteration [298]: 0.0025150616503403656
Loss at iteration [299]: 0.002514815490977162
Loss at iteration [300]: 0.0025145787715633037
Loss at iteration [301]: 0.002514343309699454
Loss at iteration [302]: 0.002514104474536415
Loss at iteration [303]: 0.0025138792192956672
Loss at iteration [304]: 0.0025136505000325953
Loss at iteration [305]: 0.0025134310224286948
Loss at iteration [306]: 0.0025132116453052225
Loss at iteration [307]: 0.002512990809412352
Loss at iteration [308]: 0.0025127744354270917
Loss at iteration [309]: 0.0025125552036401894
Loss at iteration [310]: 0.0025123459591958747
Loss at iteration [311]: 0.0025121287393337984
Loss at iteration [312]: 0.002511919466347822
Loss at iteration [313]: 0.002511703024359937
Loss at iteration [314]: 0.00251147558496441
Loss at iteration [315]: 0.0025112513071836686
Loss at iteration [316]: 0.002511019962024709
Loss at iteration [317]: 0.0025107974891393787
Loss at iteration [318]: 0.0025105722735266887
Loss at iteration [319]: 0.002510355223909148
Loss at iteration [320]: 0.002510135630060547
Loss at iteration [321]: 0.002509924321255261
Loss at iteration [322]: 0.0025097117324164838
Loss at iteration [323]: 0.00250950035787873
Loss at iteration [324]: 0.0025092982871947277
Loss at iteration [325]: 0.0025090925657754795
Loss at iteration [326]: 0.0025088907921234573
Loss at iteration [327]: 0.0025086904078832997
Loss at iteration [328]: 0.0025084944790887327
Loss at iteration [329]: 0.002508301990118273
Loss at iteration [330]: 0.0025081095341257715
Loss at iteration [331]: 0.002507924049912921
Loss at iteration [332]: 0.002507729979790738
Loss at iteration [333]: 0.002507545124399168
Loss at iteration [334]: 0.002507355876817058
Loss at iteration [335]: 0.0025071641747521256
Loss at iteration [336]: 0.0025069829993429617
Loss at iteration [337]: 0.0025067913300386322
Loss at iteration [338]: 0.0025065982287196904
Loss at iteration [339]: 0.0025064019488336125
Loss at iteration [340]: 0.0025062059773572434
Loss at iteration [341]: 0.002506010473077911
Loss at iteration [342]: 0.0025058270991118745
Loss at iteration [343]: 0.0025056434064808877
Loss at iteration [344]: 0.002505459820661077
Loss at iteration [345]: 0.002505285841661324
Loss at iteration [346]: 0.0025051040689439484
Loss at iteration [347]: 0.002504930473885077
Loss at iteration [348]: 0.0025047557496948062
Loss at iteration [349]: 0.0025045809981918254
Loss at iteration [350]: 0.0025044150400417224
Loss at iteration [351]: 0.002504246273111507
Loss at iteration [352]: 0.0025040876571320804
Loss at iteration [353]: 0.002503920570205029
Loss at iteration [354]: 0.002503758260715418
Loss at iteration [355]: 0.002503594732955095
Loss at iteration [356]: 0.0025034313475300047
Loss at iteration [357]: 0.002503270993062806
Loss at iteration [358]: 0.0025031111058877805
Loss at iteration [359]: 0.0025029525389972324
Loss at iteration [360]: 0.002502791361763213
Loss at iteration [361]: 0.002502638653728918
Loss at iteration [362]: 0.002502478015017924
Loss at iteration [363]: 0.002502324546367288
Loss at iteration [364]: 0.002502169072345643
Loss at iteration [365]: 0.0025020151506086655
Loss at iteration [366]: 0.0025018682852561893
Loss at iteration [367]: 0.002501721553237034
Loss at iteration [368]: 0.00250157623216326
Loss at iteration [369]: 0.0025014271075580116
Loss at iteration [370]: 0.0025012872392491843
Loss at iteration [371]: 0.0025011387352180297
Loss at iteration [372]: 0.0025009945849541167
Loss at iteration [373]: 0.0025008489305593513
Loss at iteration [374]: 0.0025007036013189035
Loss at iteration [375]: 0.0025005588406175655
Loss at iteration [376]: 0.0025004187000229688
Loss at iteration [377]: 0.002500276714614422
Loss at iteration [378]: 0.0025001341839548785
Loss at iteration [379]: 0.0024999974283582142
Loss at iteration [380]: 0.002499854692496857
Loss at iteration [381]: 0.0024997178403960555
Loss at iteration [382]: 0.0024995736338483546
Loss at iteration [383]: 0.0024994357528517796
Loss at iteration [384]: 0.002499294218117499
Loss at iteration [385]: 0.0024991516682199553
Loss at iteration [386]: 0.0024990129121413803
Loss at iteration [387]: 0.0024988737756482175
Loss at iteration [388]: 0.0024987364272230196
Loss at iteration [389]: 0.0024985955196282147
Loss at iteration [390]: 0.0024984656516449824
Loss at iteration [391]: 0.002498326344352031
Loss at iteration [392]: 0.002498191345682248
Loss at iteration [393]: 0.0024980549994378307
Loss at iteration [394]: 0.002497917023664807
Loss at iteration [395]: 0.0024977800998391623
Loss at iteration [396]: 0.0024976437122454353
Loss at iteration [397]: 0.002497509215536114
Loss at iteration [398]: 0.0024973708020309196
Loss at iteration [399]: 0.0024972393483574194
Loss at iteration [400]: 0.0024971001177315657
Loss at iteration [401]: 0.0024969693185279505
Loss at iteration [402]: 0.002496833638485007
Loss at iteration [403]: 0.0024966943551435862
Loss at iteration [404]: 0.0024965668252629196
Loss at iteration [405]: 0.0024964295230213546
Loss at iteration [406]: 0.0024962963594534807
Loss at iteration [407]: 0.002496162985959246
Loss at iteration [408]: 0.002496028911282951
Loss at iteration [409]: 0.0024958971256262125
Loss at iteration [410]: 0.002495763679885408
Loss at iteration [411]: 0.0024956341114258157
Loss at iteration [412]: 0.0024954982543949453
Loss at iteration [413]: 0.0024953656350580043
Loss at iteration [414]: 0.0024952282078026314
Loss at iteration [415]: 0.0024950971622593175
Loss at iteration [416]: 0.0024949621283437175
Loss at iteration [417]: 0.0024948289093980835
Loss at iteration [418]: 0.0024947010054522504
Loss at iteration [419]: 0.0024945686175007883
Loss at iteration [420]: 0.0024944397375944167
Loss at iteration [421]: 0.0024943083907758633
Loss at iteration [422]: 0.0024941827182980722
Loss at iteration [423]: 0.0024940533242013645
Loss at iteration [424]: 0.00249392387684821
Loss at iteration [425]: 0.0024938004733180506
Loss at iteration [426]: 0.0024936668736132827
Loss at iteration [427]: 0.0024935424435906734
Loss at iteration [428]: 0.002493415464265617
Loss at iteration [429]: 0.002493283462782211
Loss at iteration [430]: 0.002493161271069913
Loss at iteration [431]: 0.0024930306637444754
Loss at iteration [432]: 0.0024929056960187415
Loss at iteration [433]: 0.002492778261587979
Loss at iteration [434]: 0.0024926482082040795
Loss at iteration [435]: 0.0024925290153568333
Loss at iteration [436]: 0.002492398481703175
Loss at iteration [437]: 0.0024922687644558586
Loss at iteration [438]: 0.0024921394001137845
Loss at iteration [439]: 0.0024920088360815265
Loss at iteration [440]: 0.00249187796236019
Loss at iteration [441]: 0.002491743832436645
Loss at iteration [442]: 0.00249161858115031
Loss at iteration [443]: 0.0024914859931050655
Loss at iteration [444]: 0.0024913616559680087
Loss at iteration [445]: 0.0024912342501140984
Loss at iteration [446]: 0.0024911028574916595
Loss at iteration [447]: 0.0024909809437751087
Loss at iteration [448]: 0.0024908521724222948
Loss at iteration [449]: 0.0024907311020506175
Loss at iteration [450]: 0.002490606985829566
Loss at iteration [451]: 0.0024904796357985357
Loss at iteration [452]: 0.002490362364851559
Loss at iteration [453]: 0.0024902357714438246
Loss at iteration [454]: 0.0024901174521443194
Loss at iteration [455]: 0.002489995406044738
Loss at iteration [456]: 0.0024898696671017922
Loss at iteration [457]: 0.0024897507840882047
Loss at iteration [458]: 0.002489625659003659
Loss at iteration [459]: 0.0024895155923731612
Loss at iteration [460]: 0.0024894009452886712
Loss at iteration [461]: 0.0024892850256219745
Loss at iteration [462]: 0.0024891728078224483
Loss at iteration [463]: 0.002489057338008782
Loss at iteration [464]: 0.002488947320661979
Loss at iteration [465]: 0.0024888331024495456
Loss at iteration [466]: 0.0024887187033953437
Loss at iteration [467]: 0.0024886096761903165
Loss at iteration [468]: 0.002488492826155808
Loss at iteration [469]: 0.0024883840167423308
Loss at iteration [470]: 0.002488271949610159
Loss at iteration [471]: 0.0024881590808210037
Loss at iteration [472]: 0.0024880518470586544
Loss at iteration [473]: 0.002487937676681395
Loss at iteration [474]: 0.002487829030351133
Loss at iteration [475]: 0.002487724304961948
Loss at iteration [476]: 0.002487615441975409
Loss at iteration [477]: 0.0024875096286602867
Loss at iteration [478]: 0.002487403868002489
Loss at iteration [479]: 0.0024872971356527615
Loss at iteration [480]: 0.002487196612598574
Loss at iteration [481]: 0.0024870918614351774
Loss at iteration [482]: 0.0024869861231213704
Loss at iteration [483]: 0.002486884492517558
Loss at iteration [484]: 0.002486780307697662
Loss at iteration [485]: 0.0024866799436419015
Loss at iteration [486]: 0.0024865758025544873
Loss at iteration [487]: 0.002486472666511705
Loss at iteration [488]: 0.0024863743680214366
Loss at iteration [489]: 0.0024862710946481417
Loss at iteration [490]: 0.0024861668394693206
Loss at iteration [491]: 0.0024860672228730124
Loss at iteration [492]: 0.002485963054403044
Loss at iteration [493]: 0.0024858628966172667
Loss at iteration [494]: 0.0024857616364749066
Loss at iteration [495]: 0.002485659528660887
Loss at iteration [496]: 0.0024855641087727113
Loss at iteration [497]: 0.002485459551174526
Loss at iteration [498]: 0.002485360116527747
Loss at iteration [499]: 0.0024852623062666325
Loss at iteration [500]: 0.00248516244621844
Loss at iteration [501]: 0.002485061461063779
Loss at iteration [502]: 0.002484966599919493
Loss at iteration [503]: 0.002484867122825334
Loss at iteration [504]: 0.002484768969694812
Loss at iteration [505]: 0.002484672344167287
Loss at iteration [506]: 0.0024845719717414504
Loss at iteration [507]: 0.0024844740742835944
Loss at iteration [508]: 0.0024843742753254414
Loss at iteration [509]: 0.002484274164810263
Loss at iteration [510]: 0.002484177613999885
Loss at iteration [511]: 0.0024840757804014584
Loss at iteration [512]: 0.0024839745717194946
Loss at iteration [513]: 0.0024838795173909266
Loss at iteration [514]: 0.002483777583334125
Loss at iteration [515]: 0.002483678450078198
Loss at iteration [516]: 0.00248358315910063
Loss at iteration [517]: 0.00248348030477976
Loss at iteration [518]: 0.0024833781475093668
Loss at iteration [519]: 0.002483280932232212
Loss at iteration [520]: 0.002483176560498282
Loss at iteration [521]: 0.0024830755152544207
Loss at iteration [522]: 0.0024829814917839304
Loss at iteration [523]: 0.002482880342129798
Loss at iteration [524]: 0.002482780787524254
Loss at iteration [525]: 0.0024826887357232664
Loss at iteration [526]: 0.00248258784037855
Loss at iteration [527]: 0.00248249022250679
Loss at iteration [528]: 0.002482396729875008
Loss at iteration [529]: 0.00248229735489873
Loss at iteration [530]: 0.002482200630320496
Loss at iteration [531]: 0.002482110915711626
Loss at iteration [532]: 0.002482014055144435
Loss at iteration [533]: 0.0024819182619705573
Loss at iteration [534]: 0.0024818252482324793
Loss at iteration [535]: 0.0024817304148066406
Loss at iteration [536]: 0.002481634568476
Loss at iteration [537]: 0.0024815401965039815
Loss at iteration [538]: 0.002481445186006798
Loss at iteration [539]: 0.0024813496810395315
Loss at iteration [540]: 0.002481253726388856
Loss at iteration [541]: 0.002481160872786506
Loss at iteration [542]: 0.0024810665847382445
Loss at iteration [543]: 0.0024809695950598226
Loss at iteration [544]: 0.0024808813021240874
Loss at iteration [545]: 0.0024807820698429803
Loss at iteration [546]: 0.002480688978514683
Loss at iteration [547]: 0.002480599669184534
Loss at iteration [548]: 0.002480505554384456
Loss at iteration [549]: 0.002480412159079252
Loss at iteration [550]: 0.002480324633306382
Loss at iteration [551]: 0.0024802323184522465
Loss at iteration [552]: 0.002480142166209139
Loss at iteration [553]: 0.0024800564056454183
Loss at iteration [554]: 0.002479966356702003
Loss at iteration [555]: 0.0024798787232572553
Loss at iteration [556]: 0.0024797891200912677
Loss at iteration [557]: 0.0024797026051047045
Loss at iteration [558]: 0.002479612479385639
Loss at iteration [559]: 0.0024795233255403455
Loss at iteration [560]: 0.0024794384867823905
Loss at iteration [561]: 0.0024793486253016574
Loss at iteration [562]: 0.0024792584680642165
Loss at iteration [563]: 0.0024791771485840586
Loss at iteration [564]: 0.0024790831843844716
Loss at iteration [565]: 0.0024789958367747228
Loss at iteration [566]: 0.0024789131852479174
Loss at iteration [567]: 0.0024788254965897763
Loss at iteration [568]: 0.0024787376708061606
Loss at iteration [569]: 0.002478650547436228
Loss at iteration [570]: 0.002478563413468428
Loss at iteration [571]: 0.002478476449421597
Loss at iteration [572]: 0.002478388588086869
Loss at iteration [573]: 0.0024783040837553748
Loss at iteration [574]: 0.0024782160777149414
Loss at iteration [575]: 0.0024781263334716567
Loss at iteration [576]: 0.002478041903434545
Loss at iteration [577]: 0.0024779474636920634
Loss at iteration [578]: 0.002477861291869473
Loss at iteration [579]: 0.00247777501553864
Loss at iteration [580]: 0.002477687335058155
Loss at iteration [581]: 0.0024775980151276623
Loss at iteration [582]: 0.002477512682024853
Loss at iteration [583]: 0.00247742630778449
Loss at iteration [584]: 0.002477339768427323
Loss at iteration [585]: 0.002477252187192616
Loss at iteration [586]: 0.002477170065784392
Loss at iteration [587]: 0.0024770841047532825
Loss at iteration [588]: 0.0024769966155516452
Loss at iteration [589]: 0.002476913525740512
Loss at iteration [590]: 0.0024768254828016665
Loss at iteration [591]: 0.0024767397952429973
Loss at iteration [592]: 0.0024766556092798873
Loss at iteration [593]: 0.002476572733429384
Loss at iteration [594]: 0.0024764885297893107
Loss at iteration [595]: 0.0024764018188461693
Loss at iteration [596]: 0.002476322317614752
Loss at iteration [597]: 0.0024762345444857958
Loss at iteration [598]: 0.002476150925710606
Loss at iteration [599]: 0.0024760706934753535
Loss at iteration [600]: 0.0024759843035451817
Loss at iteration [601]: 0.00247589994037063
Loss at iteration [602]: 0.002475818666802175
Loss at iteration [603]: 0.0024757351486158264
Loss at iteration [604]: 0.0024756503897858276
Loss at iteration [605]: 0.0024755664537667635
Loss at iteration [606]: 0.00247548473474933
Loss at iteration [607]: 0.0024754006338656063
Loss at iteration [608]: 0.0024753149251846743
Loss at iteration [609]: 0.002475233710114928
Loss at iteration [610]: 0.002475148127869164
Loss at iteration [611]: 0.002475064044280404
Loss at iteration [612]: 0.002474985007064161
Loss at iteration [613]: 0.002474902658974923
Loss at iteration [614]: 0.0024748211867575624
Loss at iteration [615]: 0.002474738989617215
Loss at iteration [616]: 0.002474658645783704
Loss at iteration [617]: 0.0024745747206637568
Loss at iteration [618]: 0.002474489781671371
Loss at iteration [619]: 0.0024744082545446245
Loss at iteration [620]: 0.0024743220002667004
Loss at iteration [621]: 0.0024742345255104603
Loss at iteration [622]: 0.002474147635586641
Loss at iteration [623]: 0.0024740632170080754
Loss at iteration [624]: 0.002473977070604287
Loss at iteration [625]: 0.0024738897643537313
Loss at iteration [626]: 0.0024738050913911966
Loss at iteration [627]: 0.0024737208140868825
Loss at iteration [628]: 0.002473636773716102
Loss at iteration [629]: 0.0024735518340579248
Loss at iteration [630]: 0.0024734727495139227
Loss at iteration [631]: 0.0024733855180226545
Loss at iteration [632]: 0.002473302973963567
Loss at iteration [633]: 0.002473224551253908
Loss at iteration [634]: 0.0024731387813236565
Loss at iteration [635]: 0.0024730552634313705
Loss at iteration [636]: 0.002472978122065236
Loss at iteration [637]: 0.002472897204682317
Loss at iteration [638]: 0.0024728158700051107
Loss at iteration [639]: 0.002472740390644697
Loss at iteration [640]: 0.0024726612793104785
Loss at iteration [641]: 0.002472580342875261
Loss at iteration [642]: 0.0024725024284951995
Loss at iteration [643]: 0.002472423639373689
Loss at iteration [644]: 0.0024723434831491462
Loss at iteration [645]: 0.0024722637516403517
Loss at iteration [646]: 0.0024721867849666944
Loss at iteration [647]: 0.0024721065638620555
Loss at iteration [648]: 0.002472023383761612
Loss at iteration [649]: 0.002471946350991581
Loss at iteration [650]: 0.0024718630587746452
Loss at iteration [651]: 0.0024717820613598053
Loss at iteration [652]: 0.002471704135378315
Loss at iteration [653]: 0.0024716215328687797
Loss at iteration [654]: 0.0024715413629842736
Loss at iteration [655]: 0.0024714614486411636
Loss at iteration [656]: 0.0024713871480778185
Loss at iteration [657]: 0.002471307087760789
Loss at iteration [658]: 0.002471226448382716
Loss at iteration [659]: 0.0024711542465812334
Loss at iteration [660]: 0.0024710725081233662
Loss at iteration [661]: 0.0024709951085691993
Loss at iteration [662]: 0.0024709221966066285
Loss at iteration [663]: 0.002470844636387997
Loss at iteration [664]: 0.0024707678214184715
Loss at iteration [665]: 0.0024706918597380903
Loss at iteration [666]: 0.0024706185797891147
Loss at iteration [667]: 0.0024705425014636536
Loss at iteration [668]: 0.002470465848126186
Loss at iteration [669]: 0.002470393823439101
Loss at iteration [670]: 0.002470316003740836
Loss at iteration [671]: 0.00247024207666124
Loss at iteration [672]: 0.002470169472286255
Loss at iteration [673]: 0.0024700965295708093
Loss at iteration [674]: 0.0024700218267671137
Loss at iteration [675]: 0.0024699455760440686
Loss at iteration [676]: 0.0024698777306976106
Loss at iteration [677]: 0.002469801203514708
Loss at iteration [678]: 0.0024697271035135633
Loss at iteration [679]: 0.002469656999596642
Loss at iteration [680]: 0.0024695845491619095
Loss at iteration [681]: 0.002469511810523861
Loss at iteration [682]: 0.0024694366030456813
Loss at iteration [683]: 0.0024693704752078603
Loss at iteration [684]: 0.0024692946549107423
Loss at iteration [685]: 0.0024692219512551378
Loss at iteration [686]: 0.0024691520287827787
Loss at iteration [687]: 0.0024690799714105344
Loss at iteration [688]: 0.0024690078854514236
Loss at iteration [689]: 0.0024689338329593074
Loss at iteration [690]: 0.002468865458054891
Loss at iteration [691]: 0.0024687911838305225
Loss at iteration [692]: 0.002468719849639734
Loss at iteration [693]: 0.002468648754500621
Loss at iteration [694]: 0.00246857891012478
Loss at iteration [695]: 0.0024685083918094238
Loss at iteration [696]: 0.002468434513052707
Loss at iteration [697]: 0.0024683636335149487
Loss at iteration [698]: 0.002468292378961348
Loss at iteration [699]: 0.0024682221178184646
Loss at iteration [700]: 0.0024681505585690358
Loss at iteration [701]: 0.002468084669578329
Loss at iteration [702]: 0.00246801273738374
Loss at iteration [703]: 0.0024679430681965302
Loss at iteration [704]: 0.002467873574563682
Loss at iteration [705]: 0.002467809590345124
Loss at iteration [706]: 0.0024677405567892813
Loss at iteration [707]: 0.0024676702747253956
Loss at iteration [708]: 0.0024676008652587214
Loss at iteration [709]: 0.002467533918683171
Loss at iteration [710]: 0.002467465957204549
Loss at iteration [711]: 0.0024673935952436725
Loss at iteration [712]: 0.0024673253156385242
Loss at iteration [713]: 0.002467255819403
Loss at iteration [714]: 0.002467184834937365
Loss at iteration [715]: 0.002467113893992465
Loss at iteration [716]: 0.002467047496779121
Loss at iteration [717]: 0.002466978036490775
Loss at iteration [718]: 0.0024669083493802867
Loss at iteration [719]: 0.0024668388824781715
Loss at iteration [720]: 0.002466774081848094
Loss at iteration [721]: 0.002466704121564903
Loss at iteration [722]: 0.0024666356494233315
Loss at iteration [723]: 0.0024665660117027003
Loss at iteration [724]: 0.002466500873978013
Loss at iteration [725]: 0.0024664311331808043
Loss at iteration [726]: 0.002466362910524503
Loss at iteration [727]: 0.002466294155970539
Loss at iteration [728]: 0.0024662301908309507
Loss at iteration [729]: 0.002466160711676268
Loss at iteration [730]: 0.002466094170712801
Loss at iteration [731]: 0.0024660250164554795
Loss at iteration [732]: 0.0024659612714252386
Loss at iteration [733]: 0.0024658929066303683
Loss at iteration [734]: 0.002465826404816303
Loss at iteration [735]: 0.002465758587595751
Loss at iteration [736]: 0.0024656964446099104
Loss at iteration [737]: 0.0024656273146303124
Loss at iteration [738]: 0.0024655615936782175
Loss at iteration [739]: 0.0024654930481117065
Loss at iteration [740]: 0.002465431894666416
Loss at iteration [741]: 0.0024653634224582883
Loss at iteration [742]: 0.002465299078426895
Loss at iteration [743]: 0.002465231029488382
Loss at iteration [744]: 0.0024651698392948933
Loss at iteration [745]: 0.0024651014650124464
Loss at iteration [746]: 0.002465036185607585
Loss at iteration [747]: 0.002464969773045788
Loss at iteration [748]: 0.0024649077926180213
Loss at iteration [749]: 0.002464840789665206
Loss at iteration [750]: 0.00246477563306345
Loss at iteration [751]: 0.0024647102869479283
Loss at iteration [752]: 0.0024646467058826228
Loss at iteration [753]: 0.002464582403815716
Loss at iteration [754]: 0.0024645176940669114
Loss at iteration [755]: 0.0024644517050251102
Loss at iteration [756]: 0.0024643888496812525
Loss at iteration [757]: 0.0024643260986782645
Loss at iteration [758]: 0.0024642628346254586
Loss at iteration [759]: 0.0024641989051234106
Loss at iteration [760]: 0.0024641362568193054
Loss at iteration [761]: 0.0024640749094133932
Loss at iteration [762]: 0.0024640119616223706
Loss at iteration [763]: 0.0024639495061160557
Loss at iteration [764]: 0.0024638840665360848
Loss at iteration [765]: 0.0024638273069042312
Loss at iteration [766]: 0.002463761274888353
Loss at iteration [767]: 0.00246369886095288
Loss at iteration [768]: 0.0024636369253637352
Loss at iteration [769]: 0.0024635782230836
Loss at iteration [770]: 0.0024635111960513113
Loss at iteration [771]: 0.0024634467075499034
Loss at iteration [772]: 0.0024633791722068563
Loss at iteration [773]: 0.0024633131569957046
Loss at iteration [774]: 0.002463250479335184
Loss at iteration [775]: 0.002463187645548492
Loss at iteration [776]: 0.002463123410828975
Loss at iteration [777]: 0.0024630595360767516
Loss at iteration [778]: 0.002462994175456868
Loss at iteration [779]: 0.0024629301752021387
Loss at iteration [780]: 0.002462866395058338
Loss at iteration [781]: 0.002462800981129076
Loss at iteration [782]: 0.002462735924346744
Loss at iteration [783]: 0.002462669370887512
Loss at iteration [784]: 0.002462603429947412
Loss at iteration [785]: 0.002462535084228154
Loss at iteration [786]: 0.0024624713067000806
Loss at iteration [787]: 0.0024624042500211835
Loss at iteration [788]: 0.002462337674488007
Loss at iteration [789]: 0.00246227232701368
Loss at iteration [790]: 0.0024622058028541264
Loss at iteration [791]: 0.002462142712897407
Loss at iteration [792]: 0.0024620800333264073
Loss at iteration [793]: 0.0024620220411895504
Loss at iteration [794]: 0.0024619569069251816
Loss at iteration [795]: 0.0024618956509895795
Loss at iteration [796]: 0.002461834127690462
Loss at iteration [797]: 0.0024617722142452232
Loss at iteration [798]: 0.0024617105627126323
Loss at iteration [799]: 0.0024616488766804993
Loss at iteration [800]: 0.0024615899121492265
Loss at iteration [801]: 0.0024615287520051263
Loss at iteration [802]: 0.002461467249458788
Loss at iteration [803]: 0.002461406865757743
Loss at iteration [804]: 0.002461345087933182
Loss at iteration [805]: 0.0024612831813784035
Loss at iteration [806]: 0.002461221714484133
Loss at iteration [807]: 0.0024611633940205733
Loss at iteration [808]: 0.0024611018339454564
Loss at iteration [809]: 0.002461040867668906
Loss at iteration [810]: 0.002460980940378169
Loss at iteration [811]: 0.0024609184749646716
Loss at iteration [812]: 0.0024608583504171205
Loss at iteration [813]: 0.0024607967050920706
Loss at iteration [814]: 0.0024607359491673323
Loss at iteration [815]: 0.0024606757491416045
Loss at iteration [816]: 0.0024606175571342957
Loss at iteration [817]: 0.0024605577524516795
Loss at iteration [818]: 0.002460498680330339
Loss at iteration [819]: 0.002460443101830974
Loss at iteration [820]: 0.0024603863446871605
Loss at iteration [821]: 0.002460329016131944
Loss at iteration [822]: 0.0024602729339201226
Loss at iteration [823]: 0.0024602168678156864
Loss at iteration [824]: 0.002460163800321623
Loss at iteration [825]: 0.0024601081131138173
Loss at iteration [826]: 0.0024600529511513347
Loss at iteration [827]: 0.0024599977996916517
Loss at iteration [828]: 0.002459941231723162
Loss at iteration [829]: 0.002459886303309322
Loss at iteration [830]: 0.0024598298668212027
Loss at iteration [831]: 0.002459774903481488
Loss at iteration [832]: 0.0024597208361769626
Loss at iteration [833]: 0.0024596644070169205
Loss at iteration [834]: 0.00245960813529581
Loss at iteration [835]: 0.002459551635934814
Loss at iteration [836]: 0.0024594956612412956
Loss at iteration [837]: 0.0024594383739176854
Loss at iteration [838]: 0.002459381434994071
Loss at iteration [839]: 0.002459324457645505
Loss at iteration [840]: 0.0024592684631418514
Loss at iteration [841]: 0.002459212965186806
Loss at iteration [842]: 0.00245915757406721
Loss at iteration [843]: 0.00245910147680157
Loss at iteration [844]: 0.00245904500229329
Loss at iteration [845]: 0.002458989121738873
Loss at iteration [846]: 0.002458932747056242
Loss at iteration [847]: 0.0024588750767187053
Loss at iteration [848]: 0.0024588185852605364
Loss at iteration [849]: 0.002458763977770123
Loss at iteration [850]: 0.0024587093272259134
Loss at iteration [851]: 0.0024586536889632553
Loss at iteration [852]: 0.002458597381847581
Loss at iteration [853]: 0.0024585408649349825
Loss at iteration [854]: 0.0024584841629807846
Loss at iteration [855]: 0.0024584282766043825
Loss at iteration [856]: 0.002458371554385769
Loss at iteration [857]: 0.002458314901934879
Loss at iteration [858]: 0.002458259109855912
Loss at iteration [859]: 0.002458203951816573
Loss at iteration [860]: 0.002458148068961177
Loss at iteration [861]: 0.002458091181750749
Loss at iteration [862]: 0.002458033889520567
Loss at iteration [863]: 0.0024579773854625864
Loss at iteration [864]: 0.002457919804702137
Loss at iteration [865]: 0.002457861269978008
Loss at iteration [866]: 0.0024578021529074235
Loss at iteration [867]: 0.0024577427268144517
Loss at iteration [868]: 0.0024576844846689295
Loss at iteration [869]: 0.0024576263921916343
Loss at iteration [870]: 0.0024575662050638877
Loss at iteration [871]: 0.002457506251194136
Loss at iteration [872]: 0.002457446269339088
Loss at iteration [873]: 0.002457385452371518
Loss at iteration [874]: 0.0024573256655797096
Loss at iteration [875]: 0.0024572650554083434
Loss at iteration [876]: 0.0024572049713978005
Loss at iteration [877]: 0.0024571455226452387
Loss at iteration [878]: 0.0024570863144344948
Loss at iteration [879]: 0.0024570275489815487
Loss at iteration [880]: 0.0024569674870363496
Loss at iteration [881]: 0.002456908215596763
Loss at iteration [882]: 0.002456848614151265
Loss at iteration [883]: 0.002456789494244853
Loss at iteration [884]: 0.002456732108437806
Loss at iteration [885]: 0.0024566731430935695
Loss at iteration [886]: 0.0024566154189155504
Loss at iteration [887]: 0.002456556479688593
Loss at iteration [888]: 0.0024564997380418932
Loss at iteration [889]: 0.002456441840467684
Loss at iteration [890]: 0.002456383980264497
Loss at iteration [891]: 0.0024563254115190615
Loss at iteration [892]: 0.002456268034956671
Loss at iteration [893]: 0.002456209019245086
Loss at iteration [894]: 0.00245614853261834
Loss at iteration [895]: 0.0024560880776721737
Loss at iteration [896]: 0.002456027804016151
Loss at iteration [897]: 0.002455966809506889
Loss at iteration [898]: 0.0024559064230422947
Loss at iteration [899]: 0.0024558448468184712
Loss at iteration [900]: 0.002455785988813954
Loss at iteration [901]: 0.0024557248640631126
Loss at iteration [902]: 0.002455666153678593
Loss at iteration [903]: 0.0024556053256757924
Loss at iteration [904]: 0.0024555439834967486
Loss at iteration [905]: 0.0024554862200455527
Loss at iteration [906]: 0.0024554246581570665
Loss at iteration [907]: 0.0024553638294127584
Loss at iteration [908]: 0.0024553006604040996
Loss at iteration [909]: 0.002455236858571265
Loss at iteration [910]: 0.0024551723819692156
Loss at iteration [911]: 0.0024551074006456328
Loss at iteration [912]: 0.0024550424210109706
Loss at iteration [913]: 0.0024549788399436936
Loss at iteration [914]: 0.002454915421552843
Loss at iteration [915]: 0.002454851259556273
Loss at iteration [916]: 0.0024547866997696615
Loss at iteration [917]: 0.002454723032126041
Loss at iteration [918]: 0.0024546585419236563
Loss at iteration [919]: 0.0024545918357348397
Loss at iteration [920]: 0.0024545244533033406
Loss at iteration [921]: 0.0024544580143457963
Loss at iteration [922]: 0.0024543908265953567
Loss at iteration [923]: 0.002454323824397204
Loss at iteration [924]: 0.0024542563659759927
Loss at iteration [925]: 0.0024541863086491255
Loss at iteration [926]: 0.0024541163229215798
Loss at iteration [927]: 0.002454045855654898
Loss at iteration [928]: 0.0024539738387860176
Loss at iteration [929]: 0.0024539030219727087
Loss at iteration [930]: 0.0024538310602582737
Loss at iteration [931]: 0.002453759137511966
Loss at iteration [932]: 0.0024536884450024653
Loss at iteration [933]: 0.0024536180961384894
Loss at iteration [934]: 0.00245354944752074
Loss at iteration [935]: 0.002453481920503395
Loss at iteration [936]: 0.00245341317927808
Loss at iteration [937]: 0.0024533446635586894
Loss at iteration [938]: 0.0024532769914807403
Loss at iteration [939]: 0.0024532090303959276
Loss at iteration [940]: 0.0024531425012872176
Loss at iteration [941]: 0.002453075323182522
Loss at iteration [942]: 0.002453008907875493
Loss at iteration [943]: 0.0024529419428131636
Loss at iteration [944]: 0.002452875922886305
Loss at iteration [945]: 0.0024528099304739147
Loss at iteration [946]: 0.0024527430268437406
Loss at iteration [947]: 0.0024526773329383122
Loss at iteration [948]: 0.0024526116843611324
Loss at iteration [949]: 0.0024525396429003975
Loss at iteration [950]: 0.002452466260155393
Loss at iteration [951]: 0.002452393741537846
Loss at iteration [952]: 0.0024523220062998606
Loss at iteration [953]: 0.0024522501462446744
Loss at iteration [954]: 0.002452178523913387
Loss at iteration [955]: 0.0024521088142528047
Loss at iteration [956]: 0.0024520422483735507
Loss at iteration [957]: 0.00245197822571647
Loss at iteration [958]: 0.0024519147491227147
Loss at iteration [959]: 0.0024518538611884755
Loss at iteration [960]: 0.002451792709309435
Loss at iteration [961]: 0.002451732331175307
Loss at iteration [962]: 0.0024516727925400095
Loss at iteration [963]: 0.00245161332713905
Loss at iteration [964]: 0.002451552131768672
Loss at iteration [965]: 0.0024514942305985427
Loss at iteration [966]: 0.0024514351897251914
Loss at iteration [967]: 0.002451375570853946
Loss at iteration [968]: 0.0024513172804917246
Loss at iteration [969]: 0.0024512583672492727
Loss at iteration [970]: 0.002451200428204707
Loss at iteration [971]: 0.0024511427058430723
Loss at iteration [972]: 0.002451084306295741
Loss at iteration [973]: 0.002451027495762791
Loss at iteration [974]: 0.0024509706328013983
Loss at iteration [975]: 0.002450912400249793
Loss at iteration [976]: 0.0024508565615294145
Loss at iteration [977]: 0.002450798822951156
Loss at iteration [978]: 0.002450742377532564
Loss at iteration [979]: 0.0024506857586857724
Loss at iteration [980]: 0.002450627680350852
Loss at iteration [981]: 0.002450572276839071
Loss at iteration [982]: 0.0024505135649207552
Loss at iteration [983]: 0.0024504572799404667
Loss at iteration [984]: 0.00245039974919163
Loss at iteration [985]: 0.0024503412828851593
Loss at iteration [986]: 0.002450283284817971
Loss at iteration [987]: 0.0024502238707875164
Loss at iteration [988]: 0.002450163912472846
Loss at iteration [989]: 0.0024501031407733105
Loss at iteration [990]: 0.0024500439604942374
Loss at iteration [991]: 0.002449983535201482
Loss at iteration [992]: 0.0024499250928379356
Loss at iteration [993]: 0.0024498643268216595
Loss at iteration [994]: 0.00244980572787428
Loss at iteration [995]: 0.002449747110276705
Loss at iteration [996]: 0.0024496879552685256
Loss at iteration [997]: 0.0024496295332289485
Loss at iteration [998]: 0.0024495702627051652
Loss at iteration [999]: 0.0024495126703113794
Loss at iteration [1000]: 0.002449455554307523
Loss at iteration [1001]: 0.0024493971417288455
Loss at iteration [1002]: 0.0024493394169138208
Loss at iteration [1003]: 0.0024492819441747846
Loss at iteration [1004]: 0.002449224851489612
Loss at iteration [1005]: 0.002449167947025439
Loss at iteration [1006]: 0.002449111062608188
Loss at iteration [1007]: 0.0024490533196062834
Loss at iteration [1008]: 0.002448995759495121
Loss at iteration [1009]: 0.002448939548017978
Loss at iteration [1010]: 0.0024488818254659785
Loss at iteration [1011]: 0.002448824533704035
Loss at iteration [1012]: 0.002448767954596667
Loss at iteration [1013]: 0.0024487102110724583
Loss at iteration [1014]: 0.0024486537133111964
Loss at iteration [1015]: 0.0024485983136264804
Loss at iteration [1016]: 0.00244854091609384
Loss at iteration [1017]: 0.002448485166445589
Loss at iteration [1018]: 0.002448428934308846
Loss at iteration [1019]: 0.002448375010928228
Loss at iteration [1020]: 0.002448319639832595
Loss at iteration [1021]: 0.002448263335647324
Loss at iteration [1022]: 0.002448208194817612
Loss at iteration [1023]: 0.0024481527665509537
Loss at iteration [1024]: 0.002448097606811988
Loss at iteration [1025]: 0.0024480429742285946
Loss at iteration [1026]: 0.002447987877568766
Loss at iteration [1027]: 0.0024479331813147117
Loss at iteration [1028]: 0.0024478786398739985
Loss at iteration [1029]: 0.002447823586606394
Loss at iteration [1030]: 0.0024477694537257625
Loss at iteration [1031]: 0.0024477141871031257
Loss at iteration [1032]: 0.002447659979960283
Loss at iteration [1033]: 0.0024476056406308503
Loss at iteration [1034]: 0.0024475515241619943
Loss at iteration [1035]: 0.00244749708632585
Loss at iteration [1036]: 0.002447443765903736
Loss at iteration [1037]: 0.002447389576873959
Loss at iteration [1038]: 0.0024473363904845007
Loss at iteration [1039]: 0.002447283866177239
Loss at iteration [1040]: 0.002447230421930703
Loss at iteration [1041]: 0.0024471786578151877
Loss at iteration [1042]: 0.0024471261008720204
Loss at iteration [1043]: 0.002447075155179007
Loss at iteration [1044]: 0.002447023388319021
Loss at iteration [1045]: 0.002446972853224708
Loss at iteration [1046]: 0.002446920921731175
Loss at iteration [1047]: 0.0024468711159308498
Loss at iteration [1048]: 0.0024468219098082483
Loss at iteration [1049]: 0.002446770824810769
Loss at iteration [1050]: 0.0024467202703609683
Loss at iteration [1051]: 0.0024466694963335266
Loss at iteration [1052]: 0.002446619239404848
Loss at iteration [1053]: 0.0024465700830880203
Loss at iteration [1054]: 0.002446518965962326
Loss at iteration [1055]: 0.002446468527786219
Loss at iteration [1056]: 0.002446418090203395
Loss at iteration [1057]: 0.0024463686021218233
Loss at iteration [1058]: 0.0024463176677561624
Loss at iteration [1059]: 0.002446268220516286
Loss at iteration [1060]: 0.002446217742193994
Loss at iteration [1061]: 0.0024461674793274085
Loss at iteration [1062]: 0.0024461179134299942
Loss at iteration [1063]: 0.00244606755996866
Loss at iteration [1064]: 0.0024460177334640143
Loss at iteration [1065]: 0.0024459681890282563
Loss at iteration [1066]: 0.002445919341746526
Loss at iteration [1067]: 0.0024458690893100887
Loss at iteration [1068]: 0.00244582081294601
Loss at iteration [1069]: 0.0024457701342093796
Loss at iteration [1070]: 0.0024457212108200863
Loss at iteration [1071]: 0.002445672882370882
Loss at iteration [1072]: 0.0024456231856091947
Loss at iteration [1073]: 0.002445574419586847
Loss at iteration [1074]: 0.0024455256832751123
Loss at iteration [1075]: 0.0024454755009342658
Loss at iteration [1076]: 0.002445426894990516
Loss at iteration [1077]: 0.002445377574694795
Loss at iteration [1078]: 0.0024453299441053017
Loss at iteration [1079]: 0.0024452808971958022
Loss at iteration [1080]: 0.0024452310716565006
Loss at iteration [1081]: 0.002445182566163339
Loss at iteration [1082]: 0.002445133364275571
Loss at iteration [1083]: 0.0024450847429715664
Loss at iteration [1084]: 0.00244503446514299
Loss at iteration [1085]: 0.0024449861534060215
Loss at iteration [1086]: 0.002444935375127512
Loss at iteration [1087]: 0.0024448861153303736
Loss at iteration [1088]: 0.0024448368518673997
Loss at iteration [1089]: 0.0024447869176144796
Loss at iteration [1090]: 0.0024447379174406597
Loss at iteration [1091]: 0.0024446881171194257
Loss at iteration [1092]: 0.0024446393653941513
Loss at iteration [1093]: 0.002444589639070889
Loss at iteration [1094]: 0.00244454000431987
Loss at iteration [1095]: 0.0024444905382162885
Loss at iteration [1096]: 0.0024444403931231035
Loss at iteration [1097]: 0.002444390902309196
Loss at iteration [1098]: 0.002444340529957861
Loss at iteration [1099]: 0.0024442913210044738
Loss at iteration [1100]: 0.002444240145390886
Loss at iteration [1101]: 0.0024441916291958747
Loss at iteration [1102]: 0.002444143035580411
Loss at iteration [1103]: 0.002444093224502119
Loss at iteration [1104]: 0.0024440456884584644
Loss at iteration [1105]: 0.0024439970582627287
Loss at iteration [1106]: 0.0024439494280432766
Loss at iteration [1107]: 0.0024439007063930328
Loss at iteration [1108]: 0.002443854176766486
Loss at iteration [1109]: 0.002443806118559352
Loss at iteration [1110]: 0.00244375818846261
Loss at iteration [1111]: 0.0024437109215558485
Loss at iteration [1112]: 0.002443661889837976
Loss at iteration [1113]: 0.002443612456786547
Loss at iteration [1114]: 0.0024435656319678717
Loss at iteration [1115]: 0.0024435174090593472
Loss at iteration [1116]: 0.0024434698918909424
Loss at iteration [1117]: 0.0024434221026080672
Loss at iteration [1118]: 0.002443373004073856
Loss at iteration [1119]: 0.002443326000416953
Loss at iteration [1120]: 0.002443278315172322
Loss at iteration [1121]: 0.0024432310096974426
Loss at iteration [1122]: 0.0024431833168515995
Loss at iteration [1123]: 0.0024431359756096104
Loss at iteration [1124]: 0.002443088589250604
Loss at iteration [1125]: 0.0024430401967739383
Loss at iteration [1126]: 0.002442993223389818
Loss at iteration [1127]: 0.002442944867117064
Loss at iteration [1128]: 0.002442899202853993
Loss at iteration [1129]: 0.002442850335152523
Loss at iteration [1130]: 0.0024428039523452225
Loss at iteration [1131]: 0.002442755727365369
Loss at iteration [1132]: 0.0024427083458635093
Loss at iteration [1133]: 0.0024426610603778087
Loss at iteration [1134]: 0.002442614076575807
Loss at iteration [1135]: 0.002442567614461601
Loss at iteration [1136]: 0.0024425207530167537
Loss at iteration [1137]: 0.002442473686386278
Loss at iteration [1138]: 0.0024424269165209426
Loss at iteration [1139]: 0.0024423804675836854
Loss at iteration [1140]: 0.0024423331972671133
Loss at iteration [1141]: 0.0024422877655244884
Loss at iteration [1142]: 0.002442241093544115
Loss at iteration [1143]: 0.0024421956201944165
Loss at iteration [1144]: 0.002442148203590293
Loss at iteration [1145]: 0.0024421023161067244
Loss at iteration [1146]: 0.0024420559617111606
Loss at iteration [1147]: 0.0024420090122626503
Loss at iteration [1148]: 0.0024419641586239187
Loss at iteration [1149]: 0.0024419175363099995
Loss at iteration [1150]: 0.0024418713458635197
Loss at iteration [1151]: 0.002441824313419637
Loss at iteration [1152]: 0.0024417789111643886
Loss at iteration [1153]: 0.002441733027991687
Loss at iteration [1154]: 0.002441686638396886
Loss at iteration [1155]: 0.0024416403777377384
Loss at iteration [1156]: 0.0024415947935525996
Loss at iteration [1157]: 0.0024415484706215534
Loss at iteration [1158]: 0.0024415025818734803
Loss at iteration [1159]: 0.002441455223241321
Loss at iteration [1160]: 0.002441408834301467
Loss at iteration [1161]: 0.0024413611200654363
Loss at iteration [1162]: 0.002441315591921638
Loss at iteration [1163]: 0.002441268254234232
Loss at iteration [1164]: 0.002441221427199459
Loss at iteration [1165]: 0.002441174556197808
Loss at iteration [1166]: 0.0024411258106851207
Loss at iteration [1167]: 0.002441079569967995
Loss at iteration [1168]: 0.002441032480716383
Loss at iteration [1169]: 0.0024409831857147455
Loss at iteration [1170]: 0.0024409358853108953
Loss at iteration [1171]: 0.0024408868240258586
Loss at iteration [1172]: 0.0024408379138209156
Loss at iteration [1173]: 0.002440788793620119
Loss at iteration [1174]: 0.00244073946559808
Loss at iteration [1175]: 0.0024406899245529956
Loss at iteration [1176]: 0.002440642266388818
Loss at iteration [1177]: 0.0024405939355657143
Loss at iteration [1178]: 0.002440545333152095
Loss at iteration [1179]: 0.0024404973303537056
Loss at iteration [1180]: 0.002440449817135232
Loss at iteration [1181]: 0.0024404003161489296
Loss at iteration [1182]: 0.002440353629663156
Loss at iteration [1183]: 0.002440305028852145
Loss at iteration [1184]: 0.0024402561690636945
Loss at iteration [1185]: 0.002440208239644533
Loss at iteration [1186]: 0.002440161326922843
Loss at iteration [1187]: 0.002440112736183318
Loss at iteration [1188]: 0.0024400644783152876
Loss at iteration [1189]: 0.0024400159564180136
Loss at iteration [1190]: 0.002439967557020354
Loss at iteration [1191]: 0.0024399193173054914
Loss at iteration [1192]: 0.0024398708582521337
Loss at iteration [1193]: 0.0024398219289025404
Loss at iteration [1194]: 0.0024397731934195865
Loss at iteration [1195]: 0.0024397242724152877
Loss at iteration [1196]: 0.0024396735631715487
Loss at iteration [1197]: 0.0024396259776373655
Loss at iteration [1198]: 0.0024395761077183557
Loss at iteration [1199]: 0.002439528574458677
Loss at iteration [1200]: 0.002439481213537737
Loss at iteration [1201]: 0.002439432751787794
Loss at iteration [1202]: 0.0024393855593456766
Loss at iteration [1203]: 0.0024393376803307967
Loss at iteration [1204]: 0.0024392918376922174
Loss at iteration [1205]: 0.0024392439949984003
Loss at iteration [1206]: 0.002439197280070159
Loss at iteration [1207]: 0.002439150265811225
Loss at iteration [1208]: 0.002439103593296548
Loss at iteration [1209]: 0.00243905685412453
Loss at iteration [1210]: 0.002439009514171265
Loss at iteration [1211]: 0.002438962579492183
Loss at iteration [1212]: 0.002438916988021432
Loss at iteration [1213]: 0.0024388692666344374
Loss at iteration [1214]: 0.0024388242463525213
Loss at iteration [1215]: 0.002438776357229356
Loss at iteration [1216]: 0.0024387301864029817
Loss at iteration [1217]: 0.002438683206906568
Loss at iteration [1218]: 0.002438636048325142
Loss at iteration [1219]: 0.0024385900343245636
Loss at iteration [1220]: 0.00243854320471791
Loss at iteration [1221]: 0.002438496467636459
Loss at iteration [1222]: 0.0024384495368860552
Loss at iteration [1223]: 0.002438402341476759
Loss at iteration [1224]: 0.002438356292939269
Loss at iteration [1225]: 0.0024383094453482874
Loss at iteration [1226]: 0.002438264168534824
Loss at iteration [1227]: 0.002438217794604046
Loss at iteration [1228]: 0.00243817048782082
Loss at iteration [1229]: 0.0024381231456049256
Loss at iteration [1230]: 0.002438075994991463
Loss at iteration [1231]: 0.002438028357261448
Loss at iteration [1232]: 0.002437981586402744
Loss at iteration [1233]: 0.0024379327669544824
Loss at iteration [1234]: 0.002437885800418513
Loss at iteration [1235]: 0.002437839289953182
Loss at iteration [1236]: 0.002437790344521046
Loss at iteration [1237]: 0.0024377432937862935
Loss at iteration [1238]: 0.0024376960334920508
Loss at iteration [1239]: 0.0024376473904811837
Loss at iteration [1240]: 0.0024376011095533496
Loss at iteration [1241]: 0.002437552530718384
Loss at iteration [1242]: 0.0024375046052519883
Loss at iteration [1243]: 0.0024374569072631784
Loss at iteration [1244]: 0.002437409721361027
Loss at iteration [1245]: 0.0024373633008333917
Loss at iteration [1246]: 0.002437318621568396
Loss at iteration [1247]: 0.0024372722760539877
Loss at iteration [1248]: 0.0024372259807560106
Loss at iteration [1249]: 0.002437178689595973
Loss at iteration [1250]: 0.0024371313758310966
Loss at iteration [1251]: 0.002437084772534749
Loss at iteration [1252]: 0.002437036575740054
Loss at iteration [1253]: 0.0024369901060983883
Loss at iteration [1254]: 0.002436941289858478
Loss at iteration [1255]: 0.002436894566697373
Loss at iteration [1256]: 0.0024368460731369625
Loss at iteration [1257]: 0.0024367994404895605
Loss at iteration [1258]: 0.0024367520370792003
Loss at iteration [1259]: 0.0024367041138934043
Loss at iteration [1260]: 0.0024366561255798574
Loss at iteration [1261]: 0.002436609458435444
Loss at iteration [1262]: 0.0024365617013047403
Loss at iteration [1263]: 0.002436514052045824
Loss at iteration [1264]: 0.002436466698725682
Loss at iteration [1265]: 0.0024364193725180745
Loss at iteration [1266]: 0.0024363721111759534
Loss at iteration [1267]: 0.002436323098055857
Loss at iteration [1268]: 0.0024362753881911245
Loss at iteration [1269]: 0.0024362270234698545
Loss at iteration [1270]: 0.0024361782301284157
Loss at iteration [1271]: 0.002436129001243508
Loss at iteration [1272]: 0.00243608023982383
Loss at iteration [1273]: 0.0024360311157154584
Loss at iteration [1274]: 0.002435981606041726
Loss at iteration [1275]: 0.0024359346951920552
Loss at iteration [1276]: 0.002435885351918378
Loss at iteration [1277]: 0.0024358359161416264
Loss at iteration [1278]: 0.0024357874296967665
Loss at iteration [1279]: 0.002435740520414927
Loss at iteration [1280]: 0.002435691498351223
Loss at iteration [1281]: 0.0024356452604231945
Loss at iteration [1282]: 0.0024355969700623733
Loss at iteration [1283]: 0.002435549116034903
Loss at iteration [1284]: 0.002435501927586941
Loss at iteration [1285]: 0.002435454242393127
Loss at iteration [1286]: 0.0024354067920611807
Loss at iteration [1287]: 0.002435358995572511
Loss at iteration [1288]: 0.002435311670890109
Loss at iteration [1289]: 0.002435264219290788
Loss at iteration [1290]: 0.002435216264705119
Loss at iteration [1291]: 0.0024351682657083574
Loss at iteration [1292]: 0.0024351209599458076
Loss at iteration [1293]: 0.002435072616679959
Loss at iteration [1294]: 0.002435024938257668
Loss at iteration [1295]: 0.0024349764020058875
Loss at iteration [1296]: 0.0024349293069887306
Loss at iteration [1297]: 0.0024348816825996602
Loss at iteration [1298]: 0.002434834432860462
Loss at iteration [1299]: 0.0024347869607434847
Loss at iteration [1300]: 0.0024347400024008247
Loss at iteration [1301]: 0.002434692085422963
Loss at iteration [1302]: 0.0024346441645983767
Loss at iteration [1303]: 0.0024345972195155482
Loss at iteration [1304]: 0.002434548978326626
Loss at iteration [1305]: 0.002434500972655549
Loss at iteration [1306]: 0.0024344516283048806
Loss at iteration [1307]: 0.002434403726111265
Loss at iteration [1308]: 0.0024343555996511504
Loss at iteration [1309]: 0.002434306823528656
Loss at iteration [1310]: 0.0024342596775075984
Loss at iteration [1311]: 0.0024342113467335914
Loss at iteration [1312]: 0.0024341629234652016
Loss at iteration [1313]: 0.00243411571485666
Loss at iteration [1314]: 0.002434067063894809
Loss at iteration [1315]: 0.002434019121141098
Loss at iteration [1316]: 0.002433972940881964
Loss at iteration [1317]: 0.0024339244857288795
Loss at iteration [1318]: 0.002433876352523239
Loss at iteration [1319]: 0.00243382884645989
Loss at iteration [1320]: 0.0024337810026567293
Loss at iteration [1321]: 0.002433732561130496
Loss at iteration [1322]: 0.002433685927137752
Loss at iteration [1323]: 0.0024336380999876047
Loss at iteration [1324]: 0.00243359101198096
Loss at iteration [1325]: 0.002433541925081989
Loss at iteration [1326]: 0.0024334953855878016
Loss at iteration [1327]: 0.002433447945793698
Loss at iteration [1328]: 0.0024334012502175676
Loss at iteration [1329]: 0.0024333544849500285
Loss at iteration [1330]: 0.002433307422716792
Loss at iteration [1331]: 0.0024332602709721783
Loss at iteration [1332]: 0.002433213464411269
Loss at iteration [1333]: 0.0024331660041442054
Loss at iteration [1334]: 0.0024331176018251664
Loss at iteration [1335]: 0.0024330696168042504
Loss at iteration [1336]: 0.002433020741547249
Loss at iteration [1337]: 0.0024329705740441954
Loss at iteration [1338]: 0.0024329198969143795
Loss at iteration [1339]: 0.0024328701619999687
Loss at iteration [1340]: 0.002432819357433895
Loss at iteration [1341]: 0.0024327672206913096
Loss at iteration [1342]: 0.002432716276260364
Loss at iteration [1343]: 0.002432665483732527
Loss at iteration [1344]: 0.002432612658276911
Loss at iteration [1345]: 0.002432558996852544
Loss at iteration [1346]: 0.0024325056283616897
Loss at iteration [1347]: 0.0024324516827682347
Loss at iteration [1348]: 0.0024323988144973638
Loss at iteration [1349]: 0.002432344892078867
Loss at iteration [1350]: 0.002432292988853476
Loss at iteration [1351]: 0.0024322426077087013
Loss at iteration [1352]: 0.002432190133285767
Loss at iteration [1353]: 0.0024321388849827775
Loss at iteration [1354]: 0.0024320895981384356
Loss at iteration [1355]: 0.0024320395030944532
Loss at iteration [1356]: 0.0024319910122596556
Loss at iteration [1357]: 0.00243194166158764
Loss at iteration [1358]: 0.002431892042238402
Loss at iteration [1359]: 0.00243184241834685
Loss at iteration [1360]: 0.0024317933706145996
Loss at iteration [1361]: 0.0024317451892532952
Loss at iteration [1362]: 0.0024316955182886713
Loss at iteration [1363]: 0.002431646573666147
Loss at iteration [1364]: 0.0024315980917528246
Loss at iteration [1365]: 0.002431548962397698
Loss at iteration [1366]: 0.002431499520446737
Loss at iteration [1367]: 0.0024314531139239845
Loss at iteration [1368]: 0.0024314033684348906
Loss at iteration [1369]: 0.0024313565211963907
Loss at iteration [1370]: 0.002431308958038042
Loss at iteration [1371]: 0.0024312606992372755
Loss at iteration [1372]: 0.0024312122478633577
Loss at iteration [1373]: 0.002431164000213056
Loss at iteration [1374]: 0.002431113792018352
Loss at iteration [1375]: 0.002431066480338385
Loss at iteration [1376]: 0.002431016194146699
Loss at iteration [1377]: 0.0024309669901562306
Loss at iteration [1378]: 0.0024309179237484825
Loss at iteration [1379]: 0.0024308692267265048
Loss at iteration [1380]: 0.0024308197566344303
Loss at iteration [1381]: 0.002430771577745728
Loss at iteration [1382]: 0.002430722090663888
Loss at iteration [1383]: 0.0024306734291951416
Loss at iteration [1384]: 0.00243062476705514
Loss at iteration [1385]: 0.002430576332840621
Loss at iteration [1386]: 0.0024305293141071395
Loss at iteration [1387]: 0.0024304810788957467
Loss at iteration [1388]: 0.0024304325510809727
Loss at iteration [1389]: 0.002430385671188055
Loss at iteration [1390]: 0.002430336730155453
Loss at iteration [1391]: 0.0024302883801813344
Loss at iteration [1392]: 0.0024302408419495064
Loss at iteration [1393]: 0.0024301922651485783
Loss at iteration [1394]: 0.002430142696119163
Loss at iteration [1395]: 0.0024300950639471112
Loss at iteration [1396]: 0.0024300478450072533
Loss at iteration [1397]: 0.0024299991206084125
Loss at iteration [1398]: 0.002429950846774462
Loss at iteration [1399]: 0.0024299021245361365
Loss at iteration [1400]: 0.0024298538676861747
Loss at iteration [1401]: 0.002429804596508714
Loss at iteration [1402]: 0.0024297563760452613
Loss at iteration [1403]: 0.0024297072751732628
Loss at iteration [1404]: 0.0024296590648060995
Loss at iteration [1405]: 0.00242961011495979
Loss at iteration [1406]: 0.002429562680042996
Loss at iteration [1407]: 0.002429514731466289
Loss at iteration [1408]: 0.002429468112141598
Loss at iteration [1409]: 0.002429419860604299
Loss at iteration [1410]: 0.0024293732461553976
Loss at iteration [1411]: 0.0024293265862910863
Loss at iteration [1412]: 0.0024292796309715483
Loss at iteration [1413]: 0.002429233155331249
Loss at iteration [1414]: 0.0024291861652327358
Loss at iteration [1415]: 0.0024291395258332427
Loss at iteration [1416]: 0.002429093635878625
Loss at iteration [1417]: 0.002429047243160905
Loss at iteration [1418]: 0.002429001860314052
Loss at iteration [1419]: 0.002428956421742167
Loss at iteration [1420]: 0.002428910475162375
Loss at iteration [1421]: 0.0024288654019401492
Loss at iteration [1422]: 0.0024288193614813436
Loss at iteration [1423]: 0.0024287746423756907
Loss at iteration [1424]: 0.0024287283686489887
Loss at iteration [1425]: 0.002428682561031468
Loss at iteration [1426]: 0.0024286373200009988
Loss at iteration [1427]: 0.0024285945739559995
Loss at iteration [1428]: 0.002428550208174982
Loss at iteration [1429]: 0.002428506251643503
Loss at iteration [1430]: 0.0024284624069006873
Loss at iteration [1431]: 0.002428419855949217
Loss at iteration [1432]: 0.002428375287516617
Loss at iteration [1433]: 0.0024283326188626136
Loss at iteration [1434]: 0.0024282887480383103
Loss at iteration [1435]: 0.0024282451691395816
Loss at iteration [1436]: 0.0024282012318988288
Loss at iteration [1437]: 0.0024281567391978218
Loss at iteration [1438]: 0.002428112330951176
Loss at iteration [1439]: 0.0024280671099467586
Loss at iteration [1440]: 0.002428014955285394
Loss at iteration [1441]: 0.002427961324699296
Loss at iteration [1442]: 0.0024279054439202007
Loss at iteration [1443]: 0.0024278494614703105
Loss at iteration [1444]: 0.0024277937114698007
Loss at iteration [1445]: 0.0024277380005903373
Loss at iteration [1446]: 0.0024276822556930466
Loss at iteration [1447]: 0.002427624811482299
Loss at iteration [1448]: 0.002427568598712293
Loss at iteration [1449]: 0.0024275113259021627
Loss at iteration [1450]: 0.002427452874706953
Loss at iteration [1451]: 0.002427395062566285
Loss at iteration [1452]: 0.0024273372619839735
Loss at iteration [1453]: 0.0024272788444759143
Loss at iteration [1454]: 0.0024272220803664185
Loss at iteration [1455]: 0.002427164340955737
Loss at iteration [1456]: 0.002427107115800752
Loss at iteration [1457]: 0.00242704922687967
Loss at iteration [1458]: 0.0024269901231989553
Loss at iteration [1459]: 0.00242693145581667
Loss at iteration [1460]: 0.0024268754912102316
Loss at iteration [1461]: 0.002426818999324861
Loss at iteration [1462]: 0.002426762155460159
Loss at iteration [1463]: 0.0024267058365860985
Loss at iteration [1464]: 0.0024266506329390166
Loss at iteration [1465]: 0.002426592862694644
Loss at iteration [1466]: 0.0024265374167433953
Loss at iteration [1467]: 0.002426479281948058
Loss at iteration [1468]: 0.0024264214848372274
Loss at iteration [1469]: 0.0024263621352035095
Loss at iteration [1470]: 0.0024263036917176167
Loss at iteration [1471]: 0.002426245010605497
Loss at iteration [1472]: 0.0024261865859206058
Loss at iteration [1473]: 0.0024261278708596137
Loss at iteration [1474]: 0.0024260693723050218
Loss at iteration [1475]: 0.0024260099051054435
Loss at iteration [1476]: 0.0024259510859657918
Loss at iteration [1477]: 0.0024258925025305595
Loss at iteration [1478]: 0.002425834797688595
Loss at iteration [1479]: 0.0024257759620025868
Loss at iteration [1480]: 0.0024257176204566825
Loss at iteration [1481]: 0.0024256593021117338
Loss at iteration [1482]: 0.002425601878870091
Loss at iteration [1483]: 0.0024255432342091565
Loss at iteration [1484]: 0.0024254857993446888
Loss at iteration [1485]: 0.0024254283410968225
Loss at iteration [1486]: 0.0024253712642084107
Loss at iteration [1487]: 0.002425313433742372
Loss at iteration [1488]: 0.0024252568812916245
Loss at iteration [1489]: 0.002425198668345254
Loss at iteration [1490]: 0.0024251406022176886
Loss at iteration [1491]: 0.002425082614470152
Loss at iteration [1492]: 0.0024250247873436738
Loss at iteration [1493]: 0.0024249665991980204
Loss at iteration [1494]: 0.002424910160918847
Loss at iteration [1495]: 0.0024248549511583463
Loss at iteration [1496]: 0.0024248009779808464
Loss at iteration [1497]: 0.0024247443172046796
Loss at iteration [1498]: 0.002424690687097324
Loss at iteration [1499]: 0.0024246354800008282
Loss at iteration [1500]: 0.002424581299625165
Loss at iteration [1501]: 0.0024245268497179
Loss at iteration [1502]: 0.0024244737645730966
Loss at iteration [1503]: 0.0024244200946923885
Loss at iteration [1504]: 0.002424366471242594
Loss at iteration [1505]: 0.0024243129094361827
Loss at iteration [1506]: 0.0024242593751917004
Loss at iteration [1507]: 0.002424204946282876
Loss at iteration [1508]: 0.002424151758724662
Loss at iteration [1509]: 0.0024240976666170225
Loss at iteration [1510]: 0.0024240449400165206
Loss at iteration [1511]: 0.002423992364367624
Loss at iteration [1512]: 0.002423941291369945
Loss at iteration [1513]: 0.00242388974148975
Loss at iteration [1514]: 0.002423838283206403
Loss at iteration [1515]: 0.0024237884314743416
Loss at iteration [1516]: 0.002423736561904584
Loss at iteration [1517]: 0.0024236863293055737
Loss at iteration [1518]: 0.0024236357439092597
Loss at iteration [1519]: 0.0024235846023099535
Loss at iteration [1520]: 0.002423535076774912
Loss at iteration [1521]: 0.002423483885702776
Loss at iteration [1522]: 0.002423434801163006
Loss at iteration [1523]: 0.00242338352889377
Loss at iteration [1524]: 0.0024233341581332683
Loss at iteration [1525]: 0.0024232838257458185
Loss at iteration [1526]: 0.002423232950155203
Loss at iteration [1527]: 0.002423182502383398
Loss at iteration [1528]: 0.0024231324603131675
Loss at iteration [1529]: 0.0024230817301823743
Loss at iteration [1530]: 0.002423031988546625
Loss at iteration [1531]: 0.0024229802048690284
Loss at iteration [1532]: 0.002422930883319397
Loss at iteration [1533]: 0.0024228803882749587
Loss at iteration [1534]: 0.0024228305229739852
Loss at iteration [1535]: 0.0024227815011528863
Loss at iteration [1536]: 0.0024227299136592687
Loss at iteration [1537]: 0.002422680470839781
Loss at iteration [1538]: 0.0024226302793632147
Loss at iteration [1539]: 0.0024225801906841505
Loss at iteration [1540]: 0.0024225320969609417
Loss at iteration [1541]: 0.002422480994922788
Loss at iteration [1542]: 0.0024224312686298584
Loss at iteration [1543]: 0.002422380896507478
Loss at iteration [1544]: 0.0024223310401745306
Loss at iteration [1545]: 0.0024222822349035415
Loss at iteration [1546]: 0.0024222320748248753
Loss at iteration [1547]: 0.002422182684476522
Loss at iteration [1548]: 0.0024221328248009545
Loss at iteration [1549]: 0.0024220836099186106
Loss at iteration [1550]: 0.002422034655939474
Loss at iteration [1551]: 0.002421984500711561
Loss at iteration [1552]: 0.0024219370526941636
Loss at iteration [1553]: 0.002421887060979124
Loss at iteration [1554]: 0.002421838026843725
Loss at iteration [1555]: 0.002421788540832701
Loss at iteration [1556]: 0.0024217393536777763
Loss at iteration [1557]: 0.002421690115850442
Loss at iteration [1558]: 0.0024216411432950607
Loss at iteration [1559]: 0.0024215920984738547
Loss at iteration [1560]: 0.0024215425987019505
Loss at iteration [1561]: 0.0024214937821582304
Loss at iteration [1562]: 0.0024214448159128
Loss at iteration [1563]: 0.0024213970343350912
Loss at iteration [1564]: 0.0024213477255247023
Loss at iteration [1565]: 0.0024212989014777754
Loss at iteration [1566]: 0.002421250242430101
Loss at iteration [1567]: 0.0024212016185034117
Loss at iteration [1568]: 0.0024211610997415052
Loss at iteration [1569]: 0.0024211174148501473
Loss at iteration [1570]: 0.0024210734581695866
Loss at iteration [1571]: 0.0024210283778414938
Loss at iteration [1572]: 0.0024209832876104695
Loss at iteration [1573]: 0.0024209439996727947
Loss at iteration [1574]: 0.0024208985081001846
Loss at iteration [1575]: 0.002420856489052929
Loss at iteration [1576]: 0.0024208137816802253
Loss at iteration [1577]: 0.0024207701783883475
Loss at iteration [1578]: 0.0024207267518512833
Loss at iteration [1579]: 0.002420685504288035
Loss at iteration [1580]: 0.0024206417039594553
Loss at iteration [1581]: 0.0024205997180389376
Loss at iteration [1582]: 0.0024205566795184393
Loss at iteration [1583]: 0.0024205147096709296
Loss at iteration [1584]: 0.0024204732045614093
Loss at iteration [1585]: 0.002420428332797886
Loss at iteration [1586]: 0.0024203852833519024
Loss at iteration [1587]: 0.00242034411555603
Loss at iteration [1588]: 0.002420300160249674
Loss at iteration [1589]: 0.0024202574594756688
Loss at iteration [1590]: 0.002420214665459808
Loss at iteration [1591]: 0.0024201730030008663
Loss at iteration [1592]: 0.002420128948428792
Loss at iteration [1593]: 0.0024200860011388205
Loss at iteration [1594]: 0.002420042706947888
Loss at iteration [1595]: 0.002420000274568788
Loss at iteration [1596]: 0.0024199579552372143
Loss at iteration [1597]: 0.0024199152417365127
Loss at iteration [1598]: 0.002419870898632837
Loss at iteration [1599]: 0.0024198283273311086
Loss at iteration [1600]: 0.0024197867035453697
Loss at iteration [1601]: 0.002419742698909221
Loss at iteration [1602]: 0.002419699579711331
Loss at iteration [1603]: 0.0024196566645015506
Loss at iteration [1604]: 0.00241961418438087
Loss at iteration [1605]: 0.002419572745605077
Loss at iteration [1606]: 0.0024195286371092414
Loss at iteration [1607]: 0.0024194858615277097
Loss at iteration [1608]: 0.0024194432520447283
Loss at iteration [1609]: 0.0024194005490963326
Loss at iteration [1610]: 0.0024193587270107523
Loss at iteration [1611]: 0.0024193156241217057
Loss at iteration [1612]: 0.002419272378778277
Loss at iteration [1613]: 0.002419229990235905
Loss at iteration [1614]: 0.0024191869785763756
Loss at iteration [1615]: 0.0024191446115539076
Loss at iteration [1616]: 0.002419102468538358
Loss at iteration [1617]: 0.002419060253451425
Loss at iteration [1618]: 0.0024190157331554565
Loss at iteration [1619]: 0.002418973719718387
Loss at iteration [1620]: 0.0024189330226165044
Loss at iteration [1621]: 0.0024188899588550544
Loss at iteration [1622]: 0.0024188464917892145
Loss at iteration [1623]: 0.0024188027067748334
Loss at iteration [1624]: 0.0024187613627882788
Loss at iteration [1625]: 0.0024187185723677194
Loss at iteration [1626]: 0.0024186765155337145
Loss at iteration [1627]: 0.0024186347895570836
Loss at iteration [1628]: 0.002418591504816471
Loss at iteration [1629]: 0.0024185489826748104
Loss at iteration [1630]: 0.002418507381720881
Loss at iteration [1631]: 0.00241846675177051
Loss at iteration [1632]: 0.002418424517030504
Loss at iteration [1633]: 0.0024183826275556877
Loss at iteration [1634]: 0.0024183402949418953
Loss at iteration [1635]: 0.0024182992214380927
Loss at iteration [1636]: 0.0024182569802607976
Loss at iteration [1637]: 0.0024182173873667626
Loss at iteration [1638]: 0.002418175467366872
Loss at iteration [1639]: 0.0024181337053618573
Loss at iteration [1640]: 0.002418092160178734
Loss at iteration [1641]: 0.002418050086140832
Loss at iteration [1642]: 0.002418010201608333
Loss at iteration [1643]: 0.00241796839269523
Loss at iteration [1644]: 0.002417925670476558
Loss at iteration [1645]: 0.002417885233507027
Loss at iteration [1646]: 0.002417842381944867
Loss at iteration [1647]: 0.0024177998165608177
Loss at iteration [1648]: 0.002417760757823667
Loss at iteration [1649]: 0.002417718202605234
Loss at iteration [1650]: 0.0024176756864745293
Loss at iteration [1651]: 0.002417633433971833
Loss at iteration [1652]: 0.0024175919962269796
Loss at iteration [1653]: 0.002417549690173325
Loss at iteration [1654]: 0.0024175083430762485
Loss at iteration [1655]: 0.0024174672281203034
Loss at iteration [1656]: 0.002417424159517112
Loss at iteration [1657]: 0.0024173834064025804
Loss at iteration [1658]: 0.0024173411745158743
Loss at iteration [1659]: 0.0024173007311986427
Loss at iteration [1660]: 0.0024172584599965975
Loss at iteration [1661]: 0.0024172160918362927
Loss at iteration [1662]: 0.0024171754232704475
Loss at iteration [1663]: 0.002417133300518432
Loss at iteration [1664]: 0.002417090807318049
Loss at iteration [1665]: 0.002417052066694761
Loss at iteration [1666]: 0.00241700872412332
Loss at iteration [1667]: 0.0024169682094310964
Loss at iteration [1668]: 0.002416925158971914
Loss at iteration [1669]: 0.002416883227979147
Loss at iteration [1670]: 0.0024168413776791083
Loss at iteration [1671]: 0.002416800322530605
Loss at iteration [1672]: 0.0024167589014214004
Loss at iteration [1673]: 0.002416717597824602
Loss at iteration [1674]: 0.0024166755018231734
Loss at iteration [1675]: 0.002416633297784062
Loss at iteration [1676]: 0.0024165917209744586
Loss at iteration [1677]: 0.0024165518965510928
Loss at iteration [1678]: 0.0024165096425964355
Loss at iteration [1679]: 0.002416468387330083
Loss at iteration [1680]: 0.0024164269871258222
Loss at iteration [1681]: 0.0024163845778032377
Loss at iteration [1682]: 0.00241634301706643
Loss at iteration [1683]: 0.0024163012736472303
Loss at iteration [1684]: 0.002416258754606708
Loss at iteration [1685]: 0.002416216409164372
Loss at iteration [1686]: 0.002416174610184518
Loss at iteration [1687]: 0.0024161306593280946
Loss at iteration [1688]: 0.0024160889690618822
Loss at iteration [1689]: 0.0024160473538074973
Loss at iteration [1690]: 0.0024160037474619976
Loss at iteration [1691]: 0.002415961444489305
Loss at iteration [1692]: 0.002415919332921364
Loss at iteration [1693]: 0.00241587697788517
Loss at iteration [1694]: 0.002415836002320503
Loss at iteration [1695]: 0.002415794208682889
Loss at iteration [1696]: 0.0024157514258230854
Loss at iteration [1697]: 0.0024157102412954317
Loss at iteration [1698]: 0.002415668058148035
Loss at iteration [1699]: 0.002415625972287145
Loss at iteration [1700]: 0.0024155851802884435
Loss at iteration [1701]: 0.002415542778716233
Loss at iteration [1702]: 0.002415501870007375
Loss at iteration [1703]: 0.002415459131051674
Loss at iteration [1704]: 0.002415416715008748
Loss at iteration [1705]: 0.002415375246505028
Loss at iteration [1706]: 0.0024153342442658045
Loss at iteration [1707]: 0.002415291801317542
Loss at iteration [1708]: 0.0024152507856105357
Loss at iteration [1709]: 0.0024152084122766137
Loss at iteration [1710]: 0.0024151663495073786
Loss at iteration [1711]: 0.002415123879711319
Loss at iteration [1712]: 0.0024150823439837653
Loss at iteration [1713]: 0.00241503868751699
Loss at iteration [1714]: 0.002414996069621164
Loss at iteration [1715]: 0.0024149535575214826
Loss at iteration [1716]: 0.0024149111647247755
Loss at iteration [1717]: 0.002414866920532845
Loss at iteration [1718]: 0.0024148247035091696
Loss at iteration [1719]: 0.0024147816354925518
Loss at iteration [1720]: 0.002414738979877528
Loss at iteration [1721]: 0.0024146957306683254
Loss at iteration [1722]: 0.0024146523379634543
Loss at iteration [1723]: 0.0024146094559961955
Loss at iteration [1724]: 0.002414567171093287
Loss at iteration [1725]: 0.0024145243560154206
Loss at iteration [1726]: 0.0024144817186216934
Loss at iteration [1727]: 0.0024144392292713966
Loss at iteration [1728]: 0.0024143960802517224
Loss at iteration [1729]: 0.0024143548925399916
Loss at iteration [1730]: 0.0024143136203682784
Loss at iteration [1731]: 0.0024142713775894406
Loss at iteration [1732]: 0.002414228414671461
Loss at iteration [1733]: 0.00241418699980049
Loss at iteration [1734]: 0.002414143623547854
Loss at iteration [1735]: 0.0024141015151824224
Loss at iteration [1736]: 0.002414059805925474
Loss at iteration [1737]: 0.0024140165984876134
Loss at iteration [1738]: 0.0024139742906304587
Loss at iteration [1739]: 0.002413931414745727
Loss at iteration [1740]: 0.0024138894259241165
Loss at iteration [1741]: 0.0024138484228606216
Loss at iteration [1742]: 0.0024138057044844645
Loss at iteration [1743]: 0.002413762631385763
Loss at iteration [1744]: 0.00241372033621451
Loss at iteration [1745]: 0.0024136772098006824
Loss at iteration [1746]: 0.002413634273879765
Loss at iteration [1747]: 0.0024135941939811755
Loss at iteration [1748]: 0.0024135508020826464
Loss at iteration [1749]: 0.0024135085675439476
Loss at iteration [1750]: 0.0024134668238274004
Loss at iteration [1751]: 0.0024134242153886275
Loss at iteration [1752]: 0.002413382487506095
Loss at iteration [1753]: 0.0024133412257730928
Loss at iteration [1754]: 0.0024133010281680856
Loss at iteration [1755]: 0.0024132586879304883
Loss at iteration [1756]: 0.002413219483351324
Loss at iteration [1757]: 0.002413176653476948
Loss at iteration [1758]: 0.002413136729328434
Loss at iteration [1759]: 0.0024130959834561243
Loss at iteration [1760]: 0.002413055026028021
Loss at iteration [1761]: 0.0024130138682335795
Loss at iteration [1762]: 0.0024129720463012577
Loss at iteration [1763]: 0.002412931273946785
Loss at iteration [1764]: 0.0024128913997799955
Loss at iteration [1765]: 0.002412851724704485
Loss at iteration [1766]: 0.0024128105383910874
Loss at iteration [1767]: 0.0024127693278088187
Loss at iteration [1768]: 0.002412729339355734
Loss at iteration [1769]: 0.0024126892136557194
Loss at iteration [1770]: 0.0024126481976375885
Loss at iteration [1771]: 0.002412609315039591
Loss at iteration [1772]: 0.002412568870057965
Loss at iteration [1773]: 0.002412528717993342
Loss at iteration [1774]: 0.0024124896529094434
Loss at iteration [1775]: 0.0024124482118882216
Loss at iteration [1776]: 0.002412408840117919
Loss at iteration [1777]: 0.0024123700576965355
Loss at iteration [1778]: 0.0024123286125708274
Loss at iteration [1779]: 0.002412289354842106
Loss at iteration [1780]: 0.002412249727769895
Loss at iteration [1781]: 0.002412207928435201
Loss at iteration [1782]: 0.0024121673916066054
Loss at iteration [1783]: 0.0024121293413437595
Loss at iteration [1784]: 0.0024120890238718113
Loss at iteration [1785]: 0.0024120480344923894
Loss at iteration [1786]: 0.0024120087098912207
Loss at iteration [1787]: 0.002411967090818139
Loss at iteration [1788]: 0.0024119281705564243
Loss at iteration [1789]: 0.0024118883952348948
Loss at iteration [1790]: 0.002411848590906279
Loss at iteration [1791]: 0.0024118096332379165
Loss at iteration [1792]: 0.0024117686282775714
Loss at iteration [1793]: 0.0024117287860196093
Loss at iteration [1794]: 0.0024116880027805067
Loss at iteration [1795]: 0.0024116501883789682
Loss at iteration [1796]: 0.0024116116215618225
Loss at iteration [1797]: 0.0024115720409990014
Loss at iteration [1798]: 0.0024115330930773956
Loss at iteration [1799]: 0.0024114942772935893
Loss at iteration [1800]: 0.002411456261432579
Loss at iteration [1801]: 0.002411417925652944
Loss at iteration [1802]: 0.0024113803637190144
Loss at iteration [1803]: 0.002411341436419129
Loss at iteration [1804]: 0.0024113037895941085
Loss at iteration [1805]: 0.0024112650620454097
Loss at iteration [1806]: 0.0024112273040009756
Loss at iteration [1807]: 0.002411189253033622
Loss at iteration [1808]: 0.0024111518002819915
Loss at iteration [1809]: 0.0024111139077551452
Loss at iteration [1810]: 0.0024110744838706155
Loss at iteration [1811]: 0.00241103728787934
Loss at iteration [1812]: 0.002410997705581697
Loss at iteration [1813]: 0.002410959629328993
Loss at iteration [1814]: 0.0024109230106231084
Loss at iteration [1815]: 0.0024108848548751033
Loss at iteration [1816]: 0.0024108455913780203
Loss at iteration [1817]: 0.002410808771103773
Loss at iteration [1818]: 0.002410771193115172
Loss at iteration [1819]: 0.0024107331045483214
Loss at iteration [1820]: 0.0024106963586501494
Loss at iteration [1821]: 0.0024106578909253214
Loss at iteration [1822]: 0.0024106215095413054
Loss at iteration [1823]: 0.002410583698236863
Loss at iteration [1824]: 0.0024105458956603446
Loss at iteration [1825]: 0.002410508865853527
Loss at iteration [1826]: 0.002410471679281123
Loss at iteration [1827]: 0.0024104342729374026
Loss at iteration [1828]: 0.002410397214107592
Loss at iteration [1829]: 0.0024103597957708714
Loss at iteration [1830]: 0.0024103222588625845
Loss at iteration [1831]: 0.002410284411348243
Loss at iteration [1832]: 0.002410248677783837
Loss at iteration [1833]: 0.0024102115329627753
Loss at iteration [1834]: 0.0024101748098260237
Loss at iteration [1835]: 0.0024101367815526236
Loss at iteration [1836]: 0.002410098518061236
Loss at iteration [1837]: 0.0024100607431114607
Loss at iteration [1838]: 0.0024100243019928563
Loss at iteration [1839]: 0.002409986740923295
Loss at iteration [1840]: 0.002409948853406604
Loss at iteration [1841]: 0.002409910590404277
Loss at iteration [1842]: 0.0024098717937767744
Loss at iteration [1843]: 0.002409833876301127
Loss at iteration [1844]: 0.0024097959843093356
Loss at iteration [1845]: 0.002409759814848545
Loss at iteration [1846]: 0.002409721215462442
Loss at iteration [1847]: 0.002409683224455725
Loss at iteration [1848]: 0.00240964632814566
Loss at iteration [1849]: 0.0024096069074252486
Loss at iteration [1850]: 0.0024095704561178403
Loss at iteration [1851]: 0.002409532707116602
Loss at iteration [1852]: 0.0024094945988253885
Loss at iteration [1853]: 0.002409456565848019
Loss at iteration [1854]: 0.0024094184768514455
Loss at iteration [1855]: 0.002409380388969127
Loss at iteration [1856]: 0.0024093440555878433
Loss at iteration [1857]: 0.0024093053358704626
Loss at iteration [1858]: 0.0024092683865772563
Loss at iteration [1859]: 0.002409230571823442
Loss at iteration [1860]: 0.0024091930108250284
Loss at iteration [1861]: 0.002409154894139201
Loss at iteration [1862]: 0.0024091190019563946
Loss at iteration [1863]: 0.002409082154480139
Loss at iteration [1864]: 0.002409045614033365
Loss at iteration [1865]: 0.0024090080015040202
Loss at iteration [1866]: 0.0024089702033347413
Loss at iteration [1867]: 0.00240893289721065
Loss at iteration [1868]: 0.002408897822533332
Loss at iteration [1869]: 0.0024088596035529335
Loss at iteration [1870]: 0.0024088237656558517
Loss at iteration [1871]: 0.00240878579284675
Loss at iteration [1872]: 0.0024087485154586615
Loss at iteration [1873]: 0.0024087109890503326
Loss at iteration [1874]: 0.002408674107914747
Loss at iteration [1875]: 0.0024086372004781666
Loss at iteration [1876]: 0.0024086003442742587
Loss at iteration [1877]: 0.002408562919649164
Loss at iteration [1878]: 0.0024085253270588027
Loss at iteration [1879]: 0.0024084879496710306
Loss at iteration [1880]: 0.0024084507227219694
Loss at iteration [1881]: 0.002408415940102145
Loss at iteration [1882]: 0.0024083771842585634
Loss at iteration [1883]: 0.002408340553693157
Loss at iteration [1884]: 0.0024083020940039806
Loss at iteration [1885]: 0.0024082660063957334
Loss at iteration [1886]: 0.0024082280745433187
Loss at iteration [1887]: 0.0024081914405877846
Loss at iteration [1888]: 0.0024081538023070885
Loss at iteration [1889]: 0.0024081168926708505
Loss at iteration [1890]: 0.0024080787848326252
Loss at iteration [1891]: 0.002408040265708056
Loss at iteration [1892]: 0.0024080028725505243
Loss at iteration [1893]: 0.002407964148663295
Loss at iteration [1894]: 0.0024079266037766328
Loss at iteration [1895]: 0.002407889916412154
Loss at iteration [1896]: 0.0024078506378733735
Loss at iteration [1897]: 0.002407813426910659
Loss at iteration [1898]: 0.0024077748868447627
Loss at iteration [1899]: 0.0024077365426206183
Loss at iteration [1900]: 0.002407698151412322
Loss at iteration [1901]: 0.0024076616412618598
Loss at iteration [1902]: 0.00240762275407764
Loss at iteration [1903]: 0.0024075838367501215
Loss at iteration [1904]: 0.002407546555810406
Loss at iteration [1905]: 0.002407507197193847
Loss at iteration [1906]: 0.002407468238110881
Loss at iteration [1907]: 0.0024074314586508693
Loss at iteration [1908]: 0.0024073923554884624
Loss at iteration [1909]: 0.0024073534493139668
Loss at iteration [1910]: 0.0024073148686519093
Loss at iteration [1911]: 0.0024072759144706636
Loss at iteration [1912]: 0.002407237026578721
Loss at iteration [1913]: 0.0024071992740569655
Loss at iteration [1914]: 0.0024071600009158397
Loss at iteration [1915]: 0.0024071220907460012
Loss at iteration [1916]: 0.002407084101286661
Loss at iteration [1917]: 0.0024070443434328287
Loss at iteration [1918]: 0.0024070052618646253
Loss at iteration [1919]: 0.0024069671480731695
Loss at iteration [1920]: 0.002406927947380977
Loss at iteration [1921]: 0.0024068902012178554
Loss at iteration [1922]: 0.002406852345776731
Loss at iteration [1923]: 0.0024068129852423126
Loss at iteration [1924]: 0.002406774682626512
Loss at iteration [1925]: 0.002406736161009985
Loss at iteration [1926]: 0.0024066965183430315
Loss at iteration [1927]: 0.0024066574404386252
Loss at iteration [1928]: 0.002406620228211194
Loss at iteration [1929]: 0.002406581172519111
Loss at iteration [1930]: 0.0024065426218646416
Loss at iteration [1931]: 0.0024065047759016184
Loss at iteration [1932]: 0.0024064645078504176
Loss at iteration [1933]: 0.002406426391048472
Loss at iteration [1934]: 0.0024063870225244192
Loss at iteration [1935]: 0.0024063489252152226
Loss at iteration [1936]: 0.0024063110464415576
Loss at iteration [1937]: 0.002406272749068107
Loss at iteration [1938]: 0.002406232659775031
Loss at iteration [1939]: 0.002406195211586956
Loss at iteration [1940]: 0.0024061582554815095
Loss at iteration [1941]: 0.002406122177091359
Loss at iteration [1942]: 0.0024060865937449443
Loss at iteration [1943]: 0.002406052387545123
Loss at iteration [1944]: 0.002406017157029492
Loss at iteration [1945]: 0.0024059800412050965
Loss at iteration [1946]: 0.0024059454418270698
Loss at iteration [1947]: 0.0024059098488430205
Loss at iteration [1948]: 0.0024058745292665565
Loss at iteration [1949]: 0.0024058383758696848
Loss at iteration [1950]: 0.0024058042188074315
Loss at iteration [1951]: 0.002405768522126197
Loss at iteration [1952]: 0.0024057328886013815
Loss at iteration [1953]: 0.0024056971538802072
Loss at iteration [1954]: 0.002405660606552889
Loss at iteration [1955]: 0.0024056253664467625
Loss at iteration [1956]: 0.0024055890191962467
Loss at iteration [1957]: 0.0024055532247267033
Loss at iteration [1958]: 0.0024055186263028036
Loss at iteration [1959]: 0.002405482696853228
Loss at iteration [1960]: 0.002405446543459414
Loss at iteration [1961]: 0.0024054116924641655
Loss at iteration [1962]: 0.0024053758655756302
Loss at iteration [1963]: 0.002405339344850823
Loss at iteration [1964]: 0.002405304858496149
Loss at iteration [1965]: 0.0024052694246558307
Loss at iteration [1966]: 0.002405234572935155
Loss at iteration [1967]: 0.0024051988418545456
Loss at iteration [1968]: 0.0024051637026414594
Loss at iteration [1969]: 0.002405127476903288
Loss at iteration [1970]: 0.002405092664936345
Loss at iteration [1971]: 0.0024050557107967207
Loss at iteration [1972]: 0.0024050208976410118
Loss at iteration [1973]: 0.0024049877577799524
Loss at iteration [1974]: 0.002404950611430045
Loss at iteration [1975]: 0.00240491551052864
Loss at iteration [1976]: 0.002404878360315876
Loss at iteration [1977]: 0.002404842402287148
Loss at iteration [1978]: 0.0024048065408503114
Loss at iteration [1979]: 0.002404770768572231
Loss at iteration [1980]: 0.002404734976211573
Loss at iteration [1981]: 0.0024046995803017096
Loss at iteration [1982]: 0.0024046642709852225
Loss at iteration [1983]: 0.0024046291499750837
Loss at iteration [1984]: 0.002404593491692526
Loss at iteration [1985]: 0.0024045585554314896
Loss at iteration [1986]: 0.0024045227481400287
Loss at iteration [1987]: 0.0024044876548028706
Loss at iteration [1988]: 0.0024044540258443678
Loss at iteration [1989]: 0.0024044173924677916
Loss at iteration [1990]: 0.0024043824652038043
Loss at iteration [1991]: 0.0024043478372879697
Loss at iteration [1992]: 0.0024043109403581314
Loss at iteration [1993]: 0.002404277149823918
Loss at iteration [1994]: 0.002404241142794841
Loss at iteration [1995]: 0.0024042051568146246
Loss at iteration [1996]: 0.002404172224649519
Loss at iteration [1997]: 0.0024041369677599875
Loss at iteration [1998]: 0.002404101497615925
Loss at iteration [1999]: 0.0024040658989619244
Loss at iteration [2000]: 0.002404031288882948
Loss at iteration [2001]: 0.0024039959648029137
Loss at iteration [2002]: 0.002403960336798311
Loss at iteration [2003]: 0.0024039271231369296
Loss at iteration [2004]: 0.002403891453524647
Loss at iteration [2005]: 0.002403856306667364
Loss at iteration [2006]: 0.0024038212640152827
Loss at iteration [2007]: 0.0024037864543497624
Loss at iteration [2008]: 0.0024037504139333404
Loss at iteration [2009]: 0.00240371469322556
Loss at iteration [2010]: 0.0024036795337143133
Loss at iteration [2011]: 0.002403644964483997
Loss at iteration [2012]: 0.0024036091401120024
Loss at iteration [2013]: 0.00240357281364579
Loss at iteration [2014]: 0.002403538728288167
Loss at iteration [2015]: 0.002403502608990312
Loss at iteration [2016]: 0.002403467045037308
Loss at iteration [2017]: 0.002403431850256553
Loss at iteration [2018]: 0.0024033953392807146
Loss at iteration [2019]: 0.002403361377385706
Loss at iteration [2020]: 0.002403325953392054
Loss at iteration [2021]: 0.002403290236001655
Loss at iteration [2022]: 0.0024032564220253434
Loss at iteration [2023]: 0.002403220124056704
Loss at iteration [2024]: 0.0024031855164152543
Loss at iteration [2025]: 0.0024031490009036884
Loss at iteration [2026]: 0.002403115208663203
Loss at iteration [2027]: 0.002403079566620127
Loss at iteration [2028]: 0.0024030449404966064
Loss at iteration [2029]: 0.002403008203894678
Loss at iteration [2030]: 0.002402973217573164
Loss at iteration [2031]: 0.0024029369832248367
Loss at iteration [2032]: 0.002402901552653671
Loss at iteration [2033]: 0.0024028658942754533
Loss at iteration [2034]: 0.002402831446208058
Loss at iteration [2035]: 0.0024027955705505162
Loss at iteration [2036]: 0.002402759899536525
Loss at iteration [2037]: 0.0024027245421386735
Loss at iteration [2038]: 0.002402689155572737
Loss at iteration [2039]: 0.0024026526896602325
Loss at iteration [2040]: 0.0024026175706920194
Loss at iteration [2041]: 0.0024025839927350563
Loss at iteration [2042]: 0.0024025476834409346
Loss at iteration [2043]: 0.002402512964293287
Loss at iteration [2044]: 0.002402477686253256
Loss at iteration [2045]: 0.002402441951147876
Loss at iteration [2046]: 0.0024024063515339783
Loss at iteration [2047]: 0.0024023709524113646
Loss at iteration [2048]: 0.002402337022389164
Loss at iteration [2049]: 0.0024023014622693737
Loss at iteration [2050]: 0.002402266871741093
Loss at iteration [2051]: 0.002402232457181395
Loss at iteration [2052]: 0.0024021964990979705
Loss at iteration [2053]: 0.0024021623239326396
Loss at iteration [2054]: 0.002402126966314438
Loss at iteration [2055]: 0.0024020918625161677
Loss at iteration [2056]: 0.0024020568997937734
Loss at iteration [2057]: 0.0024020226076362987
Loss at iteration [2058]: 0.0024019876314925006
Loss at iteration [2059]: 0.002401952015787069
Loss at iteration [2060]: 0.0024019169692559824
Loss at iteration [2061]: 0.0024018817621513093
Loss at iteration [2062]: 0.002401845290779882
Loss at iteration [2063]: 0.0024018095471001893
Loss at iteration [2064]: 0.0024017716315169256
Loss at iteration [2065]: 0.0024017322551333708
Loss at iteration [2066]: 0.002401694973473187
Loss at iteration [2067]: 0.002401656972248393
Loss at iteration [2068]: 0.002401619195812576
Loss at iteration [2069]: 0.0024015836025536516
Loss at iteration [2070]: 0.002401547462817032
Loss at iteration [2071]: 0.002401512983715571
Loss at iteration [2072]: 0.002401476396635209
Loss at iteration [2073]: 0.0024014404320352283
Loss at iteration [2074]: 0.002401406340626155
Loss at iteration [2075]: 0.0024013695523224425
Loss at iteration [2076]: 0.0024013338265339037
Loss at iteration [2077]: 0.0024012981352466082
Loss at iteration [2078]: 0.002401263345642149
Loss at iteration [2079]: 0.002401229051640333
Loss at iteration [2080]: 0.0024011925929620847
Loss at iteration [2081]: 0.0024011583975779576
Loss at iteration [2082]: 0.002401121973928508
Loss at iteration [2083]: 0.002401086721761371
Loss at iteration [2084]: 0.0024010516878498252
Loss at iteration [2085]: 0.002401015435605408
Loss at iteration [2086]: 0.0024009825522916316
Loss at iteration [2087]: 0.0024009463366204517
Loss at iteration [2088]: 0.002400910915331005
Loss at iteration [2089]: 0.0024008763218574744
Loss at iteration [2090]: 0.002400840253806189
Loss at iteration [2091]: 0.0024008049343213584
Loss at iteration [2092]: 0.00240077043036904
Loss at iteration [2093]: 0.002400735427255886
Loss at iteration [2094]: 0.00240069959932586
Loss at iteration [2095]: 0.0024006648566446895
Loss at iteration [2096]: 0.002400631233840858
Loss at iteration [2097]: 0.002400596459166534
Loss at iteration [2098]: 0.0024005609715593585
Loss at iteration [2099]: 0.0024005263421648165
Loss at iteration [2100]: 0.0024004921183475676
Loss at iteration [2101]: 0.002400456638785173
Loss at iteration [2102]: 0.0024004214620546786
Loss at iteration [2103]: 0.0024003875113772595
Loss at iteration [2104]: 0.0024003535028172093
Loss at iteration [2105]: 0.0024003192672049107
Loss at iteration [2106]: 0.002400285404118326
Loss at iteration [2107]: 0.002400249461564401
Loss at iteration [2108]: 0.0024002159002254287
Loss at iteration [2109]: 0.0024001810241700713
Loss at iteration [2110]: 0.0024001466375340873
Loss at iteration [2111]: 0.002400111241516178
Loss at iteration [2112]: 0.002400075898488412
Loss at iteration [2113]: 0.0024000440100862713
Loss at iteration [2114]: 0.002400009604871265
Loss at iteration [2115]: 0.0023999751520671652
Loss at iteration [2116]: 0.0023999400294540747
Loss at iteration [2117]: 0.002399905159932431
Loss at iteration [2118]: 0.0023998714858646814
Loss at iteration [2119]: 0.002399835556848869
Loss at iteration [2120]: 0.0023997999314543067
Loss at iteration [2121]: 0.0023997626304940326
Loss at iteration [2122]: 0.002399724909538714
Loss at iteration [2123]: 0.002399684330773224
Loss at iteration [2124]: 0.002399638746483074
Loss at iteration [2125]: 0.0023995919053063303
Loss at iteration [2126]: 0.0023995485982169725
Loss at iteration [2127]: 0.00239951109654794
Loss at iteration [2128]: 0.002399474626141269
Loss at iteration [2129]: 0.0023994392794112482
Loss at iteration [2130]: 0.002399402228167972
Loss at iteration [2131]: 0.002399365254133861
Loss at iteration [2132]: 0.002399330013385514
Loss at iteration [2133]: 0.0023992935671581696
Loss at iteration [2134]: 0.0023992568933487047
Loss at iteration [2135]: 0.002399219730464546
Loss at iteration [2136]: 0.002399182115399277
Loss at iteration [2137]: 0.0023991469488260963
Loss at iteration [2138]: 0.0023991106972578533
Loss at iteration [2139]: 0.002399075244197934
Loss at iteration [2140]: 0.0023990400096518157
Loss at iteration [2141]: 0.002399004355699189
Loss at iteration [2142]: 0.002398969771396541
Loss at iteration [2143]: 0.002398934119493431
Loss at iteration [2144]: 0.002398897406981758
Loss at iteration [2145]: 0.0023988624580843325
Loss at iteration [2146]: 0.00239882580021155
Loss at iteration [2147]: 0.0023987914815734855
Loss at iteration [2148]: 0.0023987550701451915
Loss at iteration [2149]: 0.002398719228226737
Loss at iteration [2150]: 0.002398684514990138
Loss at iteration [2151]: 0.0023986471870063395
Loss at iteration [2152]: 0.00239861289293663
Loss at iteration [2153]: 0.0023985767527912225
Loss at iteration [2154]: 0.0023985401247644594
Loss at iteration [2155]: 0.0023985050273436013
Loss at iteration [2156]: 0.0023984674824426826
Loss at iteration [2157]: 0.002398433453036029
Loss at iteration [2158]: 0.002398397617109575
Loss at iteration [2159]: 0.002398361321000106
Loss at iteration [2160]: 0.0023983255174231874
Loss at iteration [2161]: 0.002398289848868194
Loss at iteration [2162]: 0.0023982541939787413
Loss at iteration [2163]: 0.0023982179468631506
Loss at iteration [2164]: 0.002398183155075524
Loss at iteration [2165]: 0.0023981463490088508
Loss at iteration [2166]: 0.0023981100781917896
Loss at iteration [2167]: 0.0023980753823375912
Loss at iteration [2168]: 0.002398039574564842
Loss at iteration [2169]: 0.0023980041475902417
Loss at iteration [2170]: 0.0023979690229898208
Loss at iteration [2171]: 0.0023979343051296373
Loss at iteration [2172]: 0.002397900327593011
Loss at iteration [2173]: 0.0023978651484522365
Loss at iteration [2174]: 0.002397830579942699
Loss at iteration [2175]: 0.0023977964136961544
Loss at iteration [2176]: 0.002397763205479869
Loss at iteration [2177]: 0.002397728966343079
Loss at iteration [2178]: 0.0023976950027847672
Loss at iteration [2179]: 0.0023976619076384632
Loss at iteration [2180]: 0.002397627225773299
Loss at iteration [2181]: 0.002397594078509839
Loss at iteration [2182]: 0.0023975598084430383
Loss at iteration [2183]: 0.0023975252687597473
Loss at iteration [2184]: 0.002397491795592338
Loss at iteration [2185]: 0.0023974575795853
Loss at iteration [2186]: 0.002397424129460687
Loss at iteration [2187]: 0.0023973910269274867
Loss at iteration [2188]: 0.00239735717065608
Loss at iteration [2189]: 0.0023973230958468953
Loss at iteration [2190]: 0.0023972892759678804
Loss at iteration [2191]: 0.002397255099465769
Loss at iteration [2192]: 0.002397220793550279
Loss at iteration [2193]: 0.0023971867680431043
Loss at iteration [2194]: 0.002397153896652428
Loss at iteration [2195]: 0.002397119283533582
Loss at iteration [2196]: 0.002397086101603442
Loss at iteration [2197]: 0.0023970526584004034
Loss at iteration [2198]: 0.002397018546976623
Loss at iteration [2199]: 0.002396985787605533
Loss at iteration [2200]: 0.00239695229264733
Loss at iteration [2201]: 0.002396918361538904
Loss at iteration [2202]: 0.002396884769940385
Loss at iteration [2203]: 0.0023968504156135174
Loss at iteration [2204]: 0.0023968171235631956
Loss at iteration [2205]: 0.002396783334402785
Loss at iteration [2206]: 0.002396749382260478
Loss at iteration [2207]: 0.0023967157294083894
Loss at iteration [2208]: 0.0023966821005990966
Loss at iteration [2209]: 0.002396647421306845
Loss at iteration [2210]: 0.002396614540257715
Loss at iteration [2211]: 0.0023965804432336257
Loss at iteration [2212]: 0.0023965472877482503
Loss at iteration [2213]: 0.0023965138300523553
Loss at iteration [2214]: 0.0023964809864137804
Loss at iteration [2215]: 0.0023964475937627554
Loss at iteration [2216]: 0.0023964148738207245
Loss at iteration [2217]: 0.0023963819627212763
Loss at iteration [2218]: 0.002396348216748777
Loss at iteration [2219]: 0.002396315218107678
Loss at iteration [2220]: 0.0023962828150515263
Loss at iteration [2221]: 0.002396249883059702
Loss at iteration [2222]: 0.0023962168749285615
Loss at iteration [2223]: 0.0023961831350505867
Loss at iteration [2224]: 0.002396150143528496
Loss at iteration [2225]: 0.002396118449221943
Loss at iteration [2226]: 0.00239608556654249
Loss at iteration [2227]: 0.0023960533417031007
Loss at iteration [2228]: 0.0023960195602225165
Loss at iteration [2229]: 0.002395986913324073
Loss at iteration [2230]: 0.0023959540310703677
Loss at iteration [2231]: 0.0023959221903820816
Loss at iteration [2232]: 0.0023958883980007275
Loss at iteration [2233]: 0.002395856609788139
Loss at iteration [2234]: 0.0023958235086518546
Loss at iteration [2235]: 0.002395790555507069
Loss at iteration [2236]: 0.0023957585186702504
Loss at iteration [2237]: 0.0023957255190562125
Loss at iteration [2238]: 0.00239569165335314
Loss at iteration [2239]: 0.002395661020223002
Loss at iteration [2240]: 0.0023956260793598343
Loss at iteration [2241]: 0.002395593923357114
Loss at iteration [2242]: 0.0023955597300722264
Loss at iteration [2243]: 0.0023955263901165535
Loss at iteration [2244]: 0.0023954932143962506
Loss at iteration [2245]: 0.0023954612677223623
Loss at iteration [2246]: 0.0023954278516760694
Loss at iteration [2247]: 0.0023953956823458177
Loss at iteration [2248]: 0.002395363600192642
Loss at iteration [2249]: 0.0023953304822294783
Loss at iteration [2250]: 0.002395298125427872
Loss at iteration [2251]: 0.0023952660456947683
Loss at iteration [2252]: 0.0023952341828077503
Loss at iteration [2253]: 0.0023952023840097085
Loss at iteration [2254]: 0.002395169270874864
Loss at iteration [2255]: 0.002395137129221216
Loss at iteration [2256]: 0.002395104720881781
Loss at iteration [2257]: 0.0023950719995252685
Loss at iteration [2258]: 0.0023950401259957336
Loss at iteration [2259]: 0.002395006947301753
Loss at iteration [2260]: 0.0023949748299191566
Loss at iteration [2261]: 0.002394942764631888
Loss at iteration [2262]: 0.0023949104918912136
Loss at iteration [2263]: 0.00239487798768528
Loss at iteration [2264]: 0.002394846117034439
Loss at iteration [2265]: 0.002394813887124883
Loss at iteration [2266]: 0.002394782378071582
Loss at iteration [2267]: 0.0023947496965799685
Loss at iteration [2268]: 0.002394717411241141
Loss at iteration [2269]: 0.00239468496944687
Loss at iteration [2270]: 0.0023946520403400145
Loss at iteration [2271]: 0.0023946197939679467
Loss at iteration [2272]: 0.0023945870213541915
Loss at iteration [2273]: 0.00239455533331164
Loss at iteration [2274]: 0.002394522628472559
Loss at iteration [2275]: 0.002394490307040445
Loss at iteration [2276]: 0.002394457270024018
Loss at iteration [2277]: 0.0023944254351968104
Loss at iteration [2278]: 0.002394393561057672
Loss at iteration [2279]: 0.002394363248409118
Loss at iteration [2280]: 0.002394330576066939
Loss at iteration [2281]: 0.0023942989096005507
Loss at iteration [2282]: 0.0023942665187060615
Loss at iteration [2283]: 0.0023942354480702157
Loss at iteration [2284]: 0.002394204038790404
Loss at iteration [2285]: 0.0023941716936777785
Loss at iteration [2286]: 0.0023941397281168385
Loss at iteration [2287]: 0.0023941077562637364
Loss at iteration [2288]: 0.0023940754564631597
Loss at iteration [2289]: 0.0023940444789787006
Loss at iteration [2290]: 0.0023940130232102657
Loss at iteration [2291]: 0.002393980481610687
Loss at iteration [2292]: 0.0023939495819006677
Loss at iteration [2293]: 0.0023939185656922796
Loss at iteration [2294]: 0.0023938853178425827
Loss at iteration [2295]: 0.002393855212032022
Loss at iteration [2296]: 0.0023938220530355324
Loss at iteration [2297]: 0.0023937918465175
Loss at iteration [2298]: 0.002393759778274285
Loss at iteration [2299]: 0.0023937274399449524
Loss at iteration [2300]: 0.002393696680559489
Loss at iteration [2301]: 0.0023936637703940384
Loss at iteration [2302]: 0.002393632162467336
Loss at iteration [2303]: 0.0023936000421441437
Loss at iteration [2304]: 0.002393568396607159
Loss at iteration [2305]: 0.002393536556454385
Loss at iteration [2306]: 0.0023935058256660826
Loss at iteration [2307]: 0.0023934738950163333
Loss at iteration [2308]: 0.0023934427211186357
Loss at iteration [2309]: 0.0023934104556019757
Loss at iteration [2310]: 0.0023933787877135695
Loss at iteration [2311]: 0.0023933481248649526
Loss at iteration [2312]: 0.0023933152189343915
Loss at iteration [2313]: 0.002393283623225339
Loss at iteration [2314]: 0.002393251116301355
Loss at iteration [2315]: 0.00239321951623119
Loss at iteration [2316]: 0.0023931884489288477
Loss at iteration [2317]: 0.0023931564277259038
Loss at iteration [2318]: 0.0023931257652246994
Loss at iteration [2319]: 0.0023930942754685613
Loss at iteration [2320]: 0.0023930632190147707
Loss at iteration [2321]: 0.002393031048960038
Loss at iteration [2322]: 0.0023929997990082045
Loss at iteration [2323]: 0.002392968570828735
Loss at iteration [2324]: 0.0023929369602077107
Loss at iteration [2325]: 0.0023929054234896
Loss at iteration [2326]: 0.002392873819093267
Loss at iteration [2327]: 0.0023928432525046994
Loss at iteration [2328]: 0.0023928113345841992
Loss at iteration [2329]: 0.002392779708150599
Loss at iteration [2330]: 0.002392747943971052
Loss at iteration [2331]: 0.0023927163420703985
Loss at iteration [2332]: 0.0023926856871974806
Loss at iteration [2333]: 0.0023926539672824796
Loss at iteration [2334]: 0.002392622977211571
Loss at iteration [2335]: 0.0023925919591729627
Loss at iteration [2336]: 0.0023925594363741775
Loss at iteration [2337]: 0.0023925279327118624
Loss at iteration [2338]: 0.0023924970982175916
Loss at iteration [2339]: 0.002392465196503616
Loss at iteration [2340]: 0.0023924341279943106
Loss at iteration [2341]: 0.0023924018293385273
Loss at iteration [2342]: 0.0023923700388380716
Loss at iteration [2343]: 0.0023923393490107346
Loss at iteration [2344]: 0.002392306954553565
Loss at iteration [2345]: 0.002392275370091566
Loss at iteration [2346]: 0.002392242959204156
Loss at iteration [2347]: 0.0023922130193233617
Loss at iteration [2348]: 0.0023921812939967863
Loss at iteration [2349]: 0.0023921481097001858
Loss at iteration [2350]: 0.0023921176269073186
Loss at iteration [2351]: 0.002392084640710357
Loss at iteration [2352]: 0.002392053834822675
Loss at iteration [2353]: 0.0023920219058387866
Loss at iteration [2354]: 0.0023919897059679206
Loss at iteration [2355]: 0.0023919585085822094
Loss at iteration [2356]: 0.002391927101690888
Loss at iteration [2357]: 0.0023918957750954126
Loss at iteration [2358]: 0.0023918640200116205
Loss at iteration [2359]: 0.0023918328383886827
Loss at iteration [2360]: 0.0023918008047210493
Loss at iteration [2361]: 0.002391768937794449
Loss at iteration [2362]: 0.0023917380905559933
Loss at iteration [2363]: 0.0023917061129153506
Loss at iteration [2364]: 0.0023916747847198844
Loss at iteration [2365]: 0.0023916429735505174
Loss at iteration [2366]: 0.0023916115923757583
Loss at iteration [2367]: 0.0023915791293246374
Loss at iteration [2368]: 0.0023915467111879467
Loss at iteration [2369]: 0.002391515234147996
Loss at iteration [2370]: 0.0023914832489812517
Loss at iteration [2371]: 0.0023914515232119743
Loss at iteration [2372]: 0.0023914197704974507
Loss at iteration [2373]: 0.002391387574384608
Loss at iteration [2374]: 0.002391356492865881
Loss at iteration [2375]: 0.0023913237526104925
Loss at iteration [2376]: 0.002391292780337152
Loss at iteration [2377]: 0.00239126108382162
Loss at iteration [2378]: 0.002391229706953844
Loss at iteration [2379]: 0.002391198212429679
Loss at iteration [2380]: 0.0023911663494733267
Loss at iteration [2381]: 0.002391134375556701
Loss at iteration [2382]: 0.002391103637472059
Loss at iteration [2383]: 0.002391070949586494
Loss at iteration [2384]: 0.0023910405340041513
Loss at iteration [2385]: 0.0023910083487336505
Loss at iteration [2386]: 0.0023909766265254135
Loss at iteration [2387]: 0.002390944942218641
Loss at iteration [2388]: 0.002390914050860392
Loss at iteration [2389]: 0.002390881889324805
Loss at iteration [2390]: 0.002390850918545739
Loss at iteration [2391]: 0.0023908190024771177
Loss at iteration [2392]: 0.002390787444835133
Loss at iteration [2393]: 0.00239075569258764
Loss at iteration [2394]: 0.0023907241092571353
Loss at iteration [2395]: 0.0023906946323594253
Loss at iteration [2396]: 0.00239066212506812
Loss at iteration [2397]: 0.0023906312889927176
Loss at iteration [2398]: 0.002390600121399633
Loss at iteration [2399]: 0.002390568621166482
Loss at iteration [2400]: 0.002390536981473069
Loss at iteration [2401]: 0.0023905052434059445
Loss at iteration [2402]: 0.0023904743246007613
Loss at iteration [2403]: 0.002390443109882041
Loss at iteration [2404]: 0.0023904115801765616
Loss at iteration [2405]: 0.002390380139775785
Loss at iteration [2406]: 0.002390348401413829
Loss at iteration [2407]: 0.002390316840152089
Loss at iteration [2408]: 0.0023902860863186646
Loss at iteration [2409]: 0.0023902539615333553
Loss at iteration [2410]: 0.0023902230119044014
Loss at iteration [2411]: 0.00239019167427892
Loss at iteration [2412]: 0.002390160296446728
Loss at iteration [2413]: 0.002390129716625721
Loss at iteration [2414]: 0.0023900980447430467
Loss at iteration [2415]: 0.0023900659729578265
Loss at iteration [2416]: 0.002390035538798143
Loss at iteration [2417]: 0.0023900036995574163
Loss at iteration [2418]: 0.0023899725344837556
Loss at iteration [2419]: 0.002389941813238652
Loss at iteration [2420]: 0.002389910173279956
Loss at iteration [2421]: 0.0023898781747492014
Loss at iteration [2422]: 0.002389847384916924
Loss at iteration [2423]: 0.0023898155734344436
Loss at iteration [2424]: 0.0023897843680401078
Loss at iteration [2425]: 0.002389753052026615
Loss at iteration [2426]: 0.0023897215013577175
Loss at iteration [2427]: 0.002389690558033516
Loss at iteration [2428]: 0.00238965900992571
Loss at iteration [2429]: 0.0023896285618691983
Loss at iteration [2430]: 0.002389597194668038
Loss at iteration [2431]: 0.0023895654484379207
Loss at iteration [2432]: 0.0023895345030144127
Loss at iteration [2433]: 0.0023895028405250063
Loss at iteration [2434]: 0.002389471219352113
Loss at iteration [2435]: 0.002389439850438768
Loss at iteration [2436]: 0.00238940778618977
Loss at iteration [2437]: 0.0023893785637595024
Loss at iteration [2438]: 0.0023893458687505
Loss at iteration [2439]: 0.0023893154080342088
Loss at iteration [2440]: 0.002389283780382405
Loss at iteration [2441]: 0.0023892524893255112
Loss at iteration [2442]: 0.0023892206298629943
Loss at iteration [2443]: 0.0023891888673840418
Loss at iteration [2444]: 0.0023891577458328124
Loss at iteration [2445]: 0.002389125861788615
Loss at iteration [2446]: 0.0023890960224913446
Loss at iteration [2447]: 0.0023890636233876547
Loss at iteration [2448]: 0.0023890320635106483
Loss at iteration [2449]: 0.0023890006927224103
Loss at iteration [2450]: 0.0023889693744355706
Loss at iteration [2451]: 0.0023889375046584334
Loss at iteration [2452]: 0.002388906440791781
Loss at iteration [2453]: 0.0023888750593115318
Loss at iteration [2454]: 0.0023888422387588356
Loss at iteration [2455]: 0.0023888106144450932
Loss at iteration [2456]: 0.002388779128683906
Loss at iteration [2457]: 0.002388748014844973
Loss at iteration [2458]: 0.0023887166584879863
Loss at iteration [2459]: 0.002388685335894359
Loss at iteration [2460]: 0.0023886528572921698
Loss at iteration [2461]: 0.0023886227395244763
Loss at iteration [2462]: 0.0023885896298463005
Loss at iteration [2463]: 0.002388559099167819
Loss at iteration [2464]: 0.002388527903243218
Loss at iteration [2465]: 0.002388497043455502
Loss at iteration [2466]: 0.0023884656352384363
Loss at iteration [2467]: 0.0023884339296659446
Loss at iteration [2468]: 0.002388402010574147
Loss at iteration [2469]: 0.002388370043783522
Loss at iteration [2470]: 0.0023883391513646653
Loss at iteration [2471]: 0.002388308079393585
Loss at iteration [2472]: 0.0023882760731373668
Loss at iteration [2473]: 0.002388244364957043
Loss at iteration [2474]: 0.0023882130265360786
Loss at iteration [2475]: 0.0023881813323827304
Loss at iteration [2476]: 0.0023881499704290227
Loss at iteration [2477]: 0.0023881177289201507
Loss at iteration [2478]: 0.002388085843351852
Loss at iteration [2479]: 0.002388054696625747
Loss at iteration [2480]: 0.0023880212004398827
Loss at iteration [2481]: 0.0023879896482988526
Loss at iteration [2482]: 0.0023879577820096276
Loss at iteration [2483]: 0.0023879257310595765
Loss at iteration [2484]: 0.002387894484357129
Loss at iteration [2485]: 0.0023878630047460565
Loss at iteration [2486]: 0.0023878300567143477
Loss at iteration [2487]: 0.002387798505646701
Loss at iteration [2488]: 0.0023877663850563452
Loss at iteration [2489]: 0.002387735264820151
Loss at iteration [2490]: 0.0023877021896386613
Loss at iteration [2491]: 0.00238767092306851
Loss at iteration [2492]: 0.002387638937570368
Loss at iteration [2493]: 0.0023876065230293104
Loss at iteration [2494]: 0.00238757418473916
Loss at iteration [2495]: 0.0023875411298970475
Loss at iteration [2496]: 0.002387509725443345
Loss at iteration [2497]: 0.002387476844262777
Loss at iteration [2498]: 0.002387445404665606
Loss at iteration [2499]: 0.0023874128473242414
Loss at iteration [2500]: 0.002387379910103192
Loss at iteration [2501]: 0.00238734772409477
Loss at iteration [2502]: 0.0023873150925531558
Loss at iteration [2503]: 0.0023872831574736643
Loss at iteration [2504]: 0.002387251085770904
Loss at iteration [2505]: 0.002387217844989633
Loss at iteration [2506]: 0.0023871854844434008
Loss at iteration [2507]: 0.0023871528463509815
Loss at iteration [2508]: 0.0023871207656976537
Loss at iteration [2509]: 0.0023870881042297506
Loss at iteration [2510]: 0.0023870554119009547
Loss at iteration [2511]: 0.0023870225069541552
Loss at iteration [2512]: 0.0023869882222655736
Loss at iteration [2513]: 0.002386954436576293
Loss at iteration [2514]: 0.002386919679359808
Loss at iteration [2515]: 0.002386883802248937
Loss at iteration [2516]: 0.002386849315547361
Loss at iteration [2517]: 0.002386813768481104
Loss at iteration [2518]: 0.0023867789235659026
Loss at iteration [2519]: 0.002386743630726478
Loss at iteration [2520]: 0.0023867105273259652
Loss at iteration [2521]: 0.002386677720857994
Loss at iteration [2522]: 0.002386644247413246
Loss at iteration [2523]: 0.002386611649934852
Loss at iteration [2524]: 0.0023865788337796836
Loss at iteration [2525]: 0.002386546085415438
Loss at iteration [2526]: 0.0023865135990080734
Loss at iteration [2527]: 0.002386481629549023
Loss at iteration [2528]: 0.002386449364941353
Loss at iteration [2529]: 0.002386416689968622
Loss at iteration [2530]: 0.0023863849579708186
Loss at iteration [2531]: 0.0023863522972472043
Loss at iteration [2532]: 0.002386319397910468
Loss at iteration [2533]: 0.0023862878709644928
Loss at iteration [2534]: 0.0023862548919167067
Loss at iteration [2535]: 0.002386222798085686
Loss at iteration [2536]: 0.002386190573209751
Loss at iteration [2537]: 0.0023861581029763945
Loss at iteration [2538]: 0.002386126481169001
Loss at iteration [2539]: 0.002386093378735682
Loss at iteration [2540]: 0.002386062378196319
Loss at iteration [2541]: 0.002386030519310831
Loss at iteration [2542]: 0.0023859977576257724
Loss at iteration [2543]: 0.0023859660747230847
Loss at iteration [2544]: 0.0023859330186313996
Loss at iteration [2545]: 0.0023859012410138887
Loss at iteration [2546]: 0.002385868861514184
Loss at iteration [2547]: 0.0023858366821592147
Loss at iteration [2548]: 0.002385804489935348
Loss at iteration [2549]: 0.002385771754005783
Loss at iteration [2550]: 0.0023857395652491283
Loss at iteration [2551]: 0.0023857073729181455
Loss at iteration [2552]: 0.002385676059489316
Loss at iteration [2553]: 0.0023856430729527213
Loss at iteration [2554]: 0.0023856114919469152
Loss at iteration [2555]: 0.002385579779115336
Loss at iteration [2556]: 0.0023855478898081126
Loss at iteration [2557]: 0.002385515118862188
Loss at iteration [2558]: 0.0023854847489216944
Loss at iteration [2559]: 0.002385451773080445
Loss at iteration [2560]: 0.0023854198663222493
Loss at iteration [2561]: 0.0023853889333320106
Loss at iteration [2562]: 0.0023853558117082367
Loss at iteration [2563]: 0.002385324061041742
Loss at iteration [2564]: 0.0023852928207458313
Loss at iteration [2565]: 0.0023852609414431584
Loss at iteration [2566]: 0.002385229199680313
Loss at iteration [2567]: 0.002385198084268489
Loss at iteration [2568]: 0.0023851662636788064
Loss at iteration [2569]: 0.002385135816445436
Loss at iteration [2570]: 0.002385103493716463
Loss at iteration [2571]: 0.002385072093208692
Loss at iteration [2572]: 0.0023850408773136225
Loss at iteration [2573]: 0.0023850085619048734
Loss at iteration [2574]: 0.002384978232142608
Loss at iteration [2575]: 0.0023849460224544443
Loss at iteration [2576]: 0.0023849147224871913
Loss at iteration [2577]: 0.0023848838712365924
Loss at iteration [2578]: 0.0023848522269518933
Loss at iteration [2579]: 0.002384821068391211
Loss at iteration [2580]: 0.0023847895622810585
Loss at iteration [2581]: 0.002384757862107306
Loss at iteration [2582]: 0.002384726642200764
Loss at iteration [2583]: 0.0023846955144394967
Loss at iteration [2584]: 0.002384663652907512
Loss at iteration [2585]: 0.002384632139480533
Loss at iteration [2586]: 0.0023846009176144377
Loss at iteration [2587]: 0.002384570184441964
Loss at iteration [2588]: 0.0023845376618002834
Loss at iteration [2589]: 0.002384507479696465
Loss at iteration [2590]: 0.0023844760383895467
Loss at iteration [2591]: 0.002384444704667765
Loss at iteration [2592]: 0.002384412979433941
Loss at iteration [2593]: 0.0023843815232469485
Loss at iteration [2594]: 0.0023843503707994913
Loss at iteration [2595]: 0.0023843189702008097
Loss at iteration [2596]: 0.002384287336438887
Loss at iteration [2597]: 0.0023842560873525275
Loss at iteration [2598]: 0.0023842239947658903
Loss at iteration [2599]: 0.0023841938522608536
Loss at iteration [2600]: 0.002384162168204526
Loss at iteration [2601]: 0.00238413130965321
Loss at iteration [2602]: 0.002384099924874126
Loss at iteration [2603]: 0.0023840681349856494
Loss at iteration [2604]: 0.002384037378759024
Loss at iteration [2605]: 0.0023840064109897966
Loss at iteration [2606]: 0.0023839731781693666
Loss at iteration [2607]: 0.0023839430632723716
Loss at iteration [2608]: 0.0023839115473154593
Loss at iteration [2609]: 0.002383879931365226
Loss at iteration [2610]: 0.0023838487302749833
Loss at iteration [2611]: 0.002383816870650052
Loss at iteration [2612]: 0.002383785031428937
Loss at iteration [2613]: 0.002383753182285793
Loss at iteration [2614]: 0.002383722819348122
Loss at iteration [2615]: 0.002383690551998378
Loss at iteration [2616]: 0.002383658431571554
Loss at iteration [2617]: 0.0023836274633543056
Loss at iteration [2618]: 0.0023835959808120996
Loss at iteration [2619]: 0.0023835645324386022
Loss at iteration [2620]: 0.0023835328546281454
Loss at iteration [2621]: 0.0023835010545368027
Loss at iteration [2622]: 0.0023834701742223774
Loss at iteration [2623]: 0.002383438538176174
Loss at iteration [2624]: 0.0023834081873549745
Loss at iteration [2625]: 0.0023833766436351343
Loss at iteration [2626]: 0.0023833448763944604
Loss at iteration [2627]: 0.002383313744460335
Loss at iteration [2628]: 0.0023832823300329303
Loss at iteration [2629]: 0.0023832503236571236
Loss at iteration [2630]: 0.002383218824856194
Loss at iteration [2631]: 0.002383186804659156
Loss at iteration [2632]: 0.0023831544972141923
Loss at iteration [2633]: 0.0023831233792536767
Loss at iteration [2634]: 0.002383089581042981
Loss at iteration [2635]: 0.0023830562194560615
Loss at iteration [2636]: 0.0023830231784566017
Loss at iteration [2637]: 0.00238299046154994
Loss at iteration [2638]: 0.0023829578127896405
Loss at iteration [2639]: 0.0023829247044349824
Loss at iteration [2640]: 0.0023828912956061817
Loss at iteration [2641]: 0.0023828578033121077
Loss at iteration [2642]: 0.0023828238571088805
Loss at iteration [2643]: 0.0023827915056196833
Loss at iteration [2644]: 0.0023827590361180768
Loss at iteration [2645]: 0.0023827260990032153
Loss at iteration [2646]: 0.0023826941967005433
Loss at iteration [2647]: 0.0023826619339471318
Loss at iteration [2648]: 0.0023826290322735595
Loss at iteration [2649]: 0.0023825976185336897
Loss at iteration [2650]: 0.002382565322261924
Loss at iteration [2651]: 0.0023825334396525254
Loss at iteration [2652]: 0.002382502152376087
Loss at iteration [2653]: 0.0023824696414591
Loss at iteration [2654]: 0.0023824381642376605
Loss at iteration [2655]: 0.002382406340372936
Loss at iteration [2656]: 0.0023823745933876823
Loss at iteration [2657]: 0.0023823434510432443
Loss at iteration [2658]: 0.002382312249040297
Loss at iteration [2659]: 0.002382279632161811
Loss at iteration [2660]: 0.002382249101885214
Loss at iteration [2661]: 0.002382217925572471
Loss at iteration [2662]: 0.002382185845143153
Loss at iteration [2663]: 0.0023821549970952857
Loss at iteration [2664]: 0.0023821237259358833
Loss at iteration [2665]: 0.0023820916243774684
Loss at iteration [2666]: 0.002382060173213516
Loss at iteration [2667]: 0.002382029534761998
Loss at iteration [2668]: 0.002381998408978498
Loss at iteration [2669]: 0.0023819654589302915
Loss at iteration [2670]: 0.002381935643691474
Loss at iteration [2671]: 0.0023819029286445935
Loss at iteration [2672]: 0.0023818728388277518
Loss at iteration [2673]: 0.0023818402940998687
Loss at iteration [2674]: 0.0023818098516929747
Loss at iteration [2675]: 0.002381778117422085
Loss at iteration [2676]: 0.0023817466322078934
Loss at iteration [2677]: 0.002381713984493563
Loss at iteration [2678]: 0.00238168303201488
Loss at iteration [2679]: 0.002381651430980748
Loss at iteration [2680]: 0.00238162032109401
Loss at iteration [2681]: 0.0023815879143362045
Loss at iteration [2682]: 0.0023815563801691825
Loss at iteration [2683]: 0.002381524583595802
Loss at iteration [2684]: 0.0023814935924004713
Loss at iteration [2685]: 0.0023814624891655895
Loss at iteration [2686]: 0.0023814314737421144
Loss at iteration [2687]: 0.002381399595511521
Loss at iteration [2688]: 0.00238136877094542
Loss at iteration [2689]: 0.0023813373597254047
Loss at iteration [2690]: 0.0023813067074701885
Loss at iteration [2691]: 0.0023812758715724045
Loss at iteration [2692]: 0.002381244213512998
Loss at iteration [2693]: 0.0023812135992944956
Loss at iteration [2694]: 0.002381182481564631
Loss at iteration [2695]: 0.0023811511429366506
Loss at iteration [2696]: 0.0023811200571216616
Loss at iteration [2697]: 0.0023810882670101817
Loss at iteration [2698]: 0.002381057661630558
Loss at iteration [2699]: 0.0023810266709143207
Loss at iteration [2700]: 0.002380995719572066
Loss at iteration [2701]: 0.002380964522822458
Loss at iteration [2702]: 0.0023809333969822878
Loss at iteration [2703]: 0.0023809033464373052
Loss at iteration [2704]: 0.002380871108827821
Loss at iteration [2705]: 0.0023808408421132003
Loss at iteration [2706]: 0.002380808963924339
Loss at iteration [2707]: 0.0023807774942245312
Loss at iteration [2708]: 0.0023807466272232625
Loss at iteration [2709]: 0.002380715363314906
Loss at iteration [2710]: 0.0023806842667797603
Loss at iteration [2711]: 0.002380653546296181
Loss at iteration [2712]: 0.0023806222181498656
Loss at iteration [2713]: 0.002380591070669318
Loss at iteration [2714]: 0.0023805600922463008
Loss at iteration [2715]: 0.002380529561395084
Loss at iteration [2716]: 0.002380499456858911
Loss at iteration [2717]: 0.0023804670142989867
Loss at iteration [2718]: 0.0023804357032960314
Loss at iteration [2719]: 0.002380405271829573
Loss at iteration [2720]: 0.002380373111965571
Loss at iteration [2721]: 0.002380342662177237
Loss at iteration [2722]: 0.002380311552168069
Loss at iteration [2723]: 0.002380280074314785
Loss at iteration [2724]: 0.002380249682667735
Loss at iteration [2725]: 0.002380217868890167
Loss at iteration [2726]: 0.0023801877348394607
Loss at iteration [2727]: 0.002380155511810436
Loss at iteration [2728]: 0.0023801245903891264
Loss at iteration [2729]: 0.0023800949079495074
Loss at iteration [2730]: 0.0023800617144005497
Loss at iteration [2731]: 0.0023800328185132804
Loss at iteration [2732]: 0.0023800010260027473
Loss at iteration [2733]: 0.0023799701778752305
Loss at iteration [2734]: 0.002379938736416554
Loss at iteration [2735]: 0.0023799076558326695
Loss at iteration [2736]: 0.0023798760684155254
Loss at iteration [2737]: 0.0023798453951256967
Loss at iteration [2738]: 0.0023798140705114756
Loss at iteration [2739]: 0.0023797837145783716
Loss at iteration [2740]: 0.002379751934410598
Loss at iteration [2741]: 0.002379720494708155
Loss at iteration [2742]: 0.0023796895949704136
Loss at iteration [2743]: 0.0023796580775138
Loss at iteration [2744]: 0.0023796270338742177
Loss at iteration [2745]: 0.0023795956124315768
Loss at iteration [2746]: 0.0023795637892103207
Loss at iteration [2747]: 0.002379532110435203
Loss at iteration [2748]: 0.0023795015778792154
Loss at iteration [2749]: 0.002379469756140818
Loss at iteration [2750]: 0.0023794392879049934
Loss at iteration [2751]: 0.0023794076963047184
Loss at iteration [2752]: 0.002379376389858494
Loss at iteration [2753]: 0.002379345243965501
Loss at iteration [2754]: 0.0023793133801298058
Loss at iteration [2755]: 0.0023792829786585166
Loss at iteration [2756]: 0.0023792519774132564
Loss at iteration [2757]: 0.002379220240423531
Loss at iteration [2758]: 0.0023791891165829875
Loss at iteration [2759]: 0.0023791576828061677
Loss at iteration [2760]: 0.0023791257495726645
Loss at iteration [2761]: 0.0023790940805757813
Loss at iteration [2762]: 0.002379063522877315
Loss at iteration [2763]: 0.0023790326840676442
Loss at iteration [2764]: 0.002379001107604959
Loss at iteration [2765]: 0.0023789698472195665
Loss at iteration [2766]: 0.002378938833600146
Loss at iteration [2767]: 0.0023789069803876756
Loss at iteration [2768]: 0.00237887679369731
Loss at iteration [2769]: 0.0023788446136197355
Loss at iteration [2770]: 0.002378814247152606
Loss at iteration [2771]: 0.0023787829867025845
Loss at iteration [2772]: 0.002378751145702837
Loss at iteration [2773]: 0.002378719935098273
Loss at iteration [2774]: 0.002378688194311901
Loss at iteration [2775]: 0.0023786571688854904
Loss at iteration [2776]: 0.002378626461864089
Loss at iteration [2777]: 0.002378595170100422
Loss at iteration [2778]: 0.0023785636378626236
Loss at iteration [2779]: 0.0023785327295863102
Loss at iteration [2780]: 0.0023785012573258476
Loss at iteration [2781]: 0.0023784704653213207
Loss at iteration [2782]: 0.002378437625020393
Loss at iteration [2783]: 0.0023784063757937074
Loss at iteration [2784]: 0.0023783740277424927
Loss at iteration [2785]: 0.002378342168875236
Loss at iteration [2786]: 0.0023783106356306894
Loss at iteration [2787]: 0.0023782794083267566
Loss at iteration [2788]: 0.0023782463212640302
Loss at iteration [2789]: 0.002378215903466319
Loss at iteration [2790]: 0.002378183088146384
Loss at iteration [2791]: 0.0023781514452920357
Loss at iteration [2792]: 0.0023781195495798974
Loss at iteration [2793]: 0.00237808766153283
Loss at iteration [2794]: 0.0023780562258751475
Loss at iteration [2795]: 0.002378024248169541
Loss at iteration [2796]: 0.002377993159091009
Loss at iteration [2797]: 0.0023779614382197574
Loss at iteration [2798]: 0.0023779286019386617
Loss at iteration [2799]: 0.002377897415346306
Loss at iteration [2800]: 0.002377864613502481
Loss at iteration [2801]: 0.002377833441591743
Loss at iteration [2802]: 0.0023777963873001236
Loss at iteration [2803]: 0.0023777593777921506
Loss at iteration [2804]: 0.0023777191994681355
Loss at iteration [2805]: 0.0023776807330707066
Loss at iteration [2806]: 0.002377641164480942
Loss at iteration [2807]: 0.002377604688443293
Loss at iteration [2808]: 0.0023775694728249285
Loss at iteration [2809]: 0.0023775337444370383
Loss at iteration [2810]: 0.0023775019674776516
Loss at iteration [2811]: 0.0023774689378614
Loss at iteration [2812]: 0.002377437351656483
Loss at iteration [2813]: 0.0023774054970570314
Loss at iteration [2814]: 0.0023773737383499267
Loss at iteration [2815]: 0.0023773425212123287
Loss at iteration [2816]: 0.0023773111344925343
Loss at iteration [2817]: 0.0023772802417734826
Loss at iteration [2818]: 0.00237724871150311
Loss at iteration [2819]: 0.0023772164611641534
Loss at iteration [2820]: 0.002377186697898518
Loss at iteration [2821]: 0.0023771538119879863
Loss at iteration [2822]: 0.002377123552661134
Loss at iteration [2823]: 0.002377092399152491
Loss at iteration [2824]: 0.002377060624954195
Loss at iteration [2825]: 0.002377030420157942
Loss at iteration [2826]: 0.0023769989822816535
Loss at iteration [2827]: 0.002376966933715319
Loss at iteration [2828]: 0.0023769360113800723
Loss at iteration [2829]: 0.002376904789484384
Loss at iteration [2830]: 0.0023768727262086418
Loss at iteration [2831]: 0.002376841056519619
Loss at iteration [2832]: 0.00237680979194859
Loss at iteration [2833]: 0.0023767777331810515
Loss at iteration [2834]: 0.0023767452221930456
Loss at iteration [2835]: 0.0023767142457822407
Loss at iteration [2836]: 0.002376681343535907
Loss at iteration [2837]: 0.0023766491135461445
Loss at iteration [2838]: 0.0023766182419847335
Loss at iteration [2839]: 0.002376586204757874
Loss at iteration [2840]: 0.002376554395819094
Loss at iteration [2841]: 0.0023765243736906267
Loss at iteration [2842]: 0.0023764916773793303
Loss at iteration [2843]: 0.0023764606557277034
Loss at iteration [2844]: 0.0023764301081349846
Loss at iteration [2845]: 0.002376398033827724
Loss at iteration [2846]: 0.00237636734504186
Loss at iteration [2847]: 0.0023763356596152325
Loss at iteration [2848]: 0.002376304450104662
Loss at iteration [2849]: 0.0023762730731016197
Loss at iteration [2850]: 0.0023762431340063938
Loss at iteration [2851]: 0.002376211041925737
Loss at iteration [2852]: 0.0023761798253892743
Loss at iteration [2853]: 0.002376147641529849
Loss at iteration [2854]: 0.002376116288690858
Loss at iteration [2855]: 0.002376084899834219
Loss at iteration [2856]: 0.002376052609098576
Loss at iteration [2857]: 0.002376021464153544
Loss at iteration [2858]: 0.0023759892910090053
Loss at iteration [2859]: 0.002375958457420325
Loss at iteration [2860]: 0.0023759262827662865
Loss at iteration [2861]: 0.0023758956740387136
Loss at iteration [2862]: 0.0023758641928352075
Loss at iteration [2863]: 0.002375831447346069
Loss at iteration [2864]: 0.002375799607535243
Loss at iteration [2865]: 0.002375769006211202
Loss at iteration [2866]: 0.0023757362891206253
Loss at iteration [2867]: 0.0023757060084004735
Loss at iteration [2868]: 0.002375673193419963
Loss at iteration [2869]: 0.002375642850797478
Loss at iteration [2870]: 0.002375611265743578
Loss at iteration [2871]: 0.0023755786995077496
Loss at iteration [2872]: 0.002375547434254433
Loss at iteration [2873]: 0.0023755162701502384
Loss at iteration [2874]: 0.002375485196923103
Loss at iteration [2875]: 0.002375454095521217
Loss at iteration [2876]: 0.00237542324356551
Loss at iteration [2877]: 0.0023753909715914633
Loss at iteration [2878]: 0.0023753607953602247
Loss at iteration [2879]: 0.002375329335675146
Loss at iteration [2880]: 0.002375298387836907
Loss at iteration [2881]: 0.002375266772115349
Loss at iteration [2882]: 0.0023752353068388415
Loss at iteration [2883]: 0.00237520496088312
Loss at iteration [2884]: 0.002375173414444472
Loss at iteration [2885]: 0.0023751422716763405
Loss at iteration [2886]: 0.0023751102153962357
Loss at iteration [2887]: 0.002375079847318455
Loss at iteration [2888]: 0.0023750498848203877
Loss at iteration [2889]: 0.0023750173994987324
Loss at iteration [2890]: 0.0023749868483268436
Loss at iteration [2891]: 0.0023749563535801848
Loss at iteration [2892]: 0.0023749243869117483
Loss at iteration [2893]: 0.00237489479698705
Loss at iteration [2894]: 0.002374862007101602
Loss at iteration [2895]: 0.0023748329016200155
Loss at iteration [2896]: 0.00237480124328567
Loss at iteration [2897]: 0.0023747687669195662
Loss at iteration [2898]: 0.0023747375294314228
Loss at iteration [2899]: 0.0023747075304623613
Loss at iteration [2900]: 0.002374675575685864
Loss at iteration [2901]: 0.0023746444825622315
Loss at iteration [2902]: 0.002374613491086183
Loss at iteration [2903]: 0.002374582347718423
Loss at iteration [2904]: 0.002374550495464252
Loss at iteration [2905]: 0.002374519787404443
Loss at iteration [2906]: 0.002374488493455659
Loss at iteration [2907]: 0.0023744572837550407
Loss at iteration [2908]: 0.002374426983104303
Loss at iteration [2909]: 0.002374395663112597
Loss at iteration [2910]: 0.002374364087876442
Loss at iteration [2911]: 0.0023743337951150022
Loss at iteration [2912]: 0.0023743020743198407
Loss at iteration [2913]: 0.002374271824275505
Loss at iteration [2914]: 0.0023742405881113566
Loss at iteration [2915]: 0.0023742096355212007
Loss at iteration [2916]: 0.0023741781444748837
Loss at iteration [2917]: 0.002374148087801132
Loss at iteration [2918]: 0.0023741168101856862
Loss at iteration [2919]: 0.0023740865191612314
Loss at iteration [2920]: 0.00237405561104171
Loss at iteration [2921]: 0.0023740237600769006
Loss at iteration [2922]: 0.002373993503609218
Loss at iteration [2923]: 0.0023739625766489494
Loss at iteration [2924]: 0.002373931221253108
Loss at iteration [2925]: 0.002373900530865357
Loss at iteration [2926]: 0.0023738692319612833
Loss at iteration [2927]: 0.002373839078339405
Loss at iteration [2928]: 0.0023738077755704108
Loss at iteration [2929]: 0.002373777149644122
Loss at iteration [2930]: 0.0023737465258078625
Loss at iteration [2931]: 0.0023737161124235406
Loss at iteration [2932]: 0.0023736852440450506
Loss at iteration [2933]: 0.0023736544277329114
Loss at iteration [2934]: 0.0023736232835551464
Loss at iteration [2935]: 0.0023735935467705947
Loss at iteration [2936]: 0.0023735624987424524
Loss at iteration [2937]: 0.002373531256933351
Loss at iteration [2938]: 0.0023735000405479888
Loss at iteration [2939]: 0.0023734702034687864
Loss at iteration [2940]: 0.0023734394893596355
Loss at iteration [2941]: 0.0023734084107495746
Loss at iteration [2942]: 0.002373377873293242
Loss at iteration [2943]: 0.0023733462325401544
Loss at iteration [2944]: 0.0023733161062115898
Loss at iteration [2945]: 0.0023732860411600464
Loss at iteration [2946]: 0.0023732559731383124
Loss at iteration [2947]: 0.002373224062903787
Loss at iteration [2948]: 0.002373194001302713
Loss at iteration [2949]: 0.0023731620675733226
Loss at iteration [2950]: 0.0023731324978567554
Loss at iteration [2951]: 0.0023731010135007663
Loss at iteration [2952]: 0.002373070141869053
Loss at iteration [2953]: 0.0023730396131843674
Loss at iteration [2954]: 0.0023730089077380672
Loss at iteration [2955]: 0.0023729785799552305
Loss at iteration [2956]: 0.002372948395163541
Loss at iteration [2957]: 0.00237291729070267
Loss at iteration [2958]: 0.002372887380863107
Loss at iteration [2959]: 0.002372856138014832
Loss at iteration [2960]: 0.002372825985363603
Loss at iteration [2961]: 0.002372795371673824
Loss at iteration [2962]: 0.002372765346578344
Loss at iteration [2963]: 0.0023727347571633143
Loss at iteration [2964]: 0.0023727040485543036
Loss at iteration [2965]: 0.002372672755543432
Loss at iteration [2966]: 0.002372643458080037
Loss at iteration [2967]: 0.0023726116318059523
Loss at iteration [2968]: 0.0023725827388984006
Loss at iteration [2969]: 0.002372552037168934
Loss at iteration [2970]: 0.002372522079774892
Loss at iteration [2971]: 0.002372491989583221
Loss at iteration [2972]: 0.0023724614411848454
Loss at iteration [2973]: 0.002372431615563641
Loss at iteration [2974]: 0.0023724027716159174
Loss at iteration [2975]: 0.0023723722209537976
Loss at iteration [2976]: 0.0023723412917307637
Loss at iteration [2977]: 0.00237231162007896
Loss at iteration [2978]: 0.002372280645092235
Loss at iteration [2979]: 0.0023722516074049594
Loss at iteration [2980]: 0.002372220536561258
Loss at iteration [2981]: 0.002372190940573519
Loss at iteration [2982]: 0.002372160537847468
Loss at iteration [2983]: 0.0023721302782907135
Loss at iteration [2984]: 0.0023721001199823303
Loss at iteration [2985]: 0.0023720692419424596
Loss at iteration [2986]: 0.0023720402649759303
Loss at iteration [2987]: 0.002372009653205856
Loss at iteration [2988]: 0.0023719791359990317
Loss at iteration [2989]: 0.002371949262747355
Loss at iteration [2990]: 0.002371919541573245
Loss at iteration [2991]: 0.0023718892565382354
Loss at iteration [2992]: 0.0023718593778034387
Loss at iteration [2993]: 0.002371830034686255
Loss at iteration [2994]: 0.002371798740449037
Loss at iteration [2995]: 0.002371768797667273
Loss at iteration [2996]: 0.0023717385681662996
Loss at iteration [2997]: 0.0023717091693754655
Loss at iteration [2998]: 0.0023716783953230546
Loss at iteration [2999]: 0.002371648125495592
Loss at iteration [3000]: 0.0023716183260210294
