Model name                            : MLP
The number of input features          : 2
The number of output features         : 1
Optimizer name                        : NonlinearCG
Learning rate                         : 0.1
Beta type                             : FR_PR
Total number of function evaluations  : 3040
Total number of iterations            : 1739
Max number of iterations              : 3000
Number of samples in training data    : 858
Number of samples in tests data       : 368
Total training time                   : 16.788183212280273
Total number of parameters            : 101001
Percentage of parameters < 1e-9       : 49.82821952257899%
Percentage of parameters < 1e-7       : 49.82821952257899%
Percentage of parameters < 1e-6       : 49.82821952257899%

=============================================
=============================================
===================Losses====================
=============================================
=============================================


Loss at iteration [1]: 0.003244404369026523
Loss at iteration [2]: 0.003142414079013706
Loss at iteration [3]: 0.0029152258836816474
Loss at iteration [4]: 0.00286023461285954
Loss at iteration [5]: 0.0028478355691598355
Loss at iteration [6]: 0.002699343623573083
Loss at iteration [7]: 0.002685757733444811
Loss at iteration [8]: 0.0026764393591459617
Loss at iteration [9]: 0.00264469377016916
Loss at iteration [10]: 0.0025996950562758026
Loss at iteration [11]: 0.002589996799006287
Loss at iteration [12]: 0.0025483744305068536
Loss at iteration [13]: 0.0025456238942920925
Loss at iteration [14]: 0.0025429503530618376
Loss at iteration [15]: 0.0025368633037409416
Loss at iteration [16]: 0.002530898596093399
Loss at iteration [17]: 0.002530898596093399
Loss at iteration [18]: 0.002525227793140484
Loss at iteration [19]: 0.002524311327246214
Loss at iteration [20]: 0.0025235252898866134
Loss at iteration [21]: 0.0025230955422958184
Loss at iteration [22]: 0.0025149039967100706
Loss at iteration [23]: 0.00250393059218248
Loss at iteration [24]: 0.0025026614684569236
Loss at iteration [25]: 0.002501828218727691
Loss at iteration [26]: 0.0024988136547219163
Loss at iteration [27]: 0.002495899166012958
Loss at iteration [28]: 0.0024924409633611537
Loss at iteration [29]: 0.0024922365071654434
Loss at iteration [30]: 0.0024900620495949335
Loss at iteration [31]: 0.0024900620495949335
Loss at iteration [32]: 0.00248967517032925
Loss at iteration [33]: 0.002489503659356541
Loss at iteration [34]: 0.0024884483339945316
Loss at iteration [35]: 0.002488182520991617
Loss at iteration [36]: 0.002487807595214953
Loss at iteration [37]: 0.0024875944564157794
Loss at iteration [38]: 0.0024872019594306826
Loss at iteration [39]: 0.002486317291754217
Loss at iteration [40]: 0.002486052631053484
Loss at iteration [41]: 0.002484994798158004
Loss at iteration [42]: 0.002484172138551087
Loss at iteration [43]: 0.0024839682209819493
Loss at iteration [44]: 0.002482357834128371
Loss at iteration [45]: 0.002477127900744678
Loss at iteration [46]: 0.00247495179917791
Loss at iteration [47]: 0.00247495179917791
Loss at iteration [48]: 0.0024744594981305186
Loss at iteration [49]: 0.002473246622918404
Loss at iteration [50]: 0.0024711413138081497
Loss at iteration [51]: 0.00247082835522074
Loss at iteration [52]: 0.002470228763065226
Loss at iteration [53]: 0.0024693516966559927
Loss at iteration [54]: 0.0024691927937337543
Loss at iteration [55]: 0.002468430240593084
Loss at iteration [56]: 0.002467501525573399
Loss at iteration [57]: 0.0024668776864490123
Loss at iteration [58]: 0.002466678022345977
Loss at iteration [59]: 0.0024653827957851937
Loss at iteration [60]: 0.0024653827957851937
Loss at iteration [61]: 0.0024638624002978966
Loss at iteration [62]: 0.002463525347764722
Loss at iteration [63]: 0.0024628509311826062
Loss at iteration [64]: 0.0024625336794857457
Loss at iteration [65]: 0.002462130614555376
Loss at iteration [66]: 0.002461803664421221
Loss at iteration [67]: 0.002461553070102764
Loss at iteration [68]: 0.002461008852024937
Loss at iteration [69]: 0.002460073237232669
Loss at iteration [70]: 0.0024590128615251763
Loss at iteration [71]: 0.0024585861596201426
Loss at iteration [72]: 0.0024584251246605815
Loss at iteration [73]: 0.002457846487886703
Loss at iteration [74]: 0.0024574683064782503
Loss at iteration [75]: 0.0024572774210499977
Loss at iteration [76]: 0.0024562879458169045
Loss at iteration [77]: 0.0024562879458169045
Loss at iteration [78]: 0.002456187039652112
Loss at iteration [79]: 0.0024561194548900446
Loss at iteration [80]: 0.0024553758380246767
Loss at iteration [81]: 0.002454436194244739
Loss at iteration [82]: 0.0024539599203441576
Loss at iteration [83]: 0.0024538129423369473
Loss at iteration [84]: 0.0024534321310800892
Loss at iteration [85]: 0.0024525721136236214
Loss at iteration [86]: 0.00245089480903876
Loss at iteration [87]: 0.0024503471776421036
Loss at iteration [88]: 0.0024502523367490093
Loss at iteration [89]: 0.0024501521442393346
Loss at iteration [90]: 0.002449933745129432
Loss at iteration [91]: 0.002449933745129432
Loss at iteration [92]: 0.0024498046640344085
Loss at iteration [93]: 0.0024497626965963855
Loss at iteration [94]: 0.002449307909733832
Loss at iteration [95]: 0.0024490211260187193
Loss at iteration [96]: 0.002448785431132789
Loss at iteration [97]: 0.0024485903076521547
Loss at iteration [98]: 0.002448373953129529
Loss at iteration [99]: 0.002447940074837457
Loss at iteration [100]: 0.002447818274043992
Loss at iteration [101]: 0.002447693586948126
Loss at iteration [102]: 0.002446707638005622
Loss at iteration [103]: 0.002445969507144424
Loss at iteration [104]: 0.002445568431544046
Loss at iteration [105]: 0.0024454476057721875
Loss at iteration [106]: 0.0024449756742132957
Loss at iteration [107]: 0.0024449756742132957
Loss at iteration [108]: 0.0024447856018337626
Loss at iteration [109]: 0.002444723904197612
Loss at iteration [110]: 0.002444387731163395
Loss at iteration [111]: 0.002444051979486614
Loss at iteration [112]: 0.0024439553332564062
Loss at iteration [113]: 0.0024437662242471183
Loss at iteration [114]: 0.002443704179865932
Loss at iteration [115]: 0.0024436453456680735
Loss at iteration [116]: 0.002443492975328727
Loss at iteration [117]: 0.002442934409133101
Loss at iteration [118]: 0.0024424233908770282
Loss at iteration [119]: 0.002441941883771541
Loss at iteration [120]: 0.0024413278954277325
Loss at iteration [121]: 0.002441168557119714
Loss at iteration [122]: 0.002441168557119714
Loss at iteration [123]: 0.0024410063656928865
Loss at iteration [124]: 0.002440936538618817
Loss at iteration [125]: 0.0024407085182119826
Loss at iteration [126]: 0.002440549979161718
Loss at iteration [127]: 0.0024403732029732515
Loss at iteration [128]: 0.0024403051267580904
Loss at iteration [129]: 0.002440084655576463
Loss at iteration [130]: 0.0024399176470776287
Loss at iteration [131]: 0.002439873887849748
Loss at iteration [132]: 0.002439824184684238
Loss at iteration [133]: 0.002439779725266146
Loss at iteration [134]: 0.0024397238662365256
Loss at iteration [135]: 0.002439634018325816
Loss at iteration [136]: 0.0024393883451682644
Loss at iteration [137]: 0.002439292008856939
Loss at iteration [138]: 0.002439292008856939
Loss at iteration [139]: 0.00243924936194726
Loss at iteration [140]: 0.002439149607060763
Loss at iteration [141]: 0.002439020497148187
Loss at iteration [142]: 0.002438932481795701
Loss at iteration [143]: 0.0024385481430423
Loss at iteration [144]: 0.0024383236509536404
Loss at iteration [145]: 0.0024371005893813603
Loss at iteration [146]: 0.002436815303978731
Loss at iteration [147]: 0.0024367182786613206
Loss at iteration [148]: 0.0024366636315324374
Loss at iteration [149]: 0.0024363742567461858
Loss at iteration [150]: 0.0024362210287745744
Loss at iteration [151]: 0.0024359706564579353
Loss at iteration [152]: 0.002435714367701318
Loss at iteration [153]: 0.0024355329135938232
Loss at iteration [154]: 0.0024355329135938232
Loss at iteration [155]: 0.0024354465225292616
Loss at iteration [156]: 0.0024354095918273045
Loss at iteration [157]: 0.002435178256073767
Loss at iteration [158]: 0.002435082492142607
Loss at iteration [159]: 0.0024350432604261997
Loss at iteration [160]: 0.002434346324411719
Loss at iteration [161]: 0.002434109225727624
Loss at iteration [162]: 0.00243395777064877
Loss at iteration [163]: 0.0024337682565571048
Loss at iteration [164]: 0.0024336640256493033
Loss at iteration [165]: 0.002433471747932452
Loss at iteration [166]: 0.0024331833118760703
Loss at iteration [167]: 0.0024329715407997677
Loss at iteration [168]: 0.0024325377052201833
Loss at iteration [169]: 0.00243231764606017
Loss at iteration [170]: 0.00243231764606017
Loss at iteration [171]: 0.002432261904827179
Loss at iteration [172]: 0.002432071396470954
Loss at iteration [173]: 0.0024319040051814993
Loss at iteration [174]: 0.0024318855357148062
Loss at iteration [175]: 0.00243186563634815
Loss at iteration [176]: 0.0024317805406534293
Loss at iteration [177]: 0.002431746080172815
Loss at iteration [178]: 0.0024316981901046563
Loss at iteration [179]: 0.0024316872973979818
Loss at iteration [180]: 0.002431562049374811
Loss at iteration [181]: 0.0024314874566085465
Loss at iteration [182]: 0.002431090769197224
Loss at iteration [183]: 0.0024310035040508208
Loss at iteration [184]: 0.002430952747182753
Loss at iteration [185]: 0.0024307909958544566
Loss at iteration [186]: 0.0024307909958544566
Loss at iteration [187]: 0.002430752101142422
Loss at iteration [188]: 0.0024307254796901026
Loss at iteration [189]: 0.002430677786484725
Loss at iteration [190]: 0.0024306242197468745
Loss at iteration [191]: 0.002430504784584779
Loss at iteration [192]: 0.0024304457693495964
Loss at iteration [193]: 0.00243038748932339
Loss at iteration [194]: 0.002430237649094228
Loss at iteration [195]: 0.0024295046564025463
Loss at iteration [196]: 0.0024292653737570673
Loss at iteration [197]: 0.0024291301080296606
Loss at iteration [198]: 0.002427834508682787
Loss at iteration [199]: 0.002427782678652658
Loss at iteration [200]: 0.0024271750341925127
Loss at iteration [201]: 0.0024271750341925127
Loss at iteration [202]: 0.0024271284903232076
Loss at iteration [203]: 0.0024268535917492257
Loss at iteration [204]: 0.0024267695669096603
Loss at iteration [205]: 0.0024267301051883483
Loss at iteration [206]: 0.0024266401282959133
Loss at iteration [207]: 0.0024264192739227226
Loss at iteration [208]: 0.0024263750359051206
Loss at iteration [209]: 0.0024259180958728804
Loss at iteration [210]: 0.0024254639840465323
Loss at iteration [211]: 0.002425424931847505
Loss at iteration [212]: 0.002425277228273155
Loss at iteration [213]: 0.002425141296322474
Loss at iteration [214]: 0.002425112069424057
Loss at iteration [215]: 0.002425112069424057
Loss at iteration [216]: 0.002425085573409485
Loss at iteration [217]: 0.00242482527260086
Loss at iteration [218]: 0.0024247123964410873
Loss at iteration [219]: 0.0024246886909475326
Loss at iteration [220]: 0.002424563482271312
Loss at iteration [221]: 0.0024244907960106104
Loss at iteration [222]: 0.002424456127482176
Loss at iteration [223]: 0.0024244327279268714
Loss at iteration [224]: 0.0024243255722321516
Loss at iteration [225]: 0.0024241596128669832
Loss at iteration [226]: 0.0024240693665198406
Loss at iteration [227]: 0.002423835318518306
Loss at iteration [228]: 0.0024236855436328007
Loss at iteration [229]: 0.0024236855436328007
Loss at iteration [230]: 0.0024236367157094655
Loss at iteration [231]: 0.0024235805884433993
Loss at iteration [232]: 0.002423421217504536
Loss at iteration [233]: 0.0024233919326651933
Loss at iteration [234]: 0.0024233295788976647
Loss at iteration [235]: 0.0024233099150436834
Loss at iteration [236]: 0.0024231182843566456
Loss at iteration [237]: 0.0024230211212466716
Loss at iteration [238]: 0.002422974214435182
Loss at iteration [239]: 0.0024226597232636805
Loss at iteration [240]: 0.0024224824662845723
Loss at iteration [241]: 0.002422448899655619
Loss at iteration [242]: 0.0024211847694274994
Loss at iteration [243]: 0.00242048877100182
Loss at iteration [244]: 0.00242048877100182
Loss at iteration [245]: 0.00242032338125717
Loss at iteration [246]: 0.00242005664720371
Loss at iteration [247]: 0.0024198659193746266
Loss at iteration [248]: 0.0024197885455414076
Loss at iteration [249]: 0.0024197163052912508
Loss at iteration [250]: 0.002419601101656166
Loss at iteration [251]: 0.002419531009743772
Loss at iteration [252]: 0.0024192455535476205
Loss at iteration [253]: 0.002419171519384535
Loss at iteration [254]: 0.002418973387182217
Loss at iteration [255]: 0.002418644497973666
Loss at iteration [256]: 0.002418624589595041
Loss at iteration [257]: 0.002418292911506679
Loss at iteration [258]: 0.002418292911506679
Loss at iteration [259]: 0.002418170547424867
Loss at iteration [260]: 0.00241813009221485
Loss at iteration [261]: 0.0024177695421351347
Loss at iteration [262]: 0.002417734061761045
Loss at iteration [263]: 0.0024176301729639713
Loss at iteration [264]: 0.002417471696262016
Loss at iteration [265]: 0.0024173677475326704
Loss at iteration [266]: 0.0024172772446655975
Loss at iteration [267]: 0.0024172327530187078
Loss at iteration [268]: 0.002417189647713278
Loss at iteration [269]: 0.002417160661604135
Loss at iteration [270]: 0.0024171082304072964
Loss at iteration [271]: 0.002417050805356349
Loss at iteration [272]: 0.0024170206620789344
Loss at iteration [273]: 0.002416960213367498
Loss at iteration [274]: 0.002416960213367498
Loss at iteration [275]: 0.002416926185081527
Loss at iteration [276]: 0.0024168347172993524
Loss at iteration [277]: 0.002416807959096928
Loss at iteration [278]: 0.002416772528734244
Loss at iteration [279]: 0.002416271525326232
Loss at iteration [280]: 0.0024159838208031035
Loss at iteration [281]: 0.002415803841992091
Loss at iteration [282]: 0.0024151878844543523
Loss at iteration [283]: 0.0024150626722466467
Loss at iteration [284]: 0.0024149356911345506
Loss at iteration [285]: 0.0024147543760142777
Loss at iteration [286]: 0.0024145593254264073
Loss at iteration [287]: 0.0024134534273664364
Loss at iteration [288]: 0.0024134534273664364
Loss at iteration [289]: 0.002412963077618272
Loss at iteration [290]: 0.002412875525266368
Loss at iteration [291]: 0.002412635711555889
Loss at iteration [292]: 0.0024125799698121236
Loss at iteration [293]: 0.002412531342579958
Loss at iteration [294]: 0.00241235359817403
Loss at iteration [295]: 0.002412281039910139
Loss at iteration [296]: 0.002412172763316206
Loss at iteration [297]: 0.0024121110399128467
Loss at iteration [298]: 0.002412006614898683
Loss at iteration [299]: 0.0024117855709517135
Loss at iteration [300]: 0.0024113735440190226
Loss at iteration [301]: 0.002411196966231703
Loss at iteration [302]: 0.0024109843307550966
Loss at iteration [303]: 0.002410782950586731
Loss at iteration [304]: 0.002410782950586731
Loss at iteration [305]: 0.0024106983732131884
Loss at iteration [306]: 0.0024106685676676463
Loss at iteration [307]: 0.0024105185285766295
Loss at iteration [308]: 0.0024103761504873818
Loss at iteration [309]: 0.0024103353475662874
Loss at iteration [310]: 0.0024101017754279697
Loss at iteration [311]: 0.002410045769896277
Loss at iteration [312]: 0.0024100025244225103
Loss at iteration [313]: 0.002409806439986221
Loss at iteration [314]: 0.0024093704173787
Loss at iteration [315]: 0.002409143167437302
Loss at iteration [316]: 0.002409085974916863
Loss at iteration [317]: 0.002408969558493392
Loss at iteration [318]: 0.002408829515243551
Loss at iteration [319]: 0.0024087782365568608
Loss at iteration [320]: 0.002408733648881826
Loss at iteration [321]: 0.002408733648881826
Loss at iteration [322]: 0.002408718432698623
Loss at iteration [323]: 0.002408571134250012
Loss at iteration [324]: 0.0024085385327713123
Loss at iteration [325]: 0.002408426019694719
Loss at iteration [326]: 0.002408144692661258
Loss at iteration [327]: 0.002408092007366197
Loss at iteration [328]: 0.0024077867253714104
Loss at iteration [329]: 0.002407686204077329
Loss at iteration [330]: 0.0024076319391583764
Loss at iteration [331]: 0.002406551536884127
Loss at iteration [332]: 0.0024060122930158047
Loss at iteration [333]: 0.00240574975145865
Loss at iteration [334]: 0.0024052734643548734
Loss at iteration [335]: 0.0024047805228046815
Loss at iteration [336]: 0.002404686397486897
Loss at iteration [337]: 0.002404314672780598
Loss at iteration [338]: 0.002404314672780598
Loss at iteration [339]: 0.002404085031543066
Loss at iteration [340]: 0.0024039033360096014
Loss at iteration [341]: 0.0024034742113935455
Loss at iteration [342]: 0.002403268415936508
Loss at iteration [343]: 0.002402880219976871
Loss at iteration [344]: 0.002402477135478149
Loss at iteration [345]: 0.002402420160835952
Loss at iteration [346]: 0.0024021957090848093
Loss at iteration [347]: 0.002401776547252227
Loss at iteration [348]: 0.002401611343880479
Loss at iteration [349]: 0.0024014859857081
Loss at iteration [350]: 0.0024013443201947246
Loss at iteration [351]: 0.002401205900672215
Loss at iteration [352]: 0.0024011415009330024
Loss at iteration [353]: 0.002401084645320878
Loss at iteration [354]: 0.002401084645320878
Loss at iteration [355]: 0.0024009590585589557
Loss at iteration [356]: 0.0024009134978684346
Loss at iteration [357]: 0.002400861340007272
Loss at iteration [358]: 0.002400841863025838
Loss at iteration [359]: 0.002400761943007261
Loss at iteration [360]: 0.0024007474581392387
Loss at iteration [361]: 0.0024007151840718093
Loss at iteration [362]: 0.0024004297786227335
Loss at iteration [363]: 0.002400187989288891
Loss at iteration [364]: 0.0024000873308045794
Loss at iteration [365]: 0.002399786934164787
Loss at iteration [366]: 0.0023994331907187154
Loss at iteration [367]: 0.002399316566810363
Loss at iteration [368]: 0.002399138841831423
Loss at iteration [369]: 0.0023990465892390657
Loss at iteration [370]: 0.002398611594927344
Loss at iteration [371]: 0.002398611594927344
Loss at iteration [372]: 0.0023984079474942558
Loss at iteration [373]: 0.002398333684129928
Loss at iteration [374]: 0.0023980626441055864
Loss at iteration [375]: 0.002398029472752242
Loss at iteration [376]: 0.0023979410536809575
Loss at iteration [377]: 0.002397789167844001
Loss at iteration [378]: 0.002397716643755751
Loss at iteration [379]: 0.0023974752398235374
Loss at iteration [380]: 0.00239741228650536
Loss at iteration [381]: 0.0023973529138808626
Loss at iteration [382]: 0.0023972172946229754
Loss at iteration [383]: 0.002397024130495114
Loss at iteration [384]: 0.0023969960746673524
Loss at iteration [385]: 0.0023968230740604966
Loss at iteration [386]: 0.0023968230740604966
Loss at iteration [387]: 0.002396777234576945
Loss at iteration [388]: 0.002396756000899283
Loss at iteration [389]: 0.0023966201434143884
Loss at iteration [390]: 0.0023965581765988085
Loss at iteration [391]: 0.002396354575622931
Loss at iteration [392]: 0.0023963229885060272
Loss at iteration [393]: 0.002396168687613885
Loss at iteration [394]: 0.0023959440900745152
Loss at iteration [395]: 0.002395856073657266
Loss at iteration [396]: 0.0023957404127006397
Loss at iteration [397]: 0.002395661484479091
Loss at iteration [398]: 0.0023956316614613853
Loss at iteration [399]: 0.002395547275490654
Loss at iteration [400]: 0.002395417839312224
Loss at iteration [401]: 0.0023953318920470644
Loss at iteration [402]: 0.0023953110199330446
Loss at iteration [403]: 0.0023953110199330446
Loss at iteration [404]: 0.0023952864009529045
Loss at iteration [405]: 0.0023952671735651353
Loss at iteration [406]: 0.002395228919937362
Loss at iteration [407]: 0.002395205413404083
Loss at iteration [408]: 0.002395151233051152
Loss at iteration [409]: 0.002395132320790408
Loss at iteration [410]: 0.002395066118309051
Loss at iteration [411]: 0.0023950169458646616
Loss at iteration [412]: 0.002395000885736913
Loss at iteration [413]: 0.0023949587712490438
Loss at iteration [414]: 0.002394720964267011
Loss at iteration [415]: 0.0023946579071097178
Loss at iteration [416]: 0.0023944658834316227
Loss at iteration [417]: 0.002394104033300783
Loss at iteration [418]: 0.0023939825133860028
Loss at iteration [419]: 0.0023939825133860028
Loss at iteration [420]: 0.0023938791168071744
Loss at iteration [421]: 0.002393848096566842
Loss at iteration [422]: 0.0023934771485523286
Loss at iteration [423]: 0.002393384608576428
Loss at iteration [424]: 0.0023933073892534506
Loss at iteration [425]: 0.002393178423601158
Loss at iteration [426]: 0.002393086860345182
Loss at iteration [427]: 0.0023930266694482598
Loss at iteration [428]: 0.0023929381958352836
Loss at iteration [429]: 0.0023928331674740073
Loss at iteration [430]: 0.002392781796832705
Loss at iteration [431]: 0.0023925885769540845
Loss at iteration [432]: 0.00239241486635069
Loss at iteration [433]: 0.0023923025008920915
Loss at iteration [434]: 0.0023922565505041095
Loss at iteration [435]: 0.002392113179043128
Loss at iteration [436]: 0.002392113179043128
Loss at iteration [437]: 0.0023920093798926053
Loss at iteration [438]: 0.00239198052045537
Loss at iteration [439]: 0.002391900586855491
Loss at iteration [440]: 0.002391886064592062
Loss at iteration [441]: 0.0023918111582480425
Loss at iteration [442]: 0.002391712361239758
Loss at iteration [443]: 0.0023916272276034837
Loss at iteration [444]: 0.0023915324811382764
Loss at iteration [445]: 0.002391481710480568
Loss at iteration [446]: 0.0023912599830473082
Loss at iteration [447]: 0.002391094066729568
Loss at iteration [448]: 0.002390996029221935
Loss at iteration [449]: 0.0023908982707522065
Loss at iteration [450]: 0.0023908982707522065
Loss at iteration [451]: 0.002390871299647614
Loss at iteration [452]: 0.0023907963453508626
Loss at iteration [453]: 0.0023907066086271845
Loss at iteration [454]: 0.0023906851010755
Loss at iteration [455]: 0.0023905888615921777
Loss at iteration [456]: 0.002390498598280263
Loss at iteration [457]: 0.0023904589988036746
Loss at iteration [458]: 0.002390406740124276
Loss at iteration [459]: 0.0023899472303886057
Loss at iteration [460]: 0.0023896823636321515
Loss at iteration [461]: 0.002389597628581437
Loss at iteration [462]: 0.0023880373314366125
Loss at iteration [463]: 0.0023858675791245247
Loss at iteration [464]: 0.0023851212545754276
Loss at iteration [465]: 0.002384578443364359
Loss at iteration [466]: 0.0023830086467951407
Loss at iteration [467]: 0.0023830086467951407
Loss at iteration [468]: 0.002382276220781197
Loss at iteration [469]: 0.0023821530589316605
Loss at iteration [470]: 0.002381920890380925
Loss at iteration [471]: 0.002381499964824801
Loss at iteration [472]: 0.002380745265534659
Loss at iteration [473]: 0.002380208609052471
Loss at iteration [474]: 0.0023799250404275027
Loss at iteration [475]: 0.0023794768910811496
Loss at iteration [476]: 0.0023793651674767716
Loss at iteration [477]: 0.0023790386289991874
Loss at iteration [478]: 0.0023777425228877235
Loss at iteration [479]: 0.0023776747013101156
Loss at iteration [480]: 0.0023775122582526368
Loss at iteration [481]: 0.0023773566043485735
Loss at iteration [482]: 0.0023773566043485735
Loss at iteration [483]: 0.0023773012205843534
Loss at iteration [484]: 0.0023772533918769243
Loss at iteration [485]: 0.0023768768001689007
Loss at iteration [486]: 0.0023767650592469275
Loss at iteration [487]: 0.002376425584055435
Loss at iteration [488]: 0.002376392524670746
Loss at iteration [489]: 0.002376335240410266
Loss at iteration [490]: 0.0023762065811078342
Loss at iteration [491]: 0.002376158691576819
Loss at iteration [492]: 0.002376123829641074
Loss at iteration [493]: 0.002376000540215197
Loss at iteration [494]: 0.002375970666598625
Loss at iteration [495]: 0.002375915750279187
Loss at iteration [496]: 0.0023757833424545294
Loss at iteration [497]: 0.0023757833424545294
Loss at iteration [498]: 0.0023757668097518754
Loss at iteration [499]: 0.0023756687091957837
Loss at iteration [500]: 0.0023756273345033893
Loss at iteration [501]: 0.002375594727571827
Loss at iteration [502]: 0.0023754121146278683
Loss at iteration [503]: 0.002375278340285446
Loss at iteration [504]: 0.002374981459718404
Loss at iteration [505]: 0.0023748197396166867
Loss at iteration [506]: 0.0023746804703477604
Loss at iteration [507]: 0.002374466643216771
Loss at iteration [508]: 0.002373992613898549
Loss at iteration [509]: 0.0023739467684275907
Loss at iteration [510]: 0.002373531006808359
Loss at iteration [511]: 0.002373275056011406
Loss at iteration [512]: 0.002373275056011406
Loss at iteration [513]: 0.0023732444323402847
Loss at iteration [514]: 0.002373167161798909
Loss at iteration [515]: 0.0023730234427805875
Loss at iteration [516]: 0.0023730046858665625
Loss at iteration [517]: 0.00237293824004664
Loss at iteration [518]: 0.002372837323567376
Loss at iteration [519]: 0.002372762745700313
Loss at iteration [520]: 0.0023726578460802695
Loss at iteration [521]: 0.0023725059387196233
Loss at iteration [522]: 0.00237220550968932
Loss at iteration [523]: 0.0023718323028099086
Loss at iteration [524]: 0.0023718323028099086
Loss at iteration [525]: 0.0023716138535720154
Loss at iteration [526]: 0.0023715610577618304
Loss at iteration [527]: 0.0023712923035723904
Loss at iteration [528]: 0.002371275590824234
Loss at iteration [529]: 0.002371242091921064
Loss at iteration [530]: 0.0023711588077619484
Loss at iteration [531]: 0.0023710864032178217
Loss at iteration [532]: 0.0023710162544827644
Loss at iteration [533]: 0.0023709554282601427
Loss at iteration [534]: 0.0023709020569914236
Loss at iteration [535]: 0.0023708616015232892
Loss at iteration [536]: 0.0023706770104893306
Loss at iteration [537]: 0.00237064453154951
Loss at iteration [538]: 0.002370547213299071
Loss at iteration [539]: 0.0023704165866556895
Loss at iteration [540]: 0.0023704165866556895
Loss at iteration [541]: 0.0023703790865016497
Loss at iteration [542]: 0.002370341801146044
Loss at iteration [543]: 0.002370213027879503
Loss at iteration [544]: 0.00237017749371806
Loss at iteration [545]: 0.002370148346381512
Loss at iteration [546]: 0.002370068082970981
Loss at iteration [547]: 0.0023700184889508284
Loss at iteration [548]: 0.002369922887490168
Loss at iteration [549]: 0.0023698059099852118
Loss at iteration [550]: 0.0023697192077022375
Loss at iteration [551]: 0.002369364136787182
Loss at iteration [552]: 0.0023692893393005066
Loss at iteration [553]: 0.002369165872623673
Loss at iteration [554]: 0.0023688621703413268
Loss at iteration [555]: 0.002368809674722731
Loss at iteration [556]: 0.002368809674722731
Loss at iteration [557]: 0.0023687870285165114
Loss at iteration [558]: 0.0023687191956213265
Loss at iteration [559]: 0.0023686328015882717
Loss at iteration [560]: 0.0023686070469948538
Loss at iteration [561]: 0.0023685722555256885
Loss at iteration [562]: 0.002368514299680913
Loss at iteration [563]: 0.002368468916662802
Loss at iteration [564]: 0.0023683968574569163
Loss at iteration [565]: 0.0023683337835047336
Loss at iteration [566]: 0.002368267102021225
Loss at iteration [567]: 0.0023681729825470975
Loss at iteration [568]: 0.0023681364253610444
Loss at iteration [569]: 0.002368026738158405
Loss at iteration [570]: 0.002367953540936586
Loss at iteration [571]: 0.002367882443091849
Loss at iteration [572]: 0.0023677951367194012
Loss at iteration [573]: 0.0023677951367194012
Loss at iteration [574]: 0.0023677708156715697
Loss at iteration [575]: 0.0023677437150603203
Loss at iteration [576]: 0.0023676596744597574
Loss at iteration [577]: 0.002367621627997118
Loss at iteration [578]: 0.0023675860294965073
Loss at iteration [579]: 0.0023675596519980757
Loss at iteration [580]: 0.0023674925511923766
Loss at iteration [581]: 0.002367437334315763
Loss at iteration [582]: 0.002367334058381406
Loss at iteration [583]: 0.0023671728588409145
Loss at iteration [584]: 0.0023669544806304353
Loss at iteration [585]: 0.002366712129820841
Loss at iteration [586]: 0.0023665922081617064
Loss at iteration [587]: 0.0023662268063387904
Loss at iteration [588]: 0.0023662268063387904
Loss at iteration [589]: 0.002366088568939698
Loss at iteration [590]: 0.0023660470722402737
Loss at iteration [591]: 0.0023658841620196915
Loss at iteration [592]: 0.0023658475949240496
Loss at iteration [593]: 0.002365650585384543
Loss at iteration [594]: 0.002365518224081098
Loss at iteration [595]: 0.002365483805834363
Loss at iteration [596]: 0.0023653657966025547
Loss at iteration [597]: 0.0023651207006621404
Loss at iteration [598]: 0.0023649561956886472
Loss at iteration [599]: 0.0023648162207377207
Loss at iteration [600]: 0.0023646541204144314
Loss at iteration [601]: 0.0023646541204144314
Loss at iteration [602]: 0.002364541945662672
Loss at iteration [603]: 0.0023644673866430508
Loss at iteration [604]: 0.0023640277558979743
Loss at iteration [605]: 0.002363973484282796
Loss at iteration [606]: 0.002363913228367899
Loss at iteration [607]: 0.0023638297338379015
Loss at iteration [608]: 0.0023637568733771573
Loss at iteration [609]: 0.0023636194267719897
Loss at iteration [610]: 0.0023633835706539535
Loss at iteration [611]: 0.002363269315023366
Loss at iteration [612]: 0.0023629034484300474
Loss at iteration [613]: 0.002362792093180348
Loss at iteration [614]: 0.0023627065252120358
Loss at iteration [615]: 0.0023627065252120358
Loss at iteration [616]: 0.0023626119048103756
Loss at iteration [617]: 0.0023625781408563315
Loss at iteration [618]: 0.0023624750729395994
Loss at iteration [619]: 0.002362441233165666
Loss at iteration [620]: 0.00236241042708134
Loss at iteration [621]: 0.0023622884631757718
Loss at iteration [622]: 0.002362176450823138
Loss at iteration [623]: 0.0023621102131803086
Loss at iteration [624]: 0.0023619943909643747
Loss at iteration [625]: 0.0023617840550630344
Loss at iteration [626]: 0.002361713019074779
Loss at iteration [627]: 0.0023615582361838205
Loss at iteration [628]: 0.0023613766758446074
Loss at iteration [629]: 0.002361336030014044
Loss at iteration [630]: 0.0023612548738288766
Loss at iteration [631]: 0.002361159436808028
Loss at iteration [632]: 0.0023610828160571785
Loss at iteration [633]: 0.0023610828160571785
Loss at iteration [634]: 0.002361036875985699
Loss at iteration [635]: 0.002361008969061295
Loss at iteration [636]: 0.0023609150734612864
Loss at iteration [637]: 0.0023608387330582036
Loss at iteration [638]: 0.0023607973014533185
Loss at iteration [639]: 0.002360768159635363
Loss at iteration [640]: 0.002360742623375165
Loss at iteration [641]: 0.0023607017488643136
Loss at iteration [642]: 0.0023606879001419616
Loss at iteration [643]: 0.00236063276234567
Loss at iteration [644]: 0.002360576515609293
Loss at iteration [645]: 0.0023604992905600815
Loss at iteration [646]: 0.002360451012759767
Loss at iteration [647]: 0.002360425927270401
Loss at iteration [648]: 0.002360052680676167
Loss at iteration [649]: 0.002360052680676167
Loss at iteration [650]: 0.002359989219818698
Loss at iteration [651]: 0.002359859154886832
Loss at iteration [652]: 0.0023597994714914857
Loss at iteration [653]: 0.0023597754079808333
Loss at iteration [654]: 0.0023597460626439345
Loss at iteration [655]: 0.0023597038797880505
Loss at iteration [656]: 0.0023596881674372173
Loss at iteration [657]: 0.0023596473005412
Loss at iteration [658]: 0.0023596329963040635
Loss at iteration [659]: 0.0023595845666214642
Loss at iteration [660]: 0.002359496600412066
Loss at iteration [661]: 0.002359496600412066
Loss at iteration [662]: 0.0023594514705847394
Loss at iteration [663]: 0.0023593980041539263
Loss at iteration [664]: 0.00235933341767676
Loss at iteration [665]: 0.002359283414130264
Loss at iteration [666]: 0.0023592513628486363
Loss at iteration [667]: 0.0023592359816175714
Loss at iteration [668]: 0.0023591957662126243
Loss at iteration [669]: 0.0023591729101332466
Loss at iteration [670]: 0.0023591285080794048
Loss at iteration [671]: 0.0023590137453945847
Loss at iteration [672]: 0.0023588435559988175
Loss at iteration [673]: 0.002358659946938535
Loss at iteration [674]: 0.0023583022326788172
Loss at iteration [675]: 0.0023563071450367597
Loss at iteration [676]: 0.0023563071450367597
Loss at iteration [677]: 0.002355756293716524
Loss at iteration [678]: 0.0023556455342431705
Loss at iteration [679]: 0.002355464362755379
Loss at iteration [680]: 0.0023552367168830067
Loss at iteration [681]: 0.0023550695419290433
Loss at iteration [682]: 0.002354980769288202
Loss at iteration [683]: 0.0023549254644625425
Loss at iteration [684]: 0.0023548196590338823
Loss at iteration [685]: 0.0023547879891572046
Loss at iteration [686]: 0.0023547333056332734
Loss at iteration [687]: 0.0023547130982757365
Loss at iteration [688]: 0.002354663738618121
Loss at iteration [689]: 0.002354543035391503
Loss at iteration [690]: 0.0023544894369787665
Loss at iteration [691]: 0.002354454546455961
Loss at iteration [692]: 0.0023543625149009422
Loss at iteration [693]: 0.0023543625149009422
Loss at iteration [694]: 0.002354316053017127
Loss at iteration [695]: 0.002354270171031825
Loss at iteration [696]: 0.0023542288059489828
Loss at iteration [697]: 0.002354177940880511
Loss at iteration [698]: 0.002354063659901689
Loss at iteration [699]: 0.002354040625767656
Loss at iteration [700]: 0.0023539878045161673
Loss at iteration [701]: 0.002353944087166978
Loss at iteration [702]: 0.002353872672887349
Loss at iteration [703]: 0.002353824496292799
Loss at iteration [704]: 0.0023537329996473158
Loss at iteration [705]: 0.00235369063224775
Loss at iteration [706]: 0.0023536013138740824
Loss at iteration [707]: 0.0023536013138740824
Loss at iteration [708]: 0.0023535551063750947
Loss at iteration [709]: 0.0023535200488872476
Loss at iteration [710]: 0.0023533674135163244
Loss at iteration [711]: 0.0023533503901649166
Loss at iteration [712]: 0.002353245930081193
Loss at iteration [713]: 0.002353194007470392
Loss at iteration [714]: 0.00235313101459492
Loss at iteration [715]: 0.002353065330207764
Loss at iteration [716]: 0.0023528209969480057
Loss at iteration [717]: 0.002352580913005506
Loss at iteration [718]: 0.002352470360185544
Loss at iteration [719]: 0.002352168927289612
Loss at iteration [720]: 0.002352168927289612
Loss at iteration [721]: 0.002351865236687707
Loss at iteration [722]: 0.0023517992997551533
Loss at iteration [723]: 0.0023513712381526062
Loss at iteration [724]: 0.002351251290664473
Loss at iteration [725]: 0.0023511251889908533
Loss at iteration [726]: 0.002351067634599709
Loss at iteration [727]: 0.0023510279833550045
Loss at iteration [728]: 0.0023509675036800168
Loss at iteration [729]: 0.002350861512164568
Loss at iteration [730]: 0.0023507354969472998
Loss at iteration [731]: 0.0023505443222949
Loss at iteration [732]: 0.0023504844394365092
Loss at iteration [733]: 0.0023504529267966063
Loss at iteration [734]: 0.0023501968631008214
Loss at iteration [735]: 0.0023501505270458606
Loss at iteration [736]: 0.0023501505270458606
Loss at iteration [737]: 0.0023501358689910685
Loss at iteration [738]: 0.0023501060290953405
Loss at iteration [739]: 0.002350076388136478
Loss at iteration [740]: 0.002350031507874534
Loss at iteration [741]: 0.00234997301225438
Loss at iteration [742]: 0.002349899610819174
Loss at iteration [743]: 0.0023497538061762677
Loss at iteration [744]: 0.002349669164495477
Loss at iteration [745]: 0.0023490914687169934
Loss at iteration [746]: 0.002348900255686384
Loss at iteration [747]: 0.0023483287212598
Loss at iteration [748]: 0.0023477537990888144
Loss at iteration [749]: 0.002347573843215486
Loss at iteration [750]: 0.002347257357869543
Loss at iteration [751]: 0.0023471176110653248
Loss at iteration [752]: 0.0023471176110653248
Loss at iteration [753]: 0.002347032533625389
Loss at iteration [754]: 0.0023466117931591614
Loss at iteration [755]: 0.0023464928567452814
Loss at iteration [756]: 0.0023463432230652202
Loss at iteration [757]: 0.002345899517541024
Loss at iteration [758]: 0.002345798899944366
Loss at iteration [759]: 0.002345746218581969
Loss at iteration [760]: 0.002345552330226946
Loss at iteration [761]: 0.0023454840408563076
Loss at iteration [762]: 0.0023454091649702333
Loss at iteration [763]: 0.0023452738346616832
Loss at iteration [764]: 0.0023452108403100047
Loss at iteration [765]: 0.0023450890038277626
Loss at iteration [766]: 0.0023450890038277626
Loss at iteration [767]: 0.0023450555241434153
Loss at iteration [768]: 0.002344991636411906
Loss at iteration [769]: 0.0023448351568343706
Loss at iteration [770]: 0.002344789162873403
Loss at iteration [771]: 0.0023446773613430704
Loss at iteration [772]: 0.0023446476088660904
Loss at iteration [773]: 0.0023446123557112953
Loss at iteration [774]: 0.002344441498674015
Loss at iteration [775]: 0.002344395974336004
Loss at iteration [776]: 0.002344352420435841
Loss at iteration [777]: 0.002344183445285857
Loss at iteration [778]: 0.0023440035253735046
Loss at iteration [779]: 0.0023438133100446936
Loss at iteration [780]: 0.002343757276044379
Loss at iteration [781]: 0.002343757276044379
Loss at iteration [782]: 0.0023437263915683966
Loss at iteration [783]: 0.002343586535876805
Loss at iteration [784]: 0.002343065827866018
Loss at iteration [785]: 0.0023430303340080632
Loss at iteration [786]: 0.002342967500831969
Loss at iteration [787]: 0.0023428738680602397
Loss at iteration [788]: 0.0023427291070663497
Loss at iteration [789]: 0.0023426888398949105
Loss at iteration [790]: 0.002342596945808069
Loss at iteration [791]: 0.002342527533749544
Loss at iteration [792]: 0.0023425071989382094
Loss at iteration [793]: 0.0023423810516634436
Loss at iteration [794]: 0.002342223988414606
Loss at iteration [795]: 0.002342223988414606
Loss at iteration [796]: 0.0023422037506966335
Loss at iteration [797]: 0.0023421473278367098
Loss at iteration [798]: 0.002342098005534948
Loss at iteration [799]: 0.0023420798753782273
Loss at iteration [800]: 0.0023420056147913483
Loss at iteration [801]: 0.0023419473530957476
Loss at iteration [802]: 0.0023419246011955816
Loss at iteration [803]: 0.0023418141543668472
Loss at iteration [804]: 0.002341729529781307
Loss at iteration [805]: 0.0023416771670111193
Loss at iteration [806]: 0.002341486857997035
Loss at iteration [807]: 0.002341413481742519
Loss at iteration [808]: 0.0023412015265441037
Loss at iteration [809]: 0.0023410068997337667
Loss at iteration [810]: 0.0023410068997337667
Loss at iteration [811]: 0.002340939955384058
Loss at iteration [812]: 0.0023408997954759867
Loss at iteration [813]: 0.0023407395015106335
Loss at iteration [814]: 0.002340716512263951
Loss at iteration [815]: 0.0023406792992489724
Loss at iteration [816]: 0.002340593945064565
Loss at iteration [817]: 0.0023405542682867647
Loss at iteration [818]: 0.002340512553765204
Loss at iteration [819]: 0.0023402957970218956
Loss at iteration [820]: 0.002340048966747969
Loss at iteration [821]: 0.002339685424447257
Loss at iteration [822]: 0.002339503701286988
Loss at iteration [823]: 0.0023385402342849778
Loss at iteration [824]: 0.002337735417214295
Loss at iteration [825]: 0.002337735417214295
Loss at iteration [826]: 0.00233745723848177
Loss at iteration [827]: 0.0023373351233174212
Loss at iteration [828]: 0.002336995542295951
Loss at iteration [829]: 0.0023369522357707044
Loss at iteration [830]: 0.002336902688963824
Loss at iteration [831]: 0.0023367914725263665
Loss at iteration [832]: 0.0023366837116416787
Loss at iteration [833]: 0.002336409705072112
Loss at iteration [834]: 0.002336354305000873
Loss at iteration [835]: 0.0023363092329429253
Loss at iteration [836]: 0.002336222280075504
Loss at iteration [837]: 0.002336150197017193
Loss at iteration [838]: 0.002335964109764745
Loss at iteration [839]: 0.0023359209251167285
Loss at iteration [840]: 0.0023358984614287445
Loss at iteration [841]: 0.0023358984614287445
Loss at iteration [842]: 0.0023358801332957484
Loss at iteration [843]: 0.0023358094799869737
Loss at iteration [844]: 0.0023357844381662897
Loss at iteration [845]: 0.0023356971799517352
Loss at iteration [846]: 0.0023355560898599033
Loss at iteration [847]: 0.0023354846979761097
Loss at iteration [848]: 0.0023352793045110375
Loss at iteration [849]: 0.002335225281841405
Loss at iteration [850]: 0.002335146567548332
Loss at iteration [851]: 0.0023350184718366343
Loss at iteration [852]: 0.0023348213588967677
Loss at iteration [853]: 0.0023348021525718228
Loss at iteration [854]: 0.0023347402178809295
Loss at iteration [855]: 0.002334711569863412
Loss at iteration [856]: 0.002334696409012756
Loss at iteration [857]: 0.002334696409012756
Loss at iteration [858]: 0.0023346764421802025
Loss at iteration [859]: 0.0023346542776633617
Loss at iteration [860]: 0.002334602245662649
Loss at iteration [861]: 0.0023345904835110746
Loss at iteration [862]: 0.0023345503328656906
Loss at iteration [863]: 0.0023345298074488392
Loss at iteration [864]: 0.0023345054938777496
Loss at iteration [865]: 0.0023344332219312346
Loss at iteration [866]: 0.0023343482807928885
Loss at iteration [867]: 0.0023342697264866073
Loss at iteration [868]: 0.002334083093090455
Loss at iteration [869]: 0.0023334186287222317
Loss at iteration [870]: 0.0023334186287222317
Loss at iteration [871]: 0.002332819759641329
Loss at iteration [872]: 0.002332725820360982
Loss at iteration [873]: 0.0023321984532847307
Loss at iteration [874]: 0.0023320541496964177
Loss at iteration [875]: 0.0023319500334018197
Loss at iteration [876]: 0.0023318994286874485
Loss at iteration [877]: 0.0023318374660151646
Loss at iteration [878]: 0.0023317890540437013
Loss at iteration [879]: 0.002331757755427827
Loss at iteration [880]: 0.002331693379173417
Loss at iteration [881]: 0.0023316563450255347
Loss at iteration [882]: 0.00233161408518299
Loss at iteration [883]: 0.0023315008586589268
Loss at iteration [884]: 0.0023314680660112656
Loss at iteration [885]: 0.0023314228955006243
Loss at iteration [886]: 0.0023314228955006243
Loss at iteration [887]: 0.0023313861544135665
Loss at iteration [888]: 0.0023313626192939547
Loss at iteration [889]: 0.002331314919422286
Loss at iteration [890]: 0.0023313004433745824
Loss at iteration [891]: 0.002331283733468757
Loss at iteration [892]: 0.0023312641692707983
Loss at iteration [893]: 0.002331247417329684
Loss at iteration [894]: 0.002331175041813426
Loss at iteration [895]: 0.0023310320839634567
Loss at iteration [896]: 0.0023309127556154314
Loss at iteration [897]: 0.0023307280074455995
Loss at iteration [898]: 0.0023304208247844536
Loss at iteration [899]: 0.0023303488602613056
Loss at iteration [900]: 0.0023302341931845903
Loss at iteration [901]: 0.002330020497322734
Loss at iteration [902]: 0.002329956038573425
Loss at iteration [903]: 0.002329865618348137
Loss at iteration [904]: 0.0023298168335859
Loss at iteration [905]: 0.0023298168335859
Loss at iteration [906]: 0.002329795882435873
Loss at iteration [907]: 0.0023297100638573153
Loss at iteration [908]: 0.002329667686267496
Loss at iteration [909]: 0.0023296525022105164
Loss at iteration [910]: 0.002329600482739077
Loss at iteration [911]: 0.0023295127641136657
Loss at iteration [912]: 0.002329451899333578
Loss at iteration [913]: 0.0023293563623727736
Loss at iteration [914]: 0.002329278773789182
Loss at iteration [915]: 0.002329224098521712
Loss at iteration [916]: 0.0023291514940941083
Loss at iteration [917]: 0.0023289875001605287
Loss at iteration [918]: 0.0023286251308807233
Loss at iteration [919]: 0.0023284894539667665
Loss at iteration [920]: 0.0023284252065439073
Loss at iteration [921]: 0.0023282113473003197
Loss at iteration [922]: 0.0023282113473003197
Loss at iteration [923]: 0.0023281978299466034
Loss at iteration [924]: 0.0023280764838134226
Loss at iteration [925]: 0.002328043729757578
Loss at iteration [926]: 0.0023280080023603852
Loss at iteration [927]: 0.0023279216206674586
Loss at iteration [928]: 0.0023278418436908374
Loss at iteration [929]: 0.0023277964375362833
Loss at iteration [930]: 0.002327689667342434
Loss at iteration [931]: 0.00232764803404476
Loss at iteration [932]: 0.0023276043207268275
Loss at iteration [933]: 0.002327509190887564
Loss at iteration [934]: 0.0023273374575265514
Loss at iteration [935]: 0.0023273374575265514
Loss at iteration [936]: 0.002327301841156496
Loss at iteration [937]: 0.002327257488629887
Loss at iteration [938]: 0.0023271619059072974
Loss at iteration [939]: 0.0023271515735842573
Loss at iteration [940]: 0.002327130091490276
Loss at iteration [941]: 0.002327115967771788
Loss at iteration [942]: 0.0023270964386509913
Loss at iteration [943]: 0.0023270830957920425
Loss at iteration [944]: 0.002327063777896726
Loss at iteration [945]: 0.00232700440396577
Loss at iteration [946]: 0.002326959280607587
Loss at iteration [947]: 0.0023268015843547736
Loss at iteration [948]: 0.002326396624536233
Loss at iteration [949]: 0.002326168705029884
Loss at iteration [950]: 0.002326168705029884
Loss at iteration [951]: 0.002326050733547097
Loss at iteration [952]: 0.002325995743478248
Loss at iteration [953]: 0.002325743081690119
Loss at iteration [954]: 0.0023254752251768017
Loss at iteration [955]: 0.0023254460297043042
Loss at iteration [956]: 0.0023253542130383543
Loss at iteration [957]: 0.0023251828711514794
Loss at iteration [958]: 0.002325114383157731
Loss at iteration [959]: 0.0023249890627053743
Loss at iteration [960]: 0.002324855053712378
Loss at iteration [961]: 0.0023248052163135752
Loss at iteration [962]: 0.002324744128249284
Loss at iteration [963]: 0.002324744128249284
Loss at iteration [964]: 0.0023247171755273292
Loss at iteration [965]: 0.0023246991936782834
Loss at iteration [966]: 0.002324655771415949
Loss at iteration [967]: 0.002324640048729517
Loss at iteration [968]: 0.0023244647936884405
Loss at iteration [969]: 0.0023244226737772432
Loss at iteration [970]: 0.00232438139228481
Loss at iteration [971]: 0.0023240276947953478
Loss at iteration [972]: 0.0023238924450663502
Loss at iteration [973]: 0.002323765548291603
Loss at iteration [974]: 0.0023233808976131005
Loss at iteration [975]: 0.0023228960219943804
Loss at iteration [976]: 0.0023228960219943804
Loss at iteration [977]: 0.0023224338596285715
Loss at iteration [978]: 0.002322346376598611
Loss at iteration [979]: 0.002322103252808991
Loss at iteration [980]: 0.0023220403836507896
Loss at iteration [981]: 0.0023218308220415347
Loss at iteration [982]: 0.002321766918950902
Loss at iteration [983]: 0.002321721510941087
Loss at iteration [984]: 0.002321642374566539
Loss at iteration [985]: 0.0023214962457229235
Loss at iteration [986]: 0.0023214354500504446
Loss at iteration [987]: 0.0023213906047161886
Loss at iteration [988]: 0.002321300904100624
Loss at iteration [989]: 0.0023212210084944617
Loss at iteration [990]: 0.0023211335958977087
Loss at iteration [991]: 0.0023211335958977087
Loss at iteration [992]: 0.002321106020536038
Loss at iteration [993]: 0.0023210694062613686
Loss at iteration [994]: 0.0023210394066902934
Loss at iteration [995]: 0.0023210105273260605
Loss at iteration [996]: 0.0023209698721017493
Loss at iteration [997]: 0.0023209522897265854
Loss at iteration [998]: 0.0023209362472763006
Loss at iteration [999]: 0.0023208896488343634
Loss at iteration [1000]: 0.002320862795239199
Loss at iteration [1001]: 0.002320787513674947
Loss at iteration [1002]: 0.0023207536516092714
Loss at iteration [1003]: 0.0023201230741324757
Loss at iteration [1004]: 0.0023192872063011517
Loss at iteration [1005]: 0.0023186592108215697
Loss at iteration [1006]: 0.0023186592108215697
Loss at iteration [1007]: 0.0023185731821954033
Loss at iteration [1008]: 0.0023183645026743334
Loss at iteration [1009]: 0.0023182449926474357
Loss at iteration [1010]: 0.00231818158093931
Loss at iteration [1011]: 0.0023179618492578623
Loss at iteration [1012]: 0.0023179440106339
Loss at iteration [1013]: 0.0023178295937577188
Loss at iteration [1014]: 0.0023177326515440556
Loss at iteration [1015]: 0.0023175227106890816
Loss at iteration [1016]: 0.002317494173987599
Loss at iteration [1017]: 0.002317445169320594
Loss at iteration [1018]: 0.002317396632709214
Loss at iteration [1019]: 0.0023173620112524446
Loss at iteration [1020]: 0.0023173342805588052
Loss at iteration [1021]: 0.0023173342805588052
Loss at iteration [1022]: 0.002317311657279949
Loss at iteration [1023]: 0.0023172784383088466
Loss at iteration [1024]: 0.002317211553882812
Loss at iteration [1025]: 0.0023171831719215
Loss at iteration [1026]: 0.0023171313745828075
Loss at iteration [1027]: 0.0023170324615977254
Loss at iteration [1028]: 0.002316935551100473
Loss at iteration [1029]: 0.0023168477002901856
Loss at iteration [1030]: 0.0023165899599388324
Loss at iteration [1031]: 0.002316411247559668
Loss at iteration [1032]: 0.0023163540000408515
Loss at iteration [1033]: 0.0023160476086906737
Loss at iteration [1034]: 0.0023155438941716475
Loss at iteration [1035]: 0.0023154515441139024
Loss at iteration [1036]: 0.0023152547930930362
Loss at iteration [1037]: 0.0023152547930930362
Loss at iteration [1038]: 0.0023151601607389527
Loss at iteration [1039]: 0.0023151214631796286
Loss at iteration [1040]: 0.0023149941045401148
Loss at iteration [1041]: 0.0023149510700425906
Loss at iteration [1042]: 0.002314915152462479
Loss at iteration [1043]: 0.0023147596385421684
Loss at iteration [1044]: 0.002314703725195706
Loss at iteration [1045]: 0.0023146564553939764
Loss at iteration [1046]: 0.0023146185946967862
Loss at iteration [1047]: 0.0023145604346613913
Loss at iteration [1048]: 0.0023144496566995954
Loss at iteration [1049]: 0.002314412461325362
Loss at iteration [1050]: 0.0023143728494444274
Loss at iteration [1051]: 0.002314328069434089
Loss at iteration [1052]: 0.002314237360598547
Loss at iteration [1053]: 0.002314237360598547
Loss at iteration [1054]: 0.0023142111332902547
Loss at iteration [1055]: 0.0023141865091802936
Loss at iteration [1056]: 0.0023141505107047854
Loss at iteration [1057]: 0.0023140889986637404
Loss at iteration [1058]: 0.0023140452151236
Loss at iteration [1059]: 0.00231402685503306
Loss at iteration [1060]: 0.0023139657075069834
Loss at iteration [1061]: 0.0023138346842099455
Loss at iteration [1062]: 0.002313770416330832
Loss at iteration [1063]: 0.002313608813710956
Loss at iteration [1064]: 0.0023134156616100585
Loss at iteration [1065]: 0.0023132085754357136
Loss at iteration [1066]: 0.00231314540243071
Loss at iteration [1067]: 0.0023130501909677946
Loss at iteration [1068]: 0.0023129466793215085
Loss at iteration [1069]: 0.0023128181925548903
Loss at iteration [1070]: 0.0023128181925548903
Loss at iteration [1071]: 0.002312762998653514
Loss at iteration [1072]: 0.0023127177816992506
Loss at iteration [1073]: 0.0023126223399906934
Loss at iteration [1074]: 0.0023125793308692937
Loss at iteration [1075]: 0.0023125096693935813
Loss at iteration [1076]: 0.0023124322813038653
Loss at iteration [1077]: 0.0023123401292034613
Loss at iteration [1078]: 0.0023122545622223972
Loss at iteration [1079]: 0.0023122119148415625
Loss at iteration [1080]: 0.0023119884658192587
Loss at iteration [1081]: 0.0023118839162923005
Loss at iteration [1082]: 0.002311796844652227
Loss at iteration [1083]: 0.0023115884284009213
Loss at iteration [1084]: 0.0023110514840866303
Loss at iteration [1085]: 0.00231092603805826
Loss at iteration [1086]: 0.00231092603805826
Loss at iteration [1087]: 0.0023109001998526534
Loss at iteration [1088]: 0.0023107817968501974
Loss at iteration [1089]: 0.0023107042461640126
Loss at iteration [1090]: 0.002310583402305279
Loss at iteration [1091]: 0.002310556749634402
Loss at iteration [1092]: 0.0023105207526553056
Loss at iteration [1093]: 0.0023104676873200915
Loss at iteration [1094]: 0.0023104115842496934
Loss at iteration [1095]: 0.0023103534855328273
Loss at iteration [1096]: 0.0023103193926232316
Loss at iteration [1097]: 0.0023102901873962743
Loss at iteration [1098]: 0.0023102650998234374
Loss at iteration [1099]: 0.0023102125634920064
Loss at iteration [1100]: 0.00231018597688281
Loss at iteration [1101]: 0.00231018597688281
Loss at iteration [1102]: 0.0023101711077284284
Loss at iteration [1103]: 0.0023101496850275694
Loss at iteration [1104]: 0.002310106025300812
Loss at iteration [1105]: 0.0023100815010967564
Loss at iteration [1106]: 0.0023100265050577766
Loss at iteration [1107]: 0.00230995432289379
Loss at iteration [1108]: 0.002309895873846756
Loss at iteration [1109]: 0.0023093946795366884
Loss at iteration [1110]: 0.0023090887594022958
Loss at iteration [1111]: 0.002308530791621973
Loss at iteration [1112]: 0.002307759009054118
Loss at iteration [1113]: 0.0023074381412177664
Loss at iteration [1114]: 0.002307128977972603
Loss at iteration [1115]: 0.0023069785561645696
Loss at iteration [1116]: 0.0023069785561645696
Loss at iteration [1117]: 0.002306876329969586
Loss at iteration [1118]: 0.002306784250267656
Loss at iteration [1119]: 0.0023064525290989782
Loss at iteration [1120]: 0.0023064008207818983
Loss at iteration [1121]: 0.002306266819261127
Loss at iteration [1122]: 0.002306024097414508
Loss at iteration [1123]: 0.002305906929248155
Loss at iteration [1124]: 0.0023058362970750923
Loss at iteration [1125]: 0.0023057425941979508
Loss at iteration [1126]: 0.0023056864658698543
Loss at iteration [1127]: 0.002305581800853905
Loss at iteration [1128]: 0.002305395987997323
Loss at iteration [1129]: 0.0023053433501306494
Loss at iteration [1130]: 0.002305150274796289
Loss at iteration [1131]: 0.0023051175995379243
Loss at iteration [1132]: 0.0023051175995379243
Loss at iteration [1133]: 0.002305103109640781
Loss at iteration [1134]: 0.002305021421826104
Loss at iteration [1135]: 0.0023049958327672117
Loss at iteration [1136]: 0.0023049613322203948
Loss at iteration [1137]: 0.0023048667031609527
Loss at iteration [1138]: 0.002304845949655245
Loss at iteration [1139]: 0.002304768622928361
Loss at iteration [1140]: 0.0023047408819158576
Loss at iteration [1141]: 0.0023047195974145816
Loss at iteration [1142]: 0.00230464287000678
Loss at iteration [1143]: 0.002304606033829198
Loss at iteration [1144]: 0.0023045688215782025
Loss at iteration [1145]: 0.0023042450198439
Loss at iteration [1146]: 0.0023039885311773845
Loss at iteration [1147]: 0.002303925843277458
Loss at iteration [1148]: 0.002303496789053296
Loss at iteration [1149]: 0.0023022748307983416
Loss at iteration [1150]: 0.0023022748307983416
Loss at iteration [1151]: 0.0023012066653003652
Loss at iteration [1152]: 0.002301023217018515
Loss at iteration [1153]: 0.0023003938158719936
Loss at iteration [1154]: 0.002300311857863236
Loss at iteration [1155]: 0.002300043724204434
Loss at iteration [1156]: 0.0022997935622676544
Loss at iteration [1157]: 0.002299681362371415
Loss at iteration [1158]: 0.0022996279617403526
Loss at iteration [1159]: 0.0022995178205513266
Loss at iteration [1160]: 0.002299366657271465
Loss at iteration [1161]: 0.002299302215511484
Loss at iteration [1162]: 0.0022992293383129955
Loss at iteration [1163]: 0.0022990526080661237
Loss at iteration [1164]: 0.0022989340499524227
Loss at iteration [1165]: 0.0022987513073167284
Loss at iteration [1166]: 0.0022986562677748254
Loss at iteration [1167]: 0.0022986562677748254
Loss at iteration [1168]: 0.0022985905607187263
Loss at iteration [1169]: 0.0022985455000232137
Loss at iteration [1170]: 0.002298452079531137
Loss at iteration [1171]: 0.002298407249271425
Loss at iteration [1172]: 0.0022983583535239683
Loss at iteration [1173]: 0.002298244714802425
Loss at iteration [1174]: 0.0022981791279218615
Loss at iteration [1175]: 0.002298110636001462
Loss at iteration [1176]: 0.002298009995465711
Loss at iteration [1177]: 0.002297948108898612
Loss at iteration [1178]: 0.002297833952271517
Loss at iteration [1179]: 0.00229779568806631
Loss at iteration [1180]: 0.00229770638453898
Loss at iteration [1181]: 0.002297660843851499
Loss at iteration [1182]: 0.0022976429320819666
Loss at iteration [1183]: 0.0022976429320819666
Loss at iteration [1184]: 0.0022976095081241126
Loss at iteration [1185]: 0.0022975661017812818
Loss at iteration [1186]: 0.0022975366403314487
Loss at iteration [1187]: 0.002297505949148383
Loss at iteration [1188]: 0.002297439636055229
Loss at iteration [1189]: 0.0022974031789816966
Loss at iteration [1190]: 0.002297335614305191
Loss at iteration [1191]: 0.0022972433414786887
Loss at iteration [1192]: 0.0022971454677668587
Loss at iteration [1193]: 0.0022968945892756585
Loss at iteration [1194]: 0.0022968538772495787
Loss at iteration [1195]: 0.0022968230302530634
Loss at iteration [1196]: 0.0022967094361603054
Loss at iteration [1197]: 0.0022966707627259187
Loss at iteration [1198]: 0.0022966707627259187
Loss at iteration [1199]: 0.0022966450943070474
Loss at iteration [1200]: 0.0022965825260976716
Loss at iteration [1201]: 0.002296557182383066
Loss at iteration [1202]: 0.0022965335014278315
Loss at iteration [1203]: 0.002296498645173106
Loss at iteration [1204]: 0.0022964719913533414
Loss at iteration [1205]: 0.002296437002436582
Loss at iteration [1206]: 0.0022963973216031885
Loss at iteration [1207]: 0.0022963827665379195
Loss at iteration [1208]: 0.0022963637390862905
Loss at iteration [1209]: 0.0022963508701625427
Loss at iteration [1210]: 0.002296328417071983
Loss at iteration [1211]: 0.0022962806642177177
Loss at iteration [1212]: 0.002296258493101464
Loss at iteration [1213]: 0.0022961913111195944
Loss at iteration [1214]: 0.002296089503237225
Loss at iteration [1215]: 0.0022960538809281023
Loss at iteration [1216]: 0.0022960538809281023
Loss at iteration [1217]: 0.002296037018929074
Loss at iteration [1218]: 0.002295993894897805
Loss at iteration [1219]: 0.0022959303800247246
Loss at iteration [1220]: 0.002295912467979571
Loss at iteration [1221]: 0.0022958567787407075
Loss at iteration [1222]: 0.002295720935376874
Loss at iteration [1223]: 0.0022956923294441306
Loss at iteration [1224]: 0.002295626169016901
Loss at iteration [1225]: 0.0022954242184679867
Loss at iteration [1226]: 0.0022952448464732002
Loss at iteration [1227]: 0.002295175464863451
Loss at iteration [1228]: 0.0022946948855880893
Loss at iteration [1229]: 0.0022946948855880893
Loss at iteration [1230]: 0.0022943526880814923
Loss at iteration [1231]: 0.0022942791542647605
Loss at iteration [1232]: 0.0022940518804363597
Loss at iteration [1233]: 0.002294033469761062
Loss at iteration [1234]: 0.002293912099592777
Loss at iteration [1235]: 0.00229387618951924
Loss at iteration [1236]: 0.0022938146224059236
Loss at iteration [1237]: 0.002293677478732877
Loss at iteration [1238]: 0.0022936211271536253
Loss at iteration [1239]: 0.0022935095413496743
Loss at iteration [1240]: 0.0022934688955456545
Loss at iteration [1241]: 0.0022934688955456545
Loss at iteration [1242]: 0.0022934530461017903
Loss at iteration [1243]: 0.0022934312263611077
Loss at iteration [1244]: 0.0022934154449968597
Loss at iteration [1245]: 0.0022933683981398822
Loss at iteration [1246]: 0.00229335057588845
Loss at iteration [1247]: 0.0022933229974807785
Loss at iteration [1248]: 0.0022932993029097896
Loss at iteration [1249]: 0.002293265865601469
Loss at iteration [1250]: 0.0022930695908493326
Loss at iteration [1251]: 0.0022930202156065584
Loss at iteration [1252]: 0.002292907057247908
Loss at iteration [1253]: 0.00229279425390472
Loss at iteration [1254]: 0.002292652440649222
Loss at iteration [1255]: 0.0022925239813062627
Loss at iteration [1256]: 0.0022924184164514693
Loss at iteration [1257]: 0.002292327006979037
Loss at iteration [1258]: 0.0022922709140904374
Loss at iteration [1259]: 0.0022922709140904374
Loss at iteration [1260]: 0.0022922518555287194
Loss at iteration [1261]: 0.0022922248656083934
Loss at iteration [1262]: 0.002292188965809938
Loss at iteration [1263]: 0.002292158315352149
Loss at iteration [1264]: 0.002292104523270124
Loss at iteration [1265]: 0.0022920623359467397
Loss at iteration [1266]: 0.0022919716053087366
Loss at iteration [1267]: 0.002291936030617048
Loss at iteration [1268]: 0.0022918731433089964
Loss at iteration [1269]: 0.0022918060600700023
Loss at iteration [1270]: 0.0022917484491153254
Loss at iteration [1271]: 0.0022915939432294322
Loss at iteration [1272]: 0.0022915190966494798
Loss at iteration [1273]: 0.002291313337050133
Loss at iteration [1274]: 0.002291313337050133
Loss at iteration [1275]: 0.0022912298992891086
Loss at iteration [1276]: 0.0022911962661274258
Loss at iteration [1277]: 0.0022910945013756676
Loss at iteration [1278]: 0.0022909762340825343
Loss at iteration [1279]: 0.002290926520224924
Loss at iteration [1280]: 0.002290892164858952
Loss at iteration [1281]: 0.0022908087340240395
Loss at iteration [1282]: 0.002290786018334657
Loss at iteration [1283]: 0.002290762102722692
Loss at iteration [1284]: 0.002290706785190577
Loss at iteration [1285]: 0.002290688818220248
Loss at iteration [1286]: 0.0022906362818696964
Loss at iteration [1287]: 0.0022906054146005317
Loss at iteration [1288]: 0.0022905080384176776
Loss at iteration [1289]: 0.0022904697600943944
Loss at iteration [1290]: 0.002290426188660473
Loss at iteration [1291]: 0.002290426188660473
Loss at iteration [1292]: 0.002290372216573432
Loss at iteration [1293]: 0.0022903533740164105
Loss at iteration [1294]: 0.0022903090435356247
Loss at iteration [1295]: 0.0022902782985424813
Loss at iteration [1296]: 0.0022902016269121584
Loss at iteration [1297]: 0.0022901442720370904
Loss at iteration [1298]: 0.0022900562455590735
Loss at iteration [1299]: 0.0022899537421444266
Loss at iteration [1300]: 0.0022899024535201293
Loss at iteration [1301]: 0.002289781385435221
Loss at iteration [1302]: 0.002289363373392877
Loss at iteration [1303]: 0.0022892123497756096
Loss at iteration [1304]: 0.002289019424844659
Loss at iteration [1305]: 0.0022885471836137346
Loss at iteration [1306]: 0.0022885471836137346
Loss at iteration [1307]: 0.0022884707485660203
Loss at iteration [1308]: 0.00228840836741595
Loss at iteration [1309]: 0.002288293680238207
Loss at iteration [1310]: 0.002288253576538781
Loss at iteration [1311]: 0.0022882052489431484
Loss at iteration [1312]: 0.0022881624196445538
Loss at iteration [1313]: 0.002288100504637942
Loss at iteration [1314]: 0.0022880071622269882
Loss at iteration [1315]: 0.0022879797430473453
Loss at iteration [1316]: 0.0022879388826023486
Loss at iteration [1317]: 0.002287893010025212
Loss at iteration [1318]: 0.0022878536860290333
Loss at iteration [1319]: 0.0022878302134064898
Loss at iteration [1320]: 0.0022877539241624853
Loss at iteration [1321]: 0.0022877230838495373
Loss at iteration [1322]: 0.0022876176005516137
Loss at iteration [1323]: 0.0022876176005516137
Loss at iteration [1324]: 0.0022875948248729833
Loss at iteration [1325]: 0.002287574652911389
Loss at iteration [1326]: 0.0022875394786648815
Loss at iteration [1327]: 0.0022875183949509457
Loss at iteration [1328]: 0.002287485019908828
Loss at iteration [1329]: 0.0022874300152852596
Loss at iteration [1330]: 0.0022873592571108024
Loss at iteration [1331]: 0.002287271081152345
Loss at iteration [1332]: 0.0022861165066837444
Loss at iteration [1333]: 0.0022859220893076447
Loss at iteration [1334]: 0.0022855506123709
Loss at iteration [1335]: 0.0022841874050616474
Loss at iteration [1336]: 0.0022797252837595977
Loss at iteration [1337]: 0.0022797252837595977
Loss at iteration [1338]: 0.0022789841112725476
Loss at iteration [1339]: 0.002278623491546796
Loss at iteration [1340]: 0.002277170352239191
Loss at iteration [1341]: 0.002275432660612622
Loss at iteration [1342]: 0.0022749982506268004
Loss at iteration [1343]: 0.0022747091813704887
Loss at iteration [1344]: 0.0022738121612639194
Loss at iteration [1345]: 0.0022733281413967158
Loss at iteration [1346]: 0.002273156597792421
Loss at iteration [1347]: 0.0022724752414165737
Loss at iteration [1348]: 0.002271976285409944
Loss at iteration [1349]: 0.0022714972321242
Loss at iteration [1350]: 0.0022714972321242
Loss at iteration [1351]: 0.002271308817039202
Loss at iteration [1352]: 0.0022710021197057785
Loss at iteration [1353]: 0.0022709443863286696
Loss at iteration [1354]: 0.0022704277987021975
Loss at iteration [1355]: 0.0022703255258066596
Loss at iteration [1356]: 0.002270131687926418
Loss at iteration [1357]: 0.002269935970946082
Loss at iteration [1358]: 0.0022698787416784443
Loss at iteration [1359]: 0.002269836392993824
Loss at iteration [1360]: 0.002269595476028908
Loss at iteration [1361]: 0.002269595476028908
Loss at iteration [1362]: 0.0022694772996814344
Loss at iteration [1363]: 0.0022694348478764894
Loss at iteration [1364]: 0.002269217614176902
Loss at iteration [1365]: 0.002269175965685005
Loss at iteration [1366]: 0.0022690985528368885
Loss at iteration [1367]: 0.0022689718402977566
Loss at iteration [1368]: 0.0022689434924896366
Loss at iteration [1369]: 0.00226879115479578
Loss at iteration [1370]: 0.002268702540077556
Loss at iteration [1371]: 0.0022686281114262844
Loss at iteration [1372]: 0.0022682787077914954
Loss at iteration [1373]: 0.002268130875789869
Loss at iteration [1374]: 0.002268055945406161
Loss at iteration [1375]: 0.002267779066408283
Loss at iteration [1376]: 0.002267779066408283
Loss at iteration [1377]: 0.0022677591098701514
Loss at iteration [1378]: 0.002267651853899781
Loss at iteration [1379]: 0.002267536626221749
Loss at iteration [1380]: 0.002267502014080983
Loss at iteration [1381]: 0.0022674186768405057
Loss at iteration [1382]: 0.002267367884084716
Loss at iteration [1383]: 0.0022672560418880304
Loss at iteration [1384]: 0.0022671732831202715
Loss at iteration [1385]: 0.0022671217215120645
Loss at iteration [1386]: 0.0022670760812367624
Loss at iteration [1387]: 0.002267039221523923
Loss at iteration [1388]: 0.0022670105197775503
Loss at iteration [1389]: 0.002266864430489007
Loss at iteration [1390]: 0.002266684612325187
Loss at iteration [1391]: 0.0022665193866868
Loss at iteration [1392]: 0.0022664420418619462
Loss at iteration [1393]: 0.0022659520104841495
Loss at iteration [1394]: 0.0022659520104841495
Loss at iteration [1395]: 0.0022654676443855794
Loss at iteration [1396]: 0.0022653467191910233
Loss at iteration [1397]: 0.0022649831268576996
Loss at iteration [1398]: 0.0022648803359701375
Loss at iteration [1399]: 0.0022647294611822175
Loss at iteration [1400]: 0.002264584195765337
Loss at iteration [1401]: 0.0022645307745751964
Loss at iteration [1402]: 0.0022644115214389567
Loss at iteration [1403]: 0.002264233323543231
Loss at iteration [1404]: 0.002264167930639915
Loss at iteration [1405]: 0.002264128230305396
Loss at iteration [1406]: 0.0022640779563190432
Loss at iteration [1407]: 0.0022639930100375825
Loss at iteration [1408]: 0.0022639406909890037
Loss at iteration [1409]: 0.0022639406909890037
Loss at iteration [1410]: 0.0022639007025761627
Loss at iteration [1411]: 0.00226382880242547
Loss at iteration [1412]: 0.00226379948427371
Loss at iteration [1413]: 0.002263784031729348
Loss at iteration [1414]: 0.0022637320917936157
Loss at iteration [1415]: 0.002263715079439778
Loss at iteration [1416]: 0.002263678286657577
Loss at iteration [1417]: 0.00226365393289972
Loss at iteration [1418]: 0.002263630598660539
Loss at iteration [1419]: 0.002263603571163792
Loss at iteration [1420]: 0.002263571058171774
Loss at iteration [1421]: 0.002263505452455708
Loss at iteration [1422]: 0.002263417533945413
Loss at iteration [1423]: 0.0022632575298946462
Loss at iteration [1424]: 0.002263057995420071
Loss at iteration [1425]: 0.0022629549890732857
Loss at iteration [1426]: 0.0022627426945251885
Loss at iteration [1427]: 0.002262498017821127
Loss at iteration [1428]: 0.002262498017821127
Loss at iteration [1429]: 0.002262433564837384
Loss at iteration [1430]: 0.002262356020923634
Loss at iteration [1431]: 0.0022621504164265986
Loss at iteration [1432]: 0.002262127994680707
Loss at iteration [1433]: 0.002262094615527297
Loss at iteration [1434]: 0.00226205185710326
Loss at iteration [1435]: 0.002262021871660047
Loss at iteration [1436]: 0.0022619854681786024
Loss at iteration [1437]: 0.0022619378665045754
Loss at iteration [1438]: 0.002261903165603001
Loss at iteration [1439]: 0.0022618376796170745
Loss at iteration [1440]: 0.002261795604581549
Loss at iteration [1441]: 0.002261749243920921
Loss at iteration [1442]: 0.0022616885557201765
Loss at iteration [1443]: 0.0022615145819685086
Loss at iteration [1444]: 0.002261270748900552
Loss at iteration [1445]: 0.0022609937266143813
Loss at iteration [1446]: 0.0022609021750810113
Loss at iteration [1447]: 0.002260500950182026
Loss at iteration [1448]: 0.002260500950182026
Loss at iteration [1449]: 0.002260349800280842
Loss at iteration [1450]: 0.0022602993735085916
Loss at iteration [1451]: 0.002260098867752479
Loss at iteration [1452]: 0.0022600154312052523
Loss at iteration [1453]: 0.002259878413079606
Loss at iteration [1454]: 0.0022598237089427953
Loss at iteration [1455]: 0.0022597313842968886
Loss at iteration [1456]: 0.0022595809262203927
Loss at iteration [1457]: 0.00225951453726403
Loss at iteration [1458]: 0.0022594856219639303
Loss at iteration [1459]: 0.0022594336384676008
Loss at iteration [1460]: 0.0022593769738852307
Loss at iteration [1461]: 0.0022593122294901763
Loss at iteration [1462]: 0.0022591973527767966
Loss at iteration [1463]: 0.002258956702495766
Loss at iteration [1464]: 0.002258956702495766
Loss at iteration [1465]: 0.0022589285154409155
Loss at iteration [1466]: 0.0022586823103647423
Loss at iteration [1467]: 0.002258653869705473
Loss at iteration [1468]: 0.0022586262446557463
Loss at iteration [1469]: 0.0022585502460221
Loss at iteration [1470]: 0.0022585256706603614
Loss at iteration [1471]: 0.0022585114008552886
Loss at iteration [1472]: 0.0022584665989110334
Loss at iteration [1473]: 0.0022584516697072947
Loss at iteration [1474]: 0.0022583381610453645
Loss at iteration [1475]: 0.002258157985657765
Loss at iteration [1476]: 0.002257991881863289
Loss at iteration [1477]: 0.0022579024480437063
Loss at iteration [1478]: 0.0022579024480437063
Loss at iteration [1479]: 0.0022578421059178686
Loss at iteration [1480]: 0.0022577731775226405
Loss at iteration [1481]: 0.0022576125278383663
Loss at iteration [1482]: 0.0022575717067965834
Loss at iteration [1483]: 0.002257535406600858
Loss at iteration [1484]: 0.0022574499281684183
Loss at iteration [1485]: 0.002257427142631547
Loss at iteration [1486]: 0.002257404986530685
Loss at iteration [1487]: 0.0022573914069198603
Loss at iteration [1488]: 0.0022573257487339825
Loss at iteration [1489]: 0.002257308273514012
Loss at iteration [1490]: 0.0022572377276807764
Loss at iteration [1491]: 0.002257118026260506
Loss at iteration [1492]: 0.002257118026260506
Loss at iteration [1493]: 0.0022570857406594715
Loss at iteration [1494]: 0.0022570420761761183
Loss at iteration [1495]: 0.0022570138470163494
Loss at iteration [1496]: 0.00225699817878488
Loss at iteration [1497]: 0.002256964208837097
Loss at iteration [1498]: 0.0022569294121439105
Loss at iteration [1499]: 0.0022569106472365664
Loss at iteration [1500]: 0.002256885351957228
Loss at iteration [1501]: 0.0022568577540899846
Loss at iteration [1502]: 0.0022568367955645608
Loss at iteration [1503]: 0.0022567897529290034
Loss at iteration [1504]: 0.0022567281017674165
Loss at iteration [1505]: 0.0022566527256079622
Loss at iteration [1506]: 0.002256486021033165
Loss at iteration [1507]: 0.0022561432871633447
Loss at iteration [1508]: 0.002256011839893647
Loss at iteration [1509]: 0.00225573278899189
Loss at iteration [1510]: 0.0022489191047901686
Loss at iteration [1511]: 0.0022489191047901686
Loss at iteration [1512]: 0.002247908591269853
Loss at iteration [1513]: 0.002247121034461781
Loss at iteration [1514]: 0.0022455001064570945
Loss at iteration [1515]: 0.0022448361056188475
Loss at iteration [1516]: 0.0022441918704969943
Loss at iteration [1517]: 0.0022417535621406855
Loss at iteration [1518]: 0.002240016704677545
Loss at iteration [1519]: 0.0022389223262966893
Loss at iteration [1520]: 0.0022386692195108366
Loss at iteration [1521]: 0.0022382262294996153
Loss at iteration [1522]: 0.0022376294262753554
Loss at iteration [1523]: 0.002237433529083461
Loss at iteration [1524]: 0.0022368333545597753
Loss at iteration [1525]: 0.0022361676903813795
Loss at iteration [1526]: 0.0022361181342129876
Loss at iteration [1527]: 0.0022361181342129876
Loss at iteration [1528]: 0.002235964289776332
Loss at iteration [1529]: 0.002235674254827275
Loss at iteration [1530]: 0.0022354845942479423
Loss at iteration [1531]: 0.0022354080023736828
Loss at iteration [1532]: 0.0022352877179667627
Loss at iteration [1533]: 0.0022351126140555825
Loss at iteration [1534]: 0.0022350568695129335
Loss at iteration [1535]: 0.0022349710389048035
Loss at iteration [1536]: 0.0022347854759746043
Loss at iteration [1537]: 0.0022347384383667023
Loss at iteration [1538]: 0.0022346559043740295
Loss at iteration [1539]: 0.0022345735377734496
Loss at iteration [1540]: 0.0022345233265130414
Loss at iteration [1541]: 0.002234341864085209
Loss at iteration [1542]: 0.002234341864085209
Loss at iteration [1543]: 0.0022342829786266925
Loss at iteration [1544]: 0.0022342344286936187
Loss at iteration [1545]: 0.0022341724471830267
Loss at iteration [1546]: 0.0022341380092803587
Loss at iteration [1547]: 0.002234106036474996
Loss at iteration [1548]: 0.0022340781511396724
Loss at iteration [1549]: 0.002234001742764099
Loss at iteration [1550]: 0.002233895093481072
Loss at iteration [1551]: 0.0022337546728413496
Loss at iteration [1552]: 0.0022336595535823074
Loss at iteration [1553]: 0.002233499037056647
Loss at iteration [1554]: 0.002233387707365524
Loss at iteration [1555]: 0.002233234377456479
Loss at iteration [1556]: 0.002233054465973244
Loss at iteration [1557]: 0.002232947190273879
Loss at iteration [1558]: 0.0022327716924870405
Loss at iteration [1559]: 0.0022327168423830223
Loss at iteration [1560]: 0.0022326308074048042
Loss at iteration [1561]: 0.002232504537068523
Loss at iteration [1562]: 0.002232464169152248
Loss at iteration [1563]: 0.002232464169152248
Loss at iteration [1564]: 0.0022324400354438566
Loss at iteration [1565]: 0.002232346053332515
Loss at iteration [1566]: 0.0022323267323964744
Loss at iteration [1567]: 0.0022323128078976856
Loss at iteration [1568]: 0.0022322759480015194
Loss at iteration [1569]: 0.002232247037520353
Loss at iteration [1570]: 0.002232198109865224
Loss at iteration [1571]: 0.0022321523386509444
Loss at iteration [1572]: 0.0022321316832476924
Loss at iteration [1573]: 0.002232090464897518
Loss at iteration [1574]: 0.002232042383180476
Loss at iteration [1575]: 0.0022318900964870226
Loss at iteration [1576]: 0.0022316865749575773
Loss at iteration [1577]: 0.0022315486954161464
Loss at iteration [1578]: 0.0022313910399336025
Loss at iteration [1579]: 0.0022311600342618198
Loss at iteration [1580]: 0.0022308532857170014
Loss at iteration [1581]: 0.0022308532857170014
Loss at iteration [1582]: 0.00223080381854086
Loss at iteration [1583]: 0.0022305614054669116
Loss at iteration [1584]: 0.0022304939264195783
Loss at iteration [1585]: 0.0022304531089316093
Loss at iteration [1586]: 0.0022302897379867805
Loss at iteration [1587]: 0.0022302672484303737
Loss at iteration [1588]: 0.002230180742430746
Loss at iteration [1589]: 0.0022301104864028785
Loss at iteration [1590]: 0.0022300656017075647
Loss at iteration [1591]: 0.0022299912342259036
Loss at iteration [1592]: 0.0022299471253745323
Loss at iteration [1593]: 0.002229900922149283
Loss at iteration [1594]: 0.0022298474065005364
Loss at iteration [1595]: 0.0022298130620132684
Loss at iteration [1596]: 0.002229795951681661
Loss at iteration [1597]: 0.002229764912783026
Loss at iteration [1598]: 0.002229764912783026
Loss at iteration [1599]: 0.0022297506850075233
Loss at iteration [1600]: 0.002229732400999579
Loss at iteration [1601]: 0.002229712534002483
Loss at iteration [1602]: 0.002229689867166631
Loss at iteration [1603]: 0.00222966308703189
Loss at iteration [1604]: 0.0022296380818935695
Loss at iteration [1605]: 0.0022296187221921377
Loss at iteration [1606]: 0.0022295938602552665
Loss at iteration [1607]: 0.002229542234139437
Loss at iteration [1608]: 0.0022294768335891896
Loss at iteration [1609]: 0.0022294176584119396
Loss at iteration [1610]: 0.002229302369753684
Loss at iteration [1611]: 0.002229199766353224
Loss at iteration [1612]: 0.002228916623436956
Loss at iteration [1613]: 0.002228760874118177
Loss at iteration [1614]: 0.0022286632930519396
Loss at iteration [1615]: 0.00222832974114268
Loss at iteration [1616]: 0.00222828381933331
Loss at iteration [1617]: 0.00222828381933331
Loss at iteration [1618]: 0.002228175889890429
Loss at iteration [1619]: 0.002228103349094458
Loss at iteration [1620]: 0.0022280574073337855
Loss at iteration [1621]: 0.0022280243901987014
Loss at iteration [1622]: 0.002227978160724958
Loss at iteration [1623]: 0.0022279592212550215
Loss at iteration [1624]: 0.002227906694323879
Loss at iteration [1625]: 0.00222787756526721
Loss at iteration [1626]: 0.0022278006763051124
Loss at iteration [1627]: 0.0022277475274414807
Loss at iteration [1628]: 0.002227713108291278
Loss at iteration [1629]: 0.00222766293355057
Loss at iteration [1630]: 0.0022275911179087163
Loss at iteration [1631]: 0.0022275451447721327
Loss at iteration [1632]: 0.0022275451447721327
Loss at iteration [1633]: 0.002227505560139263
Loss at iteration [1634]: 0.002227464981681486
Loss at iteration [1635]: 0.0022274376502266734
Loss at iteration [1636]: 0.002227401680720997
Loss at iteration [1637]: 0.002227365784441593
Loss at iteration [1638]: 0.002227291135767598
Loss at iteration [1639]: 0.0022272529928115577
Loss at iteration [1640]: 0.002227158529022023
Loss at iteration [1641]: 0.0022270596577141566
Loss at iteration [1642]: 0.002226952235957225
Loss at iteration [1643]: 0.002226808214353054
Loss at iteration [1644]: 0.0022266254091687374
Loss at iteration [1645]: 0.002226078003026173
Loss at iteration [1646]: 0.002225610835342226
Loss at iteration [1647]: 0.002225610835342226
Loss at iteration [1648]: 0.002225528534686124
Loss at iteration [1649]: 0.002225039451064835
Loss at iteration [1650]: 0.0022249647951957784
Loss at iteration [1651]: 0.002224920767616389
Loss at iteration [1652]: 0.002224678740784775
Loss at iteration [1653]: 0.0022245651469763
Loss at iteration [1654]: 0.0022245001221271026
Loss at iteration [1655]: 0.0022244101276858727
Loss at iteration [1656]: 0.002224330030970389
Loss at iteration [1657]: 0.002224263402681482
Loss at iteration [1658]: 0.002224201663079854
Loss at iteration [1659]: 0.002224201663079854
Loss at iteration [1660]: 0.0022241783660685408
Loss at iteration [1661]: 0.002224105618548177
Loss at iteration [1662]: 0.0022240811371388764
Loss at iteration [1663]: 0.002224000005806203
Loss at iteration [1664]: 0.002223978733009939
Loss at iteration [1665]: 0.0022239545391318366
Loss at iteration [1666]: 0.002223832007900315
Loss at iteration [1667]: 0.0022238010306708015
Loss at iteration [1668]: 0.002223736927503398
Loss at iteration [1669]: 0.002223604509254766
Loss at iteration [1670]: 0.002223516770754074
Loss at iteration [1671]: 0.002223185110065123
Loss at iteration [1672]: 0.002223145899929958
Loss at iteration [1673]: 0.002222933554984433
Loss at iteration [1674]: 0.002222933554984433
Loss at iteration [1675]: 0.0022228632447673486
Loss at iteration [1676]: 0.0022227325048350256
Loss at iteration [1677]: 0.0022226855578267395
Loss at iteration [1678]: 0.00222264392729384
Loss at iteration [1679]: 0.0022225299518938628
Loss at iteration [1680]: 0.0022224693221818484
Loss at iteration [1681]: 0.002222391271505881
Loss at iteration [1682]: 0.002222328968652043
Loss at iteration [1683]: 0.002222287692831785
Loss at iteration [1684]: 0.0022222421215629356
Loss at iteration [1685]: 0.002222188425807846
Loss at iteration [1686]: 0.0022221554777673144
Loss at iteration [1687]: 0.0022220937904834756
Loss at iteration [1688]: 0.002222092437580313
Loss at iteration [1689]: 0.002222092437580313
Loss at iteration [1690]: 0.002222063866369719
Loss at iteration [1691]: 0.0022220340241217275
Loss at iteration [1692]: 0.002222021130795373
Loss at iteration [1693]: 0.002222003373746012
Loss at iteration [1694]: 0.002221979489627489
Loss at iteration [1695]: 0.002221940253862995
Loss at iteration [1696]: 0.0022217812523020438
Loss at iteration [1697]: 0.00222165995366853
Loss at iteration [1698]: 0.0022215419356491966
Loss at iteration [1699]: 0.002221404722911715
Loss at iteration [1700]: 0.0022211905240343993
Loss at iteration [1701]: 0.0022209889435809704
Loss at iteration [1702]: 0.0022206007099163415
Loss at iteration [1703]: 0.0022204984032997872
Loss at iteration [1704]: 0.002220244688637058
Loss at iteration [1705]: 0.0022199936799103858
Loss at iteration [1706]: 0.0022198299883937627
Loss at iteration [1707]: 0.002219561354267328
Loss at iteration [1708]: 0.002219561354267328
Loss at iteration [1709]: 0.0022194531014968644
Loss at iteration [1710]: 0.0022194337625954107
Loss at iteration [1711]: 0.002219376400497708
Loss at iteration [1712]: 0.002219328852817874
Loss at iteration [1713]: 0.0022192831234522942
Loss at iteration [1714]: 0.0022191999323281104
Loss at iteration [1715]: 0.002219147355597892
Loss at iteration [1716]: 0.0022191094156963406
Loss at iteration [1717]: 0.0022190418498309423
Loss at iteration [1718]: 0.0022190182258901314
Loss at iteration [1719]: 0.0022189650237450266
Loss at iteration [1720]: 0.0022189362415069185
Loss at iteration [1721]: 0.0022188769712500516
Loss at iteration [1722]: 0.0022188276589813673
Loss at iteration [1723]: 0.0022188000887435663
Loss at iteration [1724]: 0.0022187269583644337
Loss at iteration [1725]: 0.0022187055778443822
Loss at iteration [1726]: 0.0022187055778443822
Loss at iteration [1727]: 0.002218689053019455
Loss at iteration [1728]: 0.0022186687966183755
Loss at iteration [1729]: 0.0022186505135157503
Loss at iteration [1730]: 0.0022186162506074325
Loss at iteration [1731]: 0.002218607981092263
Loss at iteration [1732]: 0.002218583454435482
Loss at iteration [1733]: 0.002218536972405857
Loss at iteration [1734]: 0.002218469825190426
Loss at iteration [1735]: 0.0022184094915654335
Loss at iteration [1736]: 0.002218243186331643
Loss at iteration [1737]: 0.002217854354937297
Loss at iteration [1738]: 0.002217723996832013
Loss at iteration [1739]: 0.0022173592813378184
Loss at iteration [1740]: 0.002216947363900226
Loss at iteration [1741]: 0.002216651366018609
Loss at iteration [1742]: 0.0022163659241835544
Loss at iteration [1743]: 0.002216121838804795
Loss at iteration [1744]: 0.002216121838804795
Loss at iteration [1745]: 0.002215929776438733
Loss at iteration [1746]: 0.002215885076036955
Loss at iteration [1747]: 0.002215762218110444
Loss at iteration [1748]: 0.0022156221574879406
Loss at iteration [1749]: 0.0022155601661114984
Loss at iteration [1750]: 0.0022153987558134053
Loss at iteration [1751]: 0.0022153330073771014
Loss at iteration [1752]: 0.0022153063669862723
Loss at iteration [1753]: 0.002215249974293314
Loss at iteration [1754]: 0.0022151817047451677
Loss at iteration [1755]: 0.0022151228364098454
Loss at iteration [1756]: 0.0022150762755347424
Loss at iteration [1757]: 0.002215031153552794
Loss at iteration [1758]: 0.0022149610101112067
Loss at iteration [1759]: 0.0022149610101112067
Loss at iteration [1760]: 0.002214941653910812
Loss at iteration [1761]: 0.0022149123137495215
Loss at iteration [1762]: 0.0022148946313532794
Loss at iteration [1763]: 0.0022148688735879082
Loss at iteration [1764]: 0.0022147828900839633
Loss at iteration [1765]: 0.0022147642475578004
Loss at iteration [1766]: 0.0022147303107499026
Loss at iteration [1767]: 0.0022147024314884125
Loss at iteration [1768]: 0.002214677418827407
Loss at iteration [1769]: 0.0022146431066876857
Loss at iteration [1770]: 0.002214576511614875
Loss at iteration [1771]: 0.002214507764146267
Loss at iteration [1772]: 0.002214386067812518
Loss at iteration [1773]: 0.0022143005550498756
Loss at iteration [1774]: 0.0022138949516660074
Loss at iteration [1775]: 0.0022133813519465023
Loss at iteration [1776]: 0.002212712637862208
Loss at iteration [1777]: 0.002212397631585257
Loss at iteration [1778]: 0.002212397631585257
Loss at iteration [1779]: 0.0022123154814252424
Loss at iteration [1780]: 0.0022117082538045075
Loss at iteration [1781]: 0.0022112292154877486
Loss at iteration [1782]: 0.0022111135105348117
Loss at iteration [1783]: 0.002210964492682136
Loss at iteration [1784]: 0.0022108890463060256
Loss at iteration [1785]: 0.0022108266321423545
Loss at iteration [1786]: 0.002210680731305899
Loss at iteration [1787]: 0.0022105793139726077
Loss at iteration [1788]: 0.0022105595804033204
Loss at iteration [1789]: 0.002210452601456131
Loss at iteration [1790]: 0.002210367451064857
Loss at iteration [1791]: 0.002210301441597247
Loss at iteration [1792]: 0.0022102209188737745
Loss at iteration [1793]: 0.0022101765593783135
Loss at iteration [1794]: 0.0022101765593783135
Loss at iteration [1795]: 0.0022101417972606656
Loss at iteration [1796]: 0.0022099793892014557
Loss at iteration [1797]: 0.0022099391384772134
Loss at iteration [1798]: 0.0022098957575378093
Loss at iteration [1799]: 0.00220985172755371
Loss at iteration [1800]: 0.002209836650165179
Loss at iteration [1801]: 0.0022097938590434213
Loss at iteration [1802]: 0.0022097647338625184
Loss at iteration [1803]: 0.002209753033170307
Loss at iteration [1804]: 0.0022097332590480024
Loss at iteration [1805]: 0.002209688848164009
Loss at iteration [1806]: 0.0022096376777510935
Loss at iteration [1807]: 0.0022095871510327534
Loss at iteration [1808]: 0.0022095659732813363
Loss at iteration [1809]: 0.0022095385172774995
Loss at iteration [1810]: 0.0022095385172774995
Loss at iteration [1811]: 0.0022095015916033375
Loss at iteration [1812]: 0.002209486662935642
Loss at iteration [1813]: 0.0022094764222303728
Loss at iteration [1814]: 0.0022094556725236417
Loss at iteration [1815]: 0.002209423129112168
Loss at iteration [1816]: 0.0022093848294033203
Loss at iteration [1817]: 0.002209309749510789
Loss at iteration [1818]: 0.002209208703778995
Loss at iteration [1819]: 0.002209124792599617
Loss at iteration [1820]: 0.002209012076436272
Loss at iteration [1821]: 0.0022088649575521604
Loss at iteration [1822]: 0.002208751994346896
Loss at iteration [1823]: 0.0022085448367139614
Loss at iteration [1824]: 0.00220842150929932
Loss at iteration [1825]: 0.0022079307951132195
Loss at iteration [1826]: 0.0022079307951132195
Loss at iteration [1827]: 0.0022078065532513775
Loss at iteration [1828]: 0.002207769491479309
Loss at iteration [1829]: 0.0022076056852283307
Loss at iteration [1830]: 0.0022075283018614176
Loss at iteration [1831]: 0.0022074337006128928
Loss at iteration [1832]: 0.0022073718003331995
Loss at iteration [1833]: 0.0022073504478302354
Loss at iteration [1834]: 0.0022073219286983586
Loss at iteration [1835]: 0.002207280734913611
Loss at iteration [1836]: 0.0022072378963996853
Loss at iteration [1837]: 0.00220716332940815
Loss at iteration [1838]: 0.0022071291713561436
Loss at iteration [1839]: 0.0022070728518571513
Loss at iteration [1840]: 0.0022070080971787914
Loss at iteration [1841]: 0.0022069806149051367
Loss at iteration [1842]: 0.002206948006180925
